{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E5pApGxJrJzZ"
   },
   "source": [
    "# **Invariant Information Clustering**\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lkv3CKoOOngo"
   },
   "source": [
    "# Setting up the Enviorement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mt7RbWX7rZB7"
   },
   "source": [
    "Clone the repository and set up the enviorement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "Fa-4QBvBDiGA",
    "outputId": "7b20fa4d-752c-4e67-d148-a49250737030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'code'...\n",
      "warning: --local is ignored\n",
      "remote: Enumerating objects: 463, done.\u001b[K\n",
      "remote: Total 463 (delta 0), reused 0 (delta 0), pack-reused 463\u001b[K\n",
      "Receiving objects: 100% (463/463), 55.67 MiB | 25.00 MiB/s, done.\n",
      "Resolving deltas: 100% (244/244), done.\n",
      "/content/code\n"
     ]
    }
   ],
   "source": [
    "!git clone -l -s https://github.com/nickpezzotti1/IIC-v0 code\n",
    "%cd code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yVr3s1ZQOMzB"
   },
   "source": [
    "Most required packages come preinstalled in Google Colab's Python 2 env. We only have to downgrade our pytorch and torchvision.\n",
    "\n",
    "Full list of packages and versions can be found [here](https://github.com/nickpezzotti1/IIC-v0/blob/master/package_versions.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "FLPTD7CdOPfD",
    "outputId": "3c80ec8e-c22a-48e2-af2f-2766d07b3083"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LiveandInspire\\AppData\\Roaming\\Python\\Python37\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 186, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"C:\\Users\\LiveandInspire\\AppData\\Roaming\\Python\\Python37\\site-packages\\pip\\_internal\\commands\\install.py\", line 258, in run\n",
      "    isolated_mode=options.isolated_mode,\n",
      "  File \"C:\\Users\\LiveandInspire\\AppData\\Roaming\\Python\\Python37\\site-packages\\pip\\_internal\\commands\\install.py\", line 604, in decide_user_install\n",
      "    if site_packages_writable(root=root_path, isolated=isolated_mode):\n",
      "  File \"C:\\Users\\LiveandInspire\\AppData\\Roaming\\Python\\Python37\\site-packages\\pip\\_internal\\commands\\install.py\", line 549, in site_packages_writable\n",
      "    test_writable_dir(d) for d in set(get_lib_location_guesses(**kwargs))\n",
      "  File \"C:\\Users\\LiveandInspire\\AppData\\Roaming\\Python\\Python37\\site-packages\\pip\\_internal\\commands\\install.py\", line 549, in <genexpr>\n",
      "    test_writable_dir(d) for d in set(get_lib_location_guesses(**kwargs))\n",
      "  File \"C:\\Users\\LiveandInspire\\AppData\\Roaming\\Python\\Python37\\site-packages\\pip\\_internal\\utils\\filesystem.py\", line 140, in test_writable_dir\n",
      "    return _test_writable_dir_win(path)\n",
      "  File \"C:\\Users\\LiveandInspire\\AppData\\Roaming\\Python\\Python37\\site-packages\\pip\\_internal\\utils\\filesystem.py\", line 153, in _test_writable_dir_win\n",
      "    fd = os.open(file, os.O_RDWR | os.O_CREAT | os.O_EXCL)\n",
      "PermissionError: [Errno 13] Permission denied: 'C:\\\\Program Files\\\\Python37\\\\Lib\\\\site-packages\\\\accesstest_deleteme_fishfingers_custard_42fxn1'\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install -q torch==0.4.1 torchvision==0.2.1 # We have to downgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xLk2d8Z8LFJN"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8de456607a6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import code.archs as archs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FU2nu4Q-OARF"
   },
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jfsmvlDIOVCI"
   },
   "source": [
    "## A) Train a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y4gMyf4iq_U8"
   },
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0 && python -m code.scripts.cluster.cluster_greyscale_twohead --out_root /content/out/adv --model_ind 687 --arch ClusterNet6cTwoHead --mode IID --dataset_root utils/cluster/MNIST.py --dataset MNIST-uniform-noise --gt_k 10 --output_k_A 10 --output_k_B 10 --lamb_A 1.0 --lamb_B 1.0 --lr 0.0001 --num_epochs 20 --batch_sz 700 --num_dataloaders 5 --num_sub_heads 5 --crop_orig --crop_other --tf1_crop centre_half --tf2_crop random --tf1_crop_sz 20 --tf2_crop_szs 16 20 24 --input_sz 24 --rot_val 25 --no_flip --head_B_epochs 2 --nu 2 --adv_path /content/pgd-adversarials.txt --adv_n 1300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J9g87u656cA7"
   },
   "source": [
    "## B) Load a pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FvTVsiiIfBRF"
   },
   "source": [
    "Upload your pickled model and config files. Change the path variables to import your own model. \n",
    "\n",
    "The following model and configs correspond to the pretrained MNIST model 685 trained by Xu Ji et al. at Oxford (2018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DCltjiWoe4pu"
   },
   "outputs": [],
   "source": [
    "config_path = \"/content/code/mnist_original/config.pickle\"\n",
    "net_path = \"/content/code/mnist_original/best_net.pytorch\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VyDdsEaxfaWj"
   },
   "source": [
    "Load the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UIu0H5CJyDNx"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "config_in = open(config_path, \"rb\")\n",
    "config = pickle.load(config_in)\n",
    "net = archs.__dict__[config.arch](config)\n",
    "net.load_state_dict(torch.load(net_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nBLp1rZ3fnis"
   },
   "source": [
    "The following code allows us to inspect some of the key features of our pretrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l_02ia0qfcw6"
   },
   "outputs": [],
   "source": [
    "config_dict = config.__dict__\n",
    "number_of_epochs = len(config_dict['epoch_acc'])\n",
    "mappings = {pair[0]: pair[1] for pair in config.__dict__['epoch_stats'][number_of_epochs - 1][\"best_train_sub_head_match\"]}\n",
    "inv_mappings = {pair[1]: pair[0] for pair in config.__dict__['epoch_stats'][number_of_epochs - 1][\"best_train_sub_head_match\"]}\n",
    "best_head = config.__dict__['epoch_stats'][number_of_epochs - 1][\"best_train_sub_head\"]\n",
    "\n",
    "print(\"Epochs\", number_of_epochs)\n",
    "print(\"Average\", config.__dict__['epoch_stats'][number_of_epochs - 1][\"avg\"])\n",
    "print(\"Best mapping\", config.__dict__['epoch_stats'][number_of_epochs - 1][\"best_train_sub_head_match\"])\n",
    "print(\"Best head\", config.__dict__['epoch_stats'][number_of_epochs - 1][\"best_train_sub_head\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0zDIJazLOhdT"
   },
   "source": [
    "# Using the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PN1dHLXKOsFM"
   },
   "source": [
    "Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e5rq916WGKRh"
   },
   "outputs": [],
   "source": [
    "dl = DataLoader(torchvision.datasets.MNIST(\n",
    "    '/data/mnist',\n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transforms.Compose([\n",
    "      transforms.ToTensor()\n",
    "      ])), \n",
    "    batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7qHEe1whOyEt"
   },
   "source": [
    "Visualise the predictions of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wW3Z0SVTw_Ra"
   },
   "outputs": [],
   "source": [
    "dataloader_iter = enumerate(dl)\n",
    "\n",
    "def display(iter, n):\n",
    "    f, axarr = plt.subplots(1, n, figsize=(20,20))\n",
    "\n",
    "    count = 0\n",
    "    for batch_index, batch in dataloader_iter:\n",
    "      for i in range(len(batch)):\n",
    "        if count >= n:\n",
    "          return\n",
    "        \n",
    "        image = batch[0][i]\n",
    "        prediction = mappings[torch.argmax(\n",
    "            net(image.reshape(1, 1, 28, 28))[best_head]).item()]\n",
    "        label = batch[1][i].item()\n",
    "\n",
    "        axarr[count].title.set_text(\"Pred \" + str(prediction) + \" for \" + \n",
    "                                    str(label))\n",
    "\n",
    "        axarr[count].imshow(image.reshape(28, 28))\n",
    "        count += 1\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "display(iter, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UOMQxBJDg-Ex"
   },
   "source": [
    "In order to calculate the accuracy of our model we must run over a mini-batch. Because of batch normalization (see. https://github.com/xu-ji/IIC/issues/49 )\n",
    "We have to test a batch at a time instead of testing one image at a time to observe max accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s3vG532iNXUB"
   },
   "outputs": [],
   "source": [
    "dataloader_iter = enumerate(dl)\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "for batch_index, batch in dataloader_iter:\n",
    "  if (batch_index == 1): break\n",
    "  softmax_predictions = net(batch[0])[best_head]\n",
    "  predictions = np.array([torch.argmax(softmax_prediction) for \n",
    "                          softmax_prediction in softmax_predictions])\n",
    "  labels = np.array([inv_mappings[label.item()] for label in batch[1]])\n",
    "\n",
    "  total += len(labels)\n",
    "  correct += np.sum(predictions == labels)\n",
    "\n",
    "\n",
    "print(\"Accuracy: \" + str(float(correct)/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2q-KJ49E0pnl"
   },
   "outputs": [],
   "source": [
    "f = open(\"/content/pgd-adversarials.txt\", \"rb\")\n",
    "      \n",
    "dataset = pickle.load(f)\n",
    "len(dataset)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of IIC - Training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
