Debug: False
Loading restarting config from: /scratch/shared/slow/xuji/iid_private/579/config.pickle
(_sobel_multioutput_make_transforms) config.include_rgb: False
not using cutout
not demeaning data
not per image demeaning data
Making datasets with <class 'torchvision.datasets.cifar.CIFAR100'> and <function _cifar100_to_cifar20 at 0x7fd818b87050>
Creating auxiliary dataloader ind 0 out of 5 time 2019-02-15 01:20:38.136073
Creating auxiliary dataloader ind 1 out of 5 time 2019-02-15 01:20:39.433040
Creating auxiliary dataloader ind 2 out of 5 time 2019-02-15 01:20:40.733070
Creating auxiliary dataloader ind 3 out of 5 time 2019-02-15 01:20:42.020456
Creating auxiliary dataloader ind 4 out of 5 time 2019-02-15 01:20:43.318709
Length of datasets vector 6
Number of batches per epoch: 300
Creating auxiliary dataloader ind 0 out of 5 time 2019-02-15 01:20:45.895187
Creating auxiliary dataloader ind 1 out of 5 time 2019-02-15 01:20:47.174835
Creating auxiliary dataloader ind 2 out of 5 time 2019-02-15 01:20:48.461562
Creating auxiliary dataloader ind 3 out of 5 time 2019-02-15 01:20:49.740749
Creating auxiliary dataloader ind 4 out of 5 time 2019-02-15 01:20:51.029932
Length of datasets vector 6
Number of batches per epoch: 300
avg_pool_sz 3
semisup: False
starting from epoch 921
Starting e_i: 921
Model ind 579 epoch 921 head B head_i_epoch 0 batch 0: avg loss -1.977632 avg loss no lamb -1.977632 time 2019-02-15 01:21:06.899628
Model ind 579 epoch 921 head B head_i_epoch 0 batch 1: avg loss -1.701615 avg loss no lamb -1.701615 time 2019-02-15 01:21:08.580450
Model ind 579 epoch 921 head B head_i_epoch 0 batch 2: avg loss -1.998923 avg loss no lamb -1.998923 time 2019-02-15 01:21:10.312279
Model ind 579 epoch 921 head B head_i_epoch 0 batch 3: avg loss -1.851820 avg loss no lamb -1.851820 time 2019-02-15 01:21:11.992318
Model ind 579 epoch 921 head B head_i_epoch 0 batch 4: avg loss -1.856868 avg loss no lamb -1.856868 time 2019-02-15 01:21:13.661578
Model ind 579 epoch 921 head B head_i_epoch 0 batch 5: avg loss -1.948768 avg loss no lamb -1.948768 time 2019-02-15 01:21:15.330644
Model ind 579 epoch 921 head B head_i_epoch 0 batch 6: avg loss -2.088297 avg loss no lamb -2.088297 time 2019-02-15 01:21:17.021075
Model ind 579 epoch 921 head B head_i_epoch 0 batch 7: avg loss -2.047546 avg loss no lamb -2.047546 time 2019-02-15 01:21:18.694346
Model ind 579 epoch 921 head B head_i_epoch 0 batch 8: avg loss -1.858242 avg loss no lamb -1.858242 time 2019-02-15 01:21:20.364288
Model ind 579 epoch 921 head B head_i_epoch 0 batch 9: avg loss -1.834207 avg loss no lamb -1.834207 time 2019-02-15 01:21:22.062871
Model ind 579 epoch 921 head B head_i_epoch 0 batch 100: avg loss -1.930550 avg loss no lamb -1.930550 time 2019-02-15 01:23:55.678132
Model ind 579 epoch 921 head B head_i_epoch 0 batch 200: avg loss -1.882018 avg loss no lamb -1.882018 time 2019-02-15 01:26:45.099510
Model ind 579 epoch 921 head A head_i_epoch 0 batch 0: avg loss -3.582583 avg loss no lamb -3.582583 time 2019-02-15 01:29:36.029655
Model ind 579 epoch 921 head A head_i_epoch 0 batch 1: avg loss -3.476614 avg loss no lamb -3.476614 time 2019-02-15 01:29:37.760910
Model ind 579 epoch 921 head A head_i_epoch 0 batch 2: avg loss -3.537500 avg loss no lamb -3.537500 time 2019-02-15 01:29:39.591299
Model ind 579 epoch 921 head A head_i_epoch 0 batch 3: avg loss -3.575473 avg loss no lamb -3.575473 time 2019-02-15 01:29:41.423641
Model ind 579 epoch 921 head A head_i_epoch 0 batch 4: avg loss -3.552786 avg loss no lamb -3.552786 time 2019-02-15 01:29:43.322667
Model ind 579 epoch 921 head A head_i_epoch 0 batch 5: avg loss -3.559234 avg loss no lamb -3.559234 time 2019-02-15 01:29:45.094323
Model ind 579 epoch 921 head A head_i_epoch 0 batch 6: avg loss -3.627615 avg loss no lamb -3.627615 time 2019-02-15 01:29:46.872240
Model ind 579 epoch 921 head A head_i_epoch 0 batch 7: avg loss -3.612681 avg loss no lamb -3.612681 time 2019-02-15 01:29:48.709706
Model ind 579 epoch 921 head A head_i_epoch 0 batch 8: avg loss -3.420109 avg loss no lamb -3.420109 time 2019-02-15 01:29:50.564531
Model ind 579 epoch 921 head A head_i_epoch 0 batch 9: avg loss -3.503546 avg loss no lamb -3.503546 time 2019-02-15 01:29:52.436202
Model ind 579 epoch 921 head A head_i_epoch 0 batch 100: avg loss -3.568697 avg loss no lamb -3.568697 time 2019-02-15 01:32:38.756458
Model ind 579 epoch 921 head A head_i_epoch 0 batch 200: avg loss -3.615835 avg loss no lamb -3.615835 time 2019-02-15 01:35:39.364837
Pre: time 2019-02-15 01:39:03.067642: 
 	std: 0.0042160745
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25426668, 0.254, 0.24355, 0.25401667, 0.25406668]
	train_accs: [0.25426668, 0.254, 0.24355, 0.25401667, 0.25406668]
	best_train_sub_head: 0
	worst: 0.24355
	avg: 0.25198
	best: 0.25426668

Starting e_i: 922
Model ind 579 epoch 922 head B head_i_epoch 0 batch 0: avg loss -1.979774 avg loss no lamb -1.979774 time 2019-02-15 01:39:07.331599
Model ind 579 epoch 922 head B head_i_epoch 0 batch 100: avg loss -1.873639 avg loss no lamb -1.873639 time 2019-02-15 01:42:06.346021
Model ind 579 epoch 922 head B head_i_epoch 0 batch 200: avg loss -1.899207 avg loss no lamb -1.899207 time 2019-02-15 01:45:00.581336
Model ind 579 epoch 922 head A head_i_epoch 0 batch 0: avg loss -3.548054 avg loss no lamb -3.548054 time 2019-02-15 01:47:54.034107
Model ind 579 epoch 922 head A head_i_epoch 0 batch 100: avg loss -3.552057 avg loss no lamb -3.552057 time 2019-02-15 01:50:51.437700
Model ind 579 epoch 922 head A head_i_epoch 0 batch 200: avg loss -3.598019 avg loss no lamb -3.598019 time 2019-02-15 01:53:48.168453
Pre: time 2019-02-15 01:57:10.900373: 
 	std: 0.0045285462
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.255, 0.25465, 0.24346666, 0.25483334, 0.25465]
	train_accs: [0.255, 0.25465, 0.24346666, 0.25483334, 0.25465]
	best_train_sub_head: 0
	worst: 0.24346666
	avg: 0.25252002
	best: 0.255

Starting e_i: 923
Model ind 579 epoch 923 head B head_i_epoch 0 batch 0: avg loss -1.985647 avg loss no lamb -1.985647 time 2019-02-15 01:57:14.790148
Model ind 579 epoch 923 head B head_i_epoch 0 batch 100: avg loss -1.927917 avg loss no lamb -1.927917 time 2019-02-15 02:00:12.673552
Model ind 579 epoch 923 head B head_i_epoch 0 batch 200: avg loss -1.933168 avg loss no lamb -1.933168 time 2019-02-15 02:03:10.037851
Model ind 579 epoch 923 head A head_i_epoch 0 batch 0: avg loss -3.499710 avg loss no lamb -3.499710 time 2019-02-15 02:06:08.516729
Model ind 579 epoch 923 head A head_i_epoch 0 batch 100: avg loss -3.620428 avg loss no lamb -3.620428 time 2019-02-15 02:09:06.376748
Model ind 579 epoch 923 head A head_i_epoch 0 batch 200: avg loss -3.609573 avg loss no lamb -3.609573 time 2019-02-15 02:12:05.396017
Pre: time 2019-02-15 02:15:30.173941: 
 	std: 0.0043148524
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25503334, 0.25456667, 0.2441, 0.25491667, 0.255]
	train_accs: [0.25503334, 0.25456667, 0.2441, 0.25491667, 0.255]
	best_train_sub_head: 0
	worst: 0.2441
	avg: 0.25272334
	best: 0.25503334

Starting e_i: 924
Model ind 579 epoch 924 head B head_i_epoch 0 batch 0: avg loss -1.906578 avg loss no lamb -1.906578 time 2019-02-15 02:15:34.482662
Model ind 579 epoch 924 head B head_i_epoch 0 batch 100: avg loss -1.903638 avg loss no lamb -1.903638 time 2019-02-15 02:18:35.168662
Model ind 579 epoch 924 head B head_i_epoch 0 batch 200: avg loss -1.965753 avg loss no lamb -1.965753 time 2019-02-15 02:21:34.685136
Model ind 579 epoch 924 head A head_i_epoch 0 batch 0: avg loss -3.578600 avg loss no lamb -3.578600 time 2019-02-15 02:24:35.925546
Model ind 579 epoch 924 head A head_i_epoch 0 batch 100: avg loss -3.560980 avg loss no lamb -3.560980 time 2019-02-15 02:27:32.062442
Model ind 579 epoch 924 head A head_i_epoch 0 batch 200: avg loss -3.605305 avg loss no lamb -3.605305 time 2019-02-15 02:30:29.526194
Pre: time 2019-02-15 02:33:51.619119: 
 	std: 0.004655403
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25351667, 0.25346667, 0.24161667, 0.253, 0.25298333]
	train_accs: [0.25351667, 0.25346667, 0.24161667, 0.253, 0.25298333]
	best_train_sub_head: 0
	worst: 0.24161667
	avg: 0.25091666
	best: 0.25351667

Starting e_i: 925
Model ind 579 epoch 925 head B head_i_epoch 0 batch 0: avg loss -1.841263 avg loss no lamb -1.841263 time 2019-02-15 02:33:55.746543
Model ind 579 epoch 925 head B head_i_epoch 0 batch 100: avg loss -1.946358 avg loss no lamb -1.946358 time 2019-02-15 02:36:52.023656
Model ind 579 epoch 925 head B head_i_epoch 0 batch 200: avg loss -1.942075 avg loss no lamb -1.942075 time 2019-02-15 02:39:48.855183
Model ind 579 epoch 925 head A head_i_epoch 0 batch 0: avg loss -3.539103 avg loss no lamb -3.539103 time 2019-02-15 02:42:46.790384
Model ind 579 epoch 925 head A head_i_epoch 0 batch 100: avg loss -3.605652 avg loss no lamb -3.605652 time 2019-02-15 02:45:42.887129
Model ind 579 epoch 925 head A head_i_epoch 0 batch 200: avg loss -3.585731 avg loss no lamb -3.585731 time 2019-02-15 02:48:38.443657
Pre: time 2019-02-15 02:51:58.498626: 
 	std: 0.0046236273
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25266665, 0.25283334, 0.24133334, 0.25305, 0.253]
	train_accs: [0.25266665, 0.25283334, 0.24133334, 0.25305, 0.253]
	best_train_sub_head: 3
	worst: 0.24133334
	avg: 0.25057667
	best: 0.25305

Starting e_i: 926
Model ind 579 epoch 926 head B head_i_epoch 0 batch 0: avg loss -1.958443 avg loss no lamb -1.958443 time 2019-02-15 02:52:02.645946
Model ind 579 epoch 926 head B head_i_epoch 0 batch 100: avg loss -1.930838 avg loss no lamb -1.930838 time 2019-02-15 02:54:59.758701
Model ind 579 epoch 926 head B head_i_epoch 0 batch 200: avg loss -1.854897 avg loss no lamb -1.854897 time 2019-02-15 02:57:57.031880
Model ind 579 epoch 926 head A head_i_epoch 0 batch 0: avg loss -3.508831 avg loss no lamb -3.508831 time 2019-02-15 03:00:51.304666
Model ind 579 epoch 926 head A head_i_epoch 0 batch 100: avg loss -3.635395 avg loss no lamb -3.635395 time 2019-02-15 03:03:47.459191
Model ind 579 epoch 926 head A head_i_epoch 0 batch 200: avg loss -3.598230 avg loss no lamb -3.598230 time 2019-02-15 03:06:43.261267
Pre: time 2019-02-15 03:10:02.977899: 
 	std: 0.0047605913
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25525, 0.2553, 0.24321666, 0.25496668, 0.25493333]
	train_accs: [0.25525, 0.2553, 0.24321666, 0.25496668, 0.25493333]
	best_train_sub_head: 1
	worst: 0.24321666
	avg: 0.25273332
	best: 0.2553

Starting e_i: 927
Model ind 579 epoch 927 head B head_i_epoch 0 batch 0: avg loss -1.950711 avg loss no lamb -1.950711 time 2019-02-15 03:10:06.941258
Model ind 579 epoch 927 head B head_i_epoch 0 batch 100: avg loss -1.957870 avg loss no lamb -1.957870 time 2019-02-15 03:13:02.042050
Model ind 579 epoch 927 head B head_i_epoch 0 batch 200: avg loss -1.949893 avg loss no lamb -1.949893 time 2019-02-15 03:15:57.067542
Model ind 579 epoch 927 head A head_i_epoch 0 batch 0: avg loss -3.572141 avg loss no lamb -3.572141 time 2019-02-15 03:18:50.731920
Model ind 579 epoch 927 head A head_i_epoch 0 batch 100: avg loss -3.580970 avg loss no lamb -3.580970 time 2019-02-15 03:21:46.402325
Model ind 579 epoch 927 head A head_i_epoch 0 batch 200: avg loss -3.550343 avg loss no lamb -3.550343 time 2019-02-15 03:24:41.265483
Pre: time 2019-02-15 03:28:00.275297: 
 	std: 0.0045497045
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25315, 0.25286666, 0.24168333, 0.25301668, 0.25318334]
	train_accs: [0.25315, 0.25286666, 0.24168333, 0.25301668, 0.25318334]
	best_train_sub_head: 4
	worst: 0.24168333
	avg: 0.25078002
	best: 0.25318334

Starting e_i: 928
Model ind 579 epoch 928 head B head_i_epoch 0 batch 0: avg loss -1.999233 avg loss no lamb -1.999233 time 2019-02-15 03:28:04.249204
Model ind 579 epoch 928 head B head_i_epoch 0 batch 100: avg loss -1.944803 avg loss no lamb -1.944803 time 2019-02-15 03:30:58.846860
Model ind 579 epoch 928 head B head_i_epoch 0 batch 200: avg loss -1.898264 avg loss no lamb -1.898264 time 2019-02-15 03:33:53.143170
Model ind 579 epoch 928 head A head_i_epoch 0 batch 0: avg loss -3.519806 avg loss no lamb -3.519806 time 2019-02-15 03:36:47.128205
Model ind 579 epoch 928 head A head_i_epoch 0 batch 100: avg loss -3.625827 avg loss no lamb -3.625827 time 2019-02-15 03:39:43.152361
Model ind 579 epoch 928 head A head_i_epoch 0 batch 200: avg loss -3.583287 avg loss no lamb -3.583287 time 2019-02-15 03:42:38.638897
Pre: time 2019-02-15 03:45:59.938714: 
 	std: 0.0047431258
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25498334, 0.25493333, 0.24311666, 0.25516668, 0.2548]
	train_accs: [0.25498334, 0.25493333, 0.24311666, 0.25516668, 0.2548]
	best_train_sub_head: 3
	worst: 0.24311666
	avg: 0.2526
	best: 0.25516668

Starting e_i: 929
Model ind 579 epoch 929 head B head_i_epoch 0 batch 0: avg loss -1.984747 avg loss no lamb -1.984747 time 2019-02-15 03:46:03.687753
Model ind 579 epoch 929 head B head_i_epoch 0 batch 100: avg loss -1.909841 avg loss no lamb -1.909841 time 2019-02-15 03:48:58.242004
Model ind 579 epoch 929 head B head_i_epoch 0 batch 200: avg loss -1.949420 avg loss no lamb -1.949420 time 2019-02-15 03:51:52.934051
Model ind 579 epoch 929 head A head_i_epoch 0 batch 0: avg loss -3.583906 avg loss no lamb -3.583906 time 2019-02-15 03:54:47.737837
Model ind 579 epoch 929 head A head_i_epoch 0 batch 100: avg loss -3.537915 avg loss no lamb -3.537915 time 2019-02-15 03:57:42.421421
Model ind 579 epoch 929 head A head_i_epoch 0 batch 200: avg loss -3.631311 avg loss no lamb -3.631311 time 2019-02-15 04:00:37.501598
Pre: time 2019-02-15 04:03:58.308254: 
 	std: 0.004790092
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 13), (4, 4), (5, 3), (6, 18), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25496668, 0.25478333, 0.2429, 0.25505, 0.25468335]
	train_accs: [0.25496668, 0.25478333, 0.2429, 0.25505, 0.25468335]
	best_train_sub_head: 3
	worst: 0.2429
	avg: 0.25247666
	best: 0.25505

Starting e_i: 930
Model ind 579 epoch 930 head B head_i_epoch 0 batch 0: avg loss -1.956479 avg loss no lamb -1.956479 time 2019-02-15 04:04:02.263694
Model ind 579 epoch 930 head B head_i_epoch 0 batch 100: avg loss -1.821499 avg loss no lamb -1.821499 time 2019-02-15 04:06:57.018101
Model ind 579 epoch 930 head B head_i_epoch 0 batch 200: avg loss -1.928087 avg loss no lamb -1.928087 time 2019-02-15 04:09:51.665956
Model ind 579 epoch 930 head A head_i_epoch 0 batch 0: avg loss -3.554913 avg loss no lamb -3.554913 time 2019-02-15 04:12:48.425932
Model ind 579 epoch 930 head A head_i_epoch 0 batch 100: avg loss -3.662864 avg loss no lamb -3.662864 time 2019-02-15 04:15:44.853660
Model ind 579 epoch 930 head A head_i_epoch 0 batch 200: avg loss -3.652454 avg loss no lamb -3.652454 time 2019-02-15 04:18:41.021320
Pre: time 2019-02-15 04:22:01.190773: 
 	std: 0.0043767435
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25421667, 0.25456667, 0.24365, 0.2551, 0.25438333]
	train_accs: [0.25421667, 0.25456667, 0.24365, 0.2551, 0.25438333]
	best_train_sub_head: 3
	worst: 0.24365
	avg: 0.25238332
	best: 0.2551

Starting e_i: 931
Model ind 579 epoch 931 head B head_i_epoch 0 batch 0: avg loss -1.894881 avg loss no lamb -1.894881 time 2019-02-15 04:22:08.690650
Model ind 579 epoch 931 head B head_i_epoch 0 batch 100: avg loss -1.918482 avg loss no lamb -1.918482 time 2019-02-15 04:25:03.158952
Model ind 579 epoch 931 head B head_i_epoch 0 batch 200: avg loss -1.777381 avg loss no lamb -1.777381 time 2019-02-15 04:27:59.262799
Model ind 579 epoch 931 head A head_i_epoch 0 batch 0: avg loss -3.632814 avg loss no lamb -3.632814 time 2019-02-15 04:30:53.422127
Model ind 579 epoch 931 head A head_i_epoch 0 batch 100: avg loss -3.596865 avg loss no lamb -3.596865 time 2019-02-15 04:33:48.958880
Model ind 579 epoch 931 head A head_i_epoch 0 batch 200: avg loss -3.598888 avg loss no lamb -3.598888 time 2019-02-15 04:36:43.921924
Pre: time 2019-02-15 04:40:02.791100: 
 	std: 0.004620485
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25693333, 0.257, 0.24563333, 0.2574, 0.25736666]
	train_accs: [0.25693333, 0.257, 0.24563333, 0.2574, 0.25736666]
	best_train_sub_head: 3
	worst: 0.24563333
	avg: 0.25486666
	best: 0.2574

Starting e_i: 932
Model ind 579 epoch 932 head B head_i_epoch 0 batch 0: avg loss -1.961418 avg loss no lamb -1.961418 time 2019-02-15 04:40:11.132137
Model ind 579 epoch 932 head B head_i_epoch 0 batch 100: avg loss -2.030599 avg loss no lamb -2.030599 time 2019-02-15 04:43:04.249623
Model ind 579 epoch 932 head B head_i_epoch 0 batch 200: avg loss -1.874416 avg loss no lamb -1.874416 time 2019-02-15 04:45:56.823458
Model ind 579 epoch 932 head A head_i_epoch 0 batch 0: avg loss -3.538340 avg loss no lamb -3.538340 time 2019-02-15 04:48:50.398294
Model ind 579 epoch 932 head A head_i_epoch 0 batch 100: avg loss -3.650635 avg loss no lamb -3.650635 time 2019-02-15 04:51:45.538294
Model ind 579 epoch 932 head A head_i_epoch 0 batch 200: avg loss -3.657607 avg loss no lamb -3.657607 time 2019-02-15 04:54:40.656632
Pre: time 2019-02-15 04:58:03.431667: 
 	std: 0.0042456556
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25203332, 0.252, 0.24153334, 0.2524, 0.25213334]
	train_accs: [0.25203332, 0.252, 0.24153334, 0.2524, 0.25213334]
	best_train_sub_head: 3
	worst: 0.24153334
	avg: 0.25002
	best: 0.2524

Starting e_i: 933
Model ind 579 epoch 933 head B head_i_epoch 0 batch 0: avg loss -1.999009 avg loss no lamb -1.999009 time 2019-02-15 04:58:07.288354
Model ind 579 epoch 933 head B head_i_epoch 0 batch 100: avg loss -1.996685 avg loss no lamb -1.996685 time 2019-02-15 05:01:03.266162
Model ind 579 epoch 933 head B head_i_epoch 0 batch 200: avg loss -1.973276 avg loss no lamb -1.973276 time 2019-02-15 05:03:58.237418
Model ind 579 epoch 933 head A head_i_epoch 0 batch 0: avg loss -3.559635 avg loss no lamb -3.559635 time 2019-02-15 05:06:51.465912
Model ind 579 epoch 933 head A head_i_epoch 0 batch 100: avg loss -3.624356 avg loss no lamb -3.624356 time 2019-02-15 05:09:46.117404
Model ind 579 epoch 933 head A head_i_epoch 0 batch 200: avg loss -3.636055 avg loss no lamb -3.636055 time 2019-02-15 05:12:41.781870
Pre: time 2019-02-15 05:16:00.874581: 
 	std: 0.0043147127
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25451666, 0.2547, 0.2438, 0.2547, 0.25441667]
	train_accs: [0.25451666, 0.2547, 0.2438, 0.2547, 0.25441667]
	best_train_sub_head: 1
	worst: 0.2438
	avg: 0.25242668
	best: 0.2547

Starting e_i: 934
Model ind 579 epoch 934 head B head_i_epoch 0 batch 0: avg loss -2.009176 avg loss no lamb -2.009176 time 2019-02-15 05:16:04.695098
Model ind 579 epoch 934 head B head_i_epoch 0 batch 100: avg loss -1.910513 avg loss no lamb -1.910513 time 2019-02-15 05:18:57.725628
Model ind 579 epoch 934 head B head_i_epoch 0 batch 200: avg loss -1.897751 avg loss no lamb -1.897751 time 2019-02-15 05:21:51.816153
Model ind 579 epoch 934 head A head_i_epoch 0 batch 0: avg loss -3.542111 avg loss no lamb -3.542111 time 2019-02-15 05:24:45.845797
Model ind 579 epoch 934 head A head_i_epoch 0 batch 100: avg loss -3.604274 avg loss no lamb -3.604274 time 2019-02-15 05:27:40.242935
Model ind 579 epoch 934 head A head_i_epoch 0 batch 200: avg loss -3.612635 avg loss no lamb -3.612635 time 2019-02-15 05:30:35.237411
Pre: time 2019-02-15 05:33:53.700881: 
 	std: 0.004350741
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25391668, 0.25333333, 0.24271667, 0.25355, 0.25353333]
	train_accs: [0.25391668, 0.25333333, 0.24271667, 0.25355, 0.25353333]
	best_train_sub_head: 0
	worst: 0.24271667
	avg: 0.25141
	best: 0.25391668

Starting e_i: 935
Model ind 579 epoch 935 head B head_i_epoch 0 batch 0: avg loss -1.995372 avg loss no lamb -1.995372 time 2019-02-15 05:33:57.734031
Model ind 579 epoch 935 head B head_i_epoch 0 batch 100: avg loss -1.972371 avg loss no lamb -1.972371 time 2019-02-15 05:36:50.871946
Model ind 579 epoch 935 head B head_i_epoch 0 batch 200: avg loss -1.971003 avg loss no lamb -1.971003 time 2019-02-15 05:39:45.528376
Model ind 579 epoch 935 head A head_i_epoch 0 batch 0: avg loss -3.549836 avg loss no lamb -3.549836 time 2019-02-15 05:42:39.310753
Model ind 579 epoch 935 head A head_i_epoch 0 batch 100: avg loss -3.674174 avg loss no lamb -3.674174 time 2019-02-15 05:45:34.614755
Model ind 579 epoch 935 head A head_i_epoch 0 batch 200: avg loss -3.583045 avg loss no lamb -3.583045 time 2019-02-15 05:48:30.158669
Pre: time 2019-02-15 05:51:48.905335: 
 	std: 0.0045621344
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25433335, 0.25396666, 0.24283333, 0.25435, 0.25428334]
	train_accs: [0.25433335, 0.25396666, 0.24283333, 0.25435, 0.25428334]
	best_train_sub_head: 3
	worst: 0.24283333
	avg: 0.25195333
	best: 0.25435

Starting e_i: 936
Model ind 579 epoch 936 head B head_i_epoch 0 batch 0: avg loss -1.966775 avg loss no lamb -1.966775 time 2019-02-15 05:51:52.894790
Model ind 579 epoch 936 head B head_i_epoch 0 batch 100: avg loss -1.904318 avg loss no lamb -1.904318 time 2019-02-15 05:54:47.089027
Model ind 579 epoch 936 head B head_i_epoch 0 batch 200: avg loss -1.962984 avg loss no lamb -1.962984 time 2019-02-15 05:57:40.778687
Model ind 579 epoch 936 head A head_i_epoch 0 batch 0: avg loss -3.524710 avg loss no lamb -3.524710 time 2019-02-15 06:00:34.351953
Model ind 579 epoch 936 head A head_i_epoch 0 batch 100: avg loss -3.588773 avg loss no lamb -3.588773 time 2019-02-15 06:03:28.918749
Model ind 579 epoch 936 head A head_i_epoch 0 batch 200: avg loss -3.626322 avg loss no lamb -3.626322 time 2019-02-15 06:06:25.543644
Pre: time 2019-02-15 06:09:44.325502: 
 	std: 0.004552348
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25333333, 0.25306666, 0.24195, 0.25338334, 0.25351667]
	train_accs: [0.25333333, 0.25306666, 0.24195, 0.25338334, 0.25351667]
	best_train_sub_head: 4
	worst: 0.24195
	avg: 0.25105
	best: 0.25351667

Starting e_i: 937
Model ind 579 epoch 937 head B head_i_epoch 0 batch 0: avg loss -1.966292 avg loss no lamb -1.966292 time 2019-02-15 06:09:48.239646
Model ind 579 epoch 937 head B head_i_epoch 0 batch 100: avg loss -1.924300 avg loss no lamb -1.924300 time 2019-02-15 06:12:41.547467
Model ind 579 epoch 937 head B head_i_epoch 0 batch 200: avg loss -1.937480 avg loss no lamb -1.937480 time 2019-02-15 06:15:35.070023
Model ind 579 epoch 937 head A head_i_epoch 0 batch 0: avg loss -3.571486 avg loss no lamb -3.571486 time 2019-02-15 06:18:28.043934
Model ind 579 epoch 937 head A head_i_epoch 0 batch 100: avg loss -3.586021 avg loss no lamb -3.586021 time 2019-02-15 06:21:23.255693
Model ind 579 epoch 937 head A head_i_epoch 0 batch 200: avg loss -3.602832 avg loss no lamb -3.602832 time 2019-02-15 06:24:17.710693
Pre: time 2019-02-15 06:27:35.724930: 
 	std: 0.004811219
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2551, 0.2553, 0.24345, 0.25576666, 0.25568333]
	train_accs: [0.2551, 0.2553, 0.24345, 0.25576666, 0.25568333]
	best_train_sub_head: 3
	worst: 0.24345
	avg: 0.25305998
	best: 0.25576666

Starting e_i: 938
Model ind 579 epoch 938 head B head_i_epoch 0 batch 0: avg loss -1.927482 avg loss no lamb -1.927482 time 2019-02-15 06:27:39.536076
Model ind 579 epoch 938 head B head_i_epoch 0 batch 100: avg loss -1.976133 avg loss no lamb -1.976133 time 2019-02-15 06:30:34.394768
Model ind 579 epoch 938 head B head_i_epoch 0 batch 200: avg loss -1.980117 avg loss no lamb -1.980117 time 2019-02-15 06:33:28.314394
Model ind 579 epoch 938 head A head_i_epoch 0 batch 0: avg loss -3.650274 avg loss no lamb -3.650274 time 2019-02-15 06:36:22.023660
Model ind 579 epoch 938 head A head_i_epoch 0 batch 100: avg loss -3.639846 avg loss no lamb -3.639846 time 2019-02-15 06:39:17.221450
Model ind 579 epoch 938 head A head_i_epoch 0 batch 200: avg loss -3.622300 avg loss no lamb -3.622300 time 2019-02-15 06:42:12.541394
Pre: time 2019-02-15 06:45:32.447301: 
 	std: 0.0049484298
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25461668, 0.25476667, 0.2423, 0.25483334, 0.25445]
	train_accs: [0.25461668, 0.25476667, 0.2423, 0.25483334, 0.25445]
	best_train_sub_head: 3
	worst: 0.2423
	avg: 0.25219333
	best: 0.25483334

Starting e_i: 939
Model ind 579 epoch 939 head B head_i_epoch 0 batch 0: avg loss -1.946027 avg loss no lamb -1.946027 time 2019-02-15 06:45:36.182981
Model ind 579 epoch 939 head B head_i_epoch 0 batch 100: avg loss -1.927037 avg loss no lamb -1.927037 time 2019-02-15 06:48:30.509325
Model ind 579 epoch 939 head B head_i_epoch 0 batch 200: avg loss -1.986021 avg loss no lamb -1.986021 time 2019-02-15 06:51:24.706345
Model ind 579 epoch 939 head A head_i_epoch 0 batch 0: avg loss -3.601498 avg loss no lamb -3.601498 time 2019-02-15 06:54:17.986614
Model ind 579 epoch 939 head A head_i_epoch 0 batch 100: avg loss -3.578348 avg loss no lamb -3.578348 time 2019-02-15 06:57:13.037857
Model ind 579 epoch 939 head A head_i_epoch 0 batch 200: avg loss -3.612999 avg loss no lamb -3.612999 time 2019-02-15 07:00:08.040278
Pre: time 2019-02-15 07:03:26.673620: 
 	std: 0.0045394427
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25408334, 0.25381666, 0.24263333, 0.25393334, 0.25408334]
	train_accs: [0.25408334, 0.25381666, 0.24263333, 0.25393334, 0.25408334]
	best_train_sub_head: 0
	worst: 0.24263333
	avg: 0.25171
	best: 0.25408334

Starting e_i: 940
Model ind 579 epoch 940 head B head_i_epoch 0 batch 0: avg loss -1.929928 avg loss no lamb -1.929928 time 2019-02-15 07:03:30.463600
Model ind 579 epoch 940 head B head_i_epoch 0 batch 100: avg loss -1.944509 avg loss no lamb -1.944509 time 2019-02-15 07:06:24.631506
Model ind 579 epoch 940 head B head_i_epoch 0 batch 200: avg loss -1.923118 avg loss no lamb -1.923118 time 2019-02-15 07:09:18.621254
Model ind 579 epoch 940 head A head_i_epoch 0 batch 0: avg loss -3.631915 avg loss no lamb -3.631915 time 2019-02-15 07:12:13.747379
Model ind 579 epoch 940 head A head_i_epoch 0 batch 100: avg loss -3.610176 avg loss no lamb -3.610176 time 2019-02-15 07:15:09.922440
Model ind 579 epoch 940 head A head_i_epoch 0 batch 200: avg loss -3.557050 avg loss no lamb -3.557050 time 2019-02-15 07:18:05.907757
Pre: time 2019-02-15 07:21:25.247131: 
 	std: 0.004524863
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25518334, 0.25485, 0.24365, 0.2549, 0.2549]
	train_accs: [0.25518334, 0.25485, 0.24365, 0.2549, 0.2549]
	best_train_sub_head: 0
	worst: 0.24365
	avg: 0.2526967
	best: 0.25518334

Starting e_i: 941
Model ind 579 epoch 941 head B head_i_epoch 0 batch 0: avg loss -1.929661 avg loss no lamb -1.929661 time 2019-02-15 07:21:32.419355
Model ind 579 epoch 941 head B head_i_epoch 0 batch 100: avg loss -1.918470 avg loss no lamb -1.918470 time 2019-02-15 07:24:26.828357
Model ind 579 epoch 941 head B head_i_epoch 0 batch 200: avg loss -1.900658 avg loss no lamb -1.900658 time 2019-02-15 07:27:20.437347
Model ind 579 epoch 941 head A head_i_epoch 0 batch 0: avg loss -3.611536 avg loss no lamb -3.611536 time 2019-02-15 07:30:13.915098
Model ind 579 epoch 941 head A head_i_epoch 0 batch 100: avg loss -3.551126 avg loss no lamb -3.551126 time 2019-02-15 07:33:09.283041
Model ind 579 epoch 941 head A head_i_epoch 0 batch 200: avg loss -3.581081 avg loss no lamb -3.581081 time 2019-02-15 07:36:04.124094
Pre: time 2019-02-15 07:39:23.275969: 
 	std: 0.004454392
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25736666, 0.25701666, 0.246, 0.2573, 0.25681666]
	train_accs: [0.25736666, 0.25701666, 0.246, 0.2573, 0.25681666]
	best_train_sub_head: 0
	worst: 0.246
	avg: 0.25489998
	best: 0.25736666

Starting e_i: 942
Model ind 579 epoch 942 head B head_i_epoch 0 batch 0: avg loss -1.955070 avg loss no lamb -1.955070 time 2019-02-15 07:39:27.199033
Model ind 579 epoch 942 head B head_i_epoch 0 batch 100: avg loss -2.013000 avg loss no lamb -2.013000 time 2019-02-15 07:42:21.204948
Model ind 579 epoch 942 head B head_i_epoch 0 batch 200: avg loss -1.936921 avg loss no lamb -1.936921 time 2019-02-15 07:45:15.187411
Model ind 579 epoch 942 head A head_i_epoch 0 batch 0: avg loss -3.558891 avg loss no lamb -3.558891 time 2019-02-15 07:48:09.891020
Model ind 579 epoch 942 head A head_i_epoch 0 batch 100: avg loss -3.589421 avg loss no lamb -3.589421 time 2019-02-15 07:51:05.530242
Model ind 579 epoch 942 head A head_i_epoch 0 batch 200: avg loss -3.553061 avg loss no lamb -3.553061 time 2019-02-15 07:54:00.179099
Pre: time 2019-02-15 07:57:19.259693: 
 	std: 0.0042970213
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25486666, 0.25468335, 0.24418333, 0.25523335, 0.25488332]
	train_accs: [0.25486666, 0.25468335, 0.24418333, 0.25523335, 0.25488332]
	best_train_sub_head: 3
	worst: 0.24418333
	avg: 0.25277
	best: 0.25523335

Starting e_i: 943
Model ind 579 epoch 943 head B head_i_epoch 0 batch 0: avg loss -1.977904 avg loss no lamb -1.977904 time 2019-02-15 07:57:23.425179
Model ind 579 epoch 943 head B head_i_epoch 0 batch 100: avg loss -1.981602 avg loss no lamb -1.981602 time 2019-02-15 08:00:18.792348
Model ind 579 epoch 943 head B head_i_epoch 0 batch 200: avg loss -1.968791 avg loss no lamb -1.968791 time 2019-02-15 08:03:14.050608
Model ind 579 epoch 943 head A head_i_epoch 0 batch 0: avg loss -3.596945 avg loss no lamb -3.596945 time 2019-02-15 08:06:08.525225
Model ind 579 epoch 943 head A head_i_epoch 0 batch 100: avg loss -3.640887 avg loss no lamb -3.640887 time 2019-02-15 08:09:04.447432
Model ind 579 epoch 943 head A head_i_epoch 0 batch 200: avg loss -3.592695 avg loss no lamb -3.592695 time 2019-02-15 08:11:59.856962
Pre: time 2019-02-15 08:15:18.892931: 
 	std: 0.004395029
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25593334, 0.25533333, 0.2446, 0.25563332, 0.2554]
	train_accs: [0.25593334, 0.25533333, 0.2446, 0.25563332, 0.2554]
	best_train_sub_head: 0
	worst: 0.2446
	avg: 0.25338
	best: 0.25593334

Starting e_i: 944
Model ind 579 epoch 944 head B head_i_epoch 0 batch 0: avg loss -1.979776 avg loss no lamb -1.979776 time 2019-02-15 08:15:22.772963
Model ind 579 epoch 944 head B head_i_epoch 0 batch 100: avg loss -1.971027 avg loss no lamb -1.971027 time 2019-02-15 08:18:16.983366
Model ind 579 epoch 944 head B head_i_epoch 0 batch 200: avg loss -2.016075 avg loss no lamb -2.016075 time 2019-02-15 08:21:10.286217
Model ind 579 epoch 944 head A head_i_epoch 0 batch 0: avg loss -3.600710 avg loss no lamb -3.600710 time 2019-02-15 08:24:04.019848
Model ind 579 epoch 944 head A head_i_epoch 0 batch 100: avg loss -3.587624 avg loss no lamb -3.587624 time 2019-02-15 08:26:58.989375
Model ind 579 epoch 944 head A head_i_epoch 0 batch 200: avg loss -3.687722 avg loss no lamb -3.687722 time 2019-02-15 08:29:54.304661
Pre: time 2019-02-15 08:33:14.348066: 
 	std: 0.004509091
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25231665, 0.25233334, 0.24113333, 0.25241667, 0.25255]
	train_accs: [0.25231665, 0.25233334, 0.24113333, 0.25241667, 0.25255]
	best_train_sub_head: 4
	worst: 0.24113333
	avg: 0.25015002
	best: 0.25255

Starting e_i: 945
Model ind 579 epoch 945 head B head_i_epoch 0 batch 0: avg loss -1.960527 avg loss no lamb -1.960527 time 2019-02-15 08:33:18.343944
Model ind 579 epoch 945 head B head_i_epoch 0 batch 100: avg loss -2.019948 avg loss no lamb -2.019948 time 2019-02-15 08:36:13.640835
Model ind 579 epoch 945 head B head_i_epoch 0 batch 200: avg loss -1.829550 avg loss no lamb -1.829550 time 2019-02-15 08:39:09.049974
Model ind 579 epoch 945 head A head_i_epoch 0 batch 0: avg loss -3.583372 avg loss no lamb -3.583372 time 2019-02-15 08:42:04.580775
Model ind 579 epoch 945 head A head_i_epoch 0 batch 100: avg loss -3.645274 avg loss no lamb -3.645274 time 2019-02-15 08:45:01.296500
Model ind 579 epoch 945 head A head_i_epoch 0 batch 200: avg loss -3.628335 avg loss no lamb -3.628335 time 2019-02-15 08:47:58.012181
Pre: time 2019-02-15 08:51:19.063467: 
 	std: 0.004679071
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25473332, 0.2548, 0.24313334, 0.2548, 0.25498334]
	train_accs: [0.25473332, 0.2548, 0.24313334, 0.2548, 0.25498334]
	best_train_sub_head: 4
	worst: 0.24313334
	avg: 0.25248998
	best: 0.25498334

Starting e_i: 946
Model ind 579 epoch 946 head B head_i_epoch 0 batch 0: avg loss -1.968661 avg loss no lamb -1.968661 time 2019-02-15 08:51:23.090396
Model ind 579 epoch 946 head B head_i_epoch 0 batch 100: avg loss -1.962523 avg loss no lamb -1.962523 time 2019-02-15 08:54:17.661966
Model ind 579 epoch 946 head B head_i_epoch 0 batch 200: avg loss -1.931848 avg loss no lamb -1.931848 time 2019-02-15 08:57:11.646326
Model ind 579 epoch 946 head A head_i_epoch 0 batch 0: avg loss -3.587495 avg loss no lamb -3.587495 time 2019-02-15 09:00:05.769877
Model ind 579 epoch 946 head A head_i_epoch 0 batch 100: avg loss -3.624153 avg loss no lamb -3.624153 time 2019-02-15 09:03:03.402427
Model ind 579 epoch 946 head A head_i_epoch 0 batch 200: avg loss -3.573414 avg loss no lamb -3.573414 time 2019-02-15 09:05:58.214445
Pre: time 2019-02-15 09:09:17.462448: 
 	std: 0.004710681
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2537, 0.25416666, 0.24225, 0.25435, 0.25383332]
	train_accs: [0.2537, 0.25416666, 0.24225, 0.25435, 0.25383332]
	best_train_sub_head: 3
	worst: 0.24225
	avg: 0.25165996
	best: 0.25435

Starting e_i: 947
Model ind 579 epoch 947 head B head_i_epoch 0 batch 0: avg loss -1.952612 avg loss no lamb -1.952612 time 2019-02-15 09:09:21.348632
Model ind 579 epoch 947 head B head_i_epoch 0 batch 100: avg loss -1.962858 avg loss no lamb -1.962858 time 2019-02-15 09:12:15.854969
Model ind 579 epoch 947 head B head_i_epoch 0 batch 200: avg loss -1.966948 avg loss no lamb -1.966948 time 2019-02-15 09:15:10.031614
Model ind 579 epoch 947 head A head_i_epoch 0 batch 0: avg loss -3.497314 avg loss no lamb -3.497314 time 2019-02-15 09:18:04.392047
Model ind 579 epoch 947 head A head_i_epoch 0 batch 100: avg loss -3.615045 avg loss no lamb -3.615045 time 2019-02-15 09:21:00.584031
Model ind 579 epoch 947 head A head_i_epoch 0 batch 200: avg loss -3.592332 avg loss no lamb -3.592332 time 2019-02-15 09:23:55.422436
Pre: time 2019-02-15 09:27:14.331327: 
 	std: 0.0041182316
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25265, 0.25273332, 0.24251667, 0.25318334, 0.25263333]
	train_accs: [0.25265, 0.25273332, 0.24251667, 0.25318334, 0.25263333]
	best_train_sub_head: 3
	worst: 0.24251667
	avg: 0.25074333
	best: 0.25318334

Starting e_i: 948
Model ind 579 epoch 948 head B head_i_epoch 0 batch 0: avg loss -1.977373 avg loss no lamb -1.977373 time 2019-02-15 09:27:18.228662
Model ind 579 epoch 948 head B head_i_epoch 0 batch 100: avg loss -2.040821 avg loss no lamb -2.040821 time 2019-02-15 09:30:12.649795
Model ind 579 epoch 948 head B head_i_epoch 0 batch 200: avg loss -1.876609 avg loss no lamb -1.876609 time 2019-02-15 09:33:07.279308
Model ind 579 epoch 948 head A head_i_epoch 0 batch 0: avg loss -3.586364 avg loss no lamb -3.586364 time 2019-02-15 09:36:01.407473
Model ind 579 epoch 948 head A head_i_epoch 0 batch 100: avg loss -3.602056 avg loss no lamb -3.602056 time 2019-02-15 09:38:55.342726
Model ind 579 epoch 948 head A head_i_epoch 0 batch 200: avg loss -3.563487 avg loss no lamb -3.563487 time 2019-02-15 09:41:53.514922
Pre: time 2019-02-15 09:45:12.743001: 
 	std: 0.004878631
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25556666, 0.25551668, 0.24346666, 0.25601667, 0.25551668]
	train_accs: [0.25556666, 0.25551668, 0.24346666, 0.25601667, 0.25551668]
	best_train_sub_head: 3
	worst: 0.24346666
	avg: 0.25321668
	best: 0.25601667

Starting e_i: 949
Model ind 579 epoch 949 head B head_i_epoch 0 batch 0: avg loss -1.967740 avg loss no lamb -1.967740 time 2019-02-15 09:45:16.576424
Model ind 579 epoch 949 head B head_i_epoch 0 batch 100: avg loss -2.046289 avg loss no lamb -2.046289 time 2019-02-15 09:48:09.625424
Model ind 579 epoch 949 head B head_i_epoch 0 batch 200: avg loss -1.976101 avg loss no lamb -1.976101 time 2019-02-15 09:51:04.840707
Model ind 579 epoch 949 head A head_i_epoch 0 batch 0: avg loss -3.538872 avg loss no lamb -3.538872 time 2019-02-15 09:53:59.056039
Model ind 579 epoch 949 head A head_i_epoch 0 batch 100: avg loss -3.572255 avg loss no lamb -3.572255 time 2019-02-15 09:56:55.614172
Model ind 579 epoch 949 head A head_i_epoch 0 batch 200: avg loss -3.593212 avg loss no lamb -3.593212 time 2019-02-15 09:59:51.493497
Pre: time 2019-02-15 10:03:11.777473: 
 	std: 0.0039944095
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25055, 0.25065, 0.24068333, 0.25108334, 0.25031668]
	train_accs: [0.25055, 0.25065, 0.24068333, 0.25108334, 0.25031668]
	best_train_sub_head: 3
	worst: 0.24068333
	avg: 0.24865666
	best: 0.25108334

Starting e_i: 950
Model ind 579 epoch 950 head B head_i_epoch 0 batch 0: avg loss -1.916513 avg loss no lamb -1.916513 time 2019-02-15 10:03:15.627243
Model ind 579 epoch 950 head B head_i_epoch 0 batch 100: avg loss -1.914234 avg loss no lamb -1.914234 time 2019-02-15 10:06:11.481504
Model ind 579 epoch 950 head B head_i_epoch 0 batch 200: avg loss -1.941333 avg loss no lamb -1.941333 time 2019-02-15 10:09:05.513963
Model ind 579 epoch 950 head A head_i_epoch 0 batch 0: avg loss -3.594186 avg loss no lamb -3.594186 time 2019-02-15 10:11:59.700563
Model ind 579 epoch 950 head A head_i_epoch 0 batch 100: avg loss -3.607410 avg loss no lamb -3.607410 time 2019-02-15 10:14:56.386852
Model ind 579 epoch 950 head A head_i_epoch 0 batch 200: avg loss -3.564928 avg loss no lamb -3.564928 time 2019-02-15 10:17:52.776135
Pre: time 2019-02-15 10:21:12.883797: 
 	std: 0.004300418
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25283334, 0.25308332, 0.24236667, 0.2534, 0.25311667]
	train_accs: [0.25283334, 0.25308332, 0.24236667, 0.2534, 0.25311667]
	best_train_sub_head: 3
	worst: 0.24236667
	avg: 0.25096002
	best: 0.2534

Starting e_i: 951
Model ind 579 epoch 951 head B head_i_epoch 0 batch 0: avg loss -1.992943 avg loss no lamb -1.992943 time 2019-02-15 10:21:19.774605
Model ind 579 epoch 951 head B head_i_epoch 0 batch 100: avg loss -1.947065 avg loss no lamb -1.947065 time 2019-02-15 10:24:15.744935
Model ind 579 epoch 951 head B head_i_epoch 0 batch 200: avg loss -1.936636 avg loss no lamb -1.936636 time 2019-02-15 10:27:09.904404
Model ind 579 epoch 951 head A head_i_epoch 0 batch 0: avg loss -3.585381 avg loss no lamb -3.585381 time 2019-02-15 10:30:03.513109
Model ind 579 epoch 951 head A head_i_epoch 0 batch 100: avg loss -3.579233 avg loss no lamb -3.579233 time 2019-02-15 10:32:59.303628
Model ind 579 epoch 951 head A head_i_epoch 0 batch 200: avg loss -3.609671 avg loss no lamb -3.609671 time 2019-02-15 10:35:55.859294
Pre: time 2019-02-15 10:39:17.068910: 
 	std: 0.0046687126
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25411665, 0.25435, 0.24258333, 0.25445, 0.25408334]
	train_accs: [0.25411665, 0.25435, 0.24258333, 0.25445, 0.25408334]
	best_train_sub_head: 3
	worst: 0.24258333
	avg: 0.25191665
	best: 0.25445

Starting e_i: 952
Model ind 579 epoch 952 head B head_i_epoch 0 batch 0: avg loss -1.948300 avg loss no lamb -1.948300 time 2019-02-15 10:39:20.743444
Model ind 579 epoch 952 head B head_i_epoch 0 batch 100: avg loss -2.007687 avg loss no lamb -2.007687 time 2019-02-15 10:42:16.075966
Model ind 579 epoch 952 head B head_i_epoch 0 batch 200: avg loss -1.968506 avg loss no lamb -1.968506 time 2019-02-15 10:45:10.988583
Model ind 579 epoch 952 head A head_i_epoch 0 batch 0: avg loss -3.610363 avg loss no lamb -3.610363 time 2019-02-15 10:48:05.869007
Model ind 579 epoch 952 head A head_i_epoch 0 batch 100: avg loss -3.627417 avg loss no lamb -3.627417 time 2019-02-15 10:51:01.347526
Model ind 579 epoch 952 head A head_i_epoch 0 batch 200: avg loss -3.645689 avg loss no lamb -3.645689 time 2019-02-15 10:53:56.990817
Pre: time 2019-02-15 10:57:16.525779: 
 	std: 0.0049954355
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25471666, 0.25453332, 0.24213333, 0.25456667, 0.25466666]
	train_accs: [0.25471666, 0.25453332, 0.24213333, 0.25456667, 0.25466666]
	best_train_sub_head: 0
	worst: 0.24213333
	avg: 0.25212333
	best: 0.25471666

Starting e_i: 953
Model ind 579 epoch 953 head B head_i_epoch 0 batch 0: avg loss -1.939561 avg loss no lamb -1.939561 time 2019-02-15 10:57:20.551560
Model ind 579 epoch 953 head B head_i_epoch 0 batch 100: avg loss -1.907960 avg loss no lamb -1.907960 time 2019-02-15 11:00:15.297580
Model ind 579 epoch 953 head B head_i_epoch 0 batch 200: avg loss -1.905532 avg loss no lamb -1.905532 time 2019-02-15 11:03:09.466647
Model ind 579 epoch 953 head A head_i_epoch 0 batch 0: avg loss -3.527608 avg loss no lamb -3.527608 time 2019-02-15 11:06:03.348932
Model ind 579 epoch 953 head A head_i_epoch 0 batch 100: avg loss -3.618404 avg loss no lamb -3.618404 time 2019-02-15 11:08:59.339858
Model ind 579 epoch 953 head A head_i_epoch 0 batch 200: avg loss -3.499230 avg loss no lamb -3.499230 time 2019-02-15 11:11:54.655888
Pre: time 2019-02-15 11:15:14.329059: 
 	std: 0.0046196845
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2541, 0.25355, 0.24221666, 0.25353333, 0.25383332]
	train_accs: [0.2541, 0.25355, 0.24221666, 0.25353333, 0.25383332]
	best_train_sub_head: 0
	worst: 0.24221666
	avg: 0.25144666
	best: 0.2541

Starting e_i: 954
Model ind 579 epoch 954 head B head_i_epoch 0 batch 0: avg loss -1.963758 avg loss no lamb -1.963758 time 2019-02-15 11:15:18.366522
Model ind 579 epoch 954 head B head_i_epoch 0 batch 100: avg loss -1.970276 avg loss no lamb -1.970276 time 2019-02-15 11:18:13.777352
Model ind 579 epoch 954 head B head_i_epoch 0 batch 200: avg loss -1.944268 avg loss no lamb -1.944268 time 2019-02-15 11:21:09.236553
Model ind 579 epoch 954 head A head_i_epoch 0 batch 0: avg loss -3.578349 avg loss no lamb -3.578349 time 2019-02-15 11:24:05.590483
Model ind 579 epoch 954 head A head_i_epoch 0 batch 100: avg loss -3.632046 avg loss no lamb -3.632046 time 2019-02-15 11:27:02.211726
Model ind 579 epoch 954 head A head_i_epoch 0 batch 200: avg loss -3.536865 avg loss no lamb -3.536865 time 2019-02-15 11:29:57.437613
Pre: time 2019-02-15 11:33:18.278593: 
 	std: 0.0047609387
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25381666, 0.25301668, 0.24161667, 0.25366667, 0.2535]
	train_accs: [0.25381666, 0.25301668, 0.24161667, 0.25366667, 0.2535]
	best_train_sub_head: 0
	worst: 0.24161667
	avg: 0.25112334
	best: 0.25381666

Starting e_i: 955
Model ind 579 epoch 955 head B head_i_epoch 0 batch 0: avg loss -1.921993 avg loss no lamb -1.921993 time 2019-02-15 11:33:22.406823
Model ind 579 epoch 955 head B head_i_epoch 0 batch 100: avg loss -1.958027 avg loss no lamb -1.958027 time 2019-02-15 11:36:17.006865
Model ind 579 epoch 955 head B head_i_epoch 0 batch 200: avg loss -1.943280 avg loss no lamb -1.943280 time 2019-02-15 11:39:11.326121
Model ind 579 epoch 955 head A head_i_epoch 0 batch 0: avg loss -3.576771 avg loss no lamb -3.576771 time 2019-02-15 11:42:06.454874
Model ind 579 epoch 955 head A head_i_epoch 0 batch 100: avg loss -3.617663 avg loss no lamb -3.617663 time 2019-02-15 11:45:03.654840
Model ind 579 epoch 955 head A head_i_epoch 0 batch 200: avg loss -3.635855 avg loss no lamb -3.635855 time 2019-02-15 11:47:59.027388
Pre: time 2019-02-15 11:51:19.343119: 
 	std: 0.004789
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25426668, 0.25411665, 0.24238333, 0.25451666, 0.2545]
	train_accs: [0.25426668, 0.25411665, 0.24238333, 0.25451666, 0.2545]
	best_train_sub_head: 3
	worst: 0.24238333
	avg: 0.25195667
	best: 0.25451666

Starting e_i: 956
Model ind 579 epoch 956 head B head_i_epoch 0 batch 0: avg loss -1.959373 avg loss no lamb -1.959373 time 2019-02-15 11:51:23.299490
Model ind 579 epoch 956 head B head_i_epoch 0 batch 100: avg loss -2.051764 avg loss no lamb -2.051764 time 2019-02-15 11:54:18.201105
Model ind 579 epoch 956 head B head_i_epoch 0 batch 200: avg loss -1.973415 avg loss no lamb -1.973415 time 2019-02-15 11:57:12.740566
Model ind 579 epoch 956 head A head_i_epoch 0 batch 0: avg loss -3.585783 avg loss no lamb -3.585783 time 2019-02-15 12:00:08.077477
Model ind 579 epoch 956 head A head_i_epoch 0 batch 100: avg loss -3.654145 avg loss no lamb -3.654145 time 2019-02-15 12:03:03.799730
Model ind 579 epoch 956 head A head_i_epoch 0 batch 200: avg loss -3.577328 avg loss no lamb -3.577328 time 2019-02-15 12:05:58.309277
Pre: time 2019-02-15 12:09:17.960593: 
 	std: 0.0046027256
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25531667, 0.25461668, 0.24356666, 0.25515, 0.25515]
	train_accs: [0.25531667, 0.25461668, 0.24356666, 0.25515, 0.25515]
	best_train_sub_head: 0
	worst: 0.24356666
	avg: 0.25276
	best: 0.25531667

Starting e_i: 957
Model ind 579 epoch 957 head B head_i_epoch 0 batch 0: avg loss -1.980480 avg loss no lamb -1.980480 time 2019-02-15 12:09:21.811665
Model ind 579 epoch 957 head B head_i_epoch 0 batch 100: avg loss -2.000412 avg loss no lamb -2.000412 time 2019-02-15 12:12:16.733282
Model ind 579 epoch 957 head B head_i_epoch 0 batch 200: avg loss -1.886070 avg loss no lamb -1.886070 time 2019-02-15 12:15:11.632122
Model ind 579 epoch 957 head A head_i_epoch 0 batch 0: avg loss -3.545494 avg loss no lamb -3.545494 time 2019-02-15 12:18:06.560773
Model ind 579 epoch 957 head A head_i_epoch 0 batch 100: avg loss -3.674604 avg loss no lamb -3.674604 time 2019-02-15 12:21:02.686300
Model ind 579 epoch 957 head A head_i_epoch 0 batch 200: avg loss -3.620150 avg loss no lamb -3.620150 time 2019-02-15 12:24:00.161477
Pre: time 2019-02-15 12:27:21.272481: 
 	std: 0.0044003176
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25356665, 0.25306666, 0.24243334, 0.25325, 0.25378335]
	train_accs: [0.25356665, 0.25306666, 0.24243334, 0.25325, 0.25378335]
	best_train_sub_head: 4
	worst: 0.24243334
	avg: 0.25122
	best: 0.25378335

Starting e_i: 958
Model ind 579 epoch 958 head B head_i_epoch 0 batch 0: avg loss -1.930433 avg loss no lamb -1.930433 time 2019-02-15 12:27:25.201951
Model ind 579 epoch 958 head B head_i_epoch 0 batch 100: avg loss -1.994726 avg loss no lamb -1.994726 time 2019-02-15 12:30:20.857815
Model ind 579 epoch 958 head B head_i_epoch 0 batch 200: avg loss -1.868915 avg loss no lamb -1.868915 time 2019-02-15 12:33:16.991284
Model ind 579 epoch 958 head A head_i_epoch 0 batch 0: avg loss -3.608925 avg loss no lamb -3.608925 time 2019-02-15 12:36:11.588191
Model ind 579 epoch 958 head A head_i_epoch 0 batch 100: avg loss -3.615215 avg loss no lamb -3.615215 time 2019-02-15 12:39:07.367485
Model ind 579 epoch 958 head A head_i_epoch 0 batch 200: avg loss -3.571060 avg loss no lamb -3.571060 time 2019-02-15 12:42:04.281785
Pre: time 2019-02-15 12:45:23.319456: 
 	std: 0.004541801
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25581667, 0.25551668, 0.2444, 0.25576666, 0.2559]
	train_accs: [0.25581667, 0.25551668, 0.2444, 0.25576666, 0.2559]
	best_train_sub_head: 4
	worst: 0.2444
	avg: 0.25348002
	best: 0.2559

Starting e_i: 959
Model ind 579 epoch 959 head B head_i_epoch 0 batch 0: avg loss -1.960041 avg loss no lamb -1.960041 time 2019-02-15 12:45:27.371833
Model ind 579 epoch 959 head B head_i_epoch 0 batch 100: avg loss -1.995937 avg loss no lamb -1.995937 time 2019-02-15 12:48:21.369976
Model ind 579 epoch 959 head B head_i_epoch 0 batch 200: avg loss -1.908462 avg loss no lamb -1.908462 time 2019-02-15 12:51:16.467563
Model ind 579 epoch 959 head A head_i_epoch 0 batch 0: avg loss -3.638136 avg loss no lamb -3.638136 time 2019-02-15 12:54:11.770445
Model ind 579 epoch 959 head A head_i_epoch 0 batch 100: avg loss -3.641172 avg loss no lamb -3.641172 time 2019-02-15 12:57:09.380359
Model ind 579 epoch 959 head A head_i_epoch 0 batch 200: avg loss -3.616015 avg loss no lamb -3.616015 time 2019-02-15 13:00:06.109750
Pre: time 2019-02-15 13:03:25.489518: 
 	std: 0.004708623
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.2551, 0.25506666, 0.24353333, 0.25513333, 0.25583333]
	train_accs: [0.2551, 0.25506666, 0.24353333, 0.25513333, 0.25583333]
	best_train_sub_head: 4
	worst: 0.24353333
	avg: 0.25293332
	best: 0.25583333

Starting e_i: 960
Model ind 579 epoch 960 head B head_i_epoch 0 batch 0: avg loss -1.995956 avg loss no lamb -1.995956 time 2019-02-15 13:03:29.836698
Model ind 579 epoch 960 head B head_i_epoch 0 batch 100: avg loss -1.908933 avg loss no lamb -1.908933 time 2019-02-15 13:06:23.496934
Model ind 579 epoch 960 head B head_i_epoch 0 batch 200: avg loss -1.882008 avg loss no lamb -1.882008 time 2019-02-15 13:09:19.313086
Model ind 579 epoch 960 head A head_i_epoch 0 batch 0: avg loss -3.557733 avg loss no lamb -3.557733 time 2019-02-15 13:12:14.154811
Model ind 579 epoch 960 head A head_i_epoch 0 batch 100: avg loss -3.666536 avg loss no lamb -3.666536 time 2019-02-15 13:15:12.003665
Model ind 579 epoch 960 head A head_i_epoch 0 batch 200: avg loss -3.620233 avg loss no lamb -3.620233 time 2019-02-15 13:18:08.472220
Pre: time 2019-02-15 13:21:27.609554: 
 	std: 0.0047867084
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25428334, 0.2539, 0.242, 0.25373334, 0.25391668]
	train_accs: [0.25428334, 0.2539, 0.242, 0.25373334, 0.25391668]
	best_train_sub_head: 0
	worst: 0.242
	avg: 0.2515667
	best: 0.25428334

Starting e_i: 961
Model ind 579 epoch 961 head B head_i_epoch 0 batch 0: avg loss -1.958487 avg loss no lamb -1.958487 time 2019-02-15 13:21:34.591462
Model ind 579 epoch 961 head B head_i_epoch 0 batch 100: avg loss -2.055405 avg loss no lamb -2.055405 time 2019-02-15 13:24:29.256321
Model ind 579 epoch 961 head B head_i_epoch 0 batch 200: avg loss -1.986943 avg loss no lamb -1.986943 time 2019-02-15 13:27:25.126705
Model ind 579 epoch 961 head A head_i_epoch 0 batch 0: avg loss -3.571629 avg loss no lamb -3.571629 time 2019-02-15 13:30:21.163064
Model ind 579 epoch 961 head A head_i_epoch 0 batch 100: avg loss -3.605001 avg loss no lamb -3.605001 time 2019-02-15 13:33:18.197567
Model ind 579 epoch 961 head A head_i_epoch 0 batch 200: avg loss -3.592806 avg loss no lamb -3.592806 time 2019-02-15 13:36:15.129793
Pre: time 2019-02-15 13:39:36.562407: 
 	std: 0.004599695
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2548, 0.2545, 0.24301666, 0.25428334, 0.25445]
	train_accs: [0.2548, 0.2545, 0.24301666, 0.25428334, 0.25445]
	best_train_sub_head: 0
	worst: 0.24301666
	avg: 0.25221
	best: 0.2548

Starting e_i: 962
Model ind 579 epoch 962 head B head_i_epoch 0 batch 0: avg loss -1.906179 avg loss no lamb -1.906179 time 2019-02-15 13:39:40.533934
Model ind 579 epoch 962 head B head_i_epoch 0 batch 100: avg loss -1.900883 avg loss no lamb -1.900883 time 2019-02-15 13:42:37.124367
Model ind 579 epoch 962 head B head_i_epoch 0 batch 200: avg loss -1.917843 avg loss no lamb -1.917843 time 2019-02-15 13:45:33.570566
Model ind 579 epoch 962 head A head_i_epoch 0 batch 0: avg loss -3.584613 avg loss no lamb -3.584613 time 2019-02-15 13:48:28.028932
Model ind 579 epoch 962 head A head_i_epoch 0 batch 100: avg loss -3.602193 avg loss no lamb -3.602193 time 2019-02-15 13:51:24.429497
Model ind 579 epoch 962 head A head_i_epoch 0 batch 200: avg loss -3.557170 avg loss no lamb -3.557170 time 2019-02-15 13:54:20.039462
Pre: time 2019-02-15 13:57:39.769784: 
 	std: 0.0045392564
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25345, 0.25371668, 0.242, 0.25323334, 0.25291666]
	train_accs: [0.25345, 0.25371668, 0.242, 0.25323334, 0.25291666]
	best_train_sub_head: 1
	worst: 0.242
	avg: 0.25106335
	best: 0.25371668

Starting e_i: 963
Model ind 579 epoch 963 head B head_i_epoch 0 batch 0: avg loss -1.829170 avg loss no lamb -1.829170 time 2019-02-15 13:57:43.610621
Model ind 579 epoch 963 head B head_i_epoch 0 batch 100: avg loss -1.901811 avg loss no lamb -1.901811 time 2019-02-15 14:00:36.355854
Model ind 579 epoch 963 head B head_i_epoch 0 batch 200: avg loss -1.989995 avg loss no lamb -1.989995 time 2019-02-15 14:03:29.253154
Model ind 579 epoch 963 head A head_i_epoch 0 batch 0: avg loss -3.603068 avg loss no lamb -3.603068 time 2019-02-15 14:06:24.258693
Model ind 579 epoch 963 head A head_i_epoch 0 batch 100: avg loss -3.661596 avg loss no lamb -3.661596 time 2019-02-15 14:09:19.296488
Model ind 579 epoch 963 head A head_i_epoch 0 batch 200: avg loss -3.595205 avg loss no lamb -3.595205 time 2019-02-15 14:12:13.532953
Pre: time 2019-02-15 14:15:31.497605: 
 	std: 0.0046140323
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 15), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 13), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2544, 0.25423333, 0.24271667, 0.25416666, 0.2542]
	train_accs: [0.2544, 0.25423333, 0.24271667, 0.25416666, 0.2542]
	best_train_sub_head: 0
	worst: 0.24271667
	avg: 0.25194335
	best: 0.2544

Starting e_i: 964
Model ind 579 epoch 964 head B head_i_epoch 0 batch 0: avg loss -1.997728 avg loss no lamb -1.997728 time 2019-02-15 14:15:35.236424
Model ind 579 epoch 964 head B head_i_epoch 0 batch 100: avg loss -1.918961 avg loss no lamb -1.918961 time 2019-02-15 14:18:29.210181
Model ind 579 epoch 964 head B head_i_epoch 0 batch 200: avg loss -1.986682 avg loss no lamb -1.986682 time 2019-02-15 14:21:22.838357
Model ind 579 epoch 964 head A head_i_epoch 0 batch 0: avg loss -3.515692 avg loss no lamb -3.515692 time 2019-02-15 14:24:17.806024
Model ind 579 epoch 964 head A head_i_epoch 0 batch 100: avg loss -3.590327 avg loss no lamb -3.590327 time 2019-02-15 14:27:09.895939
Model ind 579 epoch 964 head A head_i_epoch 0 batch 200: avg loss -3.581806 avg loss no lamb -3.581806 time 2019-02-15 14:30:01.741988
Pre: time 2019-02-15 14:33:16.542074: 
 	std: 0.0042464696
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25383332, 0.2532, 0.24291667, 0.25348333, 0.25356665]
	train_accs: [0.25383332, 0.2532, 0.24291667, 0.25348333, 0.25356665]
	best_train_sub_head: 0
	worst: 0.24291667
	avg: 0.2514
	best: 0.25383332

Starting e_i: 965
Model ind 579 epoch 965 head B head_i_epoch 0 batch 0: avg loss -1.968206 avg loss no lamb -1.968206 time 2019-02-15 14:33:20.472006
Model ind 579 epoch 965 head B head_i_epoch 0 batch 100: avg loss -2.020003 avg loss no lamb -2.020003 time 2019-02-15 14:36:10.591372
Model ind 579 epoch 965 head B head_i_epoch 0 batch 200: avg loss -1.952452 avg loss no lamb -1.952452 time 2019-02-15 14:39:00.824170
Model ind 579 epoch 965 head A head_i_epoch 0 batch 0: avg loss -3.559608 avg loss no lamb -3.559608 time 2019-02-15 14:41:51.165183
Model ind 579 epoch 965 head A head_i_epoch 0 batch 100: avg loss -3.629137 avg loss no lamb -3.629137 time 2019-02-15 14:44:44.478884
Model ind 579 epoch 965 head A head_i_epoch 0 batch 200: avg loss -3.542049 avg loss no lamb -3.542049 time 2019-02-15 14:47:36.442691
Pre: time 2019-02-15 14:50:53.648095: 
 	std: 0.0043604756
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25273332, 0.25243333, 0.24166666, 0.25283334, 0.25221667]
	train_accs: [0.25273332, 0.25243333, 0.24166666, 0.25283334, 0.25221667]
	best_train_sub_head: 3
	worst: 0.24166666
	avg: 0.25037667
	best: 0.25283334

Starting e_i: 966
Model ind 579 epoch 966 head B head_i_epoch 0 batch 0: avg loss -1.954528 avg loss no lamb -1.954528 time 2019-02-15 14:50:57.487879
Model ind 579 epoch 966 head B head_i_epoch 0 batch 100: avg loss -1.976852 avg loss no lamb -1.976852 time 2019-02-15 14:53:46.249078
Model ind 579 epoch 966 head B head_i_epoch 0 batch 200: avg loss -1.929116 avg loss no lamb -1.929116 time 2019-02-15 14:56:34.961485
Model ind 579 epoch 966 head A head_i_epoch 0 batch 0: avg loss -3.577465 avg loss no lamb -3.577465 time 2019-02-15 14:59:23.814447
Model ind 579 epoch 966 head A head_i_epoch 0 batch 100: avg loss -3.618729 avg loss no lamb -3.618729 time 2019-02-15 15:02:14.764083
Model ind 579 epoch 966 head A head_i_epoch 0 batch 200: avg loss -3.552483 avg loss no lamb -3.552483 time 2019-02-15 15:05:05.598055
Pre: time 2019-02-15 15:08:19.223099: 
 	std: 0.0044077607
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25256667, 0.25251666, 0.24163334, 0.25275, 0.25276667]
	train_accs: [0.25256667, 0.25251666, 0.24163334, 0.25275, 0.25276667]
	best_train_sub_head: 4
	worst: 0.24163334
	avg: 0.25044665
	best: 0.25276667

Starting e_i: 967
Model ind 579 epoch 967 head B head_i_epoch 0 batch 0: avg loss -1.974821 avg loss no lamb -1.974821 time 2019-02-15 15:08:23.237021
Model ind 579 epoch 967 head B head_i_epoch 0 batch 100: avg loss -1.991579 avg loss no lamb -1.991579 time 2019-02-15 15:11:11.292430
Model ind 579 epoch 967 head B head_i_epoch 0 batch 200: avg loss -1.875932 avg loss no lamb -1.875932 time 2019-02-15 15:13:57.846921
Model ind 579 epoch 967 head A head_i_epoch 0 batch 0: avg loss -3.571156 avg loss no lamb -3.571156 time 2019-02-15 15:16:45.143766
Model ind 579 epoch 967 head A head_i_epoch 0 batch 100: avg loss -3.652761 avg loss no lamb -3.652761 time 2019-02-15 15:19:34.125446
Model ind 579 epoch 967 head A head_i_epoch 0 batch 200: avg loss -3.646924 avg loss no lamb -3.646924 time 2019-02-15 15:22:23.794434
Pre: time 2019-02-15 15:25:35.103296: 
 	std: 0.0042171683
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25386667, 0.25386667, 0.24351667, 0.25435, 0.25411665]
	train_accs: [0.25386667, 0.25386667, 0.24351667, 0.25435, 0.25411665]
	best_train_sub_head: 3
	worst: 0.24351667
	avg: 0.25194332
	best: 0.25435

Starting e_i: 968
Model ind 579 epoch 968 head B head_i_epoch 0 batch 0: avg loss -1.948424 avg loss no lamb -1.948424 time 2019-02-15 15:25:38.825054
Model ind 579 epoch 968 head B head_i_epoch 0 batch 100: avg loss -1.943301 avg loss no lamb -1.943301 time 2019-02-15 15:28:29.112706
Model ind 579 epoch 968 head B head_i_epoch 0 batch 200: avg loss -1.958303 avg loss no lamb -1.958303 time 2019-02-15 15:31:21.535534
Model ind 579 epoch 968 head A head_i_epoch 0 batch 0: avg loss -3.516071 avg loss no lamb -3.516071 time 2019-02-15 15:34:14.121428
Model ind 579 epoch 968 head A head_i_epoch 0 batch 100: avg loss -3.626007 avg loss no lamb -3.626007 time 2019-02-15 15:37:08.891066
Model ind 579 epoch 968 head A head_i_epoch 0 batch 200: avg loss -3.599756 avg loss no lamb -3.599756 time 2019-02-15 15:40:02.475498
Pre: time 2019-02-15 15:43:19.619796: 
 	std: 0.0044992664
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 7), (7, 10), (8, 14), (9, 15), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 13), (16, 6), (17, 3), (18, 5), (19, 12)]
	test_accs: [0.25335, 0.25358334, 0.24225, 0.25345, 0.2536]
	train_accs: [0.25335, 0.25358334, 0.24225, 0.25345, 0.2536]
	best_train_sub_head: 4
	worst: 0.24225
	avg: 0.25124666
	best: 0.2536

Starting e_i: 969
Model ind 579 epoch 969 head B head_i_epoch 0 batch 0: avg loss -1.927545 avg loss no lamb -1.927545 time 2019-02-15 15:43:23.915643
Model ind 579 epoch 969 head B head_i_epoch 0 batch 100: avg loss -1.933261 avg loss no lamb -1.933261 time 2019-02-15 15:46:15.923732
Model ind 579 epoch 969 head B head_i_epoch 0 batch 200: avg loss -1.983224 avg loss no lamb -1.983224 time 2019-02-15 15:49:08.180009
Model ind 579 epoch 969 head A head_i_epoch 0 batch 0: avg loss -3.582813 avg loss no lamb -3.582813 time 2019-02-15 15:52:00.870701
Model ind 579 epoch 969 head A head_i_epoch 0 batch 100: avg loss -3.722467 avg loss no lamb -3.722467 time 2019-02-15 15:54:53.996772
Model ind 579 epoch 969 head A head_i_epoch 0 batch 200: avg loss -3.557606 avg loss no lamb -3.557606 time 2019-02-15 15:57:47.657636
Pre: time 2019-02-15 16:01:05.399903: 
 	std: 0.0044371765
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25241667, 0.25193334, 0.24115, 0.25215, 0.25243333]
	train_accs: [0.25241667, 0.25193334, 0.24115, 0.25215, 0.25243333]
	best_train_sub_head: 4
	worst: 0.24115
	avg: 0.25001666
	best: 0.25243333

Starting e_i: 970
Model ind 579 epoch 970 head B head_i_epoch 0 batch 0: avg loss -1.913494 avg loss no lamb -1.913494 time 2019-02-15 16:01:09.052712
Model ind 579 epoch 970 head B head_i_epoch 0 batch 100: avg loss -1.936157 avg loss no lamb -1.936157 time 2019-02-15 16:04:01.858005
Model ind 579 epoch 970 head B head_i_epoch 0 batch 200: avg loss -1.907219 avg loss no lamb -1.907219 time 2019-02-15 16:06:54.061034
Model ind 579 epoch 970 head A head_i_epoch 0 batch 0: avg loss -3.534134 avg loss no lamb -3.534134 time 2019-02-15 16:09:46.377074
Model ind 579 epoch 970 head A head_i_epoch 0 batch 100: avg loss -3.631962 avg loss no lamb -3.631962 time 2019-02-15 16:12:39.727647
Model ind 579 epoch 970 head A head_i_epoch 0 batch 200: avg loss -3.601685 avg loss no lamb -3.601685 time 2019-02-15 16:15:34.035982
Pre: time 2019-02-15 16:18:51.093872: 
 	std: 0.0042738705
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.2533, 0.25318334, 0.24263333, 0.2532, 0.25356665]
	train_accs: [0.2533, 0.25318334, 0.24263333, 0.2532, 0.25356665]
	best_train_sub_head: 4
	worst: 0.24263333
	avg: 0.25117666
	best: 0.25356665

Starting e_i: 971
Model ind 579 epoch 971 head B head_i_epoch 0 batch 0: avg loss -1.965097 avg loss no lamb -1.965097 time 2019-02-15 16:18:59.931217
Model ind 579 epoch 971 head B head_i_epoch 0 batch 100: avg loss -2.015650 avg loss no lamb -2.015650 time 2019-02-15 16:21:51.983049
Model ind 579 epoch 971 head B head_i_epoch 0 batch 200: avg loss -1.899019 avg loss no lamb -1.899019 time 2019-02-15 16:24:44.485589
Model ind 579 epoch 971 head A head_i_epoch 0 batch 0: avg loss -3.605626 avg loss no lamb -3.605626 time 2019-02-15 16:27:37.764360
Model ind 579 epoch 971 head A head_i_epoch 0 batch 100: avg loss -3.676140 avg loss no lamb -3.676140 time 2019-02-15 16:30:32.297405
Model ind 579 epoch 971 head A head_i_epoch 0 batch 200: avg loss -3.639157 avg loss no lamb -3.639157 time 2019-02-15 16:33:25.975012
Pre: time 2019-02-15 16:36:42.527469: 
 	std: 0.0042580203
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25445, 0.25386667, 0.2436, 0.25436667, 0.25425]
	train_accs: [0.25445, 0.25386667, 0.2436, 0.25436667, 0.25425]
	best_train_sub_head: 0
	worst: 0.2436
	avg: 0.25210667
	best: 0.25445

Starting e_i: 972
Model ind 579 epoch 972 head B head_i_epoch 0 batch 0: avg loss -2.020697 avg loss no lamb -2.020697 time 2019-02-15 16:36:46.448657
Model ind 579 epoch 972 head B head_i_epoch 0 batch 100: avg loss -2.011063 avg loss no lamb -2.011063 time 2019-02-15 16:39:38.405712
Model ind 579 epoch 972 head B head_i_epoch 0 batch 200: avg loss -1.907624 avg loss no lamb -1.907624 time 2019-02-15 16:42:29.995912
Model ind 579 epoch 972 head A head_i_epoch 0 batch 0: avg loss -3.610691 avg loss no lamb -3.610691 time 2019-02-15 16:45:19.875470
Model ind 579 epoch 972 head A head_i_epoch 0 batch 100: avg loss -3.651425 avg loss no lamb -3.651425 time 2019-02-15 16:48:11.187916
Model ind 579 epoch 972 head A head_i_epoch 0 batch 200: avg loss -3.584850 avg loss no lamb -3.584850 time 2019-02-15 16:51:05.209222
Pre: time 2019-02-15 16:54:23.161215: 
 	std: 0.0043755304
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25445, 0.2544, 0.24346666, 0.25448334, 0.25428334]
	train_accs: [0.25445, 0.2544, 0.24346666, 0.25448334, 0.25428334]
	best_train_sub_head: 3
	worst: 0.24346666
	avg: 0.25221664
	best: 0.25448334

Starting e_i: 973
Model ind 579 epoch 973 head B head_i_epoch 0 batch 0: avg loss -2.020204 avg loss no lamb -2.020204 time 2019-02-15 16:54:27.094979
Model ind 579 epoch 973 head B head_i_epoch 0 batch 100: avg loss -1.995898 avg loss no lamb -1.995898 time 2019-02-15 16:57:19.499152
Model ind 579 epoch 973 head B head_i_epoch 0 batch 200: avg loss -1.896408 avg loss no lamb -1.896408 time 2019-02-15 17:00:12.052412
Model ind 579 epoch 973 head A head_i_epoch 0 batch 0: avg loss -3.568572 avg loss no lamb -3.568572 time 2019-02-15 17:03:05.915592
Model ind 579 epoch 973 head A head_i_epoch 0 batch 100: avg loss -3.638816 avg loss no lamb -3.638816 time 2019-02-15 17:05:59.688376
Model ind 579 epoch 973 head A head_i_epoch 0 batch 200: avg loss -3.614801 avg loss no lamb -3.614801 time 2019-02-15 17:08:53.087528
Pre: time 2019-02-15 17:12:10.049909: 
 	std: 0.004008145
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.2544, 0.25421667, 0.2443, 0.25408334, 0.25455]
	train_accs: [0.2544, 0.25421667, 0.2443, 0.25408334, 0.25455]
	best_train_sub_head: 4
	worst: 0.2443
	avg: 0.25230998
	best: 0.25455

Starting e_i: 974
Model ind 579 epoch 974 head B head_i_epoch 0 batch 0: avg loss -1.945702 avg loss no lamb -1.945702 time 2019-02-15 17:12:14.006673
Model ind 579 epoch 974 head B head_i_epoch 0 batch 100: avg loss -1.941885 avg loss no lamb -1.941885 time 2019-02-15 17:15:06.827028
Model ind 579 epoch 974 head B head_i_epoch 0 batch 200: avg loss -1.984374 avg loss no lamb -1.984374 time 2019-02-15 17:17:59.374592
Model ind 579 epoch 974 head A head_i_epoch 0 batch 0: avg loss -3.607157 avg loss no lamb -3.607157 time 2019-02-15 17:20:51.070305
Model ind 579 epoch 974 head A head_i_epoch 0 batch 100: avg loss -3.634969 avg loss no lamb -3.634969 time 2019-02-15 17:23:44.863361
Model ind 579 epoch 974 head A head_i_epoch 0 batch 200: avg loss -3.590958 avg loss no lamb -3.590958 time 2019-02-15 17:26:38.368105
Pre: time 2019-02-15 17:29:54.938851: 
 	std: 0.004418093
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25498334, 0.25471666, 0.24375, 0.25481668, 0.25465]
	train_accs: [0.25498334, 0.25471666, 0.24375, 0.25481668, 0.25465]
	best_train_sub_head: 0
	worst: 0.24375
	avg: 0.25258332
	best: 0.25498334

Starting e_i: 975
Model ind 579 epoch 975 head B head_i_epoch 0 batch 0: avg loss -1.929231 avg loss no lamb -1.929231 time 2019-02-15 17:29:59.139886
Model ind 579 epoch 975 head B head_i_epoch 0 batch 100: avg loss -1.951210 avg loss no lamb -1.951210 time 2019-02-15 17:32:51.364103
Model ind 579 epoch 975 head B head_i_epoch 0 batch 200: avg loss -1.917179 avg loss no lamb -1.917179 time 2019-02-15 17:35:45.184872
Model ind 579 epoch 975 head A head_i_epoch 0 batch 0: avg loss -3.599142 avg loss no lamb -3.599142 time 2019-02-15 17:38:36.567051
Model ind 579 epoch 975 head A head_i_epoch 0 batch 100: avg loss -3.650174 avg loss no lamb -3.650174 time 2019-02-15 17:41:29.364816
Model ind 579 epoch 975 head A head_i_epoch 0 batch 200: avg loss -3.622792 avg loss no lamb -3.622792 time 2019-02-15 17:44:23.062266
Pre: time 2019-02-15 17:47:40.796567: 
 	std: 0.004258516
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25278333, 0.25255, 0.24186666, 0.25243333, 0.25225]
	train_accs: [0.25278333, 0.25255, 0.24186666, 0.25243333, 0.25225]
	best_train_sub_head: 0
	worst: 0.24186666
	avg: 0.25037664
	best: 0.25278333

Starting e_i: 976
Model ind 579 epoch 976 head B head_i_epoch 0 batch 0: avg loss -1.971613 avg loss no lamb -1.971613 time 2019-02-15 17:47:44.827841
Model ind 579 epoch 976 head B head_i_epoch 0 batch 100: avg loss -2.010656 avg loss no lamb -2.010656 time 2019-02-15 17:50:36.992599
Model ind 579 epoch 976 head B head_i_epoch 0 batch 200: avg loss -1.898902 avg loss no lamb -1.898902 time 2019-02-15 17:53:28.130927
Model ind 579 epoch 976 head A head_i_epoch 0 batch 0: avg loss -3.557889 avg loss no lamb -3.557889 time 2019-02-15 17:56:19.349922
Model ind 579 epoch 976 head A head_i_epoch 0 batch 100: avg loss -3.673135 avg loss no lamb -3.673135 time 2019-02-15 17:59:10.972739
Model ind 579 epoch 976 head A head_i_epoch 0 batch 200: avg loss -3.581940 avg loss no lamb -3.581940 time 2019-02-15 18:02:04.416850
Pre: time 2019-02-15 18:05:20.747195: 
 	std: 0.0039970223
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25433335, 0.254, 0.2441, 0.25401667, 0.254]
	train_accs: [0.25433335, 0.254, 0.2441, 0.25401667, 0.254]
	best_train_sub_head: 0
	worst: 0.2441
	avg: 0.25208998
	best: 0.25433335

Starting e_i: 977
Model ind 579 epoch 977 head B head_i_epoch 0 batch 0: avg loss -2.013993 avg loss no lamb -2.013993 time 2019-02-15 18:05:24.499132
Model ind 579 epoch 977 head B head_i_epoch 0 batch 100: avg loss -1.845813 avg loss no lamb -1.845813 time 2019-02-15 18:08:16.649828
Model ind 579 epoch 977 head B head_i_epoch 0 batch 200: avg loss -1.826170 avg loss no lamb -1.826170 time 2019-02-15 18:11:07.865759
Model ind 579 epoch 977 head A head_i_epoch 0 batch 0: avg loss -3.616585 avg loss no lamb -3.616585 time 2019-02-15 18:14:00.336176
Model ind 579 epoch 977 head A head_i_epoch 0 batch 100: avg loss -3.683955 avg loss no lamb -3.683955 time 2019-02-15 18:16:54.220942
Model ind 579 epoch 977 head A head_i_epoch 0 batch 200: avg loss -3.591060 avg loss no lamb -3.591060 time 2019-02-15 18:19:47.053999
Pre: time 2019-02-15 18:23:03.524187: 
 	std: 0.004207832
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2534, 0.25358334, 0.24293333, 0.25361666, 0.25318334]
	train_accs: [0.2534, 0.25358334, 0.24293333, 0.25361666, 0.25318334]
	best_train_sub_head: 3
	worst: 0.24293333
	avg: 0.25134334
	best: 0.25361666

Starting e_i: 978
Model ind 579 epoch 978 head B head_i_epoch 0 batch 0: avg loss -2.057960 avg loss no lamb -2.057960 time 2019-02-15 18:23:07.385095
Model ind 579 epoch 978 head B head_i_epoch 0 batch 100: avg loss -2.029625 avg loss no lamb -2.029625 time 2019-02-15 18:26:00.125685
Model ind 579 epoch 978 head B head_i_epoch 0 batch 200: avg loss -1.964572 avg loss no lamb -1.964572 time 2019-02-15 18:28:52.761314
Model ind 579 epoch 978 head A head_i_epoch 0 batch 0: avg loss -3.619198 avg loss no lamb -3.619198 time 2019-02-15 18:31:44.754317
Model ind 579 epoch 978 head A head_i_epoch 0 batch 100: avg loss -3.634058 avg loss no lamb -3.634058 time 2019-02-15 18:34:37.980424
Model ind 579 epoch 978 head A head_i_epoch 0 batch 200: avg loss -3.616782 avg loss no lamb -3.616782 time 2019-02-15 18:37:32.315606
Pre: time 2019-02-15 18:40:48.416456: 
 	std: 0.0040924666
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25413334, 0.25443333, 0.24405, 0.2541, 0.25443333]
	train_accs: [0.25413334, 0.25443333, 0.24405, 0.2541, 0.25443333]
	best_train_sub_head: 1
	worst: 0.24405
	avg: 0.25223
	best: 0.25443333

Starting e_i: 979
Model ind 579 epoch 979 head B head_i_epoch 0 batch 0: avg loss -1.995445 avg loss no lamb -1.995445 time 2019-02-15 18:40:52.444704
Model ind 579 epoch 979 head B head_i_epoch 0 batch 100: avg loss -1.979862 avg loss no lamb -1.979862 time 2019-02-15 18:43:44.512700
Model ind 579 epoch 979 head B head_i_epoch 0 batch 200: avg loss -1.921827 avg loss no lamb -1.921827 time 2019-02-15 18:46:36.383637
Model ind 579 epoch 979 head A head_i_epoch 0 batch 0: avg loss -3.591240 avg loss no lamb -3.591240 time 2019-02-15 18:49:29.471180
Model ind 579 epoch 979 head A head_i_epoch 0 batch 100: avg loss -3.623223 avg loss no lamb -3.623223 time 2019-02-15 18:52:22.485302
Model ind 579 epoch 979 head A head_i_epoch 0 batch 200: avg loss -3.623552 avg loss no lamb -3.623552 time 2019-02-15 18:55:15.822587
Pre: time 2019-02-15 18:58:33.312068: 
 	std: 0.004392292
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25335, 0.25331667, 0.24241666, 0.25338334, 0.25353333]
	train_accs: [0.25335, 0.25331667, 0.24241666, 0.25338334, 0.25353333]
	best_train_sub_head: 4
	worst: 0.24241666
	avg: 0.25120002
	best: 0.25353333

Starting e_i: 980
Model ind 579 epoch 980 head B head_i_epoch 0 batch 0: avg loss -2.003988 avg loss no lamb -2.003988 time 2019-02-15 18:58:36.927445
Model ind 579 epoch 980 head B head_i_epoch 0 batch 100: avg loss -1.862484 avg loss no lamb -1.862484 time 2019-02-15 19:01:28.964320
Model ind 579 epoch 980 head B head_i_epoch 0 batch 200: avg loss -1.963255 avg loss no lamb -1.963255 time 2019-02-15 19:04:20.252614
Model ind 579 epoch 980 head A head_i_epoch 0 batch 0: avg loss -3.586084 avg loss no lamb -3.586084 time 2019-02-15 19:07:12.399516
Model ind 579 epoch 980 head A head_i_epoch 0 batch 100: avg loss -3.595734 avg loss no lamb -3.595734 time 2019-02-15 19:10:05.878516
Model ind 579 epoch 980 head A head_i_epoch 0 batch 200: avg loss -3.614476 avg loss no lamb -3.614476 time 2019-02-15 19:12:58.836474
Pre: time 2019-02-15 19:16:15.603691: 
 	std: 0.0047927876
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25363332, 0.25331667, 0.24145, 0.25318334, 0.25356665]
	train_accs: [0.25363332, 0.25331667, 0.24145, 0.25318334, 0.25356665]
	best_train_sub_head: 0
	worst: 0.24145
	avg: 0.25103
	best: 0.25363332

Starting e_i: 981
Model ind 579 epoch 981 head B head_i_epoch 0 batch 0: avg loss -2.015354 avg loss no lamb -2.015354 time 2019-02-15 19:16:23.200217
Model ind 579 epoch 981 head B head_i_epoch 0 batch 100: avg loss -2.027701 avg loss no lamb -2.027701 time 2019-02-15 19:19:15.245654
Model ind 579 epoch 981 head B head_i_epoch 0 batch 200: avg loss -2.005481 avg loss no lamb -2.005481 time 2019-02-15 19:22:07.378723
Model ind 579 epoch 981 head A head_i_epoch 0 batch 0: avg loss -3.566936 avg loss no lamb -3.566936 time 2019-02-15 19:24:58.456200
Model ind 579 epoch 981 head A head_i_epoch 0 batch 100: avg loss -3.643342 avg loss no lamb -3.643342 time 2019-02-15 19:27:51.916797
Model ind 579 epoch 981 head A head_i_epoch 0 batch 200: avg loss -3.617152 avg loss no lamb -3.617152 time 2019-02-15 19:30:45.882476
Pre: time 2019-02-15 19:34:02.245576: 
 	std: 0.0046549025
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25391668, 0.25333333, 0.24211666, 0.25326666, 0.25433335]
	train_accs: [0.25391668, 0.25333333, 0.24211666, 0.25326666, 0.25433335]
	best_train_sub_head: 4
	worst: 0.24211666
	avg: 0.25139335
	best: 0.25433335

Starting e_i: 982
Model ind 579 epoch 982 head B head_i_epoch 0 batch 0: avg loss -1.981204 avg loss no lamb -1.981204 time 2019-02-15 19:34:06.194072
Model ind 579 epoch 982 head B head_i_epoch 0 batch 100: avg loss -1.975270 avg loss no lamb -1.975270 time 2019-02-15 19:36:58.074762
Model ind 579 epoch 982 head B head_i_epoch 0 batch 200: avg loss -1.885756 avg loss no lamb -1.885756 time 2019-02-15 19:39:50.060973
Model ind 579 epoch 982 head A head_i_epoch 0 batch 0: avg loss -3.579808 avg loss no lamb -3.579808 time 2019-02-15 19:42:42.705997
Model ind 579 epoch 982 head A head_i_epoch 0 batch 100: avg loss -3.679216 avg loss no lamb -3.679216 time 2019-02-15 19:45:35.538263
Model ind 579 epoch 982 head A head_i_epoch 0 batch 200: avg loss -3.619980 avg loss no lamb -3.619980 time 2019-02-15 19:48:29.285664
Pre: time 2019-02-15 19:51:46.673670: 
 	std: 0.0042927293
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 18), (12, 13), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 5), (19, 12)]
	test_accs: [0.25331667, 0.25316668, 0.24253333, 0.25266665, 0.25376666]
	train_accs: [0.25331667, 0.25316668, 0.24253333, 0.25266665, 0.25376666]
	best_train_sub_head: 4
	worst: 0.24253333
	avg: 0.25109
	best: 0.25376666

Starting e_i: 983
Model ind 579 epoch 983 head B head_i_epoch 0 batch 0: avg loss -2.026405 avg loss no lamb -2.026405 time 2019-02-15 19:51:50.481601
Model ind 579 epoch 983 head B head_i_epoch 0 batch 100: avg loss -1.913224 avg loss no lamb -1.913224 time 2019-02-15 19:54:43.266740
Model ind 579 epoch 983 head B head_i_epoch 0 batch 200: avg loss -1.924299 avg loss no lamb -1.924299 time 2019-02-15 19:57:34.505754
Model ind 579 epoch 983 head A head_i_epoch 0 batch 0: avg loss -3.559139 avg loss no lamb -3.559139 time 2019-02-15 20:00:26.167912
Model ind 579 epoch 983 head A head_i_epoch 0 batch 100: avg loss -3.617044 avg loss no lamb -3.617044 time 2019-02-15 20:03:18.083389
Model ind 579 epoch 983 head A head_i_epoch 0 batch 200: avg loss -3.565494 avg loss no lamb -3.565494 time 2019-02-15 20:06:10.782018
Pre: time 2019-02-15 20:09:26.310822: 
 	std: 0.004337387
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25486666, 0.25421667, 0.24361667, 0.25435, 0.25435]
	train_accs: [0.25486666, 0.25421667, 0.24361667, 0.25435, 0.25435]
	best_train_sub_head: 0
	worst: 0.24361667
	avg: 0.25228
	best: 0.25486666

Starting e_i: 984
Model ind 579 epoch 984 head B head_i_epoch 0 batch 0: avg loss -1.967517 avg loss no lamb -1.967517 time 2019-02-15 20:09:30.042153
Model ind 579 epoch 984 head B head_i_epoch 0 batch 100: avg loss -1.956046 avg loss no lamb -1.956046 time 2019-02-15 20:12:22.633797
Model ind 579 epoch 984 head B head_i_epoch 0 batch 200: avg loss -1.974187 avg loss no lamb -1.974187 time 2019-02-15 20:15:14.372083
Model ind 579 epoch 984 head A head_i_epoch 0 batch 0: avg loss -3.604638 avg loss no lamb -3.604638 time 2019-02-15 20:18:06.999236
Model ind 579 epoch 984 head A head_i_epoch 0 batch 100: avg loss -3.600845 avg loss no lamb -3.600845 time 2019-02-15 20:20:59.547736
Model ind 579 epoch 984 head A head_i_epoch 0 batch 200: avg loss -3.619888 avg loss no lamb -3.619888 time 2019-02-15 20:23:52.059356
Pre: time 2019-02-15 20:27:07.883038: 
 	std: 0.0043729176
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25485, 0.25515, 0.24405, 0.25475, 0.25515]
	train_accs: [0.25485, 0.25515, 0.24405, 0.25475, 0.25515]
	best_train_sub_head: 1
	worst: 0.24405
	avg: 0.25279
	best: 0.25515

Starting e_i: 985
Model ind 579 epoch 985 head B head_i_epoch 0 batch 0: avg loss -1.986822 avg loss no lamb -1.986822 time 2019-02-15 20:27:11.874255
Model ind 579 epoch 985 head B head_i_epoch 0 batch 100: avg loss -1.963657 avg loss no lamb -1.963657 time 2019-02-15 20:30:04.544752
Model ind 579 epoch 985 head B head_i_epoch 0 batch 200: avg loss -1.899734 avg loss no lamb -1.899734 time 2019-02-15 20:32:56.419919
Model ind 579 epoch 985 head A head_i_epoch 0 batch 0: avg loss -3.652689 avg loss no lamb -3.652689 time 2019-02-15 20:35:47.638772
Model ind 579 epoch 985 head A head_i_epoch 0 batch 100: avg loss -3.617413 avg loss no lamb -3.617413 time 2019-02-15 20:38:41.108509
Model ind 579 epoch 985 head A head_i_epoch 0 batch 200: avg loss -3.558853 avg loss no lamb -3.558853 time 2019-02-15 20:41:33.789357
Pre: time 2019-02-15 20:44:50.427703: 
 	std: 0.004492413
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25341666, 0.25318334, 0.24178334, 0.25268334, 0.25268334]
	train_accs: [0.25341666, 0.25318334, 0.24178334, 0.25268334, 0.25268334]
	best_train_sub_head: 0
	worst: 0.24178334
	avg: 0.25075
	best: 0.25341666

Starting e_i: 986
Model ind 579 epoch 986 head B head_i_epoch 0 batch 0: avg loss -1.942417 avg loss no lamb -1.942417 time 2019-02-15 20:44:54.520473
Model ind 579 epoch 986 head B head_i_epoch 0 batch 100: avg loss -1.936505 avg loss no lamb -1.936505 time 2019-02-15 20:47:47.797930
Model ind 579 epoch 986 head B head_i_epoch 0 batch 200: avg loss -1.955944 avg loss no lamb -1.955944 time 2019-02-15 20:50:39.544939
Model ind 579 epoch 986 head A head_i_epoch 0 batch 0: avg loss -3.584347 avg loss no lamb -3.584347 time 2019-02-15 20:53:32.454327
Model ind 579 epoch 986 head A head_i_epoch 0 batch 100: avg loss -3.600576 avg loss no lamb -3.600576 time 2019-02-15 20:56:25.627023
Model ind 579 epoch 986 head A head_i_epoch 0 batch 200: avg loss -3.685117 avg loss no lamb -3.685117 time 2019-02-15 20:59:18.994133
Pre: time 2019-02-15 21:02:35.309577: 
 	std: 0.0041264347
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25368333, 0.25358334, 0.24343333, 0.25381666, 0.2539]
	train_accs: [0.25368333, 0.25358334, 0.24343333, 0.25381666, 0.2539]
	best_train_sub_head: 4
	worst: 0.24343333
	avg: 0.25168332
	best: 0.2539

Starting e_i: 987
Model ind 579 epoch 987 head B head_i_epoch 0 batch 0: avg loss -1.963026 avg loss no lamb -1.963026 time 2019-02-15 21:02:39.386711
Model ind 579 epoch 987 head B head_i_epoch 0 batch 100: avg loss -1.935057 avg loss no lamb -1.935057 time 2019-02-15 21:05:32.714382
Model ind 579 epoch 987 head B head_i_epoch 0 batch 200: avg loss -1.899493 avg loss no lamb -1.899493 time 2019-02-15 21:08:23.670123
Model ind 579 epoch 987 head A head_i_epoch 0 batch 0: avg loss -3.621869 avg loss no lamb -3.621869 time 2019-02-15 21:11:14.732638
Model ind 579 epoch 987 head A head_i_epoch 0 batch 100: avg loss -3.604393 avg loss no lamb -3.604393 time 2019-02-15 21:14:08.280308
Model ind 579 epoch 987 head A head_i_epoch 0 batch 200: avg loss -3.582893 avg loss no lamb -3.582893 time 2019-02-15 21:17:01.278545
Pre: time 2019-02-15 21:20:17.775548: 
 	std: 0.0046195886
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25513333, 0.25486666, 0.24323334, 0.2544, 0.25466666]
	train_accs: [0.25513333, 0.25486666, 0.24323334, 0.2544, 0.25466666]
	best_train_sub_head: 0
	worst: 0.24323334
	avg: 0.25246
	best: 0.25513333

Starting e_i: 988
Model ind 579 epoch 988 head B head_i_epoch 0 batch 0: avg loss -1.993103 avg loss no lamb -1.993103 time 2019-02-15 21:20:21.764460
Model ind 579 epoch 988 head B head_i_epoch 0 batch 100: avg loss -2.023734 avg loss no lamb -2.023734 time 2019-02-15 21:23:14.169248
Model ind 579 epoch 988 head B head_i_epoch 0 batch 200: avg loss -1.982895 avg loss no lamb -1.982895 time 2019-02-15 21:26:06.832511
Model ind 579 epoch 988 head A head_i_epoch 0 batch 0: avg loss -3.587086 avg loss no lamb -3.587086 time 2019-02-15 21:28:57.978452
Model ind 579 epoch 988 head A head_i_epoch 0 batch 100: avg loss -3.618563 avg loss no lamb -3.618563 time 2019-02-15 21:31:51.723835
Model ind 579 epoch 988 head A head_i_epoch 0 batch 200: avg loss -3.607193 avg loss no lamb -3.607193 time 2019-02-15 21:34:45.452338
Pre: time 2019-02-15 21:38:02.082848: 
 	std: 0.0045854496
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25431666, 0.25395, 0.2427, 0.25406668, 0.2543]
	train_accs: [0.25431666, 0.25395, 0.2427, 0.25406668, 0.2543]
	best_train_sub_head: 0
	worst: 0.2427
	avg: 0.25186667
	best: 0.25431666

Starting e_i: 989
Model ind 579 epoch 989 head B head_i_epoch 0 batch 0: avg loss -1.949865 avg loss no lamb -1.949865 time 2019-02-15 21:38:06.277816
Model ind 579 epoch 989 head B head_i_epoch 0 batch 100: avg loss -1.907318 avg loss no lamb -1.907318 time 2019-02-15 21:40:58.817089
Model ind 579 epoch 989 head B head_i_epoch 0 batch 200: avg loss -1.996741 avg loss no lamb -1.996741 time 2019-02-15 21:43:51.153374
Model ind 579 epoch 989 head A head_i_epoch 0 batch 0: avg loss -3.512496 avg loss no lamb -3.512496 time 2019-02-15 21:46:43.133858
Model ind 579 epoch 989 head A head_i_epoch 0 batch 100: avg loss -3.596364 avg loss no lamb -3.596364 time 2019-02-15 21:49:37.802328
Model ind 579 epoch 989 head A head_i_epoch 0 batch 200: avg loss -3.604236 avg loss no lamb -3.604236 time 2019-02-15 21:52:31.532114
Pre: time 2019-02-15 21:55:50.680193: 
 	std: 0.0047498723
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25285, 0.25261667, 0.2409, 0.25266665, 0.25295]
	train_accs: [0.25285, 0.25261667, 0.2409, 0.25266665, 0.25295]
	best_train_sub_head: 4
	worst: 0.2409
	avg: 0.25039667
	best: 0.25295

Starting e_i: 990
Model ind 579 epoch 990 head B head_i_epoch 0 batch 0: avg loss -1.966736 avg loss no lamb -1.966736 time 2019-02-15 21:55:54.645422
Model ind 579 epoch 990 head B head_i_epoch 0 batch 100: avg loss -1.970755 avg loss no lamb -1.970755 time 2019-02-15 21:58:45.610904
Model ind 579 epoch 990 head B head_i_epoch 0 batch 200: avg loss -1.977945 avg loss no lamb -1.977945 time 2019-02-15 22:01:38.312971
Model ind 579 epoch 990 head A head_i_epoch 0 batch 0: avg loss -3.571992 avg loss no lamb -3.571992 time 2019-02-15 22:04:30.485909
Model ind 579 epoch 990 head A head_i_epoch 0 batch 100: avg loss -3.651777 avg loss no lamb -3.651777 time 2019-02-15 22:07:24.956989
Model ind 579 epoch 990 head A head_i_epoch 0 batch 200: avg loss -3.635504 avg loss no lamb -3.635504 time 2019-02-15 22:10:18.417226
Pre: time 2019-02-15 22:13:35.289829: 
 	std: 0.0046537733
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25398332, 0.2532, 0.24196666, 0.25346667, 0.25368333]
	train_accs: [0.25398332, 0.2532, 0.24196666, 0.25346667, 0.25368333]
	best_train_sub_head: 0
	worst: 0.24196666
	avg: 0.25125998
	best: 0.25398332

Starting e_i: 991
Model ind 579 epoch 991 head B head_i_epoch 0 batch 0: avg loss -1.977633 avg loss no lamb -1.977633 time 2019-02-15 22:13:44.549172
Model ind 579 epoch 991 head B head_i_epoch 0 batch 100: avg loss -2.058060 avg loss no lamb -2.058060 time 2019-02-15 22:16:37.516519
Model ind 579 epoch 991 head B head_i_epoch 0 batch 200: avg loss -1.929525 avg loss no lamb -1.929525 time 2019-02-15 22:19:29.185689
Model ind 579 epoch 991 head A head_i_epoch 0 batch 0: avg loss -3.627360 avg loss no lamb -3.627360 time 2019-02-15 22:22:21.898977
Model ind 579 epoch 991 head A head_i_epoch 0 batch 100: avg loss -3.600079 avg loss no lamb -3.600079 time 2019-02-15 22:25:15.647761
Model ind 579 epoch 991 head A head_i_epoch 0 batch 200: avg loss -3.600923 avg loss no lamb -3.600923 time 2019-02-15 22:28:09.117410
Pre: time 2019-02-15 22:31:26.634380: 
 	std: 0.00469439
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25515, 0.25503334, 0.2436, 0.25536665, 0.25573334]
	train_accs: [0.25515, 0.25503334, 0.2436, 0.25536665, 0.25573334]
	best_train_sub_head: 4
	worst: 0.2436
	avg: 0.2529767
	best: 0.25573334

Starting e_i: 992
Model ind 579 epoch 992 head B head_i_epoch 0 batch 0: avg loss -1.923161 avg loss no lamb -1.923161 time 2019-02-15 22:31:30.826810
Model ind 579 epoch 992 head B head_i_epoch 0 batch 100: avg loss -1.979237 avg loss no lamb -1.979237 time 2019-02-15 22:34:23.228686
Model ind 579 epoch 992 head B head_i_epoch 0 batch 200: avg loss -1.891251 avg loss no lamb -1.891251 time 2019-02-15 22:37:15.366885
Model ind 579 epoch 992 head A head_i_epoch 0 batch 0: avg loss -3.587969 avg loss no lamb -3.587969 time 2019-02-15 22:40:06.636602
Model ind 579 epoch 992 head A head_i_epoch 0 batch 100: avg loss -3.622826 avg loss no lamb -3.622826 time 2019-02-15 22:42:59.706225
Model ind 579 epoch 992 head A head_i_epoch 0 batch 200: avg loss -3.579880 avg loss no lamb -3.579880 time 2019-02-15 22:45:53.977820
Pre: time 2019-02-15 22:49:10.617038: 
 	std: 0.0044300943
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25293332, 0.25296667, 0.24218333, 0.25326666, 0.25376666]
	train_accs: [0.25293332, 0.25296667, 0.24218333, 0.25326666, 0.25376666]
	best_train_sub_head: 4
	worst: 0.24218333
	avg: 0.25102335
	best: 0.25376666

Starting e_i: 993
Model ind 579 epoch 993 head B head_i_epoch 0 batch 0: avg loss -1.965980 avg loss no lamb -1.965980 time 2019-02-15 22:49:14.679662
Model ind 579 epoch 993 head B head_i_epoch 0 batch 100: avg loss -1.876050 avg loss no lamb -1.876050 time 2019-02-15 22:52:06.353715
Model ind 579 epoch 993 head B head_i_epoch 0 batch 200: avg loss -1.859488 avg loss no lamb -1.859488 time 2019-02-15 22:54:58.927269
Model ind 579 epoch 993 head A head_i_epoch 0 batch 0: avg loss -3.649748 avg loss no lamb -3.649748 time 2019-02-15 22:57:52.603227
Model ind 579 epoch 993 head A head_i_epoch 0 batch 100: avg loss -3.685824 avg loss no lamb -3.685824 time 2019-02-15 23:00:44.712957
Model ind 579 epoch 993 head A head_i_epoch 0 batch 200: avg loss -3.620195 avg loss no lamb -3.620195 time 2019-02-15 23:03:38.011309
Pre: time 2019-02-15 23:06:55.248564: 
 	std: 0.004511218
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25496668, 0.25498334, 0.24391666, 0.25526667, 0.25551668]
	train_accs: [0.25496668, 0.25498334, 0.24391666, 0.25526667, 0.25551668]
	best_train_sub_head: 4
	worst: 0.24391666
	avg: 0.25293
	best: 0.25551668

Starting e_i: 994
Model ind 579 epoch 994 head B head_i_epoch 0 batch 0: avg loss -2.093707 avg loss no lamb -2.093707 time 2019-02-15 23:06:59.118408
Model ind 579 epoch 994 head B head_i_epoch 0 batch 100: avg loss -1.916234 avg loss no lamb -1.916234 time 2019-02-15 23:09:51.704038
Model ind 579 epoch 994 head B head_i_epoch 0 batch 200: avg loss -2.005292 avg loss no lamb -2.005292 time 2019-02-15 23:12:42.993189
Model ind 579 epoch 994 head A head_i_epoch 0 batch 0: avg loss -3.590917 avg loss no lamb -3.590917 time 2019-02-15 23:15:35.938482
Model ind 579 epoch 994 head A head_i_epoch 0 batch 100: avg loss -3.624809 avg loss no lamb -3.624809 time 2019-02-15 23:18:29.684018
Model ind 579 epoch 994 head A head_i_epoch 0 batch 200: avg loss -3.642712 avg loss no lamb -3.642712 time 2019-02-15 23:21:22.502465
Pre: time 2019-02-15 23:24:39.081897: 
 	std: 0.0045477143
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25478333, 0.25433335, 0.24326667, 0.25466666, 0.25473332]
	train_accs: [0.25478333, 0.25433335, 0.24326667, 0.25466666, 0.25473332]
	best_train_sub_head: 0
	worst: 0.24326667
	avg: 0.25235668
	best: 0.25478333

Starting e_i: 995
Model ind 579 epoch 995 head B head_i_epoch 0 batch 0: avg loss -1.928707 avg loss no lamb -1.928707 time 2019-02-15 23:24:43.151274
Model ind 579 epoch 995 head B head_i_epoch 0 batch 100: avg loss -1.973164 avg loss no lamb -1.973164 time 2019-02-15 23:27:35.117901
Model ind 579 epoch 995 head B head_i_epoch 0 batch 200: avg loss -1.931513 avg loss no lamb -1.931513 time 2019-02-15 23:30:27.491036
Model ind 579 epoch 995 head A head_i_epoch 0 batch 0: avg loss -3.583659 avg loss no lamb -3.583659 time 2019-02-15 23:33:20.203825
Model ind 579 epoch 995 head A head_i_epoch 0 batch 100: avg loss -3.658026 avg loss no lamb -3.658026 time 2019-02-15 23:36:13.374536
Model ind 579 epoch 995 head A head_i_epoch 0 batch 200: avg loss -3.635350 avg loss no lamb -3.635350 time 2019-02-15 23:39:07.539921
Pre: time 2019-02-15 23:42:25.889761: 
 	std: 0.004732983
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25311667, 0.25293332, 0.2413, 0.25326666, 0.2532]
	train_accs: [0.25311667, 0.25293332, 0.2413, 0.25326666, 0.2532]
	best_train_sub_head: 3
	worst: 0.2413
	avg: 0.25076333
	best: 0.25326666

Starting e_i: 996
Model ind 579 epoch 996 head B head_i_epoch 0 batch 0: avg loss -1.997643 avg loss no lamb -1.997643 time 2019-02-15 23:42:29.489787
Model ind 579 epoch 996 head B head_i_epoch 0 batch 100: avg loss -1.957832 avg loss no lamb -1.957832 time 2019-02-15 23:45:21.654162
Model ind 579 epoch 996 head B head_i_epoch 0 batch 200: avg loss -1.983680 avg loss no lamb -1.983680 time 2019-02-15 23:48:14.522894
Model ind 579 epoch 996 head A head_i_epoch 0 batch 0: avg loss -3.618491 avg loss no lamb -3.618491 time 2019-02-15 23:51:07.112509
Model ind 579 epoch 996 head A head_i_epoch 0 batch 100: avg loss -3.615349 avg loss no lamb -3.615349 time 2019-02-15 23:54:00.443110
Model ind 579 epoch 996 head A head_i_epoch 0 batch 200: avg loss -3.652936 avg loss no lamb -3.652936 time 2019-02-15 23:56:53.861976
Pre: time 2019-02-16 00:00:11.918536: 
 	std: 0.0045521003
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25573334, 0.25575, 0.24458334, 0.25596666, 0.25635]
	train_accs: [0.25573334, 0.25575, 0.24458334, 0.25596666, 0.25635]
	best_train_sub_head: 4
	worst: 0.24458334
	avg: 0.25367668
	best: 0.25635

Starting e_i: 997
Model ind 579 epoch 997 head B head_i_epoch 0 batch 0: avg loss -2.008274 avg loss no lamb -2.008274 time 2019-02-16 00:00:15.891349
Model ind 579 epoch 997 head B head_i_epoch 0 batch 100: avg loss -2.044206 avg loss no lamb -2.044206 time 2019-02-16 00:03:09.482784
Model ind 579 epoch 997 head B head_i_epoch 0 batch 200: avg loss -1.962424 avg loss no lamb -1.962424 time 2019-02-16 00:06:02.575273
Model ind 579 epoch 997 head A head_i_epoch 0 batch 0: avg loss -3.527843 avg loss no lamb -3.527843 time 2019-02-16 00:08:54.269487
Model ind 579 epoch 997 head A head_i_epoch 0 batch 100: avg loss -3.577723 avg loss no lamb -3.577723 time 2019-02-16 00:11:48.527441
Model ind 579 epoch 997 head A head_i_epoch 0 batch 200: avg loss -3.605459 avg loss no lamb -3.605459 time 2019-02-16 00:14:36.351462
Pre: time 2019-02-16 00:17:48.600691: 
 	std: 0.0047739707
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.253, 0.25295, 0.24111667, 0.25306666, 0.25318334]
	train_accs: [0.253, 0.25295, 0.24111667, 0.25306666, 0.25318334]
	best_train_sub_head: 4
	worst: 0.24111667
	avg: 0.25066334
	best: 0.25318334

Starting e_i: 998
Model ind 579 epoch 998 head B head_i_epoch 0 batch 0: avg loss -1.997757 avg loss no lamb -1.997757 time 2019-02-16 00:17:52.128045
Model ind 579 epoch 998 head B head_i_epoch 0 batch 100: avg loss -1.992756 avg loss no lamb -1.992756 time 2019-02-16 00:20:39.743158
Model ind 579 epoch 998 head B head_i_epoch 0 batch 200: avg loss -1.913884 avg loss no lamb -1.913884 time 2019-02-16 00:23:27.561313
Model ind 579 epoch 998 head A head_i_epoch 0 batch 0: avg loss -3.671807 avg loss no lamb -3.671807 time 2019-02-16 00:26:14.259898
Model ind 579 epoch 998 head A head_i_epoch 0 batch 100: avg loss -3.647277 avg loss no lamb -3.647277 time 2019-02-16 00:29:04.328291
Model ind 579 epoch 998 head A head_i_epoch 0 batch 200: avg loss -3.587265 avg loss no lamb -3.587265 time 2019-02-16 00:31:53.047092
Pre: time 2019-02-16 00:35:05.139968: 
 	std: 0.0044665006
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25406668, 0.25378335, 0.24288334, 0.2539, 0.2544]
	train_accs: [0.25406668, 0.25378335, 0.24288334, 0.2539, 0.2544]
	best_train_sub_head: 4
	worst: 0.24288334
	avg: 0.25180668
	best: 0.2544

Starting e_i: 999
Model ind 579 epoch 999 head B head_i_epoch 0 batch 0: avg loss -1.893171 avg loss no lamb -1.893171 time 2019-02-16 00:35:08.981058
Model ind 579 epoch 999 head B head_i_epoch 0 batch 100: avg loss -1.929408 avg loss no lamb -1.929408 time 2019-02-16 00:37:55.135159
Model ind 579 epoch 999 head B head_i_epoch 0 batch 200: avg loss -1.932693 avg loss no lamb -1.932693 time 2019-02-16 00:40:42.713193
Model ind 579 epoch 999 head A head_i_epoch 0 batch 0: avg loss -3.605335 avg loss no lamb -3.605335 time 2019-02-16 00:43:31.064362
Model ind 579 epoch 999 head A head_i_epoch 0 batch 100: avg loss -3.659601 avg loss no lamb -3.659601 time 2019-02-16 00:46:19.336975
Model ind 579 epoch 999 head A head_i_epoch 0 batch 200: avg loss -3.631165 avg loss no lamb -3.631165 time 2019-02-16 00:49:07.233101
Pre: time 2019-02-16 00:52:18.505877: 
 	std: 0.004736023
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.2522, 0.25228333, 0.24045, 0.25208333, 0.25256667]
	train_accs: [0.2522, 0.25228333, 0.24045, 0.25208333, 0.25256667]
	best_train_sub_head: 4
	worst: 0.24045
	avg: 0.24991667
	best: 0.25256667

Starting e_i: 1000
Model ind 579 epoch 1000 head B head_i_epoch 0 batch 0: avg loss -1.979464 avg loss no lamb -1.979464 time 2019-02-16 00:52:22.219973
Model ind 579 epoch 1000 head B head_i_epoch 0 batch 100: avg loss -1.986170 avg loss no lamb -1.986170 time 2019-02-16 00:55:08.300986
Model ind 579 epoch 1000 head B head_i_epoch 0 batch 200: avg loss -1.950680 avg loss no lamb -1.950680 time 2019-02-16 00:57:55.643258
Model ind 579 epoch 1000 head A head_i_epoch 0 batch 0: avg loss -3.641741 avg loss no lamb -3.641741 time 2019-02-16 01:00:43.399539
Model ind 579 epoch 1000 head A head_i_epoch 0 batch 100: avg loss -3.647384 avg loss no lamb -3.647384 time 2019-02-16 01:03:32.230461
Model ind 579 epoch 1000 head A head_i_epoch 0 batch 200: avg loss -3.583392 avg loss no lamb -3.583392 time 2019-02-16 01:06:21.269082
Pre: time 2019-02-16 01:09:31.106165: 
 	std: 0.0046472885
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25526667, 0.25525, 0.24385, 0.25555, 0.25576666]
	train_accs: [0.25526667, 0.25525, 0.24385, 0.25555, 0.25576666]
	best_train_sub_head: 4
	worst: 0.24385
	avg: 0.25313666
	best: 0.25576666

Starting e_i: 1001
Model ind 579 epoch 1001 head B head_i_epoch 0 batch 0: avg loss -2.019444 avg loss no lamb -2.019444 time 2019-02-16 01:09:38.469514
Model ind 579 epoch 1001 head B head_i_epoch 0 batch 100: avg loss -1.898452 avg loss no lamb -1.898452 time 2019-02-16 01:12:25.833760
Model ind 579 epoch 1001 head B head_i_epoch 0 batch 200: avg loss -1.898191 avg loss no lamb -1.898191 time 2019-02-16 01:15:13.396016
Model ind 579 epoch 1001 head A head_i_epoch 0 batch 0: avg loss -3.634499 avg loss no lamb -3.634499 time 2019-02-16 01:17:59.731463
Model ind 579 epoch 1001 head A head_i_epoch 0 batch 100: avg loss -3.684237 avg loss no lamb -3.684237 time 2019-02-16 01:20:48.597596
Model ind 579 epoch 1001 head A head_i_epoch 0 batch 200: avg loss -3.568420 avg loss no lamb -3.568420 time 2019-02-16 01:23:35.586945
Pre: time 2019-02-16 01:26:48.835695: 
 	std: 0.0045874785
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25471666, 0.25453332, 0.24321666, 0.2548, 0.25468335]
	train_accs: [0.25471666, 0.25453332, 0.24321666, 0.2548, 0.25468335]
	best_train_sub_head: 3
	worst: 0.24321666
	avg: 0.25239
	best: 0.2548

Starting e_i: 1002
Model ind 579 epoch 1002 head B head_i_epoch 0 batch 0: avg loss -1.885088 avg loss no lamb -1.885088 time 2019-02-16 01:26:52.649287
Model ind 579 epoch 1002 head B head_i_epoch 0 batch 100: avg loss -1.991273 avg loss no lamb -1.991273 time 2019-02-16 01:29:42.796982
Model ind 579 epoch 1002 head B head_i_epoch 0 batch 200: avg loss -1.933059 avg loss no lamb -1.933059 time 2019-02-16 01:32:33.211379
Model ind 579 epoch 1002 head A head_i_epoch 0 batch 0: avg loss -3.562300 avg loss no lamb -3.562300 time 2019-02-16 01:35:21.600151
Model ind 579 epoch 1002 head A head_i_epoch 0 batch 100: avg loss -3.639653 avg loss no lamb -3.639653 time 2019-02-16 01:38:10.400939
Model ind 579 epoch 1002 head A head_i_epoch 0 batch 200: avg loss -3.592130 avg loss no lamb -3.592130 time 2019-02-16 01:40:59.331544
Pre: time 2019-02-16 01:44:12.285355: 
 	std: 0.00442017
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2556, 0.25516668, 0.24445, 0.25568333, 0.25551668]
	train_accs: [0.2556, 0.25516668, 0.24445, 0.25568333, 0.25551668]
	best_train_sub_head: 3
	worst: 0.24445
	avg: 0.25328332
	best: 0.25568333

Starting e_i: 1003
Model ind 579 epoch 1003 head B head_i_epoch 0 batch 0: avg loss -1.989769 avg loss no lamb -1.989769 time 2019-02-16 01:44:16.282648
Model ind 579 epoch 1003 head B head_i_epoch 0 batch 100: avg loss -1.998264 avg loss no lamb -1.998264 time 2019-02-16 01:47:05.405374
Model ind 579 epoch 1003 head B head_i_epoch 0 batch 200: avg loss -1.911588 avg loss no lamb -1.911588 time 2019-02-16 01:49:54.176837
Model ind 579 epoch 1003 head A head_i_epoch 0 batch 0: avg loss -3.645344 avg loss no lamb -3.645344 time 2019-02-16 01:52:44.223241
Model ind 579 epoch 1003 head A head_i_epoch 0 batch 100: avg loss -3.642094 avg loss no lamb -3.642094 time 2019-02-16 01:55:34.676745
Model ind 579 epoch 1003 head A head_i_epoch 0 batch 200: avg loss -3.651880 avg loss no lamb -3.651880 time 2019-02-16 01:58:26.609586
Pre: time 2019-02-16 02:01:41.184896: 
 	std: 0.0042554885
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25288334, 0.25273332, 0.24231666, 0.25308332, 0.2531]
	train_accs: [0.25288334, 0.25273332, 0.24231666, 0.25308332, 0.2531]
	best_train_sub_head: 4
	worst: 0.24231666
	avg: 0.25082332
	best: 0.2531

Starting e_i: 1004
Model ind 579 epoch 1004 head B head_i_epoch 0 batch 0: avg loss -1.889771 avg loss no lamb -1.889771 time 2019-02-16 02:01:45.080477
Model ind 579 epoch 1004 head B head_i_epoch 0 batch 100: avg loss -2.005418 avg loss no lamb -2.005418 time 2019-02-16 02:04:34.964765
Model ind 579 epoch 1004 head B head_i_epoch 0 batch 200: avg loss -1.914919 avg loss no lamb -1.914919 time 2019-02-16 02:07:25.603965
Model ind 579 epoch 1004 head A head_i_epoch 0 batch 0: avg loss -3.624367 avg loss no lamb -3.624367 time 2019-02-16 02:10:16.144377
Model ind 579 epoch 1004 head A head_i_epoch 0 batch 100: avg loss -3.612779 avg loss no lamb -3.612779 time 2019-02-16 02:13:08.333718
Model ind 579 epoch 1004 head A head_i_epoch 0 batch 200: avg loss -3.600394 avg loss no lamb -3.600394 time 2019-02-16 02:16:00.606185
Pre: time 2019-02-16 02:19:13.501288: 
 	std: 0.0045835506
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25476667, 0.25443333, 0.24295, 0.2541, 0.25428334]
	train_accs: [0.25476667, 0.25443333, 0.24295, 0.2541, 0.25428334]
	best_train_sub_head: 0
	worst: 0.24295
	avg: 0.25210667
	best: 0.25476667

Starting e_i: 1005
Model ind 579 epoch 1005 head B head_i_epoch 0 batch 0: avg loss -1.931640 avg loss no lamb -1.931640 time 2019-02-16 02:19:17.322111
Model ind 579 epoch 1005 head B head_i_epoch 0 batch 100: avg loss -2.049772 avg loss no lamb -2.049772 time 2019-02-16 02:22:06.477358
Model ind 579 epoch 1005 head B head_i_epoch 0 batch 200: avg loss -1.953096 avg loss no lamb -1.953096 time 2019-02-16 02:24:56.890304
Model ind 579 epoch 1005 head A head_i_epoch 0 batch 0: avg loss -3.602988 avg loss no lamb -3.602988 time 2019-02-16 02:27:46.362736
Model ind 579 epoch 1005 head A head_i_epoch 0 batch 100: avg loss -3.655697 avg loss no lamb -3.655697 time 2019-02-16 02:30:36.995904
Model ind 579 epoch 1005 head A head_i_epoch 0 batch 200: avg loss -3.589960 avg loss no lamb -3.589960 time 2019-02-16 02:33:27.176088
Pre: time 2019-02-16 02:36:41.703510: 
 	std: 0.00438033
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25161666, 0.25136667, 0.24053334, 0.2513, 0.25163335]
	train_accs: [0.25161666, 0.25136667, 0.24053334, 0.2513, 0.25163335]
	best_train_sub_head: 4
	worst: 0.24053334
	avg: 0.24928999
	best: 0.25163335

Starting e_i: 1006
Model ind 579 epoch 1006 head B head_i_epoch 0 batch 0: avg loss -1.925945 avg loss no lamb -1.925945 time 2019-02-16 02:36:45.588495
Model ind 579 epoch 1006 head B head_i_epoch 0 batch 100: avg loss -2.034263 avg loss no lamb -2.034263 time 2019-02-16 02:39:35.155344
Model ind 579 epoch 1006 head B head_i_epoch 0 batch 200: avg loss -1.941251 avg loss no lamb -1.941251 time 2019-02-16 02:42:24.402443
Model ind 579 epoch 1006 head A head_i_epoch 0 batch 0: avg loss -3.532807 avg loss no lamb -3.532807 time 2019-02-16 02:45:15.063541
Model ind 579 epoch 1006 head A head_i_epoch 0 batch 100: avg loss -3.682358 avg loss no lamb -3.682358 time 2019-02-16 02:48:05.877571
Model ind 579 epoch 1006 head A head_i_epoch 0 batch 200: avg loss -3.612894 avg loss no lamb -3.612894 time 2019-02-16 02:50:56.449298
Pre: time 2019-02-16 02:54:09.297133: 
 	std: 0.004345797
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25376666, 0.25371668, 0.24268334, 0.25305, 0.25358334]
	train_accs: [0.25376666, 0.25371668, 0.24268334, 0.25305, 0.25358334]
	best_train_sub_head: 0
	worst: 0.24268334
	avg: 0.25136
	best: 0.25376666

Starting e_i: 1007
Model ind 579 epoch 1007 head B head_i_epoch 0 batch 0: avg loss -1.997013 avg loss no lamb -1.997013 time 2019-02-16 02:54:13.395761
Model ind 579 epoch 1007 head B head_i_epoch 0 batch 100: avg loss -1.964876 avg loss no lamb -1.964876 time 2019-02-16 02:57:03.477051
Model ind 579 epoch 1007 head B head_i_epoch 0 batch 200: avg loss -1.895935 avg loss no lamb -1.895935 time 2019-02-16 02:59:53.881690
Model ind 579 epoch 1007 head A head_i_epoch 0 batch 0: avg loss -3.565567 avg loss no lamb -3.565567 time 2019-02-16 03:02:43.757110
Model ind 579 epoch 1007 head A head_i_epoch 0 batch 100: avg loss -3.646671 avg loss no lamb -3.646671 time 2019-02-16 03:05:33.956578
Model ind 579 epoch 1007 head A head_i_epoch 0 batch 200: avg loss -3.645799 avg loss no lamb -3.645799 time 2019-02-16 03:08:24.432465
Pre: time 2019-02-16 03:11:39.065958: 
 	std: 0.0046583423
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25465, 0.25478333, 0.24316667, 0.25503334, 0.25476667]
	train_accs: [0.25465, 0.25478333, 0.24316667, 0.25503334, 0.25476667]
	best_train_sub_head: 3
	worst: 0.24316667
	avg: 0.25248
	best: 0.25503334

Starting e_i: 1008
Model ind 579 epoch 1008 head B head_i_epoch 0 batch 0: avg loss -1.999200 avg loss no lamb -1.999200 time 2019-02-16 03:11:43.010740
Model ind 579 epoch 1008 head B head_i_epoch 0 batch 100: avg loss -2.019988 avg loss no lamb -2.019988 time 2019-02-16 03:14:32.926488
Model ind 579 epoch 1008 head B head_i_epoch 0 batch 200: avg loss -1.973357 avg loss no lamb -1.973357 time 2019-02-16 03:17:22.440317
Model ind 579 epoch 1008 head A head_i_epoch 0 batch 0: avg loss -3.598129 avg loss no lamb -3.598129 time 2019-02-16 03:20:12.480711
Model ind 579 epoch 1008 head A head_i_epoch 0 batch 100: avg loss -3.631097 avg loss no lamb -3.631097 time 2019-02-16 03:23:03.856469
Model ind 579 epoch 1008 head A head_i_epoch 0 batch 200: avg loss -3.676434 avg loss no lamb -3.676434 time 2019-02-16 03:25:54.599657
Pre: time 2019-02-16 03:29:10.426105: 
 	std: 0.0046235737
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2544, 0.25475, 0.24316667, 0.25496668, 0.25475]
	train_accs: [0.2544, 0.25475, 0.24316667, 0.25496668, 0.25475]
	best_train_sub_head: 3
	worst: 0.24316667
	avg: 0.2524067
	best: 0.25496668

Starting e_i: 1009
Model ind 579 epoch 1009 head B head_i_epoch 0 batch 0: avg loss -1.961531 avg loss no lamb -1.961531 time 2019-02-16 03:29:14.403155
Model ind 579 epoch 1009 head B head_i_epoch 0 batch 100: avg loss -2.018340 avg loss no lamb -2.018340 time 2019-02-16 03:32:03.268425
Model ind 579 epoch 1009 head B head_i_epoch 0 batch 200: avg loss -1.979566 avg loss no lamb -1.979566 time 2019-02-16 03:34:52.314220
Model ind 579 epoch 1009 head A head_i_epoch 0 batch 0: avg loss -3.544703 avg loss no lamb -3.544703 time 2019-02-16 03:37:42.018519
Model ind 579 epoch 1009 head A head_i_epoch 0 batch 100: avg loss -3.670325 avg loss no lamb -3.670325 time 2019-02-16 03:40:33.348777
Model ind 579 epoch 1009 head A head_i_epoch 0 batch 200: avg loss -3.602655 avg loss no lamb -3.602655 time 2019-02-16 03:43:24.206512
Pre: time 2019-02-16 03:46:39.703823: 
 	std: 0.0051145107
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25476667, 0.25525, 0.24218333, 0.25481668, 0.25501665]
	train_accs: [0.25476667, 0.25525, 0.24218333, 0.25481668, 0.25501665]
	best_train_sub_head: 1
	worst: 0.24218333
	avg: 0.25240666
	best: 0.25525

Starting e_i: 1010
Model ind 579 epoch 1010 head B head_i_epoch 0 batch 0: avg loss -2.114876 avg loss no lamb -2.114876 time 2019-02-16 03:46:43.629405
Model ind 579 epoch 1010 head B head_i_epoch 0 batch 100: avg loss -2.059544 avg loss no lamb -2.059544 time 2019-02-16 03:49:35.205677
Model ind 579 epoch 1010 head B head_i_epoch 0 batch 200: avg loss -1.983637 avg loss no lamb -1.983637 time 2019-02-16 03:52:24.988612
Model ind 579 epoch 1010 head A head_i_epoch 0 batch 0: avg loss -3.696380 avg loss no lamb -3.696380 time 2019-02-16 03:55:14.157686
Model ind 579 epoch 1010 head A head_i_epoch 0 batch 100: avg loss -3.631530 avg loss no lamb -3.631530 time 2019-02-16 03:58:06.958483
Model ind 579 epoch 1010 head A head_i_epoch 0 batch 200: avg loss -3.696884 avg loss no lamb -3.696884 time 2019-02-16 04:00:57.974627
Pre: time 2019-02-16 04:04:12.572916: 
 	std: 0.0048388313
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25391668, 0.25433335, 0.24201667, 0.25418332, 0.254]
	train_accs: [0.25391668, 0.25433335, 0.24201667, 0.25418332, 0.254]
	best_train_sub_head: 1
	worst: 0.24201667
	avg: 0.25169
	best: 0.25433335

Starting e_i: 1011
Model ind 579 epoch 1011 head B head_i_epoch 0 batch 0: avg loss -1.985711 avg loss no lamb -1.985711 time 2019-02-16 04:04:20.693863
Model ind 579 epoch 1011 head B head_i_epoch 0 batch 100: avg loss -1.955298 avg loss no lamb -1.955298 time 2019-02-16 04:07:10.517371
Model ind 579 epoch 1011 head B head_i_epoch 0 batch 200: avg loss -1.894861 avg loss no lamb -1.894861 time 2019-02-16 04:10:00.287371
Model ind 579 epoch 1011 head A head_i_epoch 0 batch 0: avg loss -3.651870 avg loss no lamb -3.651870 time 2019-02-16 04:12:50.248794
Model ind 579 epoch 1011 head A head_i_epoch 0 batch 100: avg loss -3.620424 avg loss no lamb -3.620424 time 2019-02-16 04:15:40.829203
Model ind 579 epoch 1011 head A head_i_epoch 0 batch 200: avg loss -3.640437 avg loss no lamb -3.640437 time 2019-02-16 04:18:31.836110
Pre: time 2019-02-16 04:21:45.812885: 
 	std: 0.0047141486
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2545, 0.25458333, 0.24266666, 0.25433335, 0.25438333]
	train_accs: [0.2545, 0.25458333, 0.24266666, 0.25433335, 0.25438333]
	best_train_sub_head: 1
	worst: 0.24266666
	avg: 0.25209334
	best: 0.25458333

Starting e_i: 1012
Model ind 579 epoch 1012 head B head_i_epoch 0 batch 0: avg loss -2.033770 avg loss no lamb -2.033770 time 2019-02-16 04:21:49.688111
Model ind 579 epoch 1012 head B head_i_epoch 0 batch 100: avg loss -1.973260 avg loss no lamb -1.973260 time 2019-02-16 04:24:39.134631
Model ind 579 epoch 1012 head B head_i_epoch 0 batch 200: avg loss -1.975151 avg loss no lamb -1.975151 time 2019-02-16 04:27:28.797990
Model ind 579 epoch 1012 head A head_i_epoch 0 batch 0: avg loss -3.594816 avg loss no lamb -3.594816 time 2019-02-16 04:30:18.796971
Model ind 579 epoch 1012 head A head_i_epoch 0 batch 100: avg loss -3.609499 avg loss no lamb -3.609499 time 2019-02-16 04:33:09.613238
Model ind 579 epoch 1012 head A head_i_epoch 0 batch 200: avg loss -3.605795 avg loss no lamb -3.605795 time 2019-02-16 04:36:01.210237
Pre: time 2019-02-16 04:39:16.767719: 
 	std: 0.004414454
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2533, 0.25355, 0.24245, 0.25373334, 0.25333333]
	train_accs: [0.2533, 0.25355, 0.24245, 0.25373334, 0.25333333]
	best_train_sub_head: 3
	worst: 0.24245
	avg: 0.25127333
	best: 0.25373334

Starting e_i: 1013
Model ind 579 epoch 1013 head B head_i_epoch 0 batch 0: avg loss -1.999625 avg loss no lamb -1.999625 time 2019-02-16 04:39:20.747018
Model ind 579 epoch 1013 head B head_i_epoch 0 batch 100: avg loss -2.015132 avg loss no lamb -2.015132 time 2019-02-16 04:42:10.213225
Model ind 579 epoch 1013 head B head_i_epoch 0 batch 200: avg loss -2.024491 avg loss no lamb -2.024491 time 2019-02-16 04:44:59.603176
Model ind 579 epoch 1013 head A head_i_epoch 0 batch 0: avg loss -3.642933 avg loss no lamb -3.642933 time 2019-02-16 04:47:49.216615
Model ind 579 epoch 1013 head A head_i_epoch 0 batch 100: avg loss -3.670169 avg loss no lamb -3.670169 time 2019-02-16 04:50:39.315818
Model ind 579 epoch 1013 head A head_i_epoch 0 batch 200: avg loss -3.629720 avg loss no lamb -3.629720 time 2019-02-16 04:53:29.322019
Pre: time 2019-02-16 04:56:43.049046: 
 	std: 0.0043400177
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2544, 0.25443333, 0.24356666, 0.25441667, 0.25441667]
	train_accs: [0.2544, 0.25443333, 0.24356666, 0.25441667, 0.25441667]
	best_train_sub_head: 1
	worst: 0.24356666
	avg: 0.25224668
	best: 0.25443333

Starting e_i: 1014
Model ind 579 epoch 1014 head B head_i_epoch 0 batch 0: avg loss -2.029342 avg loss no lamb -2.029342 time 2019-02-16 04:56:46.829588
Model ind 579 epoch 1014 head B head_i_epoch 0 batch 100: avg loss -1.970526 avg loss no lamb -1.970526 time 2019-02-16 04:59:36.191794
Model ind 579 epoch 1014 head B head_i_epoch 0 batch 200: avg loss -1.949493 avg loss no lamb -1.949493 time 2019-02-16 05:02:24.920898
Model ind 579 epoch 1014 head A head_i_epoch 0 batch 0: avg loss -3.590871 avg loss no lamb -3.590871 time 2019-02-16 05:05:14.005954
Model ind 579 epoch 1014 head A head_i_epoch 0 batch 100: avg loss -3.675987 avg loss no lamb -3.675987 time 2019-02-16 05:08:03.891355
Model ind 579 epoch 1014 head A head_i_epoch 0 batch 200: avg loss -3.641811 avg loss no lamb -3.641811 time 2019-02-16 05:10:53.758143
Pre: time 2019-02-16 05:14:08.797420: 
 	std: 0.004516703
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25411665, 0.25378335, 0.24273333, 0.25406668, 0.25411665]
	train_accs: [0.25411665, 0.25378335, 0.24273333, 0.25406668, 0.25411665]
	best_train_sub_head: 0
	worst: 0.24273333
	avg: 0.25176334
	best: 0.25411665

Starting e_i: 1015
Model ind 579 epoch 1015 head B head_i_epoch 0 batch 0: avg loss -1.989946 avg loss no lamb -1.989946 time 2019-02-16 05:14:12.833495
Model ind 579 epoch 1015 head B head_i_epoch 0 batch 100: avg loss -2.057080 avg loss no lamb -2.057080 time 2019-02-16 05:17:01.943120
Model ind 579 epoch 1015 head B head_i_epoch 0 batch 200: avg loss -1.982328 avg loss no lamb -1.982328 time 2019-02-16 05:19:50.720136
Model ind 579 epoch 1015 head A head_i_epoch 0 batch 0: avg loss -3.578325 avg loss no lamb -3.578325 time 2019-02-16 05:22:39.820751
Model ind 579 epoch 1015 head A head_i_epoch 0 batch 100: avg loss -3.644114 avg loss no lamb -3.644114 time 2019-02-16 05:25:30.183827
Model ind 579 epoch 1015 head A head_i_epoch 0 batch 200: avg loss -3.646467 avg loss no lamb -3.646467 time 2019-02-16 05:28:20.985131
Pre: time 2019-02-16 05:31:36.252882: 
 	std: 0.0044575613
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25521666, 0.25471666, 0.24395, 0.25526667, 0.25513333]
	train_accs: [0.25521666, 0.25471666, 0.24395, 0.25526667, 0.25513333]
	best_train_sub_head: 3
	worst: 0.24395
	avg: 0.25285667
	best: 0.25526667

Starting e_i: 1016
Model ind 579 epoch 1016 head B head_i_epoch 0 batch 0: avg loss -2.007887 avg loss no lamb -2.007887 time 2019-02-16 05:31:40.134492
Model ind 579 epoch 1016 head B head_i_epoch 0 batch 100: avg loss -1.963569 avg loss no lamb -1.963569 time 2019-02-16 05:34:29.785183
Model ind 579 epoch 1016 head B head_i_epoch 0 batch 200: avg loss -1.933861 avg loss no lamb -1.933861 time 2019-02-16 05:37:19.444904
Model ind 579 epoch 1016 head A head_i_epoch 0 batch 0: avg loss -3.577918 avg loss no lamb -3.577918 time 2019-02-16 05:40:08.899471
Model ind 579 epoch 1016 head A head_i_epoch 0 batch 100: avg loss -3.602681 avg loss no lamb -3.602681 time 2019-02-16 05:42:59.537366
Model ind 579 epoch 1016 head A head_i_epoch 0 batch 200: avg loss -3.662830 avg loss no lamb -3.662830 time 2019-02-16 05:45:50.334080
Pre: time 2019-02-16 05:49:03.577922: 
 	std: 0.0044440483
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25521666, 0.25498334, 0.24396667, 0.25501665, 0.25508332]
	train_accs: [0.25521666, 0.25498334, 0.24396667, 0.25501665, 0.25508332]
	best_train_sub_head: 0
	worst: 0.24396667
	avg: 0.25285333
	best: 0.25521666

Starting e_i: 1017
Model ind 579 epoch 1017 head B head_i_epoch 0 batch 0: avg loss -1.935101 avg loss no lamb -1.935101 time 2019-02-16 05:49:07.217660
Model ind 579 epoch 1017 head B head_i_epoch 0 batch 100: avg loss -1.988838 avg loss no lamb -1.988838 time 2019-02-16 05:51:57.382835
Model ind 579 epoch 1017 head B head_i_epoch 0 batch 200: avg loss -1.878179 avg loss no lamb -1.878179 time 2019-02-16 05:54:47.030188
Model ind 579 epoch 1017 head A head_i_epoch 0 batch 0: avg loss -3.614991 avg loss no lamb -3.614991 time 2019-02-16 05:57:36.662570
Model ind 579 epoch 1017 head A head_i_epoch 0 batch 100: avg loss -3.617237 avg loss no lamb -3.617237 time 2019-02-16 06:00:27.477188
Model ind 579 epoch 1017 head A head_i_epoch 0 batch 200: avg loss -3.667760 avg loss no lamb -3.667760 time 2019-02-16 06:03:18.162052
Pre: time 2019-02-16 06:06:32.971685: 
 	std: 0.004519638
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25263333, 0.25231665, 0.24118334, 0.25255, 0.25241667]
	train_accs: [0.25263333, 0.25231665, 0.24118334, 0.25255, 0.25241667]
	best_train_sub_head: 0
	worst: 0.24118334
	avg: 0.25022
	best: 0.25263333

Starting e_i: 1018
Model ind 579 epoch 1018 head B head_i_epoch 0 batch 0: avg loss -2.017713 avg loss no lamb -2.017713 time 2019-02-16 06:06:36.718808
Model ind 579 epoch 1018 head B head_i_epoch 0 batch 100: avg loss -1.951574 avg loss no lamb -1.951574 time 2019-02-16 06:09:26.172775
Model ind 579 epoch 1018 head B head_i_epoch 0 batch 200: avg loss -1.948810 avg loss no lamb -1.948810 time 2019-02-16 06:12:15.639230
Model ind 579 epoch 1018 head A head_i_epoch 0 batch 0: avg loss -3.650620 avg loss no lamb -3.650620 time 2019-02-16 06:15:05.902748
Model ind 579 epoch 1018 head A head_i_epoch 0 batch 100: avg loss -3.592257 avg loss no lamb -3.592257 time 2019-02-16 06:17:56.836681
Model ind 579 epoch 1018 head A head_i_epoch 0 batch 200: avg loss -3.587994 avg loss no lamb -3.587994 time 2019-02-16 06:20:47.715588
Pre: time 2019-02-16 06:24:03.195498: 
 	std: 0.0043598805
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25313333, 0.25348333, 0.24245, 0.25336668, 0.2534]
	train_accs: [0.25313333, 0.25348333, 0.24245, 0.25336668, 0.2534]
	best_train_sub_head: 1
	worst: 0.24245
	avg: 0.25116664
	best: 0.25348333

Starting e_i: 1019
Model ind 579 epoch 1019 head B head_i_epoch 0 batch 0: avg loss -1.981237 avg loss no lamb -1.981237 time 2019-02-16 06:24:07.005468
Model ind 579 epoch 1019 head B head_i_epoch 0 batch 100: avg loss -1.974589 avg loss no lamb -1.974589 time 2019-02-16 06:26:56.451749
Model ind 579 epoch 1019 head B head_i_epoch 0 batch 200: avg loss -1.918733 avg loss no lamb -1.918733 time 2019-02-16 06:29:45.968675
Model ind 579 epoch 1019 head A head_i_epoch 0 batch 0: avg loss -3.558019 avg loss no lamb -3.558019 time 2019-02-16 06:32:35.769321
Model ind 579 epoch 1019 head A head_i_epoch 0 batch 100: avg loss -3.617392 avg loss no lamb -3.617392 time 2019-02-16 06:35:27.204702
Model ind 579 epoch 1019 head A head_i_epoch 0 batch 200: avg loss -3.619660 avg loss no lamb -3.619660 time 2019-02-16 06:38:18.681970
Pre: time 2019-02-16 06:41:32.855626: 
 	std: 0.0043219766
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25281668, 0.25301668, 0.24223334, 0.25335, 0.25293332]
	train_accs: [0.25281668, 0.25301668, 0.24223334, 0.25335, 0.25293332]
	best_train_sub_head: 3
	worst: 0.24223334
	avg: 0.25087
	best: 0.25335

Starting e_i: 1020
Model ind 579 epoch 1020 head B head_i_epoch 0 batch 0: avg loss -2.089086 avg loss no lamb -2.089086 time 2019-02-16 06:41:36.565921
Model ind 579 epoch 1020 head B head_i_epoch 0 batch 100: avg loss -1.952139 avg loss no lamb -1.952139 time 2019-02-16 06:44:26.259460
Model ind 579 epoch 1020 head B head_i_epoch 0 batch 200: avg loss -1.919297 avg loss no lamb -1.919297 time 2019-02-16 06:47:15.798456
Model ind 579 epoch 1020 head A head_i_epoch 0 batch 0: avg loss -3.574610 avg loss no lamb -3.574610 time 2019-02-16 06:50:05.900968
Model ind 579 epoch 1020 head A head_i_epoch 0 batch 100: avg loss -3.577726 avg loss no lamb -3.577726 time 2019-02-16 06:52:57.971206
Model ind 579 epoch 1020 head A head_i_epoch 0 batch 200: avg loss -3.624451 avg loss no lamb -3.624451 time 2019-02-16 06:55:49.603685
Pre: time 2019-02-16 06:59:05.237969: 
 	std: 0.004373359
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25263333, 0.2528, 0.24188334, 0.2528, 0.25301668]
	train_accs: [0.25263333, 0.2528, 0.24188334, 0.2528, 0.25301668]
	best_train_sub_head: 4
	worst: 0.24188334
	avg: 0.25062665
	best: 0.25301668

Starting e_i: 1021
Model ind 579 epoch 1021 head B head_i_epoch 0 batch 0: avg loss -2.102332 avg loss no lamb -2.102332 time 2019-02-16 06:59:12.820287
Model ind 579 epoch 1021 head B head_i_epoch 0 batch 100: avg loss -1.936210 avg loss no lamb -1.936210 time 2019-02-16 07:02:02.592696
Model ind 579 epoch 1021 head B head_i_epoch 0 batch 200: avg loss -1.909121 avg loss no lamb -1.909121 time 2019-02-16 07:04:54.001611
Model ind 579 epoch 1021 head A head_i_epoch 0 batch 0: avg loss -3.640740 avg loss no lamb -3.640740 time 2019-02-16 07:07:45.628803
Model ind 579 epoch 1021 head A head_i_epoch 0 batch 100: avg loss -3.710334 avg loss no lamb -3.710334 time 2019-02-16 07:10:37.389891
Model ind 579 epoch 1021 head A head_i_epoch 0 batch 200: avg loss -3.595425 avg loss no lamb -3.595425 time 2019-02-16 07:13:29.143447
Pre: time 2019-02-16 07:16:44.209319: 
 	std: 0.0045109754
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25423333, 0.25376666, 0.2427, 0.25388333, 0.254]
	train_accs: [0.25423333, 0.25376666, 0.2427, 0.25388333, 0.254]
	best_train_sub_head: 0
	worst: 0.2427
	avg: 0.25171667
	best: 0.25423333

Starting e_i: 1022
Model ind 579 epoch 1022 head B head_i_epoch 0 batch 0: avg loss -2.002406 avg loss no lamb -2.002406 time 2019-02-16 07:16:48.133206
Model ind 579 epoch 1022 head B head_i_epoch 0 batch 100: avg loss -2.032081 avg loss no lamb -2.032081 time 2019-02-16 07:19:38.067499
Model ind 579 epoch 1022 head B head_i_epoch 0 batch 200: avg loss -1.905034 avg loss no lamb -1.905034 time 2019-02-16 07:22:28.258088
Model ind 579 epoch 1022 head A head_i_epoch 0 batch 0: avg loss -3.618089 avg loss no lamb -3.618089 time 2019-02-16 07:25:18.943005
Model ind 579 epoch 1022 head A head_i_epoch 0 batch 100: avg loss -3.664586 avg loss no lamb -3.664586 time 2019-02-16 07:28:10.774973
Model ind 579 epoch 1022 head A head_i_epoch 0 batch 200: avg loss -3.611315 avg loss no lamb -3.611315 time 2019-02-16 07:31:02.652496
Pre: time 2019-02-16 07:34:17.766122: 
 	std: 0.0045825345
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25445, 0.2544, 0.24303333, 0.25476667, 0.25431666]
	train_accs: [0.25445, 0.2544, 0.24303333, 0.25476667, 0.25431666]
	best_train_sub_head: 3
	worst: 0.24303333
	avg: 0.25219333
	best: 0.25476667

Starting e_i: 1023
Model ind 579 epoch 1023 head B head_i_epoch 0 batch 0: avg loss -1.976354 avg loss no lamb -1.976354 time 2019-02-16 07:34:21.602540
Model ind 579 epoch 1023 head B head_i_epoch 0 batch 100: avg loss -1.965013 avg loss no lamb -1.965013 time 2019-02-16 07:37:12.320984
Model ind 579 epoch 1023 head B head_i_epoch 0 batch 200: avg loss -2.025914 avg loss no lamb -2.025914 time 2019-02-16 07:40:03.219397
Model ind 579 epoch 1023 head A head_i_epoch 0 batch 0: avg loss -3.646214 avg loss no lamb -3.646214 time 2019-02-16 07:42:53.555190
Model ind 579 epoch 1023 head A head_i_epoch 0 batch 100: avg loss -3.661517 avg loss no lamb -3.661517 time 2019-02-16 07:45:45.094797
Model ind 579 epoch 1023 head A head_i_epoch 0 batch 200: avg loss -3.578154 avg loss no lamb -3.578154 time 2019-02-16 07:48:36.068429
Pre: time 2019-02-16 07:51:49.747819: 
 	std: 0.004661249
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25608334, 0.25636667, 0.24473333, 0.25651667, 0.25655]
	train_accs: [0.25608334, 0.25636667, 0.24473333, 0.25651667, 0.25655]
	best_train_sub_head: 4
	worst: 0.24473333
	avg: 0.25405002
	best: 0.25655

Starting e_i: 1024
Model ind 579 epoch 1024 head B head_i_epoch 0 batch 0: avg loss -2.096952 avg loss no lamb -2.096952 time 2019-02-16 07:51:53.675129
Model ind 579 epoch 1024 head B head_i_epoch 0 batch 100: avg loss -2.025931 avg loss no lamb -2.025931 time 2019-02-16 07:54:43.254871
Model ind 579 epoch 1024 head B head_i_epoch 0 batch 200: avg loss -2.012018 avg loss no lamb -2.012018 time 2019-02-16 07:57:32.495810
Model ind 579 epoch 1024 head A head_i_epoch 0 batch 0: avg loss -3.661508 avg loss no lamb -3.661508 time 2019-02-16 08:00:22.089834
Model ind 579 epoch 1024 head A head_i_epoch 0 batch 100: avg loss -3.585726 avg loss no lamb -3.585726 time 2019-02-16 08:03:12.983643
Model ind 579 epoch 1024 head A head_i_epoch 0 batch 200: avg loss -3.539871 avg loss no lamb -3.539871 time 2019-02-16 08:06:04.180233
Pre: time 2019-02-16 08:09:18.542574: 
 	std: 0.004544245
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25478333, 0.25476667, 0.2434, 0.25488332, 0.2546]
	train_accs: [0.25478333, 0.25476667, 0.2434, 0.25488332, 0.2546]
	best_train_sub_head: 3
	worst: 0.2434
	avg: 0.25248665
	best: 0.25488332

Starting e_i: 1025
Model ind 579 epoch 1025 head B head_i_epoch 0 batch 0: avg loss -1.951028 avg loss no lamb -1.951028 time 2019-02-16 08:09:22.380879
Model ind 579 epoch 1025 head B head_i_epoch 0 batch 100: avg loss -1.990727 avg loss no lamb -1.990727 time 2019-02-16 08:12:13.798343
Model ind 579 epoch 1025 head B head_i_epoch 0 batch 200: avg loss -1.935778 avg loss no lamb -1.935778 time 2019-02-16 08:15:05.695587
Model ind 579 epoch 1025 head A head_i_epoch 0 batch 0: avg loss -3.605858 avg loss no lamb -3.605858 time 2019-02-16 08:17:55.897427
Model ind 579 epoch 1025 head A head_i_epoch 0 batch 100: avg loss -3.690285 avg loss no lamb -3.690285 time 2019-02-16 08:20:49.415557
Model ind 579 epoch 1025 head A head_i_epoch 0 batch 200: avg loss -3.560145 avg loss no lamb -3.560145 time 2019-02-16 08:23:40.942396
Pre: time 2019-02-16 08:26:55.373722: 
 	std: 0.0044627516
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.2538, 0.25395, 0.24281667, 0.25405, 0.25408334]
	train_accs: [0.2538, 0.25395, 0.24281667, 0.25405, 0.25408334]
	best_train_sub_head: 4
	worst: 0.24281667
	avg: 0.25174004
	best: 0.25408334

Starting e_i: 1026
Model ind 579 epoch 1026 head B head_i_epoch 0 batch 0: avg loss -2.041571 avg loss no lamb -2.041571 time 2019-02-16 08:26:59.177643
Model ind 579 epoch 1026 head B head_i_epoch 0 batch 100: avg loss -1.944118 avg loss no lamb -1.944118 time 2019-02-16 08:29:48.444031
Model ind 579 epoch 1026 head B head_i_epoch 0 batch 200: avg loss -1.975644 avg loss no lamb -1.975644 time 2019-02-16 08:32:38.868802
Model ind 579 epoch 1026 head A head_i_epoch 0 batch 0: avg loss -3.595055 avg loss no lamb -3.595055 time 2019-02-16 08:35:28.329357
Model ind 579 epoch 1026 head A head_i_epoch 0 batch 100: avg loss -3.615253 avg loss no lamb -3.615253 time 2019-02-16 08:38:19.647751
Model ind 579 epoch 1026 head A head_i_epoch 0 batch 200: avg loss -3.594063 avg loss no lamb -3.594063 time 2019-02-16 08:41:11.263705
Pre: time 2019-02-16 08:44:24.431682: 
 	std: 0.004563057
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25513333, 0.25565, 0.24396667, 0.2553, 0.25538334]
	train_accs: [0.25513333, 0.25565, 0.24396667, 0.2553, 0.25538334]
	best_train_sub_head: 1
	worst: 0.24396667
	avg: 0.2530867
	best: 0.25565

Starting e_i: 1027
Model ind 579 epoch 1027 head B head_i_epoch 0 batch 0: avg loss -1.992763 avg loss no lamb -1.992763 time 2019-02-16 08:44:28.332374
Model ind 579 epoch 1027 head B head_i_epoch 0 batch 100: avg loss -1.952481 avg loss no lamb -1.952481 time 2019-02-16 08:47:18.390023
Model ind 579 epoch 1027 head B head_i_epoch 0 batch 200: avg loss -1.936544 avg loss no lamb -1.936544 time 2019-02-16 08:50:09.969635
Model ind 579 epoch 1027 head A head_i_epoch 0 batch 0: avg loss -3.682284 avg loss no lamb -3.682284 time 2019-02-16 08:52:59.404925
Model ind 579 epoch 1027 head A head_i_epoch 0 batch 100: avg loss -3.650366 avg loss no lamb -3.650366 time 2019-02-16 08:55:50.839157
Model ind 579 epoch 1027 head A head_i_epoch 0 batch 200: avg loss -3.588030 avg loss no lamb -3.588030 time 2019-02-16 08:58:42.740375
Pre: time 2019-02-16 09:01:58.024293: 
 	std: 0.004597145
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2544, 0.25445, 0.24315, 0.25485, 0.25483334]
	train_accs: [0.2544, 0.25445, 0.24315, 0.25485, 0.25483334]
	best_train_sub_head: 3
	worst: 0.24315
	avg: 0.25233668
	best: 0.25485

Starting e_i: 1028
Model ind 579 epoch 1028 head B head_i_epoch 0 batch 0: avg loss -1.976613 avg loss no lamb -1.976613 time 2019-02-16 09:02:02.039405
Model ind 579 epoch 1028 head B head_i_epoch 0 batch 100: avg loss -1.926735 avg loss no lamb -1.926735 time 2019-02-16 09:04:53.610525
Model ind 579 epoch 1028 head B head_i_epoch 0 batch 200: avg loss -1.965773 avg loss no lamb -1.965773 time 2019-02-16 09:07:43.993236
Model ind 579 epoch 1028 head A head_i_epoch 0 batch 0: avg loss -3.618370 avg loss no lamb -3.618370 time 2019-02-16 09:10:37.867427
Model ind 579 epoch 1028 head A head_i_epoch 0 batch 100: avg loss -3.642959 avg loss no lamb -3.642959 time 2019-02-16 09:13:30.147296
Model ind 579 epoch 1028 head A head_i_epoch 0 batch 200: avg loss -3.651387 avg loss no lamb -3.651387 time 2019-02-16 09:16:24.025851
Pre: time 2019-02-16 09:19:39.218845: 
 	std: 0.004712305
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25551668, 0.25571668, 0.24405, 0.25601667, 0.25603333]
	train_accs: [0.25551668, 0.25571668, 0.24405, 0.25601667, 0.25603333]
	best_train_sub_head: 4
	worst: 0.24405
	avg: 0.25346667
	best: 0.25603333

Starting e_i: 1029
Model ind 579 epoch 1029 head B head_i_epoch 0 batch 0: avg loss -1.988669 avg loss no lamb -1.988669 time 2019-02-16 09:19:43.156408
Model ind 579 epoch 1029 head B head_i_epoch 0 batch 100: avg loss -2.008712 avg loss no lamb -2.008712 time 2019-02-16 09:22:33.525689
Model ind 579 epoch 1029 head B head_i_epoch 0 batch 200: avg loss -2.100616 avg loss no lamb -2.100616 time 2019-02-16 09:25:25.588495
Model ind 579 epoch 1029 head A head_i_epoch 0 batch 0: avg loss -3.593412 avg loss no lamb -3.593412 time 2019-02-16 09:28:16.255123
Model ind 579 epoch 1029 head A head_i_epoch 0 batch 100: avg loss -3.599989 avg loss no lamb -3.599989 time 2019-02-16 09:31:08.720180
Model ind 579 epoch 1029 head A head_i_epoch 0 batch 200: avg loss -3.591476 avg loss no lamb -3.591476 time 2019-02-16 09:34:01.081293
Pre: time 2019-02-16 09:37:15.768167: 
 	std: 0.0046882685
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25663334, 0.25693333, 0.24511667, 0.25678334, 0.25698334]
	train_accs: [0.25663334, 0.25693333, 0.24511667, 0.25678334, 0.25698334]
	best_train_sub_head: 4
	worst: 0.24511667
	avg: 0.25449
	best: 0.25698334

Starting e_i: 1030
Model ind 579 epoch 1030 head B head_i_epoch 0 batch 0: avg loss -2.011052 avg loss no lamb -2.011052 time 2019-02-16 09:37:19.560050
Model ind 579 epoch 1030 head B head_i_epoch 0 batch 100: avg loss -2.051176 avg loss no lamb -2.051176 time 2019-02-16 09:40:09.300883
Model ind 579 epoch 1030 head B head_i_epoch 0 batch 200: avg loss -2.029108 avg loss no lamb -2.029108 time 2019-02-16 09:42:58.777582
Model ind 579 epoch 1030 head A head_i_epoch 0 batch 0: avg loss -3.621724 avg loss no lamb -3.621724 time 2019-02-16 09:45:48.208988
Model ind 579 epoch 1030 head A head_i_epoch 0 batch 100: avg loss -3.633836 avg loss no lamb -3.633836 time 2019-02-16 09:48:38.727558
Model ind 579 epoch 1030 head A head_i_epoch 0 batch 200: avg loss -3.657212 avg loss no lamb -3.657212 time 2019-02-16 09:51:28.720319
Pre: time 2019-02-16 09:54:42.779235: 
 	std: 0.004740788
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25448334, 0.25463334, 0.24263333, 0.25436667, 0.25445]
	train_accs: [0.25448334, 0.25463334, 0.24263333, 0.25436667, 0.25445]
	best_train_sub_head: 1
	worst: 0.24263333
	avg: 0.2521133
	best: 0.25463334

Starting e_i: 1031
Model ind 579 epoch 1031 head B head_i_epoch 0 batch 0: avg loss -2.013979 avg loss no lamb -2.013979 time 2019-02-16 09:54:49.977202
Model ind 579 epoch 1031 head B head_i_epoch 0 batch 100: avg loss -1.929905 avg loss no lamb -1.929905 time 2019-02-16 09:57:40.502820
Model ind 579 epoch 1031 head B head_i_epoch 0 batch 200: avg loss -1.940377 avg loss no lamb -1.940377 time 2019-02-16 10:00:31.059819
Model ind 579 epoch 1031 head A head_i_epoch 0 batch 0: avg loss -3.591806 avg loss no lamb -3.591806 time 2019-02-16 10:03:21.269516
Model ind 579 epoch 1031 head A head_i_epoch 0 batch 100: avg loss -3.661802 avg loss no lamb -3.661802 time 2019-02-16 10:06:12.389929
Model ind 579 epoch 1031 head A head_i_epoch 0 batch 200: avg loss -3.594775 avg loss no lamb -3.594775 time 2019-02-16 10:09:04.706698
Pre: time 2019-02-16 10:12:21.019579: 
 	std: 0.0049804505
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25461668, 0.25546667, 0.24256666, 0.25513333, 0.25476667]
	train_accs: [0.25461668, 0.25546667, 0.24256666, 0.25513333, 0.25476667]
	best_train_sub_head: 1
	worst: 0.24256666
	avg: 0.25251
	best: 0.25546667

Starting e_i: 1032
Model ind 579 epoch 1032 head B head_i_epoch 0 batch 0: avg loss -2.060657 avg loss no lamb -2.060657 time 2019-02-16 10:12:24.999396
Model ind 579 epoch 1032 head B head_i_epoch 0 batch 100: avg loss -1.955585 avg loss no lamb -1.955585 time 2019-02-16 10:15:15.320654
Model ind 579 epoch 1032 head B head_i_epoch 0 batch 200: avg loss -1.907488 avg loss no lamb -1.907488 time 2019-02-16 10:18:06.794867
Model ind 579 epoch 1032 head A head_i_epoch 0 batch 0: avg loss -3.578813 avg loss no lamb -3.578813 time 2019-02-16 10:20:57.002770
Model ind 579 epoch 1032 head A head_i_epoch 0 batch 100: avg loss -3.653338 avg loss no lamb -3.653338 time 2019-02-16 10:23:48.485890
Model ind 579 epoch 1032 head A head_i_epoch 0 batch 200: avg loss -3.606234 avg loss no lamb -3.606234 time 2019-02-16 10:26:39.941809
Pre: time 2019-02-16 10:29:57.246390: 
 	std: 0.004770169
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25343335, 0.25381666, 0.2417, 0.2537, 0.25353333]
	train_accs: [0.25343335, 0.25381666, 0.2417, 0.2537, 0.25353333]
	best_train_sub_head: 1
	worst: 0.2417
	avg: 0.25123668
	best: 0.25381666

Starting e_i: 1033
Model ind 579 epoch 1033 head B head_i_epoch 0 batch 0: avg loss -2.027945 avg loss no lamb -2.027945 time 2019-02-16 10:30:01.160724
Model ind 579 epoch 1033 head B head_i_epoch 0 batch 100: avg loss -1.996297 avg loss no lamb -1.996297 time 2019-02-16 10:32:51.947659
Model ind 579 epoch 1033 head B head_i_epoch 0 batch 200: avg loss -1.998882 avg loss no lamb -1.998882 time 2019-02-16 10:35:41.744353
Model ind 579 epoch 1033 head A head_i_epoch 0 batch 0: avg loss -3.593263 avg loss no lamb -3.593263 time 2019-02-16 10:38:31.992341
Model ind 579 epoch 1033 head A head_i_epoch 0 batch 100: avg loss -3.636149 avg loss no lamb -3.636149 time 2019-02-16 10:41:23.614375
Model ind 579 epoch 1033 head A head_i_epoch 0 batch 200: avg loss -3.609212 avg loss no lamb -3.609212 time 2019-02-16 10:44:14.602032
Pre: time 2019-02-16 10:47:29.367318: 
 	std: 0.0047424347
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25525, 0.25525, 0.24331667, 0.25501665, 0.25516668]
	train_accs: [0.25525, 0.25525, 0.24331667, 0.25501665, 0.25516668]
	best_train_sub_head: 0
	worst: 0.24331667
	avg: 0.2528
	best: 0.25525

Starting e_i: 1034
Model ind 579 epoch 1034 head B head_i_epoch 0 batch 0: avg loss -2.122771 avg loss no lamb -2.122771 time 2019-02-16 10:47:33.120460
Model ind 579 epoch 1034 head B head_i_epoch 0 batch 100: avg loss -2.017473 avg loss no lamb -2.017473 time 2019-02-16 10:50:22.344352
Model ind 579 epoch 1034 head B head_i_epoch 0 batch 200: avg loss -2.026862 avg loss no lamb -2.026862 time 2019-02-16 10:53:09.813946
Model ind 579 epoch 1034 head A head_i_epoch 0 batch 0: avg loss -3.620938 avg loss no lamb -3.620938 time 2019-02-16 10:55:55.920638
Model ind 579 epoch 1034 head A head_i_epoch 0 batch 100: avg loss -3.668555 avg loss no lamb -3.668555 time 2019-02-16 10:58:43.754650
Model ind 579 epoch 1034 head A head_i_epoch 0 batch 200: avg loss -3.578266 avg loss no lamb -3.578266 time 2019-02-16 11:01:34.180002
Pre: time 2019-02-16 11:04:44.413226: 
 	std: 0.0047464184
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2555, 0.25551668, 0.24365, 0.2557, 0.25533333]
	train_accs: [0.2555, 0.25551668, 0.24365, 0.2557, 0.25533333]
	best_train_sub_head: 3
	worst: 0.24365
	avg: 0.25314
	best: 0.2557

Starting e_i: 1035
Model ind 579 epoch 1035 head B head_i_epoch 0 batch 0: avg loss -1.977982 avg loss no lamb -1.977982 time 2019-02-16 11:04:48.112376
Model ind 579 epoch 1035 head B head_i_epoch 0 batch 100: avg loss -2.042956 avg loss no lamb -2.042956 time 2019-02-16 11:07:40.878926
Model ind 579 epoch 1035 head B head_i_epoch 0 batch 200: avg loss -1.911854 avg loss no lamb -1.911854 time 2019-02-16 11:10:33.752712
Model ind 579 epoch 1035 head A head_i_epoch 0 batch 0: avg loss -3.550886 avg loss no lamb -3.550886 time 2019-02-16 11:13:28.005457
Model ind 579 epoch 1035 head A head_i_epoch 0 batch 100: avg loss -3.694773 avg loss no lamb -3.694773 time 2019-02-16 11:16:22.844883
Model ind 579 epoch 1035 head A head_i_epoch 0 batch 200: avg loss -3.610936 avg loss no lamb -3.610936 time 2019-02-16 11:19:17.144691
Pre: time 2019-02-16 11:22:36.282593: 
 	std: 0.0044235177
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25405, 0.25441667, 0.24315, 0.25425, 0.2541]
	train_accs: [0.25405, 0.25441667, 0.24315, 0.25425, 0.2541]
	best_train_sub_head: 1
	worst: 0.24315
	avg: 0.25199333
	best: 0.25441667

Starting e_i: 1036
Model ind 579 epoch 1036 head B head_i_epoch 0 batch 0: avg loss -2.013174 avg loss no lamb -2.013174 time 2019-02-16 11:22:40.199495
Model ind 579 epoch 1036 head B head_i_epoch 0 batch 100: avg loss -1.995292 avg loss no lamb -1.995292 time 2019-02-16 11:25:33.664349
Model ind 579 epoch 1036 head B head_i_epoch 0 batch 200: avg loss -1.931351 avg loss no lamb -1.931351 time 2019-02-16 11:28:26.998559
Model ind 579 epoch 1036 head A head_i_epoch 0 batch 0: avg loss -3.600949 avg loss no lamb -3.600949 time 2019-02-16 11:31:21.557462
Model ind 579 epoch 1036 head A head_i_epoch 0 batch 100: avg loss -3.574472 avg loss no lamb -3.574472 time 2019-02-16 11:34:15.607917
Model ind 579 epoch 1036 head A head_i_epoch 0 batch 200: avg loss -3.564193 avg loss no lamb -3.564193 time 2019-02-16 11:37:10.540958
Pre: time 2019-02-16 11:40:28.882465: 
 	std: 0.0042431015
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25311667, 0.25328332, 0.24253333, 0.2532, 0.25295]
	train_accs: [0.25311667, 0.25328332, 0.24253333, 0.2532, 0.25295]
	best_train_sub_head: 1
	worst: 0.24253333
	avg: 0.25101668
	best: 0.25328332

Starting e_i: 1037
Model ind 579 epoch 1037 head B head_i_epoch 0 batch 0: avg loss -2.005313 avg loss no lamb -2.005313 time 2019-02-16 11:40:32.844090
Model ind 579 epoch 1037 head B head_i_epoch 0 batch 100: avg loss -1.947511 avg loss no lamb -1.947511 time 2019-02-16 11:43:27.095434
Model ind 579 epoch 1037 head B head_i_epoch 0 batch 200: avg loss -1.951048 avg loss no lamb -1.951048 time 2019-02-16 11:46:20.608394
Model ind 579 epoch 1037 head A head_i_epoch 0 batch 0: avg loss -3.653180 avg loss no lamb -3.653180 time 2019-02-16 11:49:16.081327
Model ind 579 epoch 1037 head A head_i_epoch 0 batch 100: avg loss -3.623747 avg loss no lamb -3.623747 time 2019-02-16 11:52:12.023080
Model ind 579 epoch 1037 head A head_i_epoch 0 batch 200: avg loss -3.614036 avg loss no lamb -3.614036 time 2019-02-16 11:55:06.183830
Pre: time 2019-02-16 11:58:26.783192: 
 	std: 0.004223884
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25408334, 0.25441667, 0.2436, 0.25408334, 0.25403333]
	train_accs: [0.25408334, 0.25441667, 0.2436, 0.25408334, 0.25403333]
	best_train_sub_head: 1
	worst: 0.2436
	avg: 0.25204334
	best: 0.25441667

Starting e_i: 1038
Model ind 579 epoch 1038 head B head_i_epoch 0 batch 0: avg loss -2.053591 avg loss no lamb -2.053591 time 2019-02-16 11:58:30.770670
Model ind 579 epoch 1038 head B head_i_epoch 0 batch 100: avg loss -1.979456 avg loss no lamb -1.979456 time 2019-02-16 12:01:26.444178
Model ind 579 epoch 1038 head B head_i_epoch 0 batch 200: avg loss -2.018705 avg loss no lamb -2.018705 time 2019-02-16 12:04:19.691319
Model ind 579 epoch 1038 head A head_i_epoch 0 batch 0: avg loss -3.666283 avg loss no lamb -3.666283 time 2019-02-16 12:07:12.889662
Model ind 579 epoch 1038 head A head_i_epoch 0 batch 100: avg loss -3.631777 avg loss no lamb -3.631777 time 2019-02-16 12:10:07.492249
Model ind 579 epoch 1038 head A head_i_epoch 0 batch 200: avg loss -3.648268 avg loss no lamb -3.648268 time 2019-02-16 12:13:04.187386
Pre: time 2019-02-16 12:16:22.033550: 
 	std: 0.004787304
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25455, 0.25426668, 0.24236667, 0.2541, 0.2544]
	train_accs: [0.25455, 0.25426668, 0.24236667, 0.2541, 0.2544]
	best_train_sub_head: 0
	worst: 0.24236667
	avg: 0.25193667
	best: 0.25455

Starting e_i: 1039
Model ind 579 epoch 1039 head B head_i_epoch 0 batch 0: avg loss -2.000278 avg loss no lamb -2.000278 time 2019-02-16 12:16:26.245591
Model ind 579 epoch 1039 head B head_i_epoch 0 batch 100: avg loss -1.970903 avg loss no lamb -1.970903 time 2019-02-16 12:19:22.618645
Model ind 579 epoch 1039 head B head_i_epoch 0 batch 200: avg loss -1.974664 avg loss no lamb -1.974664 time 2019-02-16 12:22:17.332389
Model ind 579 epoch 1039 head A head_i_epoch 0 batch 0: avg loss -3.606663 avg loss no lamb -3.606663 time 2019-02-16 12:25:12.606867
Model ind 579 epoch 1039 head A head_i_epoch 0 batch 100: avg loss -3.692804 avg loss no lamb -3.692804 time 2019-02-16 12:28:07.682905
Model ind 579 epoch 1039 head A head_i_epoch 0 batch 200: avg loss -3.648502 avg loss no lamb -3.648502 time 2019-02-16 12:31:02.571088
Pre: time 2019-02-16 12:34:20.873173: 
 	std: 0.004404023
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25596666, 0.25541666, 0.24461667, 0.2555, 0.25558335]
	train_accs: [0.25596666, 0.25541666, 0.24461667, 0.2555, 0.25558335]
	best_train_sub_head: 0
	worst: 0.24461667
	avg: 0.2534167
	best: 0.25596666

Starting e_i: 1040
Model ind 579 epoch 1040 head B head_i_epoch 0 batch 0: avg loss -2.050429 avg loss no lamb -2.050429 time 2019-02-16 12:34:24.853573
Model ind 579 epoch 1040 head B head_i_epoch 0 batch 100: avg loss -1.998021 avg loss no lamb -1.998021 time 2019-02-16 12:37:20.044194
Model ind 579 epoch 1040 head B head_i_epoch 0 batch 200: avg loss -2.023358 avg loss no lamb -2.023358 time 2019-02-16 12:40:14.244459
Model ind 579 epoch 1040 head A head_i_epoch 0 batch 0: avg loss -3.593617 avg loss no lamb -3.593617 time 2019-02-16 12:43:08.741927
Model ind 579 epoch 1040 head A head_i_epoch 0 batch 100: avg loss -3.677580 avg loss no lamb -3.677580 time 2019-02-16 12:46:05.510162
Model ind 579 epoch 1040 head A head_i_epoch 0 batch 200: avg loss -3.617123 avg loss no lamb -3.617123 time 2019-02-16 12:49:01.120320
Pre: time 2019-02-16 12:52:21.656336: 
 	std: 0.004586774
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25471666, 0.25491667, 0.24335, 0.25463334, 0.25498334]
	train_accs: [0.25471666, 0.25491667, 0.24335, 0.25463334, 0.25498334]
	best_train_sub_head: 4
	worst: 0.24335
	avg: 0.25252
	best: 0.25498334

Starting e_i: 1041
Model ind 579 epoch 1041 head B head_i_epoch 0 batch 0: avg loss -1.996117 avg loss no lamb -1.996117 time 2019-02-16 12:52:28.665621
Model ind 579 epoch 1041 head B head_i_epoch 0 batch 100: avg loss -1.893119 avg loss no lamb -1.893119 time 2019-02-16 12:55:22.615058
Model ind 579 epoch 1041 head B head_i_epoch 0 batch 200: avg loss -1.920975 avg loss no lamb -1.920975 time 2019-02-16 12:58:16.953987
Model ind 579 epoch 1041 head A head_i_epoch 0 batch 0: avg loss -3.560845 avg loss no lamb -3.560845 time 2019-02-16 13:01:10.652787
Model ind 579 epoch 1041 head A head_i_epoch 0 batch 100: avg loss -3.712719 avg loss no lamb -3.712719 time 2019-02-16 13:04:05.729037
Model ind 579 epoch 1041 head A head_i_epoch 0 batch 200: avg loss -3.632022 avg loss no lamb -3.632022 time 2019-02-16 13:07:01.209867
Pre: time 2019-02-16 13:10:21.800198: 
 	std: 0.004126027
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25303334, 0.25331667, 0.24286667, 0.25321665, 0.25315]
	train_accs: [0.25303334, 0.25331667, 0.24286667, 0.25321665, 0.25315]
	best_train_sub_head: 1
	worst: 0.24286667
	avg: 0.25111666
	best: 0.25331667

Starting e_i: 1042
Model ind 579 epoch 1042 head B head_i_epoch 0 batch 0: avg loss -2.037974 avg loss no lamb -2.037974 time 2019-02-16 13:10:25.798145
Model ind 579 epoch 1042 head B head_i_epoch 0 batch 100: avg loss -1.980569 avg loss no lamb -1.980569 time 2019-02-16 13:13:19.599386
Model ind 579 epoch 1042 head B head_i_epoch 0 batch 200: avg loss -2.020467 avg loss no lamb -2.020467 time 2019-02-16 13:16:13.801690
Model ind 579 epoch 1042 head A head_i_epoch 0 batch 0: avg loss -3.599129 avg loss no lamb -3.599129 time 2019-02-16 13:19:07.771927
Model ind 579 epoch 1042 head A head_i_epoch 0 batch 100: avg loss -3.674318 avg loss no lamb -3.674318 time 2019-02-16 13:22:03.315921
Model ind 579 epoch 1042 head A head_i_epoch 0 batch 200: avg loss -3.606390 avg loss no lamb -3.606390 time 2019-02-16 13:25:00.041484
Pre: time 2019-02-16 13:28:19.999142: 
 	std: 0.004638312
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25465, 0.2546, 0.24318333, 0.2551, 0.25473332]
	train_accs: [0.25465, 0.2546, 0.24318333, 0.2551, 0.25473332]
	best_train_sub_head: 3
	worst: 0.24318333
	avg: 0.25245333
	best: 0.2551

Starting e_i: 1043
Model ind 579 epoch 1043 head B head_i_epoch 0 batch 0: avg loss -2.020231 avg loss no lamb -2.020231 time 2019-02-16 13:28:24.037635
Model ind 579 epoch 1043 head B head_i_epoch 0 batch 100: avg loss -2.102095 avg loss no lamb -2.102095 time 2019-02-16 13:31:18.790669
Model ind 579 epoch 1043 head B head_i_epoch 0 batch 200: avg loss -1.939516 avg loss no lamb -1.939516 time 2019-02-16 13:34:08.770758
Model ind 579 epoch 1043 head A head_i_epoch 0 batch 0: avg loss -3.615386 avg loss no lamb -3.615386 time 2019-02-16 13:36:55.303266
Model ind 579 epoch 1043 head A head_i_epoch 0 batch 100: avg loss -3.632757 avg loss no lamb -3.632757 time 2019-02-16 13:39:50.306081
Model ind 579 epoch 1043 head A head_i_epoch 0 batch 200: avg loss -3.592810 avg loss no lamb -3.592810 time 2019-02-16 13:42:46.359920
Pre: time 2019-02-16 13:46:06.948819: 
 	std: 0.004394304
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25356665, 0.25363332, 0.24251667, 0.25338334, 0.25341666]
	train_accs: [0.25356665, 0.25363332, 0.24251667, 0.25338334, 0.25341666]
	best_train_sub_head: 1
	worst: 0.24251667
	avg: 0.25130332
	best: 0.25363332

Starting e_i: 1044
Model ind 579 epoch 1044 head B head_i_epoch 0 batch 0: avg loss -1.948432 avg loss no lamb -1.948432 time 2019-02-16 13:46:10.890880
Model ind 579 epoch 1044 head B head_i_epoch 0 batch 100: avg loss -2.000989 avg loss no lamb -2.000989 time 2019-02-16 13:49:07.034919
Model ind 579 epoch 1044 head B head_i_epoch 0 batch 200: avg loss -1.944892 avg loss no lamb -1.944892 time 2019-02-16 13:52:01.253151
Model ind 579 epoch 1044 head A head_i_epoch 0 batch 0: avg loss -3.603689 avg loss no lamb -3.603689 time 2019-02-16 13:54:55.869306
Model ind 579 epoch 1044 head A head_i_epoch 0 batch 100: avg loss -3.598731 avg loss no lamb -3.598731 time 2019-02-16 13:57:51.485328
Model ind 579 epoch 1044 head A head_i_epoch 0 batch 200: avg loss -3.631071 avg loss no lamb -3.631071 time 2019-02-16 14:00:47.372970
Pre: time 2019-02-16 14:04:07.787420: 
 	std: 0.00411672
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25405, 0.25446665, 0.24395, 0.25436667, 0.25405]
	train_accs: [0.25405, 0.25446665, 0.24395, 0.25436667, 0.25405]
	best_train_sub_head: 1
	worst: 0.24395
	avg: 0.25217667
	best: 0.25446665

Starting e_i: 1045
Model ind 579 epoch 1045 head B head_i_epoch 0 batch 0: avg loss -1.979408 avg loss no lamb -1.979408 time 2019-02-16 14:04:11.714520
Model ind 579 epoch 1045 head B head_i_epoch 0 batch 100: avg loss -2.047432 avg loss no lamb -2.047432 time 2019-02-16 14:07:06.833999
Model ind 579 epoch 1045 head B head_i_epoch 0 batch 200: avg loss -2.002576 avg loss no lamb -2.002576 time 2019-02-16 14:10:00.872420
Model ind 579 epoch 1045 head A head_i_epoch 0 batch 0: avg loss -3.651472 avg loss no lamb -3.651472 time 2019-02-16 14:12:54.940558
Model ind 579 epoch 1045 head A head_i_epoch 0 batch 100: avg loss -3.623572 avg loss no lamb -3.623572 time 2019-02-16 14:15:50.789319
Model ind 579 epoch 1045 head A head_i_epoch 0 batch 200: avg loss -3.660144 avg loss no lamb -3.660144 time 2019-02-16 14:18:47.426446
Pre: time 2019-02-16 14:22:07.763311: 
 	std: 0.004605734
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2528, 0.25333333, 0.24165, 0.25345, 0.25301668]
	train_accs: [0.2528, 0.25333333, 0.24165, 0.25345, 0.25301668]
	best_train_sub_head: 3
	worst: 0.24165
	avg: 0.25085002
	best: 0.25345

Starting e_i: 1046
Model ind 579 epoch 1046 head B head_i_epoch 0 batch 0: avg loss -2.060479 avg loss no lamb -2.060479 time 2019-02-16 14:22:11.969553
Model ind 579 epoch 1046 head B head_i_epoch 0 batch 100: avg loss -2.059546 avg loss no lamb -2.059546 time 2019-02-16 14:25:07.139406
Model ind 579 epoch 1046 head B head_i_epoch 0 batch 200: avg loss -2.043839 avg loss no lamb -2.043839 time 2019-02-16 14:28:01.885558
Model ind 579 epoch 1046 head A head_i_epoch 0 batch 0: avg loss -3.552824 avg loss no lamb -3.552824 time 2019-02-16 14:30:57.085917
Model ind 579 epoch 1046 head A head_i_epoch 0 batch 100: avg loss -3.645263 avg loss no lamb -3.645263 time 2019-02-16 14:33:53.241467
Model ind 579 epoch 1046 head A head_i_epoch 0 batch 200: avg loss -3.551059 avg loss no lamb -3.551059 time 2019-02-16 14:36:49.078205
Pre: time 2019-02-16 14:40:12.042508: 
 	std: 0.004363692
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25423333, 0.25463334, 0.24346666, 0.25455, 0.25403333]
	train_accs: [0.25423333, 0.25463334, 0.24346666, 0.25455, 0.25403333]
	best_train_sub_head: 1
	worst: 0.24346666
	avg: 0.25218335
	best: 0.25463334

Starting e_i: 1047
Model ind 579 epoch 1047 head B head_i_epoch 0 batch 0: avg loss -1.993074 avg loss no lamb -1.993074 time 2019-02-16 14:40:16.263713
Model ind 579 epoch 1047 head B head_i_epoch 0 batch 100: avg loss -1.902796 avg loss no lamb -1.902796 time 2019-02-16 14:43:11.660125
Model ind 579 epoch 1047 head B head_i_epoch 0 batch 200: avg loss -1.925652 avg loss no lamb -1.925652 time 2019-02-16 14:46:07.244566
Model ind 579 epoch 1047 head A head_i_epoch 0 batch 0: avg loss -3.606704 avg loss no lamb -3.606704 time 2019-02-16 14:49:03.193793
Model ind 579 epoch 1047 head A head_i_epoch 0 batch 100: avg loss -3.694764 avg loss no lamb -3.694764 time 2019-02-16 14:51:59.451595
Model ind 579 epoch 1047 head A head_i_epoch 0 batch 200: avg loss -3.632484 avg loss no lamb -3.632484 time 2019-02-16 14:54:56.414978
Pre: time 2019-02-16 14:58:17.040831: 
 	std: 0.004136672
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25501665, 0.25516668, 0.24466667, 0.25503334, 0.2548]
	train_accs: [0.25501665, 0.25516668, 0.24466667, 0.25503334, 0.2548]
	best_train_sub_head: 1
	worst: 0.24466667
	avg: 0.25293666
	best: 0.25516668

Starting e_i: 1048
Model ind 579 epoch 1048 head B head_i_epoch 0 batch 0: avg loss -1.956017 avg loss no lamb -1.956017 time 2019-02-16 14:58:21.044875
Model ind 579 epoch 1048 head B head_i_epoch 0 batch 100: avg loss -1.963608 avg loss no lamb -1.963608 time 2019-02-16 15:01:16.341750
Model ind 579 epoch 1048 head B head_i_epoch 0 batch 200: avg loss -1.947920 avg loss no lamb -1.947920 time 2019-02-16 15:04:12.038187
Model ind 579 epoch 1048 head A head_i_epoch 0 batch 0: avg loss -3.592795 avg loss no lamb -3.592795 time 2019-02-16 15:07:08.018697
Model ind 579 epoch 1048 head A head_i_epoch 0 batch 100: avg loss -3.585335 avg loss no lamb -3.585335 time 2019-02-16 15:10:03.436569
Model ind 579 epoch 1048 head A head_i_epoch 0 batch 200: avg loss -3.662553 avg loss no lamb -3.662553 time 2019-02-16 15:12:58.934735
Pre: time 2019-02-16 15:16:18.909926: 
 	std: 0.0044551045
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25565, 0.25565, 0.24448334, 0.25561666, 0.25556666]
	train_accs: [0.25565, 0.25565, 0.24448334, 0.25561666, 0.25556666]
	best_train_sub_head: 0
	worst: 0.24448334
	avg: 0.25339332
	best: 0.25565

Starting e_i: 1049
Model ind 579 epoch 1049 head B head_i_epoch 0 batch 0: avg loss -1.964355 avg loss no lamb -1.964355 time 2019-02-16 15:16:22.977993
Model ind 579 epoch 1049 head B head_i_epoch 0 batch 100: avg loss -2.002552 avg loss no lamb -2.002552 time 2019-02-16 15:19:18.260941
Model ind 579 epoch 1049 head B head_i_epoch 0 batch 200: avg loss -1.962990 avg loss no lamb -1.962990 time 2019-02-16 15:22:13.477169
Model ind 579 epoch 1049 head A head_i_epoch 0 batch 0: avg loss -3.624047 avg loss no lamb -3.624047 time 2019-02-16 15:25:07.424350
Model ind 579 epoch 1049 head A head_i_epoch 0 batch 100: avg loss -3.656263 avg loss no lamb -3.656263 time 2019-02-16 15:28:03.692504
Model ind 579 epoch 1049 head A head_i_epoch 0 batch 200: avg loss -3.680050 avg loss no lamb -3.680050 time 2019-02-16 15:30:59.683879
Pre: time 2019-02-16 15:34:19.632120: 
 	std: 0.004222355
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2542, 0.25438333, 0.24368334, 0.2542, 0.25416666]
	train_accs: [0.2542, 0.25438333, 0.24368334, 0.2542, 0.25416666]
	best_train_sub_head: 1
	worst: 0.24368334
	avg: 0.25212663
	best: 0.25438333

Starting e_i: 1050
Model ind 579 epoch 1050 head B head_i_epoch 0 batch 0: avg loss -2.103103 avg loss no lamb -2.103103 time 2019-02-16 15:34:23.696990
Model ind 579 epoch 1050 head B head_i_epoch 0 batch 100: avg loss -1.947920 avg loss no lamb -1.947920 time 2019-02-16 15:37:19.795054
Model ind 579 epoch 1050 head B head_i_epoch 0 batch 200: avg loss -1.973662 avg loss no lamb -1.973662 time 2019-02-16 15:40:15.405121
Model ind 579 epoch 1050 head A head_i_epoch 0 batch 0: avg loss -3.648540 avg loss no lamb -3.648540 time 2019-02-16 15:43:10.459830
Model ind 579 epoch 1050 head A head_i_epoch 0 batch 100: avg loss -3.653012 avg loss no lamb -3.653012 time 2019-02-16 15:46:06.971341
Model ind 579 epoch 1050 head A head_i_epoch 0 batch 200: avg loss -3.618797 avg loss no lamb -3.618797 time 2019-02-16 15:49:02.237267
Pre: time 2019-02-16 15:52:22.210501: 
 	std: 0.0042767804
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2548, 0.25491667, 0.24401666, 0.25468335, 0.2544]
	train_accs: [0.2548, 0.25491667, 0.24401666, 0.25468335, 0.2544]
	best_train_sub_head: 1
	worst: 0.24401666
	avg: 0.25256333
	best: 0.25491667

Starting e_i: 1051
Model ind 579 epoch 1051 head B head_i_epoch 0 batch 0: avg loss -2.003178 avg loss no lamb -2.003178 time 2019-02-16 15:52:29.343620
Model ind 579 epoch 1051 head B head_i_epoch 0 batch 100: avg loss -1.973874 avg loss no lamb -1.973874 time 2019-02-16 15:55:23.481678
Model ind 579 epoch 1051 head B head_i_epoch 0 batch 200: avg loss -1.943403 avg loss no lamb -1.943403 time 2019-02-16 15:58:18.449905
Model ind 579 epoch 1051 head A head_i_epoch 0 batch 0: avg loss -3.624738 avg loss no lamb -3.624738 time 2019-02-16 16:01:12.999879
