Debug: False
Config: Config: -----
data_mean: []
out_dir: /scratch/shared/slow/xuji/iid_private/579
use_second_opt: False
second_opt_mult: 2.0
dataset: CIFAR20
lamb: 1.0
num_epochs: 2000
lr_schedule: []
eval_mode: hung
output_k_B: 20
save_freq: 10
output_k_A: 140
lr_mult: 0.1
input_sz: 32
dataloader_batch_sz: 200
rand_crop_szs_tf: []
in_channels: 2
lr: 0.0001
cutout: False
gt_k: 20
opt: Adam
stl_leave_out_unlabelled: False
double_eval: False
output_k: 20
num_dataloaders: 5
fluid_warp: False
head_B_epochs: 1
num_sub_heads: 5
crop_orig: True
mix_train: False
test_code: False
twohead: True
per_img_demean: False
dataset_root: /scratch/local/ssd/xuji/CIFAR
arch: ClusterNet5gTwoHead
head_A_first: False
restart: False
batch_sz: 1000
out_root: /scratch/shared/slow/xuji/iid_private
model_ind: 579
data_std: []
head_A_epochs: 1
include_rgb: False
demean: False
mode: IID
rand_crop_sz: 20
cutout_max_box: 0.5
rot_val: 0.0
cutout_p: 0.5
----------
(_sobel_multioutput_make_transforms) config.include_rgb: False
not using cutout
not demeaning data
not per image demeaning data
Making datasets with <class 'torchvision.datasets.cifar.CIFAR100'> and <function _cifar100_to_cifar20 at 0x7f94c88e4c08>
Creating auxiliary dataloader ind 0 out of 5 time 2019-01-27 02:55:12.201581
Creating auxiliary dataloader ind 1 out of 5 time 2019-01-27 02:55:13.560696
Creating auxiliary dataloader ind 2 out of 5 time 2019-01-27 02:55:14.910889
Creating auxiliary dataloader ind 3 out of 5 time 2019-01-27 02:55:16.231622
Creating auxiliary dataloader ind 4 out of 5 time 2019-01-27 02:55:17.591784
Length of datasets vector 6
Number of batches per epoch: 300
Creating auxiliary dataloader ind 0 out of 5 time 2019-01-27 02:55:20.234977
Creating auxiliary dataloader ind 1 out of 5 time 2019-01-27 02:55:21.560947
Creating auxiliary dataloader ind 2 out of 5 time 2019-01-27 02:55:22.879862
Creating auxiliary dataloader ind 3 out of 5 time 2019-01-27 02:55:24.217801
Creating auxiliary dataloader ind 4 out of 5 time 2019-01-27 02:55:25.541345
Length of datasets vector 6
Number of batches per epoch: 300
avg_pool_sz 3
semisup: False
Pre: time 2019-01-27 02:55:58.670134: 
 	std: 0.0045395745
	best_train_sub_head_match: [(0, 1), (1, 19), (2, 12), (3, 18), (4, 2), (5, 4), (6, 5), (7, 6), (8, 7), (9, 3), (10, 8), (11, 9), (12, 0), (13, 11), (14, 13), (15, 14), (16, 15), (17, 16), (18, 10), (19, 17)]
	test_accs: [0.05, 0.050566666, 0.061666667, 0.050816666, 0.05]
	train_accs: [0.05, 0.050566666, 0.061666667, 0.050816666, 0.05]
	best_train_sub_head: 2
	worst: 0.05
	avg: 0.052610002
	best: 0.061666667

Starting e_i: 1
Model ind 579 epoch 1 head B head_i_epoch 0 batch 0: avg loss -0.000011 avg loss no lamb -0.000011 time 2019-01-27 02:55:59.869340
Model ind 579 epoch 1 head B head_i_epoch 0 batch 1: avg loss -0.000028 avg loss no lamb -0.000028 time 2019-01-27 02:56:01.645130
Model ind 579 epoch 1 head B head_i_epoch 0 batch 2: avg loss -0.000215 avg loss no lamb -0.000215 time 2019-01-27 02:56:03.339212
Model ind 579 epoch 1 head B head_i_epoch 0 batch 3: avg loss -0.000854 avg loss no lamb -0.000854 time 2019-01-27 02:56:05.084295
Model ind 579 epoch 1 head B head_i_epoch 0 batch 4: avg loss -0.004483 avg loss no lamb -0.004483 time 2019-01-27 02:56:06.799946
Model ind 579 epoch 1 head B head_i_epoch 0 batch 5: avg loss -0.009097 avg loss no lamb -0.009097 time 2019-01-27 02:56:08.531766
Model ind 579 epoch 1 head B head_i_epoch 0 batch 6: avg loss -0.017123 avg loss no lamb -0.017123 time 2019-01-27 02:56:10.214791
Model ind 579 epoch 1 head B head_i_epoch 0 batch 7: avg loss -0.021760 avg loss no lamb -0.021760 time 2019-01-27 02:56:11.911891
Model ind 579 epoch 1 head B head_i_epoch 0 batch 8: avg loss -0.017316 avg loss no lamb -0.017316 time 2019-01-27 02:56:13.606919
Model ind 579 epoch 1 head B head_i_epoch 0 batch 9: avg loss -0.026442 avg loss no lamb -0.026442 time 2019-01-27 02:56:15.297457
Model ind 579 epoch 1 head B head_i_epoch 0 batch 100: avg loss -0.361680 avg loss no lamb -0.361680 time 2019-01-27 02:58:49.680296
Model ind 579 epoch 1 head B head_i_epoch 0 batch 200: avg loss -0.596895 avg loss no lamb -0.596895 time 2019-01-27 03:01:41.498388
Model ind 579 epoch 1 head A head_i_epoch 0 batch 0: avg loss -0.004311 avg loss no lamb -0.004311 time 2019-01-27 03:04:32.349257
Model ind 579 epoch 1 head A head_i_epoch 0 batch 1: avg loss -0.006995 avg loss no lamb -0.006995 time 2019-01-27 03:04:34.102561
Model ind 579 epoch 1 head A head_i_epoch 0 batch 2: avg loss -0.012132 avg loss no lamb -0.012132 time 2019-01-27 03:04:35.899556
Model ind 579 epoch 1 head A head_i_epoch 0 batch 3: avg loss -0.015414 avg loss no lamb -0.015414 time 2019-01-27 03:04:37.682357
Model ind 579 epoch 1 head A head_i_epoch 0 batch 4: avg loss -0.022615 avg loss no lamb -0.022615 time 2019-01-27 03:04:39.438992
Model ind 579 epoch 1 head A head_i_epoch 0 batch 5: avg loss -0.029997 avg loss no lamb -0.029997 time 2019-01-27 03:04:41.181971
Model ind 579 epoch 1 head A head_i_epoch 0 batch 6: avg loss -0.044144 avg loss no lamb -0.044144 time 2019-01-27 03:04:42.948362
Model ind 579 epoch 1 head A head_i_epoch 0 batch 7: avg loss -0.058336 avg loss no lamb -0.058336 time 2019-01-27 03:04:44.701881
Model ind 579 epoch 1 head A head_i_epoch 0 batch 8: avg loss -0.079665 avg loss no lamb -0.079665 time 2019-01-27 03:04:46.477366
Model ind 579 epoch 1 head A head_i_epoch 0 batch 9: avg loss -0.091853 avg loss no lamb -0.091853 time 2019-01-27 03:04:48.234281
Model ind 579 epoch 1 head A head_i_epoch 0 batch 100: avg loss -0.663795 avg loss no lamb -0.663795 time 2019-01-27 03:07:28.425694
Model ind 579 epoch 1 head A head_i_epoch 0 batch 200: avg loss -0.720187 avg loss no lamb -0.720187 time 2019-01-27 03:10:25.430426
Pre: time 2019-01-27 03:13:46.038814: 
 	std: 0.00036003033
	best_train_sub_head_match: [(0, 16), (1, 19), (2, 18), (3, 6), (4, 17), (5, 2), (6, 4), (7, 9), (8, 8), (9, 3), (10, 14), (11, 12), (12, 5), (13, 11), (14, 7), (15, 1), (16, 13), (17, 10), (18, 0), (19, 15)]
	test_accs: [0.103, 0.10216667, 0.10211667, 0.10288333, 0.10255]
	train_accs: [0.103, 0.10216667, 0.10211667, 0.10288333, 0.10255]
	best_train_sub_head: 0
	worst: 0.10211667
	avg: 0.10254333
	best: 0.103

Starting e_i: 2
Model ind 579 epoch 2 head B head_i_epoch 0 batch 0: avg loss -0.682323 avg loss no lamb -0.682323 time 2019-01-27 03:13:52.924817
Model ind 579 epoch 2 head B head_i_epoch 0 batch 100: avg loss -0.719632 avg loss no lamb -0.719632 time 2019-01-27 03:16:48.252005
Model ind 579 epoch 2 head B head_i_epoch 0 batch 200: avg loss -0.718983 avg loss no lamb -0.718983 time 2019-01-27 03:19:43.978710
Model ind 579 epoch 2 head A head_i_epoch 0 batch 0: avg loss -0.682357 avg loss no lamb -0.682357 time 2019-01-27 03:22:39.929907
Model ind 579 epoch 2 head A head_i_epoch 0 batch 100: avg loss -0.882836 avg loss no lamb -0.882836 time 2019-01-27 03:25:37.433043
Model ind 579 epoch 2 head A head_i_epoch 0 batch 200: avg loss -0.849368 avg loss no lamb -0.849368 time 2019-01-27 03:28:36.646095
Pre: time 2019-01-27 03:31:57.553958: 
 	std: 0.0016879505
	best_train_sub_head_match: [(0, 14), (1, 19), (2, 11), (3, 17), (4, 18), (5, 15), (6, 8), (7, 16), (8, 2), (9, 10), (10, 4), (11, 12), (12, 5), (13, 1), (14, 7), (15, 9), (16, 0), (17, 6), (18, 3), (19, 13)]
	test_accs: [0.10813333, 0.10898333, 0.1094, 0.10463333, 0.108216666]
	train_accs: [0.10813333, 0.10898333, 0.1094, 0.10463333, 0.108216666]
	best_train_sub_head: 2
	worst: 0.10463333
	avg: 0.107873335
	best: 0.1094

Starting e_i: 3
Model ind 579 epoch 3 head B head_i_epoch 0 batch 0: avg loss -0.771698 avg loss no lamb -0.771698 time 2019-01-27 03:32:04.893778
Model ind 579 epoch 3 head B head_i_epoch 0 batch 100: avg loss -0.783848 avg loss no lamb -0.783848 time 2019-01-27 03:35:02.865145
Model ind 579 epoch 3 head B head_i_epoch 0 batch 200: avg loss -0.753584 avg loss no lamb -0.753584 time 2019-01-27 03:38:02.536065
Model ind 579 epoch 3 head A head_i_epoch 0 batch 0: avg loss -0.822121 avg loss no lamb -0.822121 time 2019-01-27 03:40:58.740118
Model ind 579 epoch 3 head A head_i_epoch 0 batch 100: avg loss -0.871906 avg loss no lamb -0.871906 time 2019-01-27 03:43:54.471472
Model ind 579 epoch 3 head A head_i_epoch 0 batch 200: avg loss -0.907543 avg loss no lamb -0.907543 time 2019-01-27 03:46:50.310412
Pre: time 2019-01-27 03:50:10.486906: 
 	std: 0.0015040176
	best_train_sub_head_match: [(0, 0), (1, 19), (2, 14), (3, 8), (4, 18), (5, 9), (6, 17), (7, 11), (8, 16), (9, 10), (10, 4), (11, 12), (12, 5), (13, 3), (14, 7), (15, 2), (16, 13), (17, 6), (18, 1), (19, 15)]
	test_accs: [0.10835, 0.11005, 0.11236667, 0.109466664, 0.108216666]
	train_accs: [0.10835, 0.11005, 0.11236667, 0.109466664, 0.108216666]
	best_train_sub_head: 2
	worst: 0.108216666
	avg: 0.109689996
	best: 0.11236667

Starting e_i: 4
Model ind 579 epoch 4 head B head_i_epoch 0 batch 0: avg loss -0.685751 avg loss no lamb -0.685751 time 2019-01-27 03:50:16.883312
Model ind 579 epoch 4 head B head_i_epoch 0 batch 100: avg loss -0.854112 avg loss no lamb -0.854112 time 2019-01-27 03:53:12.223586
Model ind 579 epoch 4 head B head_i_epoch 0 batch 200: avg loss -0.922509 avg loss no lamb -0.922509 time 2019-01-27 03:56:07.383250
Model ind 579 epoch 4 head A head_i_epoch 0 batch 0: avg loss -1.013804 avg loss no lamb -1.013804 time 2019-01-27 03:59:02.586618
Model ind 579 epoch 4 head A head_i_epoch 0 batch 100: avg loss -1.295957 avg loss no lamb -1.295957 time 2019-01-27 04:01:58.751574
Model ind 579 epoch 4 head A head_i_epoch 0 batch 200: avg loss -1.401680 avg loss no lamb -1.401680 time 2019-01-27 04:04:55.253450
Pre: time 2019-01-27 04:08:15.334390: 
 	std: 0.00053555943
	best_train_sub_head_match: [(0, 3), (1, 1), (2, 11), (3, 17), (4, 13), (5, 14), (6, 19), (7, 8), (8, 15), (9, 18), (10, 16), (11, 7), (12, 12), (13, 9), (14, 4), (15, 5), (16, 2), (17, 10), (18, 6), (19, 0)]
	test_accs: [0.11731666, 0.1165, 0.11805, 0.11753333, 0.11686666]
	train_accs: [0.11731666, 0.1165, 0.11805, 0.11753333, 0.11686666]
	best_train_sub_head: 2
	worst: 0.1165
	avg: 0.117253326
	best: 0.11805

Starting e_i: 5
Model ind 579 epoch 5 head B head_i_epoch 0 batch 0: avg loss -0.971066 avg loss no lamb -0.971066 time 2019-01-27 04:08:22.394116
Model ind 579 epoch 5 head B head_i_epoch 0 batch 100: avg loss -0.955596 avg loss no lamb -0.955596 time 2019-01-27 04:11:17.673927
Model ind 579 epoch 5 head B head_i_epoch 0 batch 200: avg loss -0.991634 avg loss no lamb -0.991634 time 2019-01-27 04:14:12.733580
Model ind 579 epoch 5 head A head_i_epoch 0 batch 0: avg loss -1.305143 avg loss no lamb -1.305143 time 2019-01-27 04:17:06.975448
Model ind 579 epoch 5 head A head_i_epoch 0 batch 100: avg loss -1.432299 avg loss no lamb -1.432299 time 2019-01-27 04:20:02.775947
Model ind 579 epoch 5 head A head_i_epoch 0 batch 200: avg loss -1.393378 avg loss no lamb -1.393378 time 2019-01-27 04:22:58.618517
Pre: time 2019-01-27 04:26:18.457038: 
 	std: 0.0010431474
	best_train_sub_head_match: [(0, 11), (1, 18), (2, 12), (3, 15), (4, 19), (5, 3), (6, 0), (7, 8), (8, 16), (9, 10), (10, 1), (11, 17), (12, 13), (13, 9), (14, 6), (15, 2), (16, 7), (17, 4), (18, 14), (19, 5)]
	test_accs: [0.119666666, 0.12105, 0.1228, 0.12151667, 0.121983334]
	train_accs: [0.119666666, 0.12105, 0.1228, 0.12151667, 0.121983334]
	best_train_sub_head: 2
	worst: 0.119666666
	avg: 0.12140334
	best: 0.1228

Starting e_i: 6
Model ind 579 epoch 6 head B head_i_epoch 0 batch 0: avg loss -1.017961 avg loss no lamb -1.017961 time 2019-01-27 04:26:26.292689
Model ind 579 epoch 6 head B head_i_epoch 0 batch 100: avg loss -1.060759 avg loss no lamb -1.060759 time 2019-01-27 04:29:20.973363
Model ind 579 epoch 6 head B head_i_epoch 0 batch 200: avg loss -1.069514 avg loss no lamb -1.069514 time 2019-01-27 04:32:15.335090
Model ind 579 epoch 6 head A head_i_epoch 0 batch 0: avg loss -1.318873 avg loss no lamb -1.318873 time 2019-01-27 04:35:09.781601
Model ind 579 epoch 6 head A head_i_epoch 0 batch 100: avg loss -1.441141 avg loss no lamb -1.441141 time 2019-01-27 04:38:05.949212
Model ind 579 epoch 6 head A head_i_epoch 0 batch 200: avg loss -1.447555 avg loss no lamb -1.447555 time 2019-01-27 04:41:02.274207
Pre: time 2019-01-27 04:44:22.233670: 
 	std: 0.00088891934
	best_train_sub_head_match: [(0, 7), (1, 1), (2, 14), (3, 4), (4, 5), (5, 2), (6, 18), (7, 8), (8, 9), (9, 11), (10, 12), (11, 0), (12, 15), (13, 13), (14, 6), (15, 16), (16, 19), (17, 10), (18, 3), (19, 17)]
	test_accs: [0.121816665, 0.12083333, 0.1218, 0.120233335, 0.11953333]
	train_accs: [0.121816665, 0.12083333, 0.1218, 0.120233335, 0.11953333]
	best_train_sub_head: 0
	worst: 0.11953333
	avg: 0.120843336
	best: 0.121816665

Starting e_i: 7
Model ind 579 epoch 7 head B head_i_epoch 0 batch 0: avg loss -1.144006 avg loss no lamb -1.144006 time 2019-01-27 04:44:24.591724
Model ind 579 epoch 7 head B head_i_epoch 0 batch 100: avg loss -1.075214 avg loss no lamb -1.075214 time 2019-01-27 04:47:19.183771
Model ind 579 epoch 7 head B head_i_epoch 0 batch 200: avg loss -1.165636 avg loss no lamb -1.165636 time 2019-01-27 04:50:14.154657
Model ind 579 epoch 7 head A head_i_epoch 0 batch 0: avg loss -1.456026 avg loss no lamb -1.456026 time 2019-01-27 04:53:09.227405
Model ind 579 epoch 7 head A head_i_epoch 0 batch 100: avg loss -1.426095 avg loss no lamb -1.426095 time 2019-01-27 04:56:05.865154
Model ind 579 epoch 7 head A head_i_epoch 0 batch 200: avg loss -1.498682 avg loss no lamb -1.498682 time 2019-01-27 04:59:02.115294
Pre: time 2019-01-27 05:02:22.315041: 
 	std: 0.001608257
	best_train_sub_head_match: [(0, 12), (1, 1), (2, 8), (3, 18), (4, 19), (5, 16), (6, 6), (7, 17), (8, 14), (9, 10), (10, 13), (11, 15), (12, 9), (13, 7), (14, 3), (15, 5), (16, 0), (17, 4), (18, 11), (19, 2)]
	test_accs: [0.11905, 0.12065, 0.12381667, 0.11998333, 0.12123334]
	train_accs: [0.11905, 0.12065, 0.12381667, 0.11998333, 0.12123334]
	best_train_sub_head: 2
	worst: 0.11905
	avg: 0.12094667
	best: 0.12381667

Starting e_i: 8
Model ind 579 epoch 8 head B head_i_epoch 0 batch 0: avg loss -1.094637 avg loss no lamb -1.094637 time 2019-01-27 05:02:28.553749
Model ind 579 epoch 8 head B head_i_epoch 0 batch 100: avg loss -1.117160 avg loss no lamb -1.117160 time 2019-01-27 05:05:23.846246
Model ind 579 epoch 8 head B head_i_epoch 0 batch 200: avg loss -1.130749 avg loss no lamb -1.130749 time 2019-01-27 05:08:18.028803
Model ind 579 epoch 8 head A head_i_epoch 0 batch 0: avg loss -1.479691 avg loss no lamb -1.479691 time 2019-01-27 05:11:13.272242
Model ind 579 epoch 8 head A head_i_epoch 0 batch 100: avg loss -1.522481 avg loss no lamb -1.522481 time 2019-01-27 05:14:09.853030
Model ind 579 epoch 8 head A head_i_epoch 0 batch 200: avg loss -1.615488 avg loss no lamb -1.615488 time 2019-01-27 05:17:05.696720
Pre: time 2019-01-27 05:20:25.714628: 
 	std: 0.0007856062
	best_train_sub_head_match: [(0, 12), (1, 1), (2, 8), (3, 9), (4, 18), (5, 14), (6, 6), (7, 15), (8, 16), (9, 10), (10, 13), (11, 17), (12, 2), (13, 0), (14, 4), (15, 5), (16, 19), (17, 3), (18, 11), (19, 7)]
	test_accs: [0.12098333, 0.11941667, 0.121533334, 0.1197, 0.12048333]
	train_accs: [0.12098333, 0.11941667, 0.121533334, 0.1197, 0.12048333]
	best_train_sub_head: 2
	worst: 0.11941667
	avg: 0.12042334
	best: 0.121533334

Starting e_i: 9
Model ind 579 epoch 9 head B head_i_epoch 0 batch 0: avg loss -1.130864 avg loss no lamb -1.130864 time 2019-01-27 05:20:28.103145
Model ind 579 epoch 9 head B head_i_epoch 0 batch 100: avg loss -1.158614 avg loss no lamb -1.158614 time 2019-01-27 05:23:23.306396
Model ind 579 epoch 9 head B head_i_epoch 0 batch 200: avg loss -1.171447 avg loss no lamb -1.171447 time 2019-01-27 05:26:18.089560
Model ind 579 epoch 9 head A head_i_epoch 0 batch 0: avg loss -1.539422 avg loss no lamb -1.539422 time 2019-01-27 05:29:12.867380
Model ind 579 epoch 9 head A head_i_epoch 0 batch 100: avg loss -1.621790 avg loss no lamb -1.621790 time 2019-01-27 05:32:09.477758
Model ind 579 epoch 9 head A head_i_epoch 0 batch 200: avg loss -1.606411 avg loss no lamb -1.606411 time 2019-01-27 05:35:06.435198
Pre: time 2019-01-27 05:38:26.844160: 
 	std: 0.00046207182
	best_train_sub_head_match: [(0, 7), (1, 0), (2, 3), (3, 16), (4, 12), (5, 2), (6, 9), (7, 19), (8, 13), (9, 1), (10, 10), (11, 6), (12, 17), (13, 14), (14, 4), (15, 18), (16, 11), (17, 5), (18, 8), (19, 15)]
	test_accs: [0.12106667, 0.1222, 0.1222, 0.12178333, 0.1213]
	train_accs: [0.12106667, 0.1222, 0.1222, 0.12178333, 0.1213]
	best_train_sub_head: 1
	worst: 0.12106667
	avg: 0.12170999
	best: 0.1222

Starting e_i: 10
Model ind 579 epoch 10 head B head_i_epoch 0 batch 0: avg loss -1.146597 avg loss no lamb -1.146597 time 2019-01-27 05:38:29.156731
Model ind 579 epoch 10 head B head_i_epoch 0 batch 100: avg loss -1.170750 avg loss no lamb -1.170750 time 2019-01-27 05:41:23.680420
Model ind 579 epoch 10 head B head_i_epoch 0 batch 200: avg loss -1.146819 avg loss no lamb -1.146819 time 2019-01-27 05:44:19.497066
Model ind 579 epoch 10 head A head_i_epoch 0 batch 0: avg loss -1.641616 avg loss no lamb -1.641616 time 2019-01-27 05:47:15.266747
Model ind 579 epoch 10 head A head_i_epoch 0 batch 100: avg loss -1.697616 avg loss no lamb -1.697616 time 2019-01-27 05:50:11.429355
Model ind 579 epoch 10 head A head_i_epoch 0 batch 200: avg loss -1.721481 avg loss no lamb -1.721481 time 2019-01-27 05:53:07.519757
Pre: time 2019-01-27 05:56:28.641861: 
 	std: 0.00082113803
	best_train_sub_head_match: [(0, 15), (1, 11), (2, 6), (3, 7), (4, 18), (5, 10), (6, 9), (7, 14), (8, 4), (9, 3), (10, 17), (11, 2), (12, 1), (13, 0), (14, 16), (15, 5), (16, 8), (17, 13), (18, 12), (19, 19)]
	test_accs: [0.11976667, 0.11976667, 0.12156667, 0.12058333, 0.121633336]
	train_accs: [0.11976667, 0.11976667, 0.12156667, 0.12058333, 0.121633336]
	best_train_sub_head: 4
	worst: 0.11976667
	avg: 0.12066333
	best: 0.121633336

Starting e_i: 11
Model ind 579 epoch 11 head B head_i_epoch 0 batch 0: avg loss -1.147899 avg loss no lamb -1.147899 time 2019-01-27 05:56:35.321783
Model ind 579 epoch 11 head B head_i_epoch 0 batch 100: avg loss -1.181694 avg loss no lamb -1.181694 time 2019-01-27 05:59:30.474191
Model ind 579 epoch 11 head B head_i_epoch 0 batch 200: avg loss -1.222566 avg loss no lamb -1.222566 time 2019-01-27 06:02:25.355482
Model ind 579 epoch 11 head A head_i_epoch 0 batch 0: avg loss -1.676563 avg loss no lamb -1.676563 time 2019-01-27 06:05:20.985386
Model ind 579 epoch 11 head A head_i_epoch 0 batch 100: avg loss -1.678678 avg loss no lamb -1.678678 time 2019-01-27 06:08:16.768725
Model ind 579 epoch 11 head A head_i_epoch 0 batch 200: avg loss -1.720316 avg loss no lamb -1.720316 time 2019-01-27 06:11:13.142276
Pre: time 2019-01-27 06:14:33.480700: 
 	std: 0.0012356273
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 17), (3, 6), (4, 18), (5, 16), (6, 5), (7, 19), (8, 12), (9, 14), (10, 15), (11, 9), (12, 3), (13, 4), (14, 2), (15, 7), (16, 10), (17, 11), (18, 8), (19, 1)]
	test_accs: [0.12395, 0.12503333, 0.12618333, 0.12246667, 0.12478333]
	train_accs: [0.12395, 0.12503333, 0.12618333, 0.12246667, 0.12478333]
	best_train_sub_head: 2
	worst: 0.12246667
	avg: 0.12448333
	best: 0.12618333

Starting e_i: 12
Model ind 579 epoch 12 head B head_i_epoch 0 batch 0: avg loss -1.183868 avg loss no lamb -1.183868 time 2019-01-27 06:14:39.151080
Model ind 579 epoch 12 head B head_i_epoch 0 batch 100: avg loss -1.182821 avg loss no lamb -1.182821 time 2019-01-27 06:17:34.440277
Model ind 579 epoch 12 head B head_i_epoch 0 batch 200: avg loss -1.190404 avg loss no lamb -1.190404 time 2019-01-27 06:20:28.687589
Model ind 579 epoch 12 head A head_i_epoch 0 batch 0: avg loss -1.708660 avg loss no lamb -1.708660 time 2019-01-27 06:23:23.281768
Model ind 579 epoch 12 head A head_i_epoch 0 batch 100: avg loss -1.721858 avg loss no lamb -1.721858 time 2019-01-27 06:26:19.693219
Model ind 579 epoch 12 head A head_i_epoch 0 batch 200: avg loss -1.784413 avg loss no lamb -1.784413 time 2019-01-27 06:29:15.548858
Pre: time 2019-01-27 06:32:36.282616: 
 	std: 0.0012597453
	best_train_sub_head_match: [(0, 3), (1, 0), (2, 15), (3, 13), (4, 1), (5, 6), (6, 5), (7, 2), (8, 16), (9, 11), (10, 7), (11, 17), (12, 8), (13, 14), (14, 19), (15, 12), (16, 10), (17, 18), (18, 4), (19, 9)]
	test_accs: [0.12696667, 0.12988333, 0.1296, 0.12691666, 0.12808333]
	train_accs: [0.12696667, 0.12988333, 0.1296, 0.12691666, 0.12808333]
	best_train_sub_head: 1
	worst: 0.12691666
	avg: 0.12829
	best: 0.12988333

Starting e_i: 13
Model ind 579 epoch 13 head B head_i_epoch 0 batch 0: avg loss -1.250865 avg loss no lamb -1.250865 time 2019-01-27 06:32:42.859462
Model ind 579 epoch 13 head B head_i_epoch 0 batch 100: avg loss -1.195380 avg loss no lamb -1.195380 time 2019-01-27 06:35:38.456125
Model ind 579 epoch 13 head B head_i_epoch 0 batch 200: avg loss -1.187533 avg loss no lamb -1.187533 time 2019-01-27 06:38:33.211057
Model ind 579 epoch 13 head A head_i_epoch 0 batch 0: avg loss -1.774617 avg loss no lamb -1.774617 time 2019-01-27 06:41:28.309144
Model ind 579 epoch 13 head A head_i_epoch 0 batch 100: avg loss -1.813028 avg loss no lamb -1.813028 time 2019-01-27 06:44:25.278049
Model ind 579 epoch 13 head A head_i_epoch 0 batch 200: avg loss -1.840934 avg loss no lamb -1.840934 time 2019-01-27 06:47:21.940850
Pre: time 2019-01-27 06:50:41.866776: 
 	std: 0.001209618
	best_train_sub_head_match: [(0, 7), (1, 14), (2, 12), (3, 6), (4, 16), (5, 8), (6, 2), (7, 19), (8, 18), (9, 17), (10, 3), (11, 5), (12, 15), (13, 0), (14, 1), (15, 13), (16, 10), (17, 4), (18, 9), (19, 11)]
	test_accs: [0.123783335, 0.121633336, 0.123833336, 0.121583335, 0.124466665]
	train_accs: [0.123783335, 0.121633336, 0.123833336, 0.121583335, 0.124466665]
	best_train_sub_head: 4
	worst: 0.121583335
	avg: 0.12306
	best: 0.124466665

Starting e_i: 14
Model ind 579 epoch 14 head B head_i_epoch 0 batch 0: avg loss -1.202690 avg loss no lamb -1.202690 time 2019-01-27 06:50:44.363594
Model ind 579 epoch 14 head B head_i_epoch 0 batch 100: avg loss -1.324305 avg loss no lamb -1.324305 time 2019-01-27 06:53:38.486765
Model ind 579 epoch 14 head B head_i_epoch 0 batch 200: avg loss -1.225622 avg loss no lamb -1.225622 time 2019-01-27 06:56:33.840289
Model ind 579 epoch 14 head A head_i_epoch 0 batch 0: avg loss -1.878365 avg loss no lamb -1.878365 time 2019-01-27 06:59:28.740607
Model ind 579 epoch 14 head A head_i_epoch 0 batch 100: avg loss -1.898778 avg loss no lamb -1.898778 time 2019-01-27 07:02:24.648175
Model ind 579 epoch 14 head A head_i_epoch 0 batch 200: avg loss -2.014692 avg loss no lamb -2.014692 time 2019-01-27 07:05:21.176960
Pre: time 2019-01-27 07:08:41.728346: 
 	std: 0.0015575485
	best_train_sub_head_match: [(0, 5), (1, 2), (2, 15), (3, 4), (4, 12), (5, 17), (6, 8), (7, 10), (8, 0), (9, 18), (10, 9), (11, 13), (12, 16), (13, 7), (14, 1), (15, 19), (16, 3), (17, 14), (18, 6), (19, 11)]
	test_accs: [0.1288, 0.12998334, 0.12673333, 0.12996666, 0.1314]
	train_accs: [0.1288, 0.12998334, 0.12673333, 0.12996666, 0.1314]
	best_train_sub_head: 4
	worst: 0.12673333
	avg: 0.12937666
	best: 0.1314

Starting e_i: 15
Model ind 579 epoch 15 head B head_i_epoch 0 batch 0: avg loss -1.211262 avg loss no lamb -1.211262 time 2019-01-27 07:08:50.113423
Model ind 579 epoch 15 head B head_i_epoch 0 batch 100: avg loss -1.177978 avg loss no lamb -1.177978 time 2019-01-27 07:11:44.869951
Model ind 579 epoch 15 head B head_i_epoch 0 batch 200: avg loss -1.333225 avg loss no lamb -1.333225 time 2019-01-27 07:14:40.428508
Model ind 579 epoch 15 head A head_i_epoch 0 batch 0: avg loss -1.975851 avg loss no lamb -1.975851 time 2019-01-27 07:17:35.411653
Model ind 579 epoch 15 head A head_i_epoch 0 batch 100: avg loss -2.033250 avg loss no lamb -2.033250 time 2019-01-27 07:20:31.131895
Model ind 579 epoch 15 head A head_i_epoch 0 batch 200: avg loss -2.074821 avg loss no lamb -2.074821 time 2019-01-27 07:23:27.019247
Pre: time 2019-01-27 07:26:47.734853: 
 	std: 0.0019035613
	best_train_sub_head_match: [(0, 9), (1, 1), (2, 10), (3, 11), (4, 5), (5, 14), (6, 12), (7, 6), (8, 19), (9, 17), (10, 0), (11, 3), (12, 7), (13, 13), (14, 16), (15, 8), (16, 4), (17, 15), (18, 18), (19, 2)]
	test_accs: [0.12578334, 0.1263, 0.12948333, 0.12465, 0.12911667]
	train_accs: [0.12578334, 0.1263, 0.12948333, 0.12465, 0.12911667]
	best_train_sub_head: 2
	worst: 0.12465
	avg: 0.12706667
	best: 0.12948333

Starting e_i: 16
Model ind 579 epoch 16 head B head_i_epoch 0 batch 0: avg loss -1.194292 avg loss no lamb -1.194292 time 2019-01-27 07:26:50.201657
Model ind 579 epoch 16 head B head_i_epoch 0 batch 100: avg loss -1.321921 avg loss no lamb -1.321921 time 2019-01-27 07:29:45.870651
Model ind 579 epoch 16 head B head_i_epoch 0 batch 200: avg loss -1.299157 avg loss no lamb -1.299157 time 2019-01-27 07:32:41.438443
Model ind 579 epoch 16 head A head_i_epoch 0 batch 0: avg loss -2.023067 avg loss no lamb -2.023067 time 2019-01-27 07:35:37.174093
Model ind 579 epoch 16 head A head_i_epoch 0 batch 100: avg loss -2.116726 avg loss no lamb -2.116726 time 2019-01-27 07:38:34.962344
Model ind 579 epoch 16 head A head_i_epoch 0 batch 200: avg loss -2.205096 avg loss no lamb -2.205096 time 2019-01-27 07:41:32.451197
Pre: time 2019-01-27 07:44:54.963750: 
 	std: 0.0017606338
	best_train_sub_head_match: [(0, 1), (1, 16), (2, 8), (3, 3), (4, 2), (5, 17), (6, 7), (7, 18), (8, 0), (9, 19), (10, 9), (11, 5), (12, 12), (13, 13), (14, 14), (15, 15), (16, 6), (17, 4), (18, 10), (19, 11)]
	test_accs: [0.13456666, 0.13391666, 0.13246667, 0.13441667, 0.13783333]
	train_accs: [0.13456666, 0.13391666, 0.13246667, 0.13441667, 0.13783333]
	best_train_sub_head: 4
	worst: 0.13246667
	avg: 0.13464001
	best: 0.13783333

Starting e_i: 17
Model ind 579 epoch 17 head B head_i_epoch 0 batch 0: avg loss -1.290219 avg loss no lamb -1.290219 time 2019-01-27 07:45:02.260404
Model ind 579 epoch 17 head B head_i_epoch 0 batch 100: avg loss -1.257914 avg loss no lamb -1.257914 time 2019-01-27 07:47:58.277511
Model ind 579 epoch 17 head B head_i_epoch 0 batch 200: avg loss -1.329586 avg loss no lamb -1.329586 time 2019-01-27 07:50:53.383543
Model ind 579 epoch 17 head A head_i_epoch 0 batch 0: avg loss -2.117760 avg loss no lamb -2.117760 time 2019-01-27 07:53:47.968764
Model ind 579 epoch 17 head A head_i_epoch 0 batch 100: avg loss -2.197532 avg loss no lamb -2.197532 time 2019-01-27 07:56:45.010726
Model ind 579 epoch 17 head A head_i_epoch 0 batch 200: avg loss -2.237916 avg loss no lamb -2.237916 time 2019-01-27 07:59:41.331145
Pre: time 2019-01-27 08:03:00.755874: 
 	std: 0.003126103
	best_train_sub_head_match: [(0, 6), (1, 0), (2, 7), (3, 12), (4, 1), (5, 9), (6, 11), (7, 14), (8, 5), (9, 15), (10, 2), (11, 8), (12, 4), (13, 18), (14, 13), (15, 16), (16, 17), (17, 19), (18, 10), (19, 3)]
	test_accs: [0.13806666, 0.13931666, 0.1308, 0.13691667, 0.13353333]
	train_accs: [0.13806666, 0.13931666, 0.1308, 0.13691667, 0.13353333]
	best_train_sub_head: 1
	worst: 0.1308
	avg: 0.13572666
	best: 0.13931666

Starting e_i: 18
Model ind 579 epoch 18 head B head_i_epoch 0 batch 0: avg loss -1.261771 avg loss no lamb -1.261771 time 2019-01-27 08:03:07.765639
Model ind 579 epoch 18 head B head_i_epoch 0 batch 100: avg loss -1.278024 avg loss no lamb -1.278024 time 2019-01-27 08:06:02.115838
Model ind 579 epoch 18 head B head_i_epoch 0 batch 200: avg loss -1.265731 avg loss no lamb -1.265731 time 2019-01-27 08:08:57.167938
Model ind 579 epoch 18 head A head_i_epoch 0 batch 0: avg loss -2.117318 avg loss no lamb -2.117318 time 2019-01-27 08:11:52.631929
Model ind 579 epoch 18 head A head_i_epoch 0 batch 100: avg loss -2.190593 avg loss no lamb -2.190593 time 2019-01-27 08:14:49.768347
Model ind 579 epoch 18 head A head_i_epoch 0 batch 200: avg loss -2.204129 avg loss no lamb -2.204129 time 2019-01-27 08:17:47.088679
Pre: time 2019-01-27 08:21:08.631563: 
 	std: 0.002709838
	best_train_sub_head_match: [(0, 13), (1, 6), (2, 2), (3, 5), (4, 4), (5, 16), (6, 7), (7, 15), (8, 3), (9, 1), (10, 9), (11, 17), (12, 0), (13, 8), (14, 10), (15, 14), (16, 12), (17, 19), (18, 18), (19, 11)]
	test_accs: [0.12658334, 0.12438333, 0.12321667, 0.1301, 0.12946667]
	train_accs: [0.12658334, 0.12438333, 0.12321667, 0.1301, 0.12946667]
	best_train_sub_head: 3
	worst: 0.12321667
	avg: 0.12674999
	best: 0.1301

Starting e_i: 19
Model ind 579 epoch 19 head B head_i_epoch 0 batch 0: avg loss -1.246689 avg loss no lamb -1.246689 time 2019-01-27 08:21:11.272146
Model ind 579 epoch 19 head B head_i_epoch 0 batch 100: avg loss -1.299730 avg loss no lamb -1.299730 time 2019-01-27 08:24:07.634339
Model ind 579 epoch 19 head B head_i_epoch 0 batch 200: avg loss -1.335275 avg loss no lamb -1.335275 time 2019-01-27 08:27:03.418683
Model ind 579 epoch 19 head A head_i_epoch 0 batch 0: avg loss -2.125323 avg loss no lamb -2.125323 time 2019-01-27 08:29:59.358367
Model ind 579 epoch 19 head A head_i_epoch 0 batch 100: avg loss -2.212857 avg loss no lamb -2.212857 time 2019-01-27 08:32:56.911627
Model ind 579 epoch 19 head A head_i_epoch 0 batch 200: avg loss -2.271419 avg loss no lamb -2.271419 time 2019-01-27 08:35:53.653936
Pre: time 2019-01-27 08:39:13.937414: 
 	std: 0.0009158827
	best_train_sub_head_match: [(0, 19), (1, 5), (2, 2), (3, 6), (4, 4), (5, 11), (6, 8), (7, 13), (8, 3), (9, 1), (10, 9), (11, 15), (12, 14), (13, 12), (14, 10), (15, 0), (16, 16), (17, 17), (18, 18), (19, 7)]
	test_accs: [0.13566667, 0.136, 0.134, 0.13675, 0.13603333]
	train_accs: [0.13566667, 0.136, 0.134, 0.13675, 0.13603333]
	best_train_sub_head: 3
	worst: 0.134
	avg: 0.13569
	best: 0.13675

Starting e_i: 20
Model ind 579 epoch 20 head B head_i_epoch 0 batch 0: avg loss -1.171473 avg loss no lamb -1.171473 time 2019-01-27 08:39:16.436591
Model ind 579 epoch 20 head B head_i_epoch 0 batch 100: avg loss -1.292456 avg loss no lamb -1.292456 time 2019-01-27 08:42:11.668119
Model ind 579 epoch 20 head B head_i_epoch 0 batch 200: avg loss -1.320489 avg loss no lamb -1.320489 time 2019-01-27 08:45:05.193220
Model ind 579 epoch 20 head A head_i_epoch 0 batch 0: avg loss -2.206234 avg loss no lamb -2.206234 time 2019-01-27 08:48:00.004178
Model ind 579 epoch 20 head A head_i_epoch 0 batch 100: avg loss -2.267822 avg loss no lamb -2.267822 time 2019-01-27 08:50:56.662846
Model ind 579 epoch 20 head A head_i_epoch 0 batch 200: avg loss -2.313361 avg loss no lamb -2.313361 time 2019-01-27 08:53:52.104034
Pre: time 2019-01-27 08:57:11.585328: 
 	std: 0.0025257226
	best_train_sub_head_match: [(0, 3), (1, 11), (2, 13), (3, 5), (4, 12), (5, 17), (6, 15), (7, 9), (8, 1), (9, 18), (10, 7), (11, 16), (12, 2), (13, 19), (14, 4), (15, 0), (16, 6), (17, 14), (18, 10), (19, 8)]
	test_accs: [0.13716666, 0.1372, 0.13645, 0.14056666, 0.14305]
	train_accs: [0.13716666, 0.1372, 0.13645, 0.14056666, 0.14305]
	best_train_sub_head: 4
	worst: 0.13645
	avg: 0.13888666
	best: 0.14305

Starting e_i: 21
Model ind 579 epoch 21 head B head_i_epoch 0 batch 0: avg loss -1.209104 avg loss no lamb -1.209104 time 2019-01-27 08:57:21.714864
Model ind 579 epoch 21 head B head_i_epoch 0 batch 100: avg loss -1.255565 avg loss no lamb -1.255565 time 2019-01-27 09:00:17.124105
Model ind 579 epoch 21 head B head_i_epoch 0 batch 200: avg loss -1.329885 avg loss no lamb -1.329885 time 2019-01-27 09:03:12.139942
Model ind 579 epoch 21 head A head_i_epoch 0 batch 0: avg loss -2.282459 avg loss no lamb -2.282459 time 2019-01-27 09:06:07.410502
Model ind 579 epoch 21 head A head_i_epoch 0 batch 100: avg loss -2.278094 avg loss no lamb -2.278094 time 2019-01-27 09:09:03.968751
Model ind 579 epoch 21 head A head_i_epoch 0 batch 200: avg loss -2.336460 avg loss no lamb -2.336460 time 2019-01-27 09:12:01.763210
Pre: time 2019-01-27 09:15:23.810465: 
 	std: 0.0026465168
	best_train_sub_head_match: [(0, 2), (1, 13), (2, 4), (3, 18), (4, 0), (5, 19), (6, 9), (7, 11), (8, 10), (9, 15), (10, 6), (11, 8), (12, 16), (13, 5), (14, 17), (15, 1), (16, 14), (17, 7), (18, 12), (19, 3)]
	test_accs: [0.13648333, 0.13475, 0.13041666, 0.13755, 0.1374]
	train_accs: [0.13648333, 0.13475, 0.13041666, 0.13755, 0.1374]
	best_train_sub_head: 3
	worst: 0.13041666
	avg: 0.13532
	best: 0.13755

Starting e_i: 22
Model ind 579 epoch 22 head B head_i_epoch 0 batch 0: avg loss -1.266843 avg loss no lamb -1.266843 time 2019-01-27 09:15:26.182796
Model ind 579 epoch 22 head B head_i_epoch 0 batch 100: avg loss -1.291537 avg loss no lamb -1.291537 time 2019-01-27 09:18:20.982004
Model ind 579 epoch 22 head B head_i_epoch 0 batch 200: avg loss -1.330165 avg loss no lamb -1.330165 time 2019-01-27 09:21:15.664211
Model ind 579 epoch 22 head A head_i_epoch 0 batch 0: avg loss -2.311964 avg loss no lamb -2.311964 time 2019-01-27 09:24:11.205101
Model ind 579 epoch 22 head A head_i_epoch 0 batch 100: avg loss -2.284414 avg loss no lamb -2.284414 time 2019-01-27 09:27:08.366195
Model ind 579 epoch 22 head A head_i_epoch 0 batch 200: avg loss -2.401752 avg loss no lamb -2.401752 time 2019-01-27 09:30:05.479436
Pre: time 2019-01-27 09:33:26.266040: 
 	std: 0.0017186383
	best_train_sub_head_match: [(0, 1), (1, 0), (2, 7), (3, 3), (4, 12), (5, 17), (6, 8), (7, 18), (8, 15), (9, 19), (10, 9), (11, 11), (12, 13), (13, 5), (14, 14), (15, 2), (16, 6), (17, 4), (18, 10), (19, 16)]
	test_accs: [0.1374, 0.13773334, 0.13495, 0.13865, 0.1402]
	train_accs: [0.1374, 0.13773334, 0.13495, 0.13865, 0.1402]
	best_train_sub_head: 4
	worst: 0.13495
	avg: 0.13778667
	best: 0.1402

Starting e_i: 23
Model ind 579 epoch 23 head B head_i_epoch 0 batch 0: avg loss -1.228849 avg loss no lamb -1.228849 time 2019-01-27 09:33:28.664837
Model ind 579 epoch 23 head B head_i_epoch 0 batch 100: avg loss -1.229239 avg loss no lamb -1.229239 time 2019-01-27 09:36:23.068815
Model ind 579 epoch 23 head B head_i_epoch 0 batch 200: avg loss -1.478335 avg loss no lamb -1.478335 time 2019-01-27 09:39:18.211239
Model ind 579 epoch 23 head A head_i_epoch 0 batch 0: avg loss -2.356155 avg loss no lamb -2.356155 time 2019-01-27 09:42:12.483500
Model ind 579 epoch 23 head A head_i_epoch 0 batch 100: avg loss -2.357135 avg loss no lamb -2.357135 time 2019-01-27 09:45:09.010249
Model ind 579 epoch 23 head A head_i_epoch 0 batch 200: avg loss -2.408658 avg loss no lamb -2.408658 time 2019-01-27 09:48:08.453970
Pre: time 2019-01-27 09:51:33.237248: 
 	std: 0.0019403151
	best_train_sub_head_match: [(0, 10), (1, 4), (2, 6), (3, 16), (4, 19), (5, 1), (6, 12), (7, 5), (8, 14), (9, 13), (10, 3), (11, 9), (12, 7), (13, 15), (14, 0), (15, 8), (16, 11), (17, 17), (18, 18), (19, 2)]
	test_accs: [0.13718334, 0.1403, 0.14266667, 0.13876666, 0.14148334]
	train_accs: [0.13718334, 0.1403, 0.14266667, 0.13876666, 0.14148334]
	best_train_sub_head: 2
	worst: 0.13718334
	avg: 0.14008
	best: 0.14266667

Starting e_i: 24
Model ind 579 epoch 24 head B head_i_epoch 0 batch 0: avg loss -1.342245 avg loss no lamb -1.342245 time 2019-01-27 09:51:35.623765
Model ind 579 epoch 24 head B head_i_epoch 0 batch 100: avg loss -1.323940 avg loss no lamb -1.323940 time 2019-01-27 09:54:32.375804
Model ind 579 epoch 24 head B head_i_epoch 0 batch 200: avg loss -1.365628 avg loss no lamb -1.365628 time 2019-01-27 09:57:27.884356
Model ind 579 epoch 24 head A head_i_epoch 0 batch 0: avg loss -2.320481 avg loss no lamb -2.320481 time 2019-01-27 10:00:26.510180
Model ind 579 epoch 24 head A head_i_epoch 0 batch 100: avg loss -2.383726 avg loss no lamb -2.383726 time 2019-01-27 10:03:24.645550
Model ind 579 epoch 24 head A head_i_epoch 0 batch 200: avg loss -2.382993 avg loss no lamb -2.382993 time 2019-01-27 10:06:22.841254
Pre: time 2019-01-27 10:09:41.877868: 
 	std: 0.004108441
	best_train_sub_head_match: [(0, 6), (1, 4), (2, 12), (3, 3), (4, 2), (5, 15), (6, 8), (7, 19), (8, 1), (9, 17), (10, 11), (11, 13), (12, 14), (13, 18), (14, 10), (15, 0), (16, 5), (17, 7), (18, 9), (19, 16)]
	test_accs: [0.13765, 0.13628334, 0.14141667, 0.13193333, 0.14375]
	train_accs: [0.13765, 0.13628334, 0.14141667, 0.13193333, 0.14375]
	best_train_sub_head: 4
	worst: 0.13193333
	avg: 0.13820668
	best: 0.14375

Starting e_i: 25
Model ind 579 epoch 25 head B head_i_epoch 0 batch 0: avg loss -1.263925 avg loss no lamb -1.263925 time 2019-01-27 10:09:50.706367
Model ind 579 epoch 25 head B head_i_epoch 0 batch 100: avg loss -1.328023 avg loss no lamb -1.328023 time 2019-01-27 10:12:45.516058
Model ind 579 epoch 25 head B head_i_epoch 0 batch 200: avg loss -1.424812 avg loss no lamb -1.424812 time 2019-01-27 10:15:40.814303
Model ind 579 epoch 25 head A head_i_epoch 0 batch 0: avg loss -2.416132 avg loss no lamb -2.416132 time 2019-01-27 10:18:35.678794
Model ind 579 epoch 25 head A head_i_epoch 0 batch 100: avg loss -2.450754 avg loss no lamb -2.450754 time 2019-01-27 10:21:32.246395
Model ind 579 epoch 25 head A head_i_epoch 0 batch 200: avg loss -2.441758 avg loss no lamb -2.441758 time 2019-01-27 10:24:29.597859
Pre: time 2019-01-27 10:27:49.669521: 
 	std: 0.001948716
	best_train_sub_head_match: [(0, 18), (1, 1), (2, 2), (3, 9), (4, 4), (5, 8), (6, 11), (7, 13), (8, 15), (9, 12), (10, 6), (11, 5), (12, 0), (13, 7), (14, 14), (15, 16), (16, 19), (17, 10), (18, 17), (19, 3)]
	test_accs: [0.14541666, 0.14583333, 0.14786667, 0.1469, 0.15088333]
	train_accs: [0.14541666, 0.14583333, 0.14786667, 0.1469, 0.15088333]
	best_train_sub_head: 4
	worst: 0.14541666
	avg: 0.14738
	best: 0.15088333

Starting e_i: 26
Model ind 579 epoch 26 head B head_i_epoch 0 batch 0: avg loss -1.229069 avg loss no lamb -1.229069 time 2019-01-27 10:27:57.664185
Model ind 579 epoch 26 head B head_i_epoch 0 batch 100: avg loss -1.302561 avg loss no lamb -1.302561 time 2019-01-27 10:30:52.725599
Model ind 579 epoch 26 head B head_i_epoch 0 batch 200: avg loss -1.360585 avg loss no lamb -1.360585 time 2019-01-27 10:33:48.375752
Model ind 579 epoch 26 head A head_i_epoch 0 batch 0: avg loss -2.386391 avg loss no lamb -2.386391 time 2019-01-27 10:36:43.504067
Model ind 579 epoch 26 head A head_i_epoch 0 batch 100: avg loss -2.473434 avg loss no lamb -2.473434 time 2019-01-27 10:39:39.841299
Model ind 579 epoch 26 head A head_i_epoch 0 batch 200: avg loss -2.536279 avg loss no lamb -2.536279 time 2019-01-27 10:42:35.957480
Pre: time 2019-01-27 10:45:56.682404: 
 	std: 0.0037091107
	best_train_sub_head_match: [(0, 4), (1, 16), (2, 8), (3, 3), (4, 12), (5, 17), (6, 7), (7, 18), (8, 0), (9, 19), (10, 11), (11, 5), (12, 13), (13, 9), (14, 1), (15, 15), (16, 6), (17, 14), (18, 10), (19, 2)]
	test_accs: [0.1478, 0.14026667, 0.1476, 0.1425, 0.15028334]
	train_accs: [0.1478, 0.14026667, 0.1476, 0.1425, 0.15028334]
	best_train_sub_head: 4
	worst: 0.14026667
	avg: 0.14569
	best: 0.15028334

Starting e_i: 27
Model ind 579 epoch 27 head B head_i_epoch 0 batch 0: avg loss -1.287217 avg loss no lamb -1.287217 time 2019-01-27 10:45:58.995856
Model ind 579 epoch 27 head B head_i_epoch 0 batch 100: avg loss -1.341383 avg loss no lamb -1.341383 time 2019-01-27 10:48:53.566080
Model ind 579 epoch 27 head B head_i_epoch 0 batch 200: avg loss -1.422177 avg loss no lamb -1.422177 time 2019-01-27 10:51:47.969600
Model ind 579 epoch 27 head A head_i_epoch 0 batch 0: avg loss -2.410754 avg loss no lamb -2.410754 time 2019-01-27 10:54:43.063038
Model ind 579 epoch 27 head A head_i_epoch 0 batch 100: avg loss -2.494064 avg loss no lamb -2.494064 time 2019-01-27 10:57:39.614837
Model ind 579 epoch 27 head A head_i_epoch 0 batch 200: avg loss -2.541738 avg loss no lamb -2.541738 time 2019-01-27 11:00:35.881614
Pre: time 2019-01-27 11:03:55.354857: 
 	std: 0.0012713714
	best_train_sub_head_match: [(0, 19), (1, 16), (2, 14), (3, 0), (4, 13), (5, 2), (6, 7), (7, 3), (8, 5), (9, 10), (10, 4), (11, 17), (12, 6), (13, 9), (14, 15), (15, 12), (16, 11), (17, 18), (18, 1), (19, 8)]
	test_accs: [0.1385, 0.13548334, 0.13471666, 0.13646667, 0.13606666]
	train_accs: [0.1385, 0.13548334, 0.13471666, 0.13646667, 0.13606666]
	best_train_sub_head: 0
	worst: 0.13471666
	avg: 0.13624667
	best: 0.1385

Starting e_i: 28
Model ind 579 epoch 28 head B head_i_epoch 0 batch 0: avg loss -1.279969 avg loss no lamb -1.279969 time 2019-01-27 11:03:57.678767
Model ind 579 epoch 28 head B head_i_epoch 0 batch 100: avg loss -1.362244 avg loss no lamb -1.362244 time 2019-01-27 11:06:52.586026
Model ind 579 epoch 28 head B head_i_epoch 0 batch 200: avg loss -1.387524 avg loss no lamb -1.387524 time 2019-01-27 11:09:46.909013
Model ind 579 epoch 28 head A head_i_epoch 0 batch 0: avg loss -2.454554 avg loss no lamb -2.454554 time 2019-01-27 11:12:42.148809
Model ind 579 epoch 28 head A head_i_epoch 0 batch 100: avg loss -2.519497 avg loss no lamb -2.519497 time 2019-01-27 11:15:38.587073
Model ind 579 epoch 28 head A head_i_epoch 0 batch 200: avg loss -2.607373 avg loss no lamb -2.607373 time 2019-01-27 11:18:35.171153
Pre: time 2019-01-27 11:21:55.559632: 
 	std: 0.002230047
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 7), (3, 6), (4, 12), (5, 17), (6, 8), (7, 0), (8, 14), (9, 19), (10, 9), (11, 13), (12, 16), (13, 18), (14, 1), (15, 15), (16, 5), (17, 3), (18, 10), (19, 11)]
	test_accs: [0.14918333, 0.14876667, 0.14838333, 0.14508334, 0.15208334]
	train_accs: [0.14918333, 0.14876667, 0.14838333, 0.14508334, 0.15208334]
	best_train_sub_head: 4
	worst: 0.14508334
	avg: 0.14870001
	best: 0.15208334

Starting e_i: 29
Model ind 579 epoch 29 head B head_i_epoch 0 batch 0: avg loss -1.278058 avg loss no lamb -1.278058 time 2019-01-27 11:22:02.340866
Model ind 579 epoch 29 head B head_i_epoch 0 batch 100: avg loss -1.405425 avg loss no lamb -1.405425 time 2019-01-27 11:24:57.013386
Model ind 579 epoch 29 head B head_i_epoch 0 batch 200: avg loss -1.360880 avg loss no lamb -1.360880 time 2019-01-27 11:27:52.607218
Model ind 579 epoch 29 head A head_i_epoch 0 batch 0: avg loss -2.597973 avg loss no lamb -2.597973 time 2019-01-27 11:30:47.616296
Model ind 579 epoch 29 head A head_i_epoch 0 batch 100: avg loss -2.526437 avg loss no lamb -2.526437 time 2019-01-27 11:33:44.635952
Model ind 579 epoch 29 head A head_i_epoch 0 batch 200: avg loss -2.587528 avg loss no lamb -2.587528 time 2019-01-27 11:36:41.892211
Pre: time 2019-01-27 11:40:03.545586: 
 	std: 0.0020117029
	best_train_sub_head_match: [(0, 13), (1, 19), (2, 16), (3, 10), (4, 1), (5, 4), (6, 3), (7, 8), (8, 6), (9, 0), (10, 5), (11, 7), (12, 12), (13, 11), (14, 18), (15, 14), (16, 2), (17, 17), (18, 15), (19, 9)]
	test_accs: [0.15155, 0.14895, 0.14781667, 0.15316667, 0.15213333]
	train_accs: [0.15155, 0.14895, 0.14781667, 0.15316667, 0.15213333]
	best_train_sub_head: 3
	worst: 0.14781667
	avg: 0.15072332
	best: 0.15316667

Starting e_i: 30
Model ind 579 epoch 30 head B head_i_epoch 0 batch 0: avg loss -1.338712 avg loss no lamb -1.338712 time 2019-01-27 11:40:09.372584
Model ind 579 epoch 30 head B head_i_epoch 0 batch 100: avg loss -1.363362 avg loss no lamb -1.363362 time 2019-01-27 11:43:04.961213
Model ind 579 epoch 30 head B head_i_epoch 0 batch 200: avg loss -1.426853 avg loss no lamb -1.426853 time 2019-01-27 11:46:01.308407
Model ind 579 epoch 30 head A head_i_epoch 0 batch 0: avg loss -2.425020 avg loss no lamb -2.425020 time 2019-01-27 11:48:58.013996
Model ind 579 epoch 30 head A head_i_epoch 0 batch 100: avg loss -2.485057 avg loss no lamb -2.485057 time 2019-01-27 11:51:55.697493
Model ind 579 epoch 30 head A head_i_epoch 0 batch 200: avg loss -2.640289 avg loss no lamb -2.640289 time 2019-01-27 11:54:54.555484
Pre: time 2019-01-27 11:58:18.039149: 
 	std: 0.0021341008
	best_train_sub_head_match: [(0, 16), (1, 8), (2, 4), (3, 10), (4, 3), (5, 5), (6, 9), (7, 11), (8, 6), (9, 15), (10, 19), (11, 12), (12, 0), (13, 14), (14, 17), (15, 1), (16, 2), (17, 7), (18, 13), (19, 18)]
	test_accs: [0.15608333, 0.15911667, 0.15501666, 0.16096666, 0.15716666]
	train_accs: [0.15608333, 0.15911667, 0.15501666, 0.16096666, 0.15716666]
	best_train_sub_head: 3
	worst: 0.15501666
	avg: 0.15766999
	best: 0.16096666

Starting e_i: 31
Model ind 579 epoch 31 head B head_i_epoch 0 batch 0: avg loss -1.276584 avg loss no lamb -1.276584 time 2019-01-27 11:58:28.425393
Model ind 579 epoch 31 head B head_i_epoch 0 batch 100: avg loss -1.320223 avg loss no lamb -1.320223 time 2019-01-27 12:01:24.616034
Model ind 579 epoch 31 head B head_i_epoch 0 batch 200: avg loss -1.432268 avg loss no lamb -1.432268 time 2019-01-27 12:04:21.034832
Model ind 579 epoch 31 head A head_i_epoch 0 batch 0: avg loss -2.520394 avg loss no lamb -2.520394 time 2019-01-27 12:07:17.761547
Model ind 579 epoch 31 head A head_i_epoch 0 batch 100: avg loss -2.619547 avg loss no lamb -2.619547 time 2019-01-27 12:10:16.371786
Model ind 579 epoch 31 head A head_i_epoch 0 batch 200: avg loss -2.649093 avg loss no lamb -2.649093 time 2019-01-27 12:13:15.257441
Pre: time 2019-01-27 12:16:39.900095: 
 	std: 0.0018396555
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 3), (3, 8), (4, 11), (5, 16), (6, 13), (7, 6), (8, 1), (9, 18), (10, 14), (11, 9), (12, 17), (13, 15), (14, 0), (15, 19), (16, 7), (17, 5), (18, 10), (19, 12)]
	test_accs: [0.14526667, 0.14406666, 0.1471, 0.14235, 0.14221667]
	train_accs: [0.14526667, 0.14406666, 0.1471, 0.14235, 0.14221667]
	best_train_sub_head: 2
	worst: 0.14221667
	avg: 0.1442
	best: 0.1471

Starting e_i: 32
Model ind 579 epoch 32 head B head_i_epoch 0 batch 0: avg loss -1.280519 avg loss no lamb -1.280519 time 2019-01-27 12:16:42.671571
Model ind 579 epoch 32 head B head_i_epoch 0 batch 100: avg loss -1.383972 avg loss no lamb -1.383972 time 2019-01-27 12:19:40.366273
Model ind 579 epoch 32 head B head_i_epoch 0 batch 200: avg loss -1.408861 avg loss no lamb -1.408861 time 2019-01-27 12:22:36.668657
Model ind 579 epoch 32 head A head_i_epoch 0 batch 0: avg loss -2.497544 avg loss no lamb -2.497544 time 2019-01-27 12:25:32.742701
Model ind 579 epoch 32 head A head_i_epoch 0 batch 100: avg loss -2.583697 avg loss no lamb -2.583697 time 2019-01-27 12:28:30.863490
Model ind 579 epoch 32 head A head_i_epoch 0 batch 200: avg loss -2.679666 avg loss no lamb -2.679666 time 2019-01-27 12:31:29.026294
Pre: time 2019-01-27 12:34:51.147301: 
 	std: 0.0010338895
	best_train_sub_head_match: [(0, 6), (1, 2), (2, 19), (3, 15), (4, 16), (5, 4), (6, 7), (7, 8), (8, 11), (9, 0), (10, 13), (11, 17), (12, 5), (13, 14), (14, 18), (15, 12), (16, 10), (17, 1), (18, 3), (19, 9)]
	test_accs: [0.15346667, 0.15366666, 0.15185, 0.15276666, 0.1509]
	train_accs: [0.15346667, 0.15366666, 0.15185, 0.15276666, 0.1509]
	best_train_sub_head: 1
	worst: 0.1509
	avg: 0.15252998
	best: 0.15366666

Starting e_i: 33
Model ind 579 epoch 33 head B head_i_epoch 0 batch 0: avg loss -1.320792 avg loss no lamb -1.320792 time 2019-01-27 12:34:53.682883
Model ind 579 epoch 33 head B head_i_epoch 0 batch 100: avg loss -1.325329 avg loss no lamb -1.325329 time 2019-01-27 12:37:49.777820
Model ind 579 epoch 33 head B head_i_epoch 0 batch 200: avg loss -1.439191 avg loss no lamb -1.439191 time 2019-01-27 12:40:45.399709
Model ind 579 epoch 33 head A head_i_epoch 0 batch 0: avg loss -2.548685 avg loss no lamb -2.548685 time 2019-01-27 12:43:41.127862
Model ind 579 epoch 33 head A head_i_epoch 0 batch 100: avg loss -2.676075 avg loss no lamb -2.676075 time 2019-01-27 12:46:39.478650
Model ind 579 epoch 33 head A head_i_epoch 0 batch 200: avg loss -2.718597 avg loss no lamb -2.718597 time 2019-01-27 12:49:36.214421
Pre: time 2019-01-27 12:52:58.276327: 
 	std: 0.0022982745
	best_train_sub_head_match: [(0, 10), (1, 4), (2, 6), (3, 2), (4, 9), (5, 1), (6, 12), (7, 18), (8, 14), (9, 17), (10, 3), (11, 19), (12, 7), (13, 13), (14, 5), (15, 8), (16, 11), (17, 15), (18, 0), (19, 16)]
	test_accs: [0.1602, 0.15611666, 0.16156666, 0.15681666, 0.16135]
	train_accs: [0.1602, 0.15611666, 0.16156666, 0.15681666, 0.16135]
	best_train_sub_head: 2
	worst: 0.15611666
	avg: 0.15921
	best: 0.16156666

Starting e_i: 34
Model ind 579 epoch 34 head B head_i_epoch 0 batch 0: avg loss -1.321924 avg loss no lamb -1.321924 time 2019-01-27 12:53:04.202027
Model ind 579 epoch 34 head B head_i_epoch 0 batch 100: avg loss -1.428171 avg loss no lamb -1.428171 time 2019-01-27 12:55:59.587772
Model ind 579 epoch 34 head B head_i_epoch 0 batch 200: avg loss -1.373020 avg loss no lamb -1.373020 time 2019-01-27 12:58:54.704049
Model ind 579 epoch 34 head A head_i_epoch 0 batch 0: avg loss -2.572144 avg loss no lamb -2.572144 time 2019-01-27 13:01:50.650582
Model ind 579 epoch 34 head A head_i_epoch 0 batch 100: avg loss -2.674665 avg loss no lamb -2.674665 time 2019-01-27 13:04:47.295780
Model ind 579 epoch 34 head A head_i_epoch 0 batch 200: avg loss -2.734732 avg loss no lamb -2.734732 time 2019-01-27 13:07:43.025164
Pre: time 2019-01-27 13:11:02.527393: 
 	std: 0.0028344193
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 13), (3, 5), (4, 12), (5, 17), (6, 8), (7, 0), (8, 14), (9, 19), (10, 9), (11, 7), (12, 16), (13, 18), (14, 1), (15, 15), (16, 6), (17, 3), (18, 10), (19, 11)]
	test_accs: [0.15486667, 0.15281667, 0.1495, 0.15596667, 0.15775]
	train_accs: [0.15486667, 0.15281667, 0.1495, 0.15596667, 0.15775]
	best_train_sub_head: 4
	worst: 0.1495
	avg: 0.15418
	best: 0.15775

Starting e_i: 35
Model ind 579 epoch 35 head B head_i_epoch 0 batch 0: avg loss -1.327312 avg loss no lamb -1.327312 time 2019-01-27 13:11:04.964231
Model ind 579 epoch 35 head B head_i_epoch 0 batch 100: avg loss -1.363337 avg loss no lamb -1.363337 time 2019-01-27 13:13:59.540120
Model ind 579 epoch 35 head B head_i_epoch 0 batch 200: avg loss -1.423000 avg loss no lamb -1.423000 time 2019-01-27 13:16:53.705829
Model ind 579 epoch 35 head A head_i_epoch 0 batch 0: avg loss -2.554916 avg loss no lamb -2.554916 time 2019-01-27 13:19:47.708943
Model ind 579 epoch 35 head A head_i_epoch 0 batch 100: avg loss -2.675256 avg loss no lamb -2.675256 time 2019-01-27 13:22:44.046987
Model ind 579 epoch 35 head A head_i_epoch 0 batch 200: avg loss -2.745990 avg loss no lamb -2.745990 time 2019-01-27 13:25:43.146237
Pre: time 2019-01-27 13:29:04.404423: 
 	std: 0.0016078507
	best_train_sub_head_match: [(0, 7), (1, 15), (2, 0), (3, 19), (4, 12), (5, 4), (6, 16), (7, 5), (8, 13), (9, 6), (10, 10), (11, 8), (12, 9), (13, 3), (14, 18), (15, 2), (16, 14), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.14408334, 0.13955, 0.14053333, 0.14248334, 0.14256667]
	train_accs: [0.14408334, 0.13955, 0.14053333, 0.14248334, 0.14256667]
	best_train_sub_head: 0
	worst: 0.13955
	avg: 0.14184335
	best: 0.14408334

Starting e_i: 36
Model ind 579 epoch 36 head B head_i_epoch 0 batch 0: avg loss -1.362747 avg loss no lamb -1.362747 time 2019-01-27 13:29:07.029069
Model ind 579 epoch 36 head B head_i_epoch 0 batch 100: avg loss -1.355705 avg loss no lamb -1.355705 time 2019-01-27 13:32:02.407667
Model ind 579 epoch 36 head B head_i_epoch 0 batch 200: avg loss -1.359510 avg loss no lamb -1.359510 time 2019-01-27 13:34:57.529682
Model ind 579 epoch 36 head A head_i_epoch 0 batch 0: avg loss -2.645501 avg loss no lamb -2.645501 time 2019-01-27 13:37:53.162927
Model ind 579 epoch 36 head A head_i_epoch 0 batch 100: avg loss -2.743044 avg loss no lamb -2.743044 time 2019-01-27 13:40:49.499313
Model ind 579 epoch 36 head A head_i_epoch 0 batch 200: avg loss -2.725267 avg loss no lamb -2.725267 time 2019-01-27 13:43:46.348955
Pre: time 2019-01-27 13:47:06.974141: 
 	std: 0.0013394862
	best_train_sub_head_match: [(0, 12), (1, 15), (2, 4), (3, 10), (4, 3), (5, 5), (6, 9), (7, 8), (8, 6), (9, 14), (10, 18), (11, 7), (12, 2), (13, 11), (14, 0), (15, 1), (16, 16), (17, 17), (18, 13), (19, 19)]
	test_accs: [0.14975, 0.15231666, 0.15325, 0.15331666, 0.15303333]
	train_accs: [0.14975, 0.15231666, 0.15325, 0.15331666, 0.15303333]
	best_train_sub_head: 3
	worst: 0.14975
	avg: 0.15233333
	best: 0.15331666

Starting e_i: 37
Model ind 579 epoch 37 head B head_i_epoch 0 batch 0: avg loss -1.335388 avg loss no lamb -1.335388 time 2019-01-27 13:47:09.409005
Model ind 579 epoch 37 head B head_i_epoch 0 batch 100: avg loss -1.477598 avg loss no lamb -1.477598 time 2019-01-27 13:50:04.387768
Model ind 579 epoch 37 head B head_i_epoch 0 batch 200: avg loss -1.421787 avg loss no lamb -1.421787 time 2019-01-27 13:52:59.633625
Model ind 579 epoch 37 head A head_i_epoch 0 batch 0: avg loss -2.658954 avg loss no lamb -2.658954 time 2019-01-27 13:55:55.120682
Model ind 579 epoch 37 head A head_i_epoch 0 batch 100: avg loss -2.756204 avg loss no lamb -2.756204 time 2019-01-27 13:58:51.264036
Model ind 579 epoch 37 head A head_i_epoch 0 batch 200: avg loss -2.711516 avg loss no lamb -2.711516 time 2019-01-27 14:01:49.062369
Pre: time 2019-01-27 14:05:10.871800: 
 	std: 0.0035637459
	best_train_sub_head_match: [(0, 9), (1, 0), (2, 5), (3, 13), (4, 3), (5, 10), (6, 2), (7, 16), (8, 4), (9, 7), (10, 8), (11, 17), (12, 11), (13, 1), (14, 15), (15, 12), (16, 18), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.15315, 0.16086666, 0.15181667, 0.15498333, 0.15963334]
	train_accs: [0.15315, 0.16086666, 0.15181667, 0.15498333, 0.15963334]
	best_train_sub_head: 1
	worst: 0.15181667
	avg: 0.15608999
	best: 0.16086666

Starting e_i: 38
Model ind 579 epoch 38 head B head_i_epoch 0 batch 0: avg loss -1.238758 avg loss no lamb -1.238758 time 2019-01-27 14:05:13.325977
Model ind 579 epoch 38 head B head_i_epoch 0 batch 100: avg loss -1.422657 avg loss no lamb -1.422657 time 2019-01-27 14:08:08.626869
Model ind 579 epoch 38 head B head_i_epoch 0 batch 200: avg loss -1.438810 avg loss no lamb -1.438810 time 2019-01-27 14:11:04.100022
Model ind 579 epoch 38 head A head_i_epoch 0 batch 0: avg loss -2.637928 avg loss no lamb -2.637928 time 2019-01-27 14:13:59.165033
Model ind 579 epoch 38 head A head_i_epoch 0 batch 100: avg loss -2.694691 avg loss no lamb -2.694691 time 2019-01-27 14:16:55.740010
Model ind 579 epoch 38 head A head_i_epoch 0 batch 200: avg loss -2.784817 avg loss no lamb -2.784817 time 2019-01-27 14:19:52.441732
Pre: time 2019-01-27 14:23:13.837468: 
 	std: 0.0022026068
	best_train_sub_head_match: [(0, 5), (1, 17), (2, 16), (3, 10), (4, 1), (5, 4), (6, 11), (7, 12), (8, 3), (9, 0), (10, 6), (11, 7), (12, 15), (13, 2), (14, 18), (15, 14), (16, 13), (17, 8), (18, 19), (19, 9)]
	test_accs: [0.15781666, 0.15611666, 0.15253334, 0.1589, 0.15745]
	train_accs: [0.15781666, 0.15611666, 0.15253334, 0.1589, 0.15745]
	best_train_sub_head: 3
	worst: 0.15253334
	avg: 0.15656334
	best: 0.1589

Starting e_i: 39
Model ind 579 epoch 39 head B head_i_epoch 0 batch 0: avg loss -1.323205 avg loss no lamb -1.323205 time 2019-01-27 14:23:16.323255
Model ind 579 epoch 39 head B head_i_epoch 0 batch 100: avg loss -1.375412 avg loss no lamb -1.375412 time 2019-01-27 14:26:11.930053
Model ind 579 epoch 39 head B head_i_epoch 0 batch 200: avg loss -1.382392 avg loss no lamb -1.382392 time 2019-01-27 14:29:06.050532
Model ind 579 epoch 39 head A head_i_epoch 0 batch 0: avg loss -2.683400 avg loss no lamb -2.683400 time 2019-01-27 14:32:00.885313
Model ind 579 epoch 39 head A head_i_epoch 0 batch 100: avg loss -2.707203 avg loss no lamb -2.707203 time 2019-01-27 14:34:57.341472
Model ind 579 epoch 39 head A head_i_epoch 0 batch 200: avg loss -2.725466 avg loss no lamb -2.725466 time 2019-01-27 14:37:55.144107
Pre: time 2019-01-27 14:41:16.333676: 
 	std: 0.0015280714
	best_train_sub_head_match: [(0, 1), (1, 16), (2, 8), (3, 5), (4, 12), (5, 17), (6, 7), (7, 6), (8, 0), (9, 18), (10, 9), (11, 2), (12, 13), (13, 19), (14, 14), (15, 15), (16, 3), (17, 4), (18, 10), (19, 11)]
	test_accs: [0.15441667, 0.15358333, 0.15091667, 0.15483333, 0.15516667]
	train_accs: [0.15441667, 0.15358333, 0.15091667, 0.15483333, 0.15516667]
	best_train_sub_head: 4
	worst: 0.15091667
	avg: 0.15378334
	best: 0.15516667

Starting e_i: 40
Model ind 579 epoch 40 head B head_i_epoch 0 batch 0: avg loss -1.350500 avg loss no lamb -1.350500 time 2019-01-27 14:41:18.729469
Model ind 579 epoch 40 head B head_i_epoch 0 batch 100: avg loss -1.441449 avg loss no lamb -1.441449 time 2019-01-27 14:44:15.768897
Model ind 579 epoch 40 head B head_i_epoch 0 batch 200: avg loss -1.403270 avg loss no lamb -1.403270 time 2019-01-27 14:47:12.581652
Model ind 579 epoch 40 head A head_i_epoch 0 batch 0: avg loss -2.671678 avg loss no lamb -2.671678 time 2019-01-27 14:50:08.369664
Model ind 579 epoch 40 head A head_i_epoch 0 batch 100: avg loss -2.709869 avg loss no lamb -2.709869 time 2019-01-27 14:53:05.277670
Model ind 579 epoch 40 head A head_i_epoch 0 batch 200: avg loss -2.783608 avg loss no lamb -2.783608 time 2019-01-27 14:56:02.415616
Pre: time 2019-01-27 14:59:23.982360: 
 	std: 0.00211585
	best_train_sub_head_match: [(0, 0), (1, 16), (2, 5), (3, 6), (4, 2), (5, 17), (6, 8), (7, 10), (8, 14), (9, 19), (10, 9), (11, 7), (12, 13), (13, 18), (14, 1), (15, 15), (16, 3), (17, 11), (18, 4), (19, 12)]
	test_accs: [0.14683333, 0.14535, 0.14251667, 0.14343333, 0.14826667]
	train_accs: [0.14683333, 0.14535, 0.14251667, 0.14343333, 0.14826667]
	best_train_sub_head: 4
	worst: 0.14251667
	avg: 0.14528
	best: 0.14826667

Starting e_i: 41
Model ind 579 epoch 41 head B head_i_epoch 0 batch 0: avg loss -1.308112 avg loss no lamb -1.308112 time 2019-01-27 14:59:29.781725
Model ind 579 epoch 41 head B head_i_epoch 0 batch 100: avg loss -1.374274 avg loss no lamb -1.374274 time 2019-01-27 15:02:25.704487
Model ind 579 epoch 41 head B head_i_epoch 0 batch 200: avg loss -1.400324 avg loss no lamb -1.400324 time 2019-01-27 15:05:21.855762
Model ind 579 epoch 41 head A head_i_epoch 0 batch 0: avg loss -2.625143 avg loss no lamb -2.625143 time 2019-01-27 15:08:18.133317
Model ind 579 epoch 41 head A head_i_epoch 0 batch 100: avg loss -2.725996 avg loss no lamb -2.725996 time 2019-01-27 15:11:15.269772
Model ind 579 epoch 41 head A head_i_epoch 0 batch 200: avg loss -2.709855 avg loss no lamb -2.709855 time 2019-01-27 15:14:12.613904
Pre: time 2019-01-27 15:17:35.036080: 
 	std: 0.0026016426
	best_train_sub_head_match: [(0, 14), (1, 5), (2, 13), (3, 11), (4, 7), (5, 8), (6, 19), (7, 0), (8, 9), (9, 2), (10, 18), (11, 10), (12, 16), (13, 17), (14, 3), (15, 12), (16, 15), (17, 4), (18, 1), (19, 6)]
	test_accs: [0.14145, 0.14751667, 0.14341667, 0.14853333, 0.14483333]
	train_accs: [0.14145, 0.14751667, 0.14341667, 0.14853333, 0.14483333]
	best_train_sub_head: 3
	worst: 0.14145
	avg: 0.14514999
	best: 0.14853333

Starting e_i: 42
Model ind 579 epoch 42 head B head_i_epoch 0 batch 0: avg loss -1.316231 avg loss no lamb -1.316231 time 2019-01-27 15:17:37.435628
Model ind 579 epoch 42 head B head_i_epoch 0 batch 100: avg loss -1.384010 avg loss no lamb -1.384010 time 2019-01-27 15:20:33.428856
Model ind 579 epoch 42 head B head_i_epoch 0 batch 200: avg loss -1.406626 avg loss no lamb -1.406626 time 2019-01-27 15:23:28.940687
Model ind 579 epoch 42 head A head_i_epoch 0 batch 0: avg loss -2.596718 avg loss no lamb -2.596718 time 2019-01-27 15:26:25.079386
Model ind 579 epoch 42 head A head_i_epoch 0 batch 100: avg loss -2.727921 avg loss no lamb -2.727921 time 2019-01-27 15:29:23.006100
Model ind 579 epoch 42 head A head_i_epoch 0 batch 200: avg loss -2.774544 avg loss no lamb -2.774544 time 2019-01-27 15:32:21.279067
Pre: time 2019-01-27 15:35:45.292768: 
 	std: 0.00159166
	best_train_sub_head_match: [(0, 15), (1, 10), (2, 16), (3, 4), (4, 2), (5, 12), (6, 18), (7, 7), (8, 11), (9, 3), (10, 5), (11, 17), (12, 14), (13, 8), (14, 6), (15, 1), (16, 13), (17, 19), (18, 0), (19, 9)]
	test_accs: [0.1477, 0.15188333, 0.15081666, 0.15195, 0.15155]
	train_accs: [0.1477, 0.15188333, 0.15081666, 0.15195, 0.15155]
	best_train_sub_head: 3
	worst: 0.1477
	avg: 0.15077999
	best: 0.15195

Starting e_i: 43
Model ind 579 epoch 43 head B head_i_epoch 0 batch 0: avg loss -1.420173 avg loss no lamb -1.420173 time 2019-01-27 15:35:47.920081
Model ind 579 epoch 43 head B head_i_epoch 0 batch 100: avg loss -1.427986 avg loss no lamb -1.427986 time 2019-01-27 15:38:48.263663
Model ind 579 epoch 43 head B head_i_epoch 0 batch 200: avg loss -1.460062 avg loss no lamb -1.460062 time 2019-01-27 15:41:48.056661
Model ind 579 epoch 43 head A head_i_epoch 0 batch 0: avg loss -2.666039 avg loss no lamb -2.666039 time 2019-01-27 15:44:46.608992
Model ind 579 epoch 43 head A head_i_epoch 0 batch 100: avg loss -2.820288 avg loss no lamb -2.820288 time 2019-01-27 15:47:43.859391
Model ind 579 epoch 43 head A head_i_epoch 0 batch 200: avg loss -2.822091 avg loss no lamb -2.822091 time 2019-01-27 15:50:41.514707
Pre: time 2019-01-27 15:54:03.752885: 
 	std: 0.0014071828
	best_train_sub_head_match: [(0, 9), (1, 1), (2, 17), (3, 12), (4, 4), (5, 10), (6, 8), (7, 11), (8, 3), (9, 16), (10, 7), (11, 13), (12, 5), (13, 14), (14, 15), (15, 2), (16, 18), (17, 0), (18, 6), (19, 19)]
	test_accs: [0.15821667, 0.1606, 0.1564, 0.15948333, 0.15911667]
	train_accs: [0.15821667, 0.1606, 0.1564, 0.15948333, 0.15911667]
	best_train_sub_head: 1
	worst: 0.1564
	avg: 0.15876333
	best: 0.1606

Starting e_i: 44
Model ind 579 epoch 44 head B head_i_epoch 0 batch 0: avg loss -1.378495 avg loss no lamb -1.378495 time 2019-01-27 15:54:06.298934
Model ind 579 epoch 44 head B head_i_epoch 0 batch 100: avg loss -1.438383 avg loss no lamb -1.438383 time 2019-01-27 15:57:02.596894
Model ind 579 epoch 44 head B head_i_epoch 0 batch 200: avg loss -1.438115 avg loss no lamb -1.438115 time 2019-01-27 15:59:58.198195
Model ind 579 epoch 44 head A head_i_epoch 0 batch 0: avg loss -2.728489 avg loss no lamb -2.728489 time 2019-01-27 16:02:53.979337
Model ind 579 epoch 44 head A head_i_epoch 0 batch 100: avg loss -2.826558 avg loss no lamb -2.826558 time 2019-01-27 16:05:51.823300
Model ind 579 epoch 44 head A head_i_epoch 0 batch 200: avg loss -2.786411 avg loss no lamb -2.786411 time 2019-01-27 16:08:49.716383
Pre: time 2019-01-27 16:12:11.565499: 
 	std: 0.0014134141
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 10), (4, 4), (5, 3), (6, 19), (7, 8), (8, 6), (9, 14), (10, 5), (11, 17), (12, 16), (13, 11), (14, 9), (15, 1), (16, 12), (17, 7), (18, 15), (19, 18)]
	test_accs: [0.15716666, 0.15726666, 0.1582, 0.1605, 0.15641667]
	train_accs: [0.15716666, 0.15726666, 0.1582, 0.1605, 0.15641667]
	best_train_sub_head: 3
	worst: 0.15641667
	avg: 0.15791
	best: 0.1605

Starting e_i: 45
Model ind 579 epoch 45 head B head_i_epoch 0 batch 0: avg loss -1.334503 avg loss no lamb -1.334503 time 2019-01-27 16:12:13.917499
Model ind 579 epoch 45 head B head_i_epoch 0 batch 100: avg loss -1.438781 avg loss no lamb -1.438781 time 2019-01-27 16:15:09.553045
Model ind 579 epoch 45 head B head_i_epoch 0 batch 200: avg loss -1.423892 avg loss no lamb -1.423892 time 2019-01-27 16:18:05.395841
Model ind 579 epoch 45 head A head_i_epoch 0 batch 0: avg loss -2.731202 avg loss no lamb -2.731202 time 2019-01-27 16:21:01.340064
Model ind 579 epoch 45 head A head_i_epoch 0 batch 100: avg loss -2.816889 avg loss no lamb -2.816889 time 2019-01-27 16:23:59.098132
Model ind 579 epoch 45 head A head_i_epoch 0 batch 200: avg loss -2.837569 avg loss no lamb -2.837569 time 2019-01-27 16:26:57.109773
Pre: time 2019-01-27 16:30:19.024164: 
 	std: 0.0023520296
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 14), (3, 15), (4, 12), (5, 5), (6, 16), (7, 6), (8, 7), (9, 0), (10, 10), (11, 8), (12, 19), (13, 18), (14, 13), (15, 4), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.16103333, 0.15838334, 0.15498333, 0.15488334, 0.15861666]
	train_accs: [0.16103333, 0.15838334, 0.15498333, 0.15488334, 0.15861666]
	best_train_sub_head: 0
	worst: 0.15488334
	avg: 0.15757999
	best: 0.16103333

Starting e_i: 46
Model ind 579 epoch 46 head B head_i_epoch 0 batch 0: avg loss -1.312387 avg loss no lamb -1.312387 time 2019-01-27 16:30:21.445061
Model ind 579 epoch 46 head B head_i_epoch 0 batch 100: avg loss -1.425759 avg loss no lamb -1.425759 time 2019-01-27 16:33:17.216549
Model ind 579 epoch 46 head B head_i_epoch 0 batch 200: avg loss -1.368654 avg loss no lamb -1.368654 time 2019-01-27 16:36:14.013094
Model ind 579 epoch 46 head A head_i_epoch 0 batch 0: avg loss -2.699805 avg loss no lamb -2.699805 time 2019-01-27 16:39:09.796421
Model ind 579 epoch 46 head A head_i_epoch 0 batch 100: avg loss -2.768637 avg loss no lamb -2.768637 time 2019-01-27 16:42:06.892826
Model ind 579 epoch 46 head A head_i_epoch 0 batch 200: avg loss -2.832780 avg loss no lamb -2.832780 time 2019-01-27 16:45:04.856990
Pre: time 2019-01-27 16:48:26.163824: 
 	std: 0.0029183184
	best_train_sub_head_match: [(0, 10), (1, 16), (2, 6), (3, 12), (4, 3), (5, 1), (6, 7), (7, 18), (8, 14), (9, 15), (10, 4), (11, 19), (12, 17), (13, 13), (14, 5), (15, 8), (16, 11), (17, 0), (18, 9), (19, 2)]
	test_accs: [0.15316667, 0.15668334, 0.16201666, 0.15533334, 0.15686667]
	train_accs: [0.15316667, 0.15668334, 0.16201666, 0.15533334, 0.15686667]
	best_train_sub_head: 2
	worst: 0.15316667
	avg: 0.15681334
	best: 0.16201666

Starting e_i: 47
Model ind 579 epoch 47 head B head_i_epoch 0 batch 0: avg loss -1.327903 avg loss no lamb -1.327903 time 2019-01-27 16:48:32.189495
Model ind 579 epoch 47 head B head_i_epoch 0 batch 100: avg loss -1.339228 avg loss no lamb -1.339228 time 2019-01-27 16:51:28.270806
Model ind 579 epoch 47 head B head_i_epoch 0 batch 200: avg loss -1.377195 avg loss no lamb -1.377195 time 2019-01-27 16:54:24.371825
Model ind 579 epoch 47 head A head_i_epoch 0 batch 0: avg loss -2.756860 avg loss no lamb -2.756860 time 2019-01-27 16:57:21.151841
Model ind 579 epoch 47 head A head_i_epoch 0 batch 100: avg loss -2.853901 avg loss no lamb -2.853901 time 2019-01-27 17:00:19.292854
Model ind 579 epoch 47 head A head_i_epoch 0 batch 200: avg loss -2.821450 avg loss no lamb -2.821450 time 2019-01-27 17:03:16.878040
Pre: time 2019-01-27 17:06:39.170692: 
 	std: 0.002827081
	best_train_sub_head_match: [(0, 5), (1, 2), (2, 13), (3, 18), (4, 12), (5, 17), (6, 8), (7, 1), (8, 14), (9, 0), (10, 9), (11, 7), (12, 16), (13, 19), (14, 4), (15, 15), (16, 6), (17, 3), (18, 10), (19, 11)]
	test_accs: [0.16111666, 0.15866667, 0.15576667, 0.16096666, 0.16426666]
	train_accs: [0.16111666, 0.15866667, 0.15576667, 0.16096666, 0.16426666]
	best_train_sub_head: 4
	worst: 0.15576667
	avg: 0.16015667
	best: 0.16426666

Starting e_i: 48
Model ind 579 epoch 48 head B head_i_epoch 0 batch 0: avg loss -1.317154 avg loss no lamb -1.317154 time 2019-01-27 17:06:45.324341
Model ind 579 epoch 48 head B head_i_epoch 0 batch 100: avg loss -1.395205 avg loss no lamb -1.395205 time 2019-01-27 17:09:40.891466
Model ind 579 epoch 48 head B head_i_epoch 0 batch 200: avg loss -1.457646 avg loss no lamb -1.457646 time 2019-01-27 17:12:36.372976
Model ind 579 epoch 48 head A head_i_epoch 0 batch 0: avg loss -2.784982 avg loss no lamb -2.784982 time 2019-01-27 17:15:31.838046
Model ind 579 epoch 48 head A head_i_epoch 0 batch 100: avg loss -2.836729 avg loss no lamb -2.836729 time 2019-01-27 17:18:29.894747
Model ind 579 epoch 48 head A head_i_epoch 0 batch 200: avg loss -2.820583 avg loss no lamb -2.820583 time 2019-01-27 17:21:27.803600
Pre: time 2019-01-27 17:24:50.804874: 
 	std: 0.0030268142
	best_train_sub_head_match: [(0, 18), (1, 16), (2, 15), (3, 17), (4, 2), (5, 3), (6, 14), (7, 6), (8, 7), (9, 0), (10, 10), (11, 12), (12, 19), (13, 9), (14, 13), (15, 4), (16, 5), (17, 8), (18, 1), (19, 11)]
	test_accs: [0.16546667, 0.16146667, 0.15665, 0.16363333, 0.16008334]
	train_accs: [0.16546667, 0.16146667, 0.15665, 0.16363333, 0.16008334]
	best_train_sub_head: 0
	worst: 0.15665
	avg: 0.16146001
	best: 0.16546667

Starting e_i: 49
Model ind 579 epoch 49 head B head_i_epoch 0 batch 0: avg loss -1.326097 avg loss no lamb -1.326097 time 2019-01-27 17:24:58.967137
Model ind 579 epoch 49 head B head_i_epoch 0 batch 100: avg loss -1.418005 avg loss no lamb -1.418005 time 2019-01-27 17:27:57.244374
Model ind 579 epoch 49 head B head_i_epoch 0 batch 200: avg loss -1.422583 avg loss no lamb -1.422583 time 2019-01-27 17:30:55.137541
Model ind 579 epoch 49 head A head_i_epoch 0 batch 0: avg loss -2.730441 avg loss no lamb -2.730441 time 2019-01-27 17:33:52.165307
Model ind 579 epoch 49 head A head_i_epoch 0 batch 100: avg loss -2.842141 avg loss no lamb -2.842141 time 2019-01-27 17:36:50.819371
Model ind 579 epoch 49 head A head_i_epoch 0 batch 200: avg loss -2.809416 avg loss no lamb -2.809416 time 2019-01-27 17:39:48.714651
Pre: time 2019-01-27 17:43:11.913884: 
 	std: 0.0024108698
	best_train_sub_head_match: [(0, 5), (1, 4), (2, 13), (3, 9), (4, 12), (5, 17), (6, 8), (7, 19), (8, 14), (9, 0), (10, 11), (11, 7), (12, 16), (13, 18), (14, 1), (15, 15), (16, 6), (17, 3), (18, 10), (19, 2)]
	test_accs: [0.1648, 0.16381666, 0.16013333, 0.16046667, 0.16625]
	train_accs: [0.1648, 0.16381666, 0.16013333, 0.16046667, 0.16625]
	best_train_sub_head: 4
	worst: 0.16013333
	avg: 0.16309333
	best: 0.16625

Starting e_i: 50
Model ind 579 epoch 50 head B head_i_epoch 0 batch 0: avg loss -1.302870 avg loss no lamb -1.302870 time 2019-01-27 17:43:18.473469
Model ind 579 epoch 50 head B head_i_epoch 0 batch 100: avg loss -1.402616 avg loss no lamb -1.402616 time 2019-01-27 17:46:17.002522
Model ind 579 epoch 50 head B head_i_epoch 0 batch 200: avg loss -1.376348 avg loss no lamb -1.376348 time 2019-01-27 17:49:14.689523
Model ind 579 epoch 50 head A head_i_epoch 0 batch 0: avg loss -2.807081 avg loss no lamb -2.807081 time 2019-01-27 17:52:10.859025
Model ind 579 epoch 50 head A head_i_epoch 0 batch 100: avg loss -2.881071 avg loss no lamb -2.881071 time 2019-01-27 17:55:09.003260
Model ind 579 epoch 50 head A head_i_epoch 0 batch 200: avg loss -2.873871 avg loss no lamb -2.873871 time 2019-01-27 17:58:07.928132
Pre: time 2019-01-27 18:01:31.691010: 
 	std: 0.001283284
	best_train_sub_head_match: [(0, 3), (1, 14), (2, 13), (3, 9), (4, 12), (5, 17), (6, 8), (7, 5), (8, 1), (9, 0), (10, 18), (11, 7), (12, 16), (13, 19), (14, 4), (15, 15), (16, 6), (17, 11), (18, 10), (19, 2)]
	test_accs: [0.16265, 0.16215, 0.16178334, 0.16236667, 0.16536666]
	train_accs: [0.16265, 0.16215, 0.16178334, 0.16236667, 0.16536666]
	best_train_sub_head: 4
	worst: 0.16178334
	avg: 0.16286334
	best: 0.16536666

Starting e_i: 51
Model ind 579 epoch 51 head B head_i_epoch 0 batch 0: avg loss -1.393718 avg loss no lamb -1.393718 time 2019-01-27 18:01:40.159538
Model ind 579 epoch 51 head B head_i_epoch 0 batch 100: avg loss -1.427816 avg loss no lamb -1.427816 time 2019-01-27 18:04:37.336361
Model ind 579 epoch 51 head B head_i_epoch 0 batch 200: avg loss -1.423498 avg loss no lamb -1.423498 time 2019-01-27 18:07:34.299780
Model ind 579 epoch 51 head A head_i_epoch 0 batch 0: avg loss -2.792116 avg loss no lamb -2.792116 time 2019-01-27 18:10:32.286663
Model ind 579 epoch 51 head A head_i_epoch 0 batch 100: avg loss -2.827766 avg loss no lamb -2.827766 time 2019-01-27 18:13:30.772540
Model ind 579 epoch 51 head A head_i_epoch 0 batch 200: avg loss -2.904864 avg loss no lamb -2.904864 time 2019-01-27 18:16:29.487448
Pre: time 2019-01-27 18:19:52.957887: 
 	std: 0.001212114
	best_train_sub_head_match: [(0, 10), (1, 2), (2, 6), (3, 12), (4, 9), (5, 16), (6, 13), (7, 18), (8, 14), (9, 5), (10, 4), (11, 19), (12, 3), (13, 15), (14, 7), (15, 17), (16, 8), (17, 0), (18, 1), (19, 11)]
	test_accs: [0.15181667, 0.15038334, 0.15413333, 0.15215, 0.1526]
	train_accs: [0.15181667, 0.15038334, 0.15413333, 0.15215, 0.1526]
	best_train_sub_head: 2
	worst: 0.15038334
	avg: 0.15221666
	best: 0.15413333

Starting e_i: 52
Model ind 579 epoch 52 head B head_i_epoch 0 batch 0: avg loss -1.380888 avg loss no lamb -1.380888 time 2019-01-27 18:19:55.431988
Model ind 579 epoch 52 head B head_i_epoch 0 batch 100: avg loss -1.497664 avg loss no lamb -1.497664 time 2019-01-27 18:22:52.330960
Model ind 579 epoch 52 head B head_i_epoch 0 batch 200: avg loss -1.403183 avg loss no lamb -1.403183 time 2019-01-27 18:25:48.725995
Model ind 579 epoch 52 head A head_i_epoch 0 batch 0: avg loss -2.812434 avg loss no lamb -2.812434 time 2019-01-27 18:28:46.339476
Model ind 579 epoch 52 head A head_i_epoch 0 batch 100: avg loss -2.850561 avg loss no lamb -2.850561 time 2019-01-27 18:31:44.874824
Model ind 579 epoch 52 head A head_i_epoch 0 batch 200: avg loss -2.889269 avg loss no lamb -2.889269 time 2019-01-27 18:34:42.285386
Pre: time 2019-01-27 18:38:05.557006: 
 	std: 0.0024778661
	best_train_sub_head_match: [(0, 4), (1, 16), (2, 7), (3, 5), (4, 12), (5, 17), (6, 8), (7, 3), (8, 14), (9, 0), (10, 9), (11, 19), (12, 13), (13, 18), (14, 1), (15, 15), (16, 6), (17, 2), (18, 10), (19, 11)]
	test_accs: [0.15586667, 0.1553, 0.1521, 0.15783334, 0.15941666]
	train_accs: [0.15586667, 0.1553, 0.1521, 0.15783334, 0.15941666]
	best_train_sub_head: 4
	worst: 0.1521
	avg: 0.15610334
	best: 0.15941666

Starting e_i: 53
Model ind 579 epoch 53 head B head_i_epoch 0 batch 0: avg loss -1.396016 avg loss no lamb -1.396016 time 2019-01-27 18:38:07.944543
Model ind 579 epoch 53 head B head_i_epoch 0 batch 100: avg loss -1.422275 avg loss no lamb -1.422275 time 2019-01-27 18:41:02.957970
Model ind 579 epoch 53 head B head_i_epoch 0 batch 200: avg loss -1.384276 avg loss no lamb -1.384276 time 2019-01-27 18:43:58.794531
Model ind 579 epoch 53 head A head_i_epoch 0 batch 0: avg loss -2.805266 avg loss no lamb -2.805266 time 2019-01-27 18:46:53.967928
Model ind 579 epoch 53 head A head_i_epoch 0 batch 100: avg loss -2.866656 avg loss no lamb -2.866656 time 2019-01-27 18:49:50.463467
Model ind 579 epoch 53 head A head_i_epoch 0 batch 200: avg loss -2.904295 avg loss no lamb -2.904295 time 2019-01-27 18:52:46.783384
Pre: time 2019-01-27 18:56:08.106046: 
 	std: 0.0021457293
	best_train_sub_head_match: [(0, 6), (1, 16), (2, 12), (3, 19), (4, 2), (5, 17), (6, 8), (7, 0), (8, 14), (9, 15), (10, 18), (11, 7), (12, 1), (13, 5), (14, 4), (15, 13), (16, 9), (17, 3), (18, 10), (19, 11)]
	test_accs: [0.1544, 0.14861667, 0.15228334, 0.15213333, 0.15455]
	train_accs: [0.1544, 0.14861667, 0.15228334, 0.15213333, 0.15455]
	best_train_sub_head: 4
	worst: 0.14861667
	avg: 0.15239666
	best: 0.15455

Starting e_i: 54
Model ind 579 epoch 54 head B head_i_epoch 0 batch 0: avg loss -1.356949 avg loss no lamb -1.356949 time 2019-01-27 18:56:10.572275
Model ind 579 epoch 54 head B head_i_epoch 0 batch 100: avg loss -1.419313 avg loss no lamb -1.419313 time 2019-01-27 18:59:07.361549
Model ind 579 epoch 54 head B head_i_epoch 0 batch 200: avg loss -1.449169 avg loss no lamb -1.449169 time 2019-01-27 19:02:05.399794
Model ind 579 epoch 54 head A head_i_epoch 0 batch 0: avg loss -2.841892 avg loss no lamb -2.841892 time 2019-01-27 19:05:03.238934
Model ind 579 epoch 54 head A head_i_epoch 0 batch 100: avg loss -2.869714 avg loss no lamb -2.869714 time 2019-01-27 19:08:01.238805
Model ind 579 epoch 54 head A head_i_epoch 0 batch 200: avg loss -2.884157 avg loss no lamb -2.884157 time 2019-01-27 19:10:59.739550
Pre: time 2019-01-27 19:14:23.459643: 
 	std: 0.0027125154
	best_train_sub_head_match: [(0, 3), (1, 2), (2, 15), (3, 9), (4, 12), (5, 17), (6, 13), (7, 10), (8, 1), (9, 0), (10, 19), (11, 7), (12, 16), (13, 18), (14, 4), (15, 14), (16, 6), (17, 11), (18, 5), (19, 8)]
	test_accs: [0.15301667, 0.15103333, 0.15128334, 0.14878333, 0.15691666]
	train_accs: [0.15301667, 0.15103333, 0.15128334, 0.14878333, 0.15691666]
	best_train_sub_head: 4
	worst: 0.14878333
	avg: 0.15220667
	best: 0.15691666

Starting e_i: 55
Model ind 579 epoch 55 head B head_i_epoch 0 batch 0: avg loss -1.389298 avg loss no lamb -1.389298 time 2019-01-27 19:14:25.991200
Model ind 579 epoch 55 head B head_i_epoch 0 batch 100: avg loss -1.477475 avg loss no lamb -1.477475 time 2019-01-27 19:17:23.464186
Model ind 579 epoch 55 head B head_i_epoch 0 batch 200: avg loss -1.490195 avg loss no lamb -1.490195 time 2019-01-27 19:20:20.462041
Model ind 579 epoch 55 head A head_i_epoch 0 batch 0: avg loss -2.814528 avg loss no lamb -2.814528 time 2019-01-27 19:23:18.376778
Model ind 579 epoch 55 head A head_i_epoch 0 batch 100: avg loss -2.898696 avg loss no lamb -2.898696 time 2019-01-27 19:26:18.258802
Model ind 579 epoch 55 head A head_i_epoch 0 batch 200: avg loss -2.894903 avg loss no lamb -2.894903 time 2019-01-27 19:29:19.187196
Pre: time 2019-01-27 19:32:45.588058: 
 	std: 0.0007342862
	best_train_sub_head_match: [(0, 4), (1, 16), (2, 6), (3, 12), (4, 11), (5, 5), (6, 13), (7, 9), (8, 1), (9, 18), (10, 2), (11, 19), (12, 17), (13, 0), (14, 14), (15, 7), (16, 8), (17, 3), (18, 10), (19, 15)]
	test_accs: [0.15881667, 0.16065, 0.16086666, 0.15966667, 0.15988334]
	train_accs: [0.15881667, 0.16065, 0.16086666, 0.15966667, 0.15988334]
	best_train_sub_head: 2
	worst: 0.15881667
	avg: 0.15997666
	best: 0.16086666

Starting e_i: 56
Model ind 579 epoch 56 head B head_i_epoch 0 batch 0: avg loss -1.333750 avg loss no lamb -1.333750 time 2019-01-27 19:32:48.067791
Model ind 579 epoch 56 head B head_i_epoch 0 batch 100: avg loss -1.427925 avg loss no lamb -1.427925 time 2019-01-27 19:35:47.442141
Model ind 579 epoch 56 head B head_i_epoch 0 batch 200: avg loss -1.388393 avg loss no lamb -1.388393 time 2019-01-27 19:38:47.127736
Model ind 579 epoch 56 head A head_i_epoch 0 batch 0: avg loss -2.819132 avg loss no lamb -2.819132 time 2019-01-27 19:41:44.899621
Model ind 579 epoch 56 head A head_i_epoch 0 batch 100: avg loss -2.834728 avg loss no lamb -2.834728 time 2019-01-27 19:44:44.523913
Model ind 579 epoch 56 head A head_i_epoch 0 batch 200: avg loss -2.878175 avg loss no lamb -2.878175 time 2019-01-27 19:47:44.841745
Pre: time 2019-01-27 19:51:08.977342: 
 	std: 0.002312369
	best_train_sub_head_match: [(0, 11), (1, 12), (2, 15), (3, 9), (4, 13), (5, 0), (6, 17), (7, 3), (8, 1), (9, 10), (10, 19), (11, 5), (12, 2), (13, 18), (14, 16), (15, 14), (16, 6), (17, 8), (18, 4), (19, 7)]
	test_accs: [0.1496, 0.14848334, 0.14836666, 0.14941667, 0.15461667]
	train_accs: [0.1496, 0.14848334, 0.14836666, 0.14941667, 0.15461667]
	best_train_sub_head: 4
	worst: 0.14836666
	avg: 0.15009667
	best: 0.15461667

Starting e_i: 57
Model ind 579 epoch 57 head B head_i_epoch 0 batch 0: avg loss -1.348089 avg loss no lamb -1.348089 time 2019-01-27 19:51:11.603339
Model ind 579 epoch 57 head B head_i_epoch 0 batch 100: avg loss -1.450783 avg loss no lamb -1.450783 time 2019-01-27 19:54:10.035920
Model ind 579 epoch 57 head B head_i_epoch 0 batch 200: avg loss -1.375849 avg loss no lamb -1.375849 time 2019-01-27 19:57:08.593681
Model ind 579 epoch 57 head A head_i_epoch 0 batch 0: avg loss -2.788388 avg loss no lamb -2.788388 time 2019-01-27 20:00:07.141611
Model ind 579 epoch 57 head A head_i_epoch 0 batch 100: avg loss -2.879159 avg loss no lamb -2.879159 time 2019-01-27 20:03:06.200120
Model ind 579 epoch 57 head A head_i_epoch 0 batch 200: avg loss -2.914520 avg loss no lamb -2.914520 time 2019-01-27 20:06:05.086675
Pre: time 2019-01-27 20:09:28.789150: 
 	std: 0.0017494002
	best_train_sub_head_match: [(0, 4), (1, 16), (2, 15), (3, 5), (4, 12), (5, 19), (6, 8), (7, 10), (8, 14), (9, 17), (10, 9), (11, 7), (12, 0), (13, 18), (14, 1), (15, 13), (16, 6), (17, 11), (18, 3), (19, 2)]
	test_accs: [0.15868333, 0.15796667, 0.15963334, 0.15986666, 0.16306667]
	train_accs: [0.15868333, 0.15796667, 0.15963334, 0.15986666, 0.16306667]
	best_train_sub_head: 4
	worst: 0.15796667
	avg: 0.15984334
	best: 0.16306667

Starting e_i: 58
Model ind 579 epoch 58 head B head_i_epoch 0 batch 0: avg loss -1.335690 avg loss no lamb -1.335690 time 2019-01-27 20:09:31.418352
Model ind 579 epoch 58 head B head_i_epoch 0 batch 100: avg loss -1.421750 avg loss no lamb -1.421750 time 2019-01-27 20:12:29.070500
Model ind 579 epoch 58 head B head_i_epoch 0 batch 200: avg loss -1.518697 avg loss no lamb -1.518697 time 2019-01-27 20:15:28.009055
Model ind 579 epoch 58 head A head_i_epoch 0 batch 0: avg loss -2.851472 avg loss no lamb -2.851472 time 2019-01-27 20:18:28.613269
Model ind 579 epoch 58 head A head_i_epoch 0 batch 100: avg loss -2.925097 avg loss no lamb -2.925097 time 2019-01-27 20:21:28.705266
Model ind 579 epoch 58 head A head_i_epoch 0 batch 200: avg loss -2.870233 avg loss no lamb -2.870233 time 2019-01-27 20:24:27.950412
Pre: time 2019-01-27 20:27:51.474225: 
 	std: 0.0024565454
	best_train_sub_head_match: [(0, 10), (1, 1), (2, 6), (3, 2), (4, 4), (5, 14), (6, 7), (7, 9), (8, 0), (9, 18), (10, 3), (11, 11), (12, 8), (13, 13), (14, 15), (15, 12), (16, 16), (17, 17), (18, 19), (19, 5)]
	test_accs: [0.1556, 0.15735, 0.16178334, 0.15463333, 0.15703334]
	train_accs: [0.1556, 0.15735, 0.16178334, 0.15463333, 0.15703334]
	best_train_sub_head: 2
	worst: 0.15463333
	avg: 0.15728
	best: 0.16178334

Starting e_i: 59
Model ind 579 epoch 59 head B head_i_epoch 0 batch 0: avg loss -1.260331 avg loss no lamb -1.260331 time 2019-01-27 20:27:53.889958
Model ind 579 epoch 59 head B head_i_epoch 0 batch 100: avg loss -1.353927 avg loss no lamb -1.353927 time 2019-01-27 20:30:50.807986
Model ind 579 epoch 59 head B head_i_epoch 0 batch 200: avg loss -1.454773 avg loss no lamb -1.454773 time 2019-01-27 20:33:48.603846
Model ind 579 epoch 59 head A head_i_epoch 0 batch 0: avg loss -2.794586 avg loss no lamb -2.794586 time 2019-01-27 20:36:46.564679
Model ind 579 epoch 59 head A head_i_epoch 0 batch 100: avg loss -2.894177 avg loss no lamb -2.894177 time 2019-01-27 20:39:44.056299
Model ind 579 epoch 59 head A head_i_epoch 0 batch 200: avg loss -2.957496 avg loss no lamb -2.957496 time 2019-01-27 20:42:42.058416
Pre: time 2019-01-27 20:46:04.926903: 
 	std: 0.0011206465
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 13), (3, 5), (4, 7), (5, 17), (6, 3), (7, 10), (8, 14), (9, 0), (10, 9), (11, 19), (12, 12), (13, 18), (14, 16), (15, 15), (16, 6), (17, 11), (18, 1), (19, 8)]
	test_accs: [0.1579, 0.15723333, 0.15893333, 0.15728334, 0.16018334]
	train_accs: [0.1579, 0.15723333, 0.15893333, 0.15728334, 0.16018334]
	best_train_sub_head: 4
	worst: 0.15723333
	avg: 0.15830667
	best: 0.16018334

Starting e_i: 60
Model ind 579 epoch 60 head B head_i_epoch 0 batch 0: avg loss -1.416822 avg loss no lamb -1.416822 time 2019-01-27 20:46:07.365321
Model ind 579 epoch 60 head B head_i_epoch 0 batch 100: avg loss -1.485592 avg loss no lamb -1.485592 time 2019-01-27 20:49:04.470289
Model ind 579 epoch 60 head B head_i_epoch 0 batch 200: avg loss -1.444230 avg loss no lamb -1.444230 time 2019-01-27 20:52:00.842364
Model ind 579 epoch 60 head A head_i_epoch 0 batch 0: avg loss -2.819754 avg loss no lamb -2.819754 time 2019-01-27 20:54:57.446167
Model ind 579 epoch 60 head A head_i_epoch 0 batch 100: avg loss -2.885170 avg loss no lamb -2.885170 time 2019-01-27 20:57:55.682611
Model ind 579 epoch 60 head A head_i_epoch 0 batch 200: avg loss -2.845025 avg loss no lamb -2.845025 time 2019-01-27 21:00:54.768169
Pre: time 2019-01-27 21:04:18.299615: 
 	std: 0.0024327056
	best_train_sub_head_match: [(0, 3), (1, 2), (2, 15), (3, 9), (4, 12), (5, 0), (6, 17), (7, 5), (8, 1), (9, 14), (10, 19), (11, 7), (12, 16), (13, 18), (14, 4), (15, 13), (16, 6), (17, 11), (18, 10), (19, 8)]
	test_accs: [0.15683334, 0.15466666, 0.15111667, 0.15388334, 0.15813333]
	train_accs: [0.15683334, 0.15466666, 0.15111667, 0.15388334, 0.15813333]
	best_train_sub_head: 4
	worst: 0.15111667
	avg: 0.15492667
	best: 0.15813333

Starting e_i: 61
Model ind 579 epoch 61 head B head_i_epoch 0 batch 0: avg loss -1.377553 avg loss no lamb -1.377553 time 2019-01-27 21:04:24.358534
Model ind 579 epoch 61 head B head_i_epoch 0 batch 100: avg loss -1.387961 avg loss no lamb -1.387961 time 2019-01-27 21:07:20.596886
Model ind 579 epoch 61 head B head_i_epoch 0 batch 200: avg loss -1.399850 avg loss no lamb -1.399850 time 2019-01-27 21:10:17.138029
Model ind 579 epoch 61 head A head_i_epoch 0 batch 0: avg loss -2.899840 avg loss no lamb -2.899840 time 2019-01-27 21:13:14.007670
Model ind 579 epoch 61 head A head_i_epoch 0 batch 100: avg loss -2.926622 avg loss no lamb -2.926622 time 2019-01-27 21:16:13.230310
Model ind 579 epoch 61 head A head_i_epoch 0 batch 200: avg loss -2.885974 avg loss no lamb -2.885974 time 2019-01-27 21:19:12.509015
Pre: time 2019-01-27 21:22:36.715847: 
 	std: 0.0035178335
	best_train_sub_head_match: [(0, 11), (1, 12), (2, 0), (3, 9), (4, 15), (5, 10), (6, 17), (7, 4), (8, 5), (9, 1), (10, 19), (11, 18), (12, 13), (13, 6), (14, 16), (15, 14), (16, 3), (17, 7), (18, 2), (19, 8)]
	test_accs: [0.14896667, 0.14511667, 0.14503333, 0.14521667, 0.15405]
	train_accs: [0.14896667, 0.14511667, 0.14503333, 0.14521667, 0.15405]
	best_train_sub_head: 4
	worst: 0.14503333
	avg: 0.14767668
	best: 0.15405

Starting e_i: 62
Model ind 579 epoch 62 head B head_i_epoch 0 batch 0: avg loss -1.339594 avg loss no lamb -1.339594 time 2019-01-27 21:22:39.283555
Model ind 579 epoch 62 head B head_i_epoch 0 batch 100: avg loss -1.387717 avg loss no lamb -1.387717 time 2019-01-27 21:25:37.830947
Model ind 579 epoch 62 head B head_i_epoch 0 batch 200: avg loss -1.451421 avg loss no lamb -1.451421 time 2019-01-27 21:28:35.291225
Model ind 579 epoch 62 head A head_i_epoch 0 batch 0: avg loss -2.745618 avg loss no lamb -2.745618 time 2019-01-27 21:31:32.310057
Model ind 579 epoch 62 head A head_i_epoch 0 batch 100: avg loss -2.866203 avg loss no lamb -2.866203 time 2019-01-27 21:34:31.818304
Model ind 579 epoch 62 head A head_i_epoch 0 batch 200: avg loss -2.914257 avg loss no lamb -2.914257 time 2019-01-27 21:37:30.490303
Pre: time 2019-01-27 21:40:58.950277: 
 	std: 0.0022887005
	best_train_sub_head_match: [(0, 2), (1, 16), (2, 13), (3, 9), (4, 12), (5, 17), (6, 7), (7, 10), (8, 1), (9, 0), (10, 19), (11, 5), (12, 14), (13, 18), (14, 3), (15, 15), (16, 6), (17, 11), (18, 4), (19, 8)]
	test_accs: [0.15521666, 0.1517, 0.151, 0.15178333, 0.15681666]
	train_accs: [0.15521666, 0.1517, 0.151, 0.15178333, 0.15681666]
	best_train_sub_head: 4
	worst: 0.151
	avg: 0.15330333
	best: 0.15681666

Starting e_i: 63
Model ind 579 epoch 63 head B head_i_epoch 0 batch 0: avg loss -1.345358 avg loss no lamb -1.345358 time 2019-01-27 21:41:01.583277
Model ind 579 epoch 63 head B head_i_epoch 0 batch 100: avg loss -1.420919 avg loss no lamb -1.420919 time 2019-01-27 21:44:04.755150
Model ind 579 epoch 63 head B head_i_epoch 0 batch 200: avg loss -1.415102 avg loss no lamb -1.415102 time 2019-01-27 21:47:05.921979
Model ind 579 epoch 63 head A head_i_epoch 0 batch 0: avg loss -2.846257 avg loss no lamb -2.846257 time 2019-01-27 21:50:04.908656
Model ind 579 epoch 63 head A head_i_epoch 0 batch 100: avg loss -2.893298 avg loss no lamb -2.893298 time 2019-01-27 21:53:04.977195
Model ind 579 epoch 63 head A head_i_epoch 0 batch 200: avg loss -2.935591 avg loss no lamb -2.935591 time 2019-01-27 21:56:04.528671
Pre: time 2019-01-27 21:59:29.512831: 
 	std: 0.0014365313
	best_train_sub_head_match: [(0, 3), (1, 11), (2, 13), (3, 18), (4, 12), (5, 17), (6, 8), (7, 1), (8, 14), (9, 0), (10, 19), (11, 7), (12, 2), (13, 15), (14, 4), (15, 16), (16, 6), (17, 9), (18, 10), (19, 5)]
	test_accs: [0.15305, 0.152, 0.15051667, 0.15423334, 0.15433334]
	train_accs: [0.15305, 0.152, 0.15051667, 0.15423334, 0.15433334]
	best_train_sub_head: 4
	worst: 0.15051667
	avg: 0.15282668
	best: 0.15433334

Starting e_i: 64
Model ind 579 epoch 64 head B head_i_epoch 0 batch 0: avg loss -1.359995 avg loss no lamb -1.359995 time 2019-01-27 21:59:32.342799
Model ind 579 epoch 64 head B head_i_epoch 0 batch 100: avg loss -1.411183 avg loss no lamb -1.411183 time 2019-01-27 22:02:32.366064
Model ind 579 epoch 64 head B head_i_epoch 0 batch 200: avg loss -1.444748 avg loss no lamb -1.444748 time 2019-01-27 22:05:32.035048
Model ind 579 epoch 64 head A head_i_epoch 0 batch 0: avg loss -2.860734 avg loss no lamb -2.860734 time 2019-01-27 22:08:30.638272
Model ind 579 epoch 64 head A head_i_epoch 0 batch 100: avg loss -2.915727 avg loss no lamb -2.915727 time 2019-01-27 22:11:30.211595
Model ind 579 epoch 64 head A head_i_epoch 0 batch 200: avg loss -2.888518 avg loss no lamb -2.888518 time 2019-01-27 22:14:30.302858
Pre: time 2019-01-27 22:17:55.149545: 
 	std: 0.001020861
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 15), (3, 19), (4, 12), (5, 17), (6, 13), (7, 10), (8, 1), (9, 0), (10, 18), (11, 7), (12, 16), (13, 5), (14, 4), (15, 14), (16, 6), (17, 11), (18, 3), (19, 8)]
	test_accs: [0.1575, 0.15731667, 0.1552, 0.15588333, 0.15783334]
	train_accs: [0.1575, 0.15731667, 0.1552, 0.15588333, 0.15783334]
	best_train_sub_head: 4
	worst: 0.1552
	avg: 0.15674666
	best: 0.15783334

Starting e_i: 65
Model ind 579 epoch 65 head B head_i_epoch 0 batch 0: avg loss -1.324426 avg loss no lamb -1.324426 time 2019-01-27 22:17:57.847228
Model ind 579 epoch 65 head B head_i_epoch 0 batch 100: avg loss -1.339909 avg loss no lamb -1.339909 time 2019-01-27 22:20:56.523410
Model ind 579 epoch 65 head B head_i_epoch 0 batch 200: avg loss -1.430098 avg loss no lamb -1.430098 time 2019-01-27 22:23:54.942574
Model ind 579 epoch 65 head A head_i_epoch 0 batch 0: avg loss -2.893466 avg loss no lamb -2.893466 time 2019-01-27 22:26:53.182987
Model ind 579 epoch 65 head A head_i_epoch 0 batch 100: avg loss -2.900987 avg loss no lamb -2.900987 time 2019-01-27 22:29:52.921003
Model ind 579 epoch 65 head A head_i_epoch 0 batch 200: avg loss -2.939613 avg loss no lamb -2.939613 time 2019-01-27 22:32:51.136487
Pre: time 2019-01-27 22:36:14.552296: 
 	std: 0.0010708963
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 15), (3, 19), (4, 12), (5, 17), (6, 7), (7, 10), (8, 1), (9, 0), (10, 13), (11, 5), (12, 2), (13, 18), (14, 4), (15, 14), (16, 6), (17, 11), (18, 3), (19, 8)]
	test_accs: [0.16646667, 0.16721667, 0.16603333, 0.1666, 0.16908333]
	train_accs: [0.16646667, 0.16721667, 0.16603333, 0.1666, 0.16908333]
	best_train_sub_head: 4
	worst: 0.16603333
	avg: 0.16708
	best: 0.16908333

Starting e_i: 66
Model ind 579 epoch 66 head B head_i_epoch 0 batch 0: avg loss -1.306253 avg loss no lamb -1.306253 time 2019-01-27 22:36:21.792889
Model ind 579 epoch 66 head B head_i_epoch 0 batch 100: avg loss -1.398790 avg loss no lamb -1.398790 time 2019-01-27 22:39:18.976757
Model ind 579 epoch 66 head B head_i_epoch 0 batch 200: avg loss -1.414198 avg loss no lamb -1.414198 time 2019-01-27 22:42:14.827540
Model ind 579 epoch 66 head A head_i_epoch 0 batch 0: avg loss -2.838425 avg loss no lamb -2.838425 time 2019-01-27 22:45:09.993035
Model ind 579 epoch 66 head A head_i_epoch 0 batch 100: avg loss -2.898017 avg loss no lamb -2.898017 time 2019-01-27 22:48:07.560118
Model ind 579 epoch 66 head A head_i_epoch 0 batch 200: avg loss -2.929240 avg loss no lamb -2.929240 time 2019-01-27 22:51:05.497467
Pre: time 2019-01-27 22:54:27.616633: 
 	std: 0.0015039721
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 13), (3, 9), (4, 12), (5, 17), (6, 8), (7, 0), (8, 14), (9, 5), (10, 19), (11, 7), (12, 16), (13, 18), (14, 1), (15, 15), (16, 6), (17, 3), (18, 10), (19, 11)]
	test_accs: [0.15565, 0.15665, 0.15523334, 0.15653333, 0.15953334]
	train_accs: [0.15565, 0.15665, 0.15523334, 0.15653333, 0.15953334]
	best_train_sub_head: 4
	worst: 0.15523334
	avg: 0.15672001
	best: 0.15953334

Starting e_i: 67
Model ind 579 epoch 67 head B head_i_epoch 0 batch 0: avg loss -1.357620 avg loss no lamb -1.357620 time 2019-01-27 22:54:30.213612
Model ind 579 epoch 67 head B head_i_epoch 0 batch 100: avg loss -1.473223 avg loss no lamb -1.473223 time 2019-01-27 22:57:25.752794
Model ind 579 epoch 67 head B head_i_epoch 0 batch 200: avg loss -1.448090 avg loss no lamb -1.448090 time 2019-01-27 23:00:21.264804
Model ind 579 epoch 67 head A head_i_epoch 0 batch 0: avg loss -2.803022 avg loss no lamb -2.803022 time 2019-01-27 23:03:16.985050
Model ind 579 epoch 67 head A head_i_epoch 0 batch 100: avg loss -2.973057 avg loss no lamb -2.973057 time 2019-01-27 23:06:13.686107
Model ind 579 epoch 67 head A head_i_epoch 0 batch 200: avg loss -2.913394 avg loss no lamb -2.913394 time 2019-01-27 23:09:10.218915
Pre: time 2019-01-27 23:12:32.796454: 
 	std: 0.0014804496
	best_train_sub_head_match: [(0, 13), (1, 14), (2, 11), (3, 10), (4, 5), (5, 3), (6, 18), (7, 7), (8, 6), (9, 1), (10, 9), (11, 17), (12, 2), (13, 8), (14, 0), (15, 4), (16, 12), (17, 15), (18, 16), (19, 19)]
	test_accs: [0.16098334, 0.15918334, 0.15748334, 0.16161667, 0.15901667]
	train_accs: [0.16098334, 0.15918334, 0.15748334, 0.16161667, 0.15901667]
	best_train_sub_head: 3
	worst: 0.15748334
	avg: 0.15965667
	best: 0.16161667

Starting e_i: 68
Model ind 579 epoch 68 head B head_i_epoch 0 batch 0: avg loss -1.335283 avg loss no lamb -1.335283 time 2019-01-27 23:12:35.351443
Model ind 579 epoch 68 head B head_i_epoch 0 batch 100: avg loss -1.310304 avg loss no lamb -1.310304 time 2019-01-27 23:15:32.005033
Model ind 579 epoch 68 head B head_i_epoch 0 batch 200: avg loss -1.434575 avg loss no lamb -1.434575 time 2019-01-27 23:18:30.798740
Model ind 579 epoch 68 head A head_i_epoch 0 batch 0: avg loss -2.866421 avg loss no lamb -2.866421 time 2019-01-27 23:21:30.495995
Model ind 579 epoch 68 head A head_i_epoch 0 batch 100: avg loss -2.919536 avg loss no lamb -2.919536 time 2019-01-27 23:24:31.088248
Model ind 579 epoch 68 head A head_i_epoch 0 batch 200: avg loss -2.954596 avg loss no lamb -2.954596 time 2019-01-27 23:27:30.906274
Pre: time 2019-01-27 23:30:56.096646: 
 	std: 0.0022652296
	best_train_sub_head_match: [(0, 5), (1, 16), (2, 12), (3, 9), (4, 2), (5, 17), (6, 8), (7, 0), (8, 14), (9, 15), (10, 18), (11, 7), (12, 1), (13, 19), (14, 4), (15, 13), (16, 6), (17, 3), (18, 10), (19, 11)]
	test_accs: [0.16563334, 0.16598333, 0.17038333, 0.1679, 0.17125]
	train_accs: [0.16563334, 0.16598333, 0.17038333, 0.1679, 0.17125]
	best_train_sub_head: 4
	worst: 0.16563334
	avg: 0.16822998
	best: 0.17125

Starting e_i: 69
Model ind 579 epoch 69 head B head_i_epoch 0 batch 0: avg loss -1.332029 avg loss no lamb -1.332029 time 2019-01-27 23:31:02.667980
Model ind 579 epoch 69 head B head_i_epoch 0 batch 100: avg loss -1.441579 avg loss no lamb -1.441579 time 2019-01-27 23:34:01.466185
Model ind 579 epoch 69 head B head_i_epoch 0 batch 200: avg loss -1.431003 avg loss no lamb -1.431003 time 2019-01-27 23:36:59.135176
Model ind 579 epoch 69 head A head_i_epoch 0 batch 0: avg loss -2.920876 avg loss no lamb -2.920876 time 2019-01-27 23:39:57.704266
Model ind 579 epoch 69 head A head_i_epoch 0 batch 100: avg loss -3.000534 avg loss no lamb -3.000534 time 2019-01-27 23:42:58.594458
Model ind 579 epoch 69 head A head_i_epoch 0 batch 200: avg loss -2.967765 avg loss no lamb -2.967765 time 2019-01-27 23:45:58.376575
Pre: time 2019-01-27 23:49:22.770412: 
 	std: 0.0014858969
	best_train_sub_head_match: [(0, 3), (1, 16), (2, 12), (3, 9), (4, 2), (5, 17), (6, 8), (7, 0), (8, 14), (9, 15), (10, 18), (11, 7), (12, 1), (13, 19), (14, 4), (15, 13), (16, 6), (17, 5), (18, 10), (19, 11)]
	test_accs: [0.16671667, 0.16373333, 0.1657, 0.16638333, 0.1683]
	train_accs: [0.16671667, 0.16373333, 0.1657, 0.16638333, 0.1683]
	best_train_sub_head: 4
	worst: 0.16373333
	avg: 0.16616666
	best: 0.1683

Starting e_i: 70
Model ind 579 epoch 70 head B head_i_epoch 0 batch 0: avg loss -1.356567 avg loss no lamb -1.356567 time 2019-01-27 23:49:25.538616
Model ind 579 epoch 70 head B head_i_epoch 0 batch 100: avg loss -1.403322 avg loss no lamb -1.403322 time 2019-01-27 23:52:24.175548
Model ind 579 epoch 70 head B head_i_epoch 0 batch 200: avg loss -1.487193 avg loss no lamb -1.487193 time 2019-01-27 23:55:22.287239
Model ind 579 epoch 70 head A head_i_epoch 0 batch 0: avg loss -2.890925 avg loss no lamb -2.890925 time 2019-01-27 23:58:20.225517
Model ind 579 epoch 70 head A head_i_epoch 0 batch 100: avg loss -2.936117 avg loss no lamb -2.936117 time 2019-01-28 00:01:19.422457
Model ind 579 epoch 70 head A head_i_epoch 0 batch 200: avg loss -2.950146 avg loss no lamb -2.950146 time 2019-01-28 00:04:17.141262
Pre: time 2019-01-28 00:07:39.940571: 
 	std: 0.0032411916
	best_train_sub_head_match: [(0, 18), (1, 16), (2, 14), (3, 0), (4, 12), (5, 3), (6, 2), (7, 6), (8, 13), (9, 5), (10, 10), (11, 7), (12, 19), (13, 9), (14, 15), (15, 4), (16, 11), (17, 17), (18, 1), (19, 8)]
	test_accs: [0.17103334, 0.16303334, 0.1658, 0.16438334, 0.1705]
	train_accs: [0.17103334, 0.16303334, 0.1658, 0.16438334, 0.1705]
	best_train_sub_head: 0
	worst: 0.16303334
	avg: 0.16695
	best: 0.17103334

Starting e_i: 71
Model ind 579 epoch 71 head B head_i_epoch 0 batch 0: avg loss -1.379972 avg loss no lamb -1.379972 time 2019-01-28 00:07:46.100582
Model ind 579 epoch 71 head B head_i_epoch 0 batch 100: avg loss -1.424295 avg loss no lamb -1.424295 time 2019-01-28 00:10:43.196891
Model ind 579 epoch 71 head B head_i_epoch 0 batch 200: avg loss -1.440907 avg loss no lamb -1.440907 time 2019-01-28 00:13:37.282625
Model ind 579 epoch 71 head A head_i_epoch 0 batch 0: avg loss -2.872016 avg loss no lamb -2.872016 time 2019-01-28 00:16:30.644986
Model ind 579 epoch 71 head A head_i_epoch 0 batch 100: avg loss -2.887229 avg loss no lamb -2.887229 time 2019-01-28 00:19:25.500807
Model ind 579 epoch 71 head A head_i_epoch 0 batch 200: avg loss -2.977603 avg loss no lamb -2.977603 time 2019-01-28 00:22:19.925623
Pre: time 2019-01-28 00:25:38.865340: 
 	std: 0.0009403639
	best_train_sub_head_match: [(0, 3), (1, 16), (2, 13), (3, 9), (4, 12), (5, 17), (6, 8), (7, 5), (8, 1), (9, 0), (10, 18), (11, 7), (12, 14), (13, 19), (14, 4), (15, 15), (16, 6), (17, 11), (18, 10), (19, 2)]
	test_accs: [0.16276667, 0.16183333, 0.1614, 0.16155, 0.16391666]
	train_accs: [0.16276667, 0.16183333, 0.1614, 0.16155, 0.16391666]
	best_train_sub_head: 4
	worst: 0.1614
	avg: 0.16229333
	best: 0.16391666

Starting e_i: 72
Model ind 579 epoch 72 head B head_i_epoch 0 batch 0: avg loss -1.357346 avg loss no lamb -1.357346 time 2019-01-28 00:25:41.441555
Model ind 579 epoch 72 head B head_i_epoch 0 batch 100: avg loss -1.468467 avg loss no lamb -1.468467 time 2019-01-28 00:28:35.485559
Model ind 579 epoch 72 head B head_i_epoch 0 batch 200: avg loss -1.559376 avg loss no lamb -1.559376 time 2019-01-28 00:31:30.482595
Model ind 579 epoch 72 head A head_i_epoch 0 batch 0: avg loss -2.887752 avg loss no lamb -2.887752 time 2019-01-28 00:34:24.385029
Model ind 579 epoch 72 head A head_i_epoch 0 batch 100: avg loss -2.912796 avg loss no lamb -2.912796 time 2019-01-28 00:37:20.130952
Model ind 579 epoch 72 head A head_i_epoch 0 batch 200: avg loss -2.944625 avg loss no lamb -2.944625 time 2019-01-28 00:40:15.936370
Pre: time 2019-01-28 00:43:37.492124: 
 	std: 0.0029777815
	best_train_sub_head_match: [(0, 11), (1, 12), (2, 15), (3, 9), (4, 13), (5, 0), (6, 17), (7, 10), (8, 4), (9, 1), (10, 19), (11, 7), (12, 16), (13, 18), (14, 2), (15, 14), (16, 6), (17, 5), (18, 3), (19, 8)]
	test_accs: [0.15415, 0.15271667, 0.1562, 0.15185, 0.1602]
	train_accs: [0.15415, 0.15271667, 0.1562, 0.15185, 0.1602]
	best_train_sub_head: 4
	worst: 0.15185
	avg: 0.15502332
	best: 0.1602

Starting e_i: 73
Model ind 579 epoch 73 head B head_i_epoch 0 batch 0: avg loss -1.381133 avg loss no lamb -1.381133 time 2019-01-28 00:43:39.977566
Model ind 579 epoch 73 head B head_i_epoch 0 batch 100: avg loss -1.476917 avg loss no lamb -1.476917 time 2019-01-28 00:46:34.449591
Model ind 579 epoch 73 head B head_i_epoch 0 batch 200: avg loss -1.503539 avg loss no lamb -1.503539 time 2019-01-28 00:49:28.666628
Model ind 579 epoch 73 head A head_i_epoch 0 batch 0: avg loss -2.835160 avg loss no lamb -2.835160 time 2019-01-28 00:52:23.001666
Model ind 579 epoch 73 head A head_i_epoch 0 batch 100: avg loss -3.019103 avg loss no lamb -3.019103 time 2019-01-28 00:55:20.001096
Model ind 579 epoch 73 head A head_i_epoch 0 batch 200: avg loss -2.975627 avg loss no lamb -2.975627 time 2019-01-28 00:58:15.866418
Pre: time 2019-01-28 01:01:35.777379: 
 	std: 0.001003082
	best_train_sub_head_match: [(0, 9), (1, 14), (2, 0), (3, 17), (4, 2), (5, 13), (6, 16), (7, 6), (8, 7), (9, 18), (10, 10), (11, 8), (12, 19), (13, 5), (14, 15), (15, 4), (16, 3), (17, 12), (18, 1), (19, 11)]
	test_accs: [0.1608, 0.1585, 0.15805, 0.16006666, 0.1593]
	train_accs: [0.1608, 0.1585, 0.15805, 0.16006666, 0.1593]
	best_train_sub_head: 0
	worst: 0.15805
	avg: 0.15934333
	best: 0.1608

Starting e_i: 74
Model ind 579 epoch 74 head B head_i_epoch 0 batch 0: avg loss -1.455657 avg loss no lamb -1.455657 time 2019-01-28 01:01:38.246291
Model ind 579 epoch 74 head B head_i_epoch 0 batch 100: avg loss -1.494144 avg loss no lamb -1.494144 time 2019-01-28 01:04:32.475556
Model ind 579 epoch 74 head B head_i_epoch 0 batch 200: avg loss -1.450133 avg loss no lamb -1.450133 time 2019-01-28 01:07:26.507664
Model ind 579 epoch 74 head A head_i_epoch 0 batch 0: avg loss -2.886863 avg loss no lamb -2.886863 time 2019-01-28 01:10:19.262401
Model ind 579 epoch 74 head A head_i_epoch 0 batch 100: avg loss -2.950697 avg loss no lamb -2.950697 time 2019-01-28 01:13:13.877044
Model ind 579 epoch 74 head A head_i_epoch 0 batch 200: avg loss -2.945735 avg loss no lamb -2.945735 time 2019-01-28 01:16:08.978379
Pre: time 2019-01-28 01:19:27.747367: 
 	std: 0.0012108774
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 13), (3, 9), (4, 12), (5, 17), (6, 8), (7, 3), (8, 14), (9, 0), (10, 19), (11, 7), (12, 16), (13, 18), (14, 1), (15, 15), (16, 6), (17, 5), (18, 10), (19, 11)]
	test_accs: [0.17003334, 0.17076667, 0.1688, 0.1707, 0.17253333]
	train_accs: [0.17003334, 0.17076667, 0.1688, 0.1707, 0.17253333]
	best_train_sub_head: 4
	worst: 0.1688
	avg: 0.17056666
	best: 0.17253333

Starting e_i: 75
Model ind 579 epoch 75 head B head_i_epoch 0 batch 0: avg loss -1.307312 avg loss no lamb -1.307312 time 2019-01-28 01:19:34.217764
Model ind 579 epoch 75 head B head_i_epoch 0 batch 100: avg loss -1.455504 avg loss no lamb -1.455504 time 2019-01-28 01:22:27.325150
Model ind 579 epoch 75 head B head_i_epoch 0 batch 200: avg loss -1.496000 avg loss no lamb -1.496000 time 2019-01-28 01:25:20.932506
Model ind 579 epoch 75 head A head_i_epoch 0 batch 0: avg loss -2.892875 avg loss no lamb -2.892875 time 2019-01-28 01:28:14.962869
Model ind 579 epoch 75 head A head_i_epoch 0 batch 100: avg loss -2.960426 avg loss no lamb -2.960426 time 2019-01-28 01:31:11.783692
Model ind 579 epoch 75 head A head_i_epoch 0 batch 200: avg loss -2.946962 avg loss no lamb -2.946962 time 2019-01-28 01:34:06.268768
Pre: time 2019-01-28 01:37:25.110239: 
 	std: 0.0016916979
	best_train_sub_head_match: [(0, 3), (1, 16), (2, 13), (3, 5), (4, 2), (5, 17), (6, 8), (7, 18), (8, 14), (9, 0), (10, 9), (11, 7), (12, 12), (13, 19), (14, 1), (15, 15), (16, 6), (17, 4), (18, 10), (19, 11)]
	test_accs: [0.16443333, 0.16351667, 0.16591667, 0.16556667, 0.16851667]
	train_accs: [0.16443333, 0.16351667, 0.16591667, 0.16556667, 0.16851667]
	best_train_sub_head: 4
	worst: 0.16351667
	avg: 0.16559
	best: 0.16851667

Starting e_i: 76
Model ind 579 epoch 76 head B head_i_epoch 0 batch 0: avg loss -1.365573 avg loss no lamb -1.365573 time 2019-01-28 01:37:27.508860
Model ind 579 epoch 76 head B head_i_epoch 0 batch 100: avg loss -1.428961 avg loss no lamb -1.428961 time 2019-01-28 01:40:21.640851
Model ind 579 epoch 76 head B head_i_epoch 0 batch 200: avg loss -1.445053 avg loss no lamb -1.445053 time 2019-01-28 01:43:14.671737
Model ind 579 epoch 76 head A head_i_epoch 0 batch 0: avg loss -2.859515 avg loss no lamb -2.859515 time 2019-01-28 01:46:08.221479
Model ind 579 epoch 76 head A head_i_epoch 0 batch 100: avg loss -2.986023 avg loss no lamb -2.986023 time 2019-01-28 01:49:02.776289
Model ind 579 epoch 76 head A head_i_epoch 0 batch 200: avg loss -2.958958 avg loss no lamb -2.958958 time 2019-01-28 01:51:58.265111
Pre: time 2019-01-28 01:55:16.361674: 
 	std: 0.0016732359
	best_train_sub_head_match: [(0, 19), (1, 16), (2, 1), (3, 0), (4, 12), (5, 3), (6, 2), (7, 6), (8, 13), (9, 5), (10, 10), (11, 7), (12, 18), (13, 9), (14, 15), (15, 14), (16, 11), (17, 17), (18, 4), (19, 8)]
	test_accs: [0.16371667, 0.16023333, 0.1627, 0.15958333, 0.16328333]
	train_accs: [0.16371667, 0.16023333, 0.1627, 0.15958333, 0.16328333]
	best_train_sub_head: 0
	worst: 0.15958333
	avg: 0.16190334
	best: 0.16371667

Starting e_i: 77
Model ind 579 epoch 77 head B head_i_epoch 0 batch 0: avg loss -1.438331 avg loss no lamb -1.438331 time 2019-01-28 01:55:18.781890
Model ind 579 epoch 77 head B head_i_epoch 0 batch 100: avg loss -1.405775 avg loss no lamb -1.405775 time 2019-01-28 01:58:11.594359
Model ind 579 epoch 77 head B head_i_epoch 0 batch 200: avg loss -1.450990 avg loss no lamb -1.450990 time 2019-01-28 02:01:04.792109
Model ind 579 epoch 77 head A head_i_epoch 0 batch 0: avg loss -2.944611 avg loss no lamb -2.944611 time 2019-01-28 02:03:58.129838
Model ind 579 epoch 77 head A head_i_epoch 0 batch 100: avg loss -2.990734 avg loss no lamb -2.990734 time 2019-01-28 02:06:52.541674
Model ind 579 epoch 77 head A head_i_epoch 0 batch 200: avg loss -2.962605 avg loss no lamb -2.962605 time 2019-01-28 02:09:47.372765
Pre: time 2019-01-28 02:13:06.556980: 
 	std: 0.0022988669
	best_train_sub_head_match: [(0, 11), (1, 16), (2, 14), (3, 0), (4, 12), (5, 3), (6, 2), (7, 6), (8, 13), (9, 18), (10, 10), (11, 7), (12, 19), (13, 9), (14, 15), (15, 4), (16, 5), (17, 17), (18, 1), (19, 8)]
	test_accs: [0.17106667, 0.165, 0.16461666, 0.16706666, 0.16641666]
	train_accs: [0.17106667, 0.165, 0.16461666, 0.16706666, 0.16641666]
	best_train_sub_head: 0
	worst: 0.16461666
	avg: 0.16683333
	best: 0.17106667

Starting e_i: 78
Model ind 579 epoch 78 head B head_i_epoch 0 batch 0: avg loss -1.432162 avg loss no lamb -1.432162 time 2019-01-28 02:13:08.954061
Model ind 579 epoch 78 head B head_i_epoch 0 batch 100: avg loss -1.446491 avg loss no lamb -1.446491 time 2019-01-28 02:16:02.185139
Model ind 579 epoch 78 head B head_i_epoch 0 batch 200: avg loss -1.463003 avg loss no lamb -1.463003 time 2019-01-28 02:18:54.955998
Model ind 579 epoch 78 head A head_i_epoch 0 batch 0: avg loss -2.919902 avg loss no lamb -2.919902 time 2019-01-28 02:21:47.353026
Model ind 579 epoch 78 head A head_i_epoch 0 batch 100: avg loss -2.930810 avg loss no lamb -2.930810 time 2019-01-28 02:24:41.610521
Model ind 579 epoch 78 head A head_i_epoch 0 batch 200: avg loss -3.030200 avg loss no lamb -3.030200 time 2019-01-28 02:27:36.767409
Pre: time 2019-01-28 02:30:55.991831: 
 	std: 0.002607454
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 13), (3, 5), (4, 16), (5, 17), (6, 8), (7, 10), (8, 14), (9, 19), (10, 9), (11, 7), (12, 0), (13, 18), (14, 1), (15, 15), (16, 6), (17, 11), (18, 3), (19, 12)]
	test_accs: [0.165, 0.1652, 0.16061667, 0.16628334, 0.16863333]
	train_accs: [0.165, 0.1652, 0.16061667, 0.16628334, 0.16863333]
	best_train_sub_head: 4
	worst: 0.16061667
	avg: 0.16514668
	best: 0.16863333

Starting e_i: 79
Model ind 579 epoch 79 head B head_i_epoch 0 batch 0: avg loss -1.391714 avg loss no lamb -1.391714 time 2019-01-28 02:30:58.416874
Model ind 579 epoch 79 head B head_i_epoch 0 batch 100: avg loss -1.498885 avg loss no lamb -1.498885 time 2019-01-28 02:33:51.557713
Model ind 579 epoch 79 head B head_i_epoch 0 batch 200: avg loss -1.506225 avg loss no lamb -1.506225 time 2019-01-28 02:36:44.227572
Model ind 579 epoch 79 head A head_i_epoch 0 batch 0: avg loss -2.904385 avg loss no lamb -2.904385 time 2019-01-28 02:39:36.855376
Model ind 579 epoch 79 head A head_i_epoch 0 batch 100: avg loss -3.048169 avg loss no lamb -3.048169 time 2019-01-28 02:42:31.136012
Model ind 579 epoch 79 head A head_i_epoch 0 batch 200: avg loss -2.978965 avg loss no lamb -2.978965 time 2019-01-28 02:45:25.591062
Pre: time 2019-01-28 02:48:43.806421: 
 	std: 0.002658188
	best_train_sub_head_match: [(0, 5), (1, 2), (2, 15), (3, 9), (4, 12), (5, 17), (6, 13), (7, 10), (8, 1), (9, 0), (10, 19), (11, 7), (12, 16), (13, 18), (14, 4), (15, 14), (16, 6), (17, 11), (18, 3), (19, 8)]
	test_accs: [0.15691666, 0.16053334, 0.15741667, 0.16015, 0.16435]
	train_accs: [0.15691666, 0.16053334, 0.15741667, 0.16015, 0.16435]
	best_train_sub_head: 4
	worst: 0.15691666
	avg: 0.15987334
	best: 0.16435

Starting e_i: 80
Model ind 579 epoch 80 head B head_i_epoch 0 batch 0: avg loss -1.380220 avg loss no lamb -1.380220 time 2019-01-28 02:48:46.447463
Model ind 579 epoch 80 head B head_i_epoch 0 batch 100: avg loss -1.404177 avg loss no lamb -1.404177 time 2019-01-28 02:51:39.099752
Model ind 579 epoch 80 head B head_i_epoch 0 batch 200: avg loss -1.508618 avg loss no lamb -1.508618 time 2019-01-28 02:54:29.792397
Model ind 579 epoch 80 head A head_i_epoch 0 batch 0: avg loss -2.903765 avg loss no lamb -2.903765 time 2019-01-28 02:57:22.447834
Model ind 579 epoch 80 head A head_i_epoch 0 batch 100: avg loss -2.983164 avg loss no lamb -2.983164 time 2019-01-28 03:00:16.678466
Model ind 579 epoch 80 head A head_i_epoch 0 batch 200: avg loss -3.053640 avg loss no lamb -3.053640 time 2019-01-28 03:03:11.501085
Pre: time 2019-01-28 03:06:28.573681: 
 	std: 0.0016989978
	best_train_sub_head_match: [(0, 3), (1, 2), (2, 15), (3, 9), (4, 12), (5, 17), (6, 13), (7, 5), (8, 1), (9, 0), (10, 19), (11, 7), (12, 16), (13, 18), (14, 4), (15, 14), (16, 6), (17, 11), (18, 10), (19, 8)]
	test_accs: [0.15876667, 0.1579, 0.15991667, 0.15875, 0.16276667]
	train_accs: [0.15876667, 0.1579, 0.15991667, 0.15875, 0.16276667]
	best_train_sub_head: 4
	worst: 0.1579
	avg: 0.15962
	best: 0.16276667

Starting e_i: 81
Model ind 579 epoch 81 head B head_i_epoch 0 batch 0: avg loss -1.423498 avg loss no lamb -1.423498 time 2019-01-28 03:06:34.487041
Model ind 579 epoch 81 head B head_i_epoch 0 batch 100: avg loss -1.450543 avg loss no lamb -1.450543 time 2019-01-28 03:09:28.245748
Model ind 579 epoch 81 head B head_i_epoch 0 batch 200: avg loss -1.441562 avg loss no lamb -1.441562 time 2019-01-28 03:12:21.280902
Model ind 579 epoch 81 head A head_i_epoch 0 batch 0: avg loss -2.877068 avg loss no lamb -2.877068 time 2019-01-28 03:15:15.552874
Model ind 579 epoch 81 head A head_i_epoch 0 batch 100: avg loss -2.946195 avg loss no lamb -2.946195 time 2019-01-28 03:18:09.383685
Model ind 579 epoch 81 head A head_i_epoch 0 batch 200: avg loss -3.011418 avg loss no lamb -3.011418 time 2019-01-28 03:21:03.573167
Pre: time 2019-01-28 03:24:21.119486: 
 	std: 0.001850507
	best_train_sub_head_match: [(0, 18), (1, 11), (2, 14), (3, 15), (4, 5), (5, 3), (6, 8), (7, 7), (8, 9), (9, 2), (10, 17), (11, 0), (12, 13), (13, 4), (14, 16), (15, 12), (16, 10), (17, 1), (18, 6), (19, 19)]
	test_accs: [0.15601666, 0.16115, 0.15996666, 0.16041666, 0.15813333]
	train_accs: [0.15601666, 0.16115, 0.15996666, 0.16041666, 0.15813333]
	best_train_sub_head: 1
	worst: 0.15601666
	avg: 0.15913667
	best: 0.16115

Starting e_i: 82
Model ind 579 epoch 82 head B head_i_epoch 0 batch 0: avg loss -1.388193 avg loss no lamb -1.388193 time 2019-01-28 03:24:23.532441
Model ind 579 epoch 82 head B head_i_epoch 0 batch 100: avg loss -1.375664 avg loss no lamb -1.375664 time 2019-01-28 03:27:15.685667
Model ind 579 epoch 82 head B head_i_epoch 0 batch 200: avg loss -1.412947 avg loss no lamb -1.412947 time 2019-01-28 03:30:08.381726
Model ind 579 epoch 82 head A head_i_epoch 0 batch 0: avg loss -2.878369 avg loss no lamb -2.878369 time 2019-01-28 03:33:01.005281
Model ind 579 epoch 82 head A head_i_epoch 0 batch 100: avg loss -2.969786 avg loss no lamb -2.969786 time 2019-01-28 03:35:55.213268
Model ind 579 epoch 82 head A head_i_epoch 0 batch 200: avg loss -2.985194 avg loss no lamb -2.985194 time 2019-01-28 03:38:48.333033
Pre: time 2019-01-28 03:42:07.531412: 
 	std: 0.0015977538
	best_train_sub_head_match: [(0, 3), (1, 16), (2, 13), (3, 9), (4, 12), (5, 17), (6, 2), (7, 5), (8, 1), (9, 0), (10, 18), (11, 7), (12, 14), (13, 19), (14, 4), (15, 15), (16, 6), (17, 11), (18, 10), (19, 8)]
	test_accs: [0.16798334, 0.16881667, 0.16685, 0.16956666, 0.1716]
	train_accs: [0.16798334, 0.16881667, 0.16685, 0.16956666, 0.1716]
	best_train_sub_head: 4
	worst: 0.16685
	avg: 0.16896334
	best: 0.1716

Starting e_i: 83
Model ind 579 epoch 83 head B head_i_epoch 0 batch 0: avg loss -1.381680 avg loss no lamb -1.381680 time 2019-01-28 03:42:09.943376
Model ind 579 epoch 83 head B head_i_epoch 0 batch 100: avg loss -1.470088 avg loss no lamb -1.470088 time 2019-01-28 03:45:02.156713
Model ind 579 epoch 83 head B head_i_epoch 0 batch 200: avg loss -1.427471 avg loss no lamb -1.427471 time 2019-01-28 03:47:54.369560
Model ind 579 epoch 83 head A head_i_epoch 0 batch 0: avg loss -2.811854 avg loss no lamb -2.811854 time 2019-01-28 03:50:47.400843
Model ind 579 epoch 83 head A head_i_epoch 0 batch 100: avg loss -3.038031 avg loss no lamb -3.038031 time 2019-01-28 03:53:41.391676
Model ind 579 epoch 83 head A head_i_epoch 0 batch 200: avg loss -2.960895 avg loss no lamb -2.960895 time 2019-01-28 03:56:35.827089
Pre: time 2019-01-28 03:59:53.883411: 
 	std: 0.0015889346
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 3), (5, 4), (6, 13), (7, 8), (8, 11), (9, 12), (10, 17), (11, 5), (12, 18), (13, 16), (14, 14), (15, 7), (16, 10), (17, 1), (18, 6), (19, 19)]
	test_accs: [0.16555, 0.16863333, 0.16446666, 0.1669, 0.1683]
	train_accs: [0.16555, 0.16863333, 0.16446666, 0.1669, 0.1683]
	best_train_sub_head: 1
	worst: 0.16446666
	avg: 0.16677001
	best: 0.16863333

Starting e_i: 84
Model ind 579 epoch 84 head B head_i_epoch 0 batch 0: avg loss -1.333326 avg loss no lamb -1.333326 time 2019-01-28 03:59:56.189635
Model ind 579 epoch 84 head B head_i_epoch 0 batch 100: avg loss -1.439631 avg loss no lamb -1.439631 time 2019-01-28 04:02:49.379871
Model ind 579 epoch 84 head B head_i_epoch 0 batch 200: avg loss -1.541661 avg loss no lamb -1.541661 time 2019-01-28 04:05:42.480962
Model ind 579 epoch 84 head A head_i_epoch 0 batch 0: avg loss -2.963649 avg loss no lamb -2.963649 time 2019-01-28 04:08:35.087527
Model ind 579 epoch 84 head A head_i_epoch 0 batch 100: avg loss -3.006282 avg loss no lamb -3.006282 time 2019-01-28 04:11:28.504681
Model ind 579 epoch 84 head A head_i_epoch 0 batch 200: avg loss -3.014772 avg loss no lamb -3.014772 time 2019-01-28 04:14:21.912256
Pre: time 2019-01-28 04:17:39.137918: 
 	std: 0.00319947
	best_train_sub_head_match: [(0, 19), (1, 2), (2, 0), (3, 15), (4, 9), (5, 3), (6, 13), (7, 8), (8, 11), (9, 16), (10, 17), (11, 5), (12, 7), (13, 4), (14, 14), (15, 12), (16, 10), (17, 1), (18, 6), (19, 18)]
	test_accs: [0.16605, 0.17396666, 0.16821666, 0.17208333, 0.16615]
	train_accs: [0.16605, 0.17396666, 0.16821666, 0.17208333, 0.16615]
	best_train_sub_head: 1
	worst: 0.16605
	avg: 0.16929333
	best: 0.17396666

Starting e_i: 85
Model ind 579 epoch 85 head B head_i_epoch 0 batch 0: avg loss -1.359789 avg loss no lamb -1.359789 time 2019-01-28 04:17:44.865892
Model ind 579 epoch 85 head B head_i_epoch 0 batch 100: avg loss -1.502422 avg loss no lamb -1.502422 time 2019-01-28 04:20:37.693450
Model ind 579 epoch 85 head B head_i_epoch 0 batch 200: avg loss -1.430812 avg loss no lamb -1.430812 time 2019-01-28 04:23:30.366921
Model ind 579 epoch 85 head A head_i_epoch 0 batch 0: avg loss -2.927927 avg loss no lamb -2.927927 time 2019-01-28 04:26:22.480629
Model ind 579 epoch 85 head A head_i_epoch 0 batch 100: avg loss -3.001233 avg loss no lamb -3.001233 time 2019-01-28 04:29:17.044589
Model ind 579 epoch 85 head A head_i_epoch 0 batch 200: avg loss -2.971809 avg loss no lamb -2.971809 time 2019-01-28 04:32:10.164877
Pre: time 2019-01-28 04:35:28.934232: 
 	std: 0.0029417416
	best_train_sub_head_match: [(0, 5), (1, 3), (2, 18), (3, 11), (4, 9), (5, 4), (6, 12), (7, 19), (8, 1), (9, 15), (10, 6), (11, 7), (12, 17), (13, 16), (14, 0), (15, 8), (16, 13), (17, 14), (18, 10), (19, 2)]
	test_accs: [0.16113333, 0.16033334, 0.16506666, 0.16155, 0.15588333]
	train_accs: [0.16113333, 0.16033334, 0.16506666, 0.16155, 0.15588333]
	best_train_sub_head: 2
	worst: 0.15588333
	avg: 0.16079333
	best: 0.16506666

Starting e_i: 86
Model ind 579 epoch 86 head B head_i_epoch 0 batch 0: avg loss -1.375055 avg loss no lamb -1.375055 time 2019-01-28 04:35:31.211156
Model ind 579 epoch 86 head B head_i_epoch 0 batch 100: avg loss -1.458533 avg loss no lamb -1.458533 time 2019-01-28 04:38:23.524993
Model ind 579 epoch 86 head B head_i_epoch 0 batch 200: avg loss -1.461677 avg loss no lamb -1.461677 time 2019-01-28 04:41:16.159946
Model ind 579 epoch 86 head A head_i_epoch 0 batch 0: avg loss -2.826572 avg loss no lamb -2.826572 time 2019-01-28 04:44:08.638969
Model ind 579 epoch 86 head A head_i_epoch 0 batch 100: avg loss -3.012032 avg loss no lamb -3.012032 time 2019-01-28 04:47:03.766898
Model ind 579 epoch 86 head A head_i_epoch 0 batch 200: avg loss -2.969505 avg loss no lamb -2.969505 time 2019-01-28 04:49:59.267781
Pre: time 2019-01-28 04:53:16.619864: 
 	std: 0.0031709329
	best_train_sub_head_match: [(0, 4), (1, 11), (2, 6), (3, 8), (4, 9), (5, 2), (6, 13), (7, 18), (8, 1), (9, 0), (10, 3), (11, 19), (12, 17), (13, 15), (14, 16), (15, 7), (16, 5), (17, 14), (18, 10), (19, 12)]
	test_accs: [0.16948333, 0.17581667, 0.1793, 0.17585, 0.17523333]
	train_accs: [0.16948333, 0.17581667, 0.1793, 0.17585, 0.17523333]
	best_train_sub_head: 2
	worst: 0.16948333
	avg: 0.17513669
	best: 0.1793

Starting e_i: 87
Model ind 579 epoch 87 head B head_i_epoch 0 batch 0: avg loss -1.424695 avg loss no lamb -1.424695 time 2019-01-28 04:53:22.958231
Model ind 579 epoch 87 head B head_i_epoch 0 batch 100: avg loss -1.442925 avg loss no lamb -1.442925 time 2019-01-28 04:56:15.897082
Model ind 579 epoch 87 head B head_i_epoch 0 batch 200: avg loss -1.527285 avg loss no lamb -1.527285 time 2019-01-28 04:59:08.673376
Model ind 579 epoch 87 head A head_i_epoch 0 batch 0: avg loss -2.933386 avg loss no lamb -2.933386 time 2019-01-28 05:02:02.266164
Model ind 579 epoch 87 head A head_i_epoch 0 batch 100: avg loss -3.028201 avg loss no lamb -3.028201 time 2019-01-28 05:04:55.841525
Model ind 579 epoch 87 head A head_i_epoch 0 batch 200: avg loss -2.993284 avg loss no lamb -2.993284 time 2019-01-28 05:07:49.710626
Pre: time 2019-01-28 05:11:08.672349: 
 	std: 0.0016441281
	best_train_sub_head_match: [(0, 3), (1, 2), (2, 15), (3, 9), (4, 12), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 18), (11, 5), (12, 16), (13, 19), (14, 4), (15, 13), (16, 6), (17, 11), (18, 1), (19, 8)]
	test_accs: [0.17653333, 0.17475, 0.17448333, 0.17411667, 0.17851667]
	train_accs: [0.17653333, 0.17475, 0.17448333, 0.17411667, 0.17851667]
	best_train_sub_head: 4
	worst: 0.17411667
	avg: 0.17568
	best: 0.17851667

Starting e_i: 88
Model ind 579 epoch 88 head B head_i_epoch 0 batch 0: avg loss -1.442007 avg loss no lamb -1.442007 time 2019-01-28 05:11:11.061149
Model ind 579 epoch 88 head B head_i_epoch 0 batch 100: avg loss -1.500048 avg loss no lamb -1.500048 time 2019-01-28 05:14:03.835873
Model ind 579 epoch 88 head B head_i_epoch 0 batch 200: avg loss -1.536857 avg loss no lamb -1.536857 time 2019-01-28 05:16:55.826169
Model ind 579 epoch 88 head A head_i_epoch 0 batch 0: avg loss -2.938990 avg loss no lamb -2.938990 time 2019-01-28 05:19:48.334826
Model ind 579 epoch 88 head A head_i_epoch 0 batch 100: avg loss -2.996943 avg loss no lamb -2.996943 time 2019-01-28 05:22:41.046678
Model ind 579 epoch 88 head A head_i_epoch 0 batch 200: avg loss -2.991708 avg loss no lamb -2.991708 time 2019-01-28 05:25:33.754443
Pre: time 2019-01-28 05:28:50.739914: 
 	std: 0.0030388741
	best_train_sub_head_match: [(0, 4), (1, 16), (2, 17), (3, 9), (4, 12), (5, 19), (6, 8), (7, 10), (8, 14), (9, 0), (10, 5), (11, 7), (12, 13), (13, 18), (14, 1), (15, 15), (16, 6), (17, 11), (18, 3), (19, 2)]
	test_accs: [0.17343333, 0.17661667, 0.16936667, 0.17465, 0.17826666]
	train_accs: [0.17343333, 0.17661667, 0.16936667, 0.17465, 0.17826666]
	best_train_sub_head: 4
	worst: 0.16936667
	avg: 0.17446667
	best: 0.17826666

Starting e_i: 89
Model ind 579 epoch 89 head B head_i_epoch 0 batch 0: avg loss -1.389778 avg loss no lamb -1.389778 time 2019-01-28 05:28:53.053462
Model ind 579 epoch 89 head B head_i_epoch 0 batch 100: avg loss -1.485568 avg loss no lamb -1.485568 time 2019-01-28 05:31:45.642333
Model ind 579 epoch 89 head B head_i_epoch 0 batch 200: avg loss -1.442733 avg loss no lamb -1.442733 time 2019-01-28 05:34:38.470827
Model ind 579 epoch 89 head A head_i_epoch 0 batch 0: avg loss -2.933025 avg loss no lamb -2.933025 time 2019-01-28 05:37:29.630680
Model ind 579 epoch 89 head A head_i_epoch 0 batch 100: avg loss -2.982179 avg loss no lamb -2.982179 time 2019-01-28 05:40:22.857979
Model ind 579 epoch 89 head A head_i_epoch 0 batch 200: avg loss -2.939853 avg loss no lamb -2.939853 time 2019-01-28 05:43:16.751656
Pre: time 2019-01-28 05:46:34.609599: 
 	std: 0.0018487693
	best_train_sub_head_match: [(0, 3), (1, 16), (2, 6), (3, 12), (4, 11), (5, 4), (6, 13), (7, 18), (8, 1), (9, 5), (10, 9), (11, 19), (12, 17), (13, 15), (14, 14), (15, 8), (16, 7), (17, 0), (18, 10), (19, 2)]
	test_accs: [0.16673334, 0.1711, 0.17146666, 0.17093334, 0.1684]
	train_accs: [0.16673334, 0.1711, 0.17146666, 0.17093334, 0.1684]
	best_train_sub_head: 2
	worst: 0.16673334
	avg: 0.16972667
	best: 0.17146666

Starting e_i: 90
Model ind 579 epoch 90 head B head_i_epoch 0 batch 0: avg loss -1.367744 avg loss no lamb -1.367744 time 2019-01-28 05:46:36.986270
Model ind 579 epoch 90 head B head_i_epoch 0 batch 100: avg loss -1.487528 avg loss no lamb -1.487528 time 2019-01-28 05:49:29.533916
Model ind 579 epoch 90 head B head_i_epoch 0 batch 200: avg loss -1.500727 avg loss no lamb -1.500727 time 2019-01-28 05:52:21.876858
Model ind 579 epoch 90 head A head_i_epoch 0 batch 0: avg loss -2.897413 avg loss no lamb -2.897413 time 2019-01-28 05:55:14.214796
Model ind 579 epoch 90 head A head_i_epoch 0 batch 100: avg loss -2.976306 avg loss no lamb -2.976306 time 2019-01-28 05:58:08.017677
Model ind 579 epoch 90 head A head_i_epoch 0 batch 200: avg loss -2.965896 avg loss no lamb -2.965896 time 2019-01-28 06:01:02.405089
Pre: time 2019-01-28 06:04:20.010622: 
 	std: 0.0020853628
	best_train_sub_head_match: [(0, 4), (1, 16), (2, 13), (3, 9), (4, 12), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 18), (11, 7), (12, 5), (13, 19), (14, 1), (15, 15), (16, 6), (17, 11), (18, 3), (19, 2)]
	test_accs: [0.16456667, 0.1669, 0.16541667, 0.1671, 0.17065]
	train_accs: [0.16456667, 0.1669, 0.16541667, 0.1671, 0.17065]
	best_train_sub_head: 4
	worst: 0.16456667
	avg: 0.16692667
	best: 0.17065

Starting e_i: 91
Model ind 579 epoch 91 head B head_i_epoch 0 batch 0: avg loss -1.357995 avg loss no lamb -1.357995 time 2019-01-28 06:04:26.098540
Model ind 579 epoch 91 head B head_i_epoch 0 batch 100: avg loss -1.540022 avg loss no lamb -1.540022 time 2019-01-28 06:07:18.122113
Model ind 579 epoch 91 head B head_i_epoch 0 batch 200: avg loss -1.526607 avg loss no lamb -1.526607 time 2019-01-28 06:10:10.619949
Model ind 579 epoch 91 head A head_i_epoch 0 batch 0: avg loss -2.930412 avg loss no lamb -2.930412 time 2019-01-28 06:13:03.144869
Model ind 579 epoch 91 head A head_i_epoch 0 batch 100: avg loss -2.970570 avg loss no lamb -2.970570 time 2019-01-28 06:15:58.080898
Model ind 579 epoch 91 head A head_i_epoch 0 batch 200: avg loss -3.010201 avg loss no lamb -3.010201 time 2019-01-28 06:18:52.304600
Pre: time 2019-01-28 06:22:09.239535: 
 	std: 0.0024341666
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 13), (3, 9), (4, 16), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 19), (11, 5), (12, 12), (13, 18), (14, 1), (15, 15), (16, 6), (17, 11), (18, 3), (19, 8)]
	test_accs: [0.17305, 0.17418334, 0.16993333, 0.17468333, 0.17743333]
	train_accs: [0.17305, 0.17418334, 0.16993333, 0.17468333, 0.17743333]
	best_train_sub_head: 4
	worst: 0.16993333
	avg: 0.17385666
	best: 0.17743333

Starting e_i: 92
Model ind 579 epoch 92 head B head_i_epoch 0 batch 0: avg loss -1.452898 avg loss no lamb -1.452898 time 2019-01-28 06:22:11.493437
Model ind 579 epoch 92 head B head_i_epoch 0 batch 100: avg loss -1.472258 avg loss no lamb -1.472258 time 2019-01-28 06:25:01.169792
Model ind 579 epoch 92 head B head_i_epoch 0 batch 200: avg loss -1.483930 avg loss no lamb -1.483930 time 2019-01-28 06:27:50.454861
Model ind 579 epoch 92 head A head_i_epoch 0 batch 0: avg loss -2.913320 avg loss no lamb -2.913320 time 2019-01-28 06:30:41.406069
Model ind 579 epoch 92 head A head_i_epoch 0 batch 100: avg loss -3.023356 avg loss no lamb -3.023356 time 2019-01-28 06:33:31.660800
Model ind 579 epoch 92 head A head_i_epoch 0 batch 200: avg loss -2.985037 avg loss no lamb -2.985037 time 2019-01-28 06:36:24.498453
Pre: time 2019-01-28 06:39:41.009869: 
 	std: 0.0020050348
	best_train_sub_head_match: [(0, 3), (1, 2), (2, 13), (3, 18), (4, 12), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 5), (11, 7), (12, 16), (13, 19), (14, 4), (15, 15), (16, 6), (17, 9), (18, 1), (19, 11)]
	test_accs: [0.17078333, 0.17226666, 0.17123333, 0.1725, 0.17645]
	train_accs: [0.17078333, 0.17226666, 0.17123333, 0.1725, 0.17645]
	best_train_sub_head: 4
	worst: 0.17078333
	avg: 0.17264667
	best: 0.17645

Starting e_i: 93
Model ind 579 epoch 93 head B head_i_epoch 0 batch 0: avg loss -1.440050 avg loss no lamb -1.440050 time 2019-01-28 06:39:43.373382
Model ind 579 epoch 93 head B head_i_epoch 0 batch 100: avg loss -1.526401 avg loss no lamb -1.526401 time 2019-01-28 06:42:32.784651
Model ind 579 epoch 93 head B head_i_epoch 0 batch 200: avg loss -1.515014 avg loss no lamb -1.515014 time 2019-01-28 06:45:23.859484
Model ind 579 epoch 93 head A head_i_epoch 0 batch 0: avg loss -2.910476 avg loss no lamb -2.910476 time 2019-01-28 06:48:14.884583
Model ind 579 epoch 93 head A head_i_epoch 0 batch 100: avg loss -2.979908 avg loss no lamb -2.979908 time 2019-01-28 06:51:08.019261
Model ind 579 epoch 93 head A head_i_epoch 0 batch 200: avg loss -2.964036 avg loss no lamb -2.964036 time 2019-01-28 06:54:01.159926
Pre: time 2019-01-28 06:57:17.072533: 
 	std: 0.0010815837
	best_train_sub_head_match: [(0, 18), (1, 11), (2, 0), (3, 16), (4, 3), (5, 5), (6, 13), (7, 8), (8, 9), (9, 2), (10, 15), (11, 17), (12, 7), (13, 4), (14, 14), (15, 12), (16, 10), (17, 1), (18, 6), (19, 19)]
	test_accs: [0.1714, 0.17451666, 0.17386666, 0.17383334, 0.1739]
	train_accs: [0.1714, 0.17451666, 0.17386666, 0.17383334, 0.1739]
	best_train_sub_head: 1
	worst: 0.1714
	avg: 0.17350332
	best: 0.17451666

Starting e_i: 94
Model ind 579 epoch 94 head B head_i_epoch 0 batch 0: avg loss -1.397057 avg loss no lamb -1.397057 time 2019-01-28 06:57:19.433092
Model ind 579 epoch 94 head B head_i_epoch 0 batch 100: avg loss -1.492061 avg loss no lamb -1.492061 time 2019-01-28 07:00:08.734723
Model ind 579 epoch 94 head B head_i_epoch 0 batch 200: avg loss -1.480365 avg loss no lamb -1.480365 time 2019-01-28 07:02:59.439824
Model ind 579 epoch 94 head A head_i_epoch 0 batch 0: avg loss -2.956968 avg loss no lamb -2.956968 time 2019-01-28 07:05:50.482085
Model ind 579 epoch 94 head A head_i_epoch 0 batch 100: avg loss -3.011278 avg loss no lamb -3.011278 time 2019-01-28 07:08:43.726146
Model ind 579 epoch 94 head A head_i_epoch 0 batch 200: avg loss -3.019114 avg loss no lamb -3.019114 time 2019-01-28 07:11:34.042642
Pre: time 2019-01-28 07:14:48.582388: 
 	std: 0.0030120611
	best_train_sub_head_match: [(0, 4), (1, 16), (2, 13), (3, 5), (4, 12), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 9), (11, 7), (12, 2), (13, 18), (14, 1), (15, 15), (16, 6), (17, 3), (18, 19), (19, 11)]
	test_accs: [0.16575, 0.16813333, 0.1645, 0.1657, 0.17295]
	train_accs: [0.16575, 0.16813333, 0.1645, 0.1657, 0.17295]
	best_train_sub_head: 4
	worst: 0.1645
	avg: 0.16740668
	best: 0.17295

Starting e_i: 95
Model ind 579 epoch 95 head B head_i_epoch 0 batch 0: avg loss -1.363357 avg loss no lamb -1.363357 time 2019-01-28 07:14:51.023490
Model ind 579 epoch 95 head B head_i_epoch 0 batch 100: avg loss -1.551791 avg loss no lamb -1.551791 time 2019-01-28 07:17:45.314816
Model ind 579 epoch 95 head B head_i_epoch 0 batch 200: avg loss -1.516591 avg loss no lamb -1.516591 time 2019-01-28 07:20:38.949039
Model ind 579 epoch 95 head A head_i_epoch 0 batch 0: avg loss -2.923426 avg loss no lamb -2.923426 time 2019-01-28 07:23:31.519969
Model ind 579 epoch 95 head A head_i_epoch 0 batch 100: avg loss -2.987345 avg loss no lamb -2.987345 time 2019-01-28 07:26:26.028685
Model ind 579 epoch 95 head A head_i_epoch 0 batch 200: avg loss -2.967613 avg loss no lamb -2.967613 time 2019-01-28 07:29:20.706534
Pre: time 2019-01-28 07:32:38.822171: 
 	std: 0.0039823637
	best_train_sub_head_match: [(0, 3), (1, 16), (2, 13), (3, 9), (4, 12), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 18), (11, 7), (12, 1), (13, 19), (14, 4), (15, 15), (16, 6), (17, 11), (18, 5), (19, 2)]
	test_accs: [0.17905, 0.17295, 0.16883333, 0.17363334, 0.17936666]
	train_accs: [0.17905, 0.17295, 0.16883333, 0.17363334, 0.17936666]
	best_train_sub_head: 4
	worst: 0.16883333
	avg: 0.17476666
	best: 0.17936666

Starting e_i: 96
Model ind 579 epoch 96 head B head_i_epoch 0 batch 0: avg loss -1.477810 avg loss no lamb -1.477810 time 2019-01-28 07:32:44.901557
Model ind 579 epoch 96 head B head_i_epoch 0 batch 100: avg loss -1.460091 avg loss no lamb -1.460091 time 2019-01-28 07:35:38.085706
Model ind 579 epoch 96 head B head_i_epoch 0 batch 200: avg loss -1.510746 avg loss no lamb -1.510746 time 2019-01-28 07:38:32.155538
Model ind 579 epoch 96 head A head_i_epoch 0 batch 0: avg loss -2.977203 avg loss no lamb -2.977203 time 2019-01-28 07:41:24.702745
Model ind 579 epoch 96 head A head_i_epoch 0 batch 100: avg loss -3.030452 avg loss no lamb -3.030452 time 2019-01-28 07:44:18.805221
Model ind 579 epoch 96 head A head_i_epoch 0 batch 200: avg loss -2.993512 avg loss no lamb -2.993512 time 2019-01-28 07:47:13.416644
Pre: time 2019-01-28 07:50:31.767123: 
 	std: 0.0044189137
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 13), (3, 9), (4, 12), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 19), (11, 5), (12, 16), (13, 18), (14, 1), (15, 15), (16, 6), (17, 11), (18, 3), (19, 8)]
	test_accs: [0.1826, 0.1809, 0.17275, 0.18066667, 0.18625]
	train_accs: [0.1826, 0.1809, 0.17275, 0.18066667, 0.18625]
	best_train_sub_head: 4
	worst: 0.17275
	avg: 0.18063334
	best: 0.18625

Starting e_i: 97
Model ind 579 epoch 97 head B head_i_epoch 0 batch 0: avg loss -1.393865 avg loss no lamb -1.393865 time 2019-01-28 07:50:38.025351
Model ind 579 epoch 97 head B head_i_epoch 0 batch 100: avg loss -1.433841 avg loss no lamb -1.433841 time 2019-01-28 07:53:31.539945
Model ind 579 epoch 97 head B head_i_epoch 0 batch 200: avg loss -1.493521 avg loss no lamb -1.493521 time 2019-01-28 07:56:24.836830
Model ind 579 epoch 97 head A head_i_epoch 0 batch 0: avg loss -2.963536 avg loss no lamb -2.963536 time 2019-01-28 07:59:17.433233
Model ind 579 epoch 97 head A head_i_epoch 0 batch 100: avg loss -3.044651 avg loss no lamb -3.044651 time 2019-01-28 08:02:11.356729
Model ind 579 epoch 97 head A head_i_epoch 0 batch 200: avg loss -2.979655 avg loss no lamb -2.979655 time 2019-01-28 08:05:04.887104
Pre: time 2019-01-28 08:08:22.544591: 
 	std: 0.0016262565
	best_train_sub_head_match: [(0, 3), (1, 2), (2, 13), (3, 9), (4, 12), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 18), (11, 7), (12, 16), (13, 19), (14, 1), (15, 15), (16, 6), (17, 5), (18, 4), (19, 11)]
	test_accs: [0.1824, 0.18073334, 0.1793, 0.1814, 0.18415]
	train_accs: [0.1824, 0.18073334, 0.1793, 0.1814, 0.18415]
	best_train_sub_head: 4
	worst: 0.1793
	avg: 0.18159667
	best: 0.18415

Starting e_i: 98
Model ind 579 epoch 98 head B head_i_epoch 0 batch 0: avg loss -1.406159 avg loss no lamb -1.406159 time 2019-01-28 08:08:25.064123
Model ind 579 epoch 98 head B head_i_epoch 0 batch 100: avg loss -1.476154 avg loss no lamb -1.476154 time 2019-01-28 08:11:18.479929
Model ind 579 epoch 98 head B head_i_epoch 0 batch 200: avg loss -1.509857 avg loss no lamb -1.509857 time 2019-01-28 08:14:11.257385
Model ind 579 epoch 98 head A head_i_epoch 0 batch 0: avg loss -2.947264 avg loss no lamb -2.947264 time 2019-01-28 08:17:04.520725
Model ind 579 epoch 98 head A head_i_epoch 0 batch 100: avg loss -3.018221 avg loss no lamb -3.018221 time 2019-01-28 08:19:58.950211
Model ind 579 epoch 98 head A head_i_epoch 0 batch 200: avg loss -3.024161 avg loss no lamb -3.024161 time 2019-01-28 08:22:53.363240
Pre: time 2019-01-28 08:26:13.136999: 
 	std: 0.002817367
	best_train_sub_head_match: [(0, 3), (1, 2), (2, 13), (3, 18), (4, 12), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 5), (11, 7), (12, 16), (13, 19), (14, 4), (15, 15), (16, 6), (17, 9), (18, 1), (19, 11)]
	test_accs: [0.17276667, 0.17235, 0.1682, 0.17173333, 0.17703333]
	train_accs: [0.17276667, 0.17235, 0.1682, 0.17173333, 0.17703333]
	best_train_sub_head: 4
	worst: 0.1682
	avg: 0.17241666
	best: 0.17703333

Starting e_i: 99
Model ind 579 epoch 99 head B head_i_epoch 0 batch 0: avg loss -1.416985 avg loss no lamb -1.416985 time 2019-01-28 08:26:15.508157
Model ind 579 epoch 99 head B head_i_epoch 0 batch 100: avg loss -1.538232 avg loss no lamb -1.538232 time 2019-01-28 08:29:08.353010
Model ind 579 epoch 99 head B head_i_epoch 0 batch 200: avg loss -1.509510 avg loss no lamb -1.509510 time 2019-01-28 08:32:01.199468
Model ind 579 epoch 99 head A head_i_epoch 0 batch 0: avg loss -2.964951 avg loss no lamb -2.964951 time 2019-01-28 08:34:54.269426
Model ind 579 epoch 99 head A head_i_epoch 0 batch 100: avg loss -3.034534 avg loss no lamb -3.034534 time 2019-01-28 08:37:48.078003
Model ind 579 epoch 99 head A head_i_epoch 0 batch 200: avg loss -3.005707 avg loss no lamb -3.005707 time 2019-01-28 08:40:42.660721
Pre: time 2019-01-28 08:44:00.922872: 
 	std: 0.0023848
	best_train_sub_head_match: [(0, 5), (1, 16), (2, 13), (3, 9), (4, 2), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 18), (11, 7), (12, 1), (13, 19), (14, 4), (15, 15), (16, 6), (17, 11), (18, 3), (19, 12)]
	test_accs: [0.17216666, 0.1685, 0.16953333, 0.17003334, 0.17521666]
	train_accs: [0.17216666, 0.1685, 0.16953333, 0.17003334, 0.17521666]
	best_train_sub_head: 4
	worst: 0.1685
	avg: 0.17108999
	best: 0.17521666

Starting e_i: 100
Model ind 579 epoch 100 head B head_i_epoch 0 batch 0: avg loss -1.335818 avg loss no lamb -1.335818 time 2019-01-28 08:44:03.330262
Model ind 579 epoch 100 head B head_i_epoch 0 batch 100: avg loss -1.548721 avg loss no lamb -1.548721 time 2019-01-28 08:46:56.114971
Model ind 579 epoch 100 head B head_i_epoch 0 batch 200: avg loss -1.562644 avg loss no lamb -1.562644 time 2019-01-28 08:49:49.290532
Model ind 579 epoch 100 head A head_i_epoch 0 batch 0: avg loss -2.979953 avg loss no lamb -2.979953 time 2019-01-28 08:52:42.047883
Model ind 579 epoch 100 head A head_i_epoch 0 batch 100: avg loss -2.971861 avg loss no lamb -2.971861 time 2019-01-28 08:55:37.070560
Model ind 579 epoch 100 head A head_i_epoch 0 batch 200: avg loss -3.012752 avg loss no lamb -3.012752 time 2019-01-28 08:58:31.406001
Pre: time 2019-01-28 09:01:50.100858: 
 	std: 0.0040924107
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 5), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 7), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.17376667, 0.17991666, 0.16933334, 0.17855, 0.17956667]
	train_accs: [0.17376667, 0.17991666, 0.16933334, 0.17855, 0.17956667]
	best_train_sub_head: 1
	worst: 0.16933334
	avg: 0.17622668
	best: 0.17991666

Starting e_i: 101
Model ind 579 epoch 101 head B head_i_epoch 0 batch 0: avg loss -1.447006 avg loss no lamb -1.447006 time 2019-01-28 09:01:58.383685
Model ind 579 epoch 101 head B head_i_epoch 0 batch 100: avg loss -1.511816 avg loss no lamb -1.511816 time 2019-01-28 09:04:51.244532
Model ind 579 epoch 101 head B head_i_epoch 0 batch 200: avg loss -1.557345 avg loss no lamb -1.557345 time 2019-01-28 09:07:43.913477
Model ind 579 epoch 101 head A head_i_epoch 0 batch 0: avg loss -2.963849 avg loss no lamb -2.963849 time 2019-01-28 09:10:36.888680
Model ind 579 epoch 101 head A head_i_epoch 0 batch 100: avg loss -3.005189 avg loss no lamb -3.005189 time 2019-01-28 09:13:30.803921
Model ind 579 epoch 101 head A head_i_epoch 0 batch 200: avg loss -3.015660 avg loss no lamb -3.015660 time 2019-01-28 09:16:25.878026
Pre: time 2019-01-28 09:19:40.537342: 
 	std: 0.0028563365
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 15), (3, 9), (4, 12), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 19), (11, 7), (12, 16), (13, 18), (14, 1), (15, 13), (16, 6), (17, 3), (18, 5), (19, 11)]
	test_accs: [0.1722, 0.17458333, 0.1692, 0.17513333, 0.17763333]
	train_accs: [0.1722, 0.17458333, 0.1692, 0.17513333, 0.17763333]
	best_train_sub_head: 4
	worst: 0.1692
	avg: 0.17375001
	best: 0.17763333

Starting e_i: 102
Model ind 579 epoch 102 head B head_i_epoch 0 batch 0: avg loss -1.381529 avg loss no lamb -1.381529 time 2019-01-28 09:19:42.865197
Model ind 579 epoch 102 head B head_i_epoch 0 batch 100: avg loss -1.493727 avg loss no lamb -1.493727 time 2019-01-28 09:22:32.682586
Model ind 579 epoch 102 head B head_i_epoch 0 batch 200: avg loss -1.473704 avg loss no lamb -1.473704 time 2019-01-28 09:25:23.507169
Model ind 579 epoch 102 head A head_i_epoch 0 batch 0: avg loss -3.020333 avg loss no lamb -3.020333 time 2019-01-28 09:28:15.658385
Model ind 579 epoch 102 head A head_i_epoch 0 batch 100: avg loss -3.021380 avg loss no lamb -3.021380 time 2019-01-28 09:31:08.029387
Model ind 579 epoch 102 head A head_i_epoch 0 batch 200: avg loss -3.066397 avg loss no lamb -3.066397 time 2019-01-28 09:34:00.012252
Pre: time 2019-01-28 09:37:17.251851: 
 	std: 0.002307747
	best_train_sub_head_match: [(0, 3), (1, 16), (2, 13), (3, 9), (4, 2), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 5), (11, 7), (12, 1), (13, 18), (14, 4), (15, 15), (16, 6), (17, 11), (18, 19), (19, 12)]
	test_accs: [0.1802, 0.17813334, 0.17411667, 0.17866667, 0.18061666]
	train_accs: [0.1802, 0.17813334, 0.17411667, 0.17866667, 0.18061666]
	best_train_sub_head: 4
	worst: 0.17411667
	avg: 0.17834666
	best: 0.18061666

Starting e_i: 103
Model ind 579 epoch 103 head B head_i_epoch 0 batch 0: avg loss -1.532900 avg loss no lamb -1.532900 time 2019-01-28 09:37:19.637279
Model ind 579 epoch 103 head B head_i_epoch 0 batch 100: avg loss -1.493161 avg loss no lamb -1.493161 time 2019-01-28 09:40:11.225693
Model ind 579 epoch 103 head B head_i_epoch 0 batch 200: avg loss -1.471930 avg loss no lamb -1.471930 time 2019-01-28 09:43:04.226051
Model ind 579 epoch 103 head A head_i_epoch 0 batch 0: avg loss -2.956810 avg loss no lamb -2.956810 time 2019-01-28 09:45:57.607835
Model ind 579 epoch 103 head A head_i_epoch 0 batch 100: avg loss -2.952698 avg loss no lamb -2.952698 time 2019-01-28 09:48:52.635524
Model ind 579 epoch 103 head A head_i_epoch 0 batch 200: avg loss -3.074813 avg loss no lamb -3.074813 time 2019-01-28 09:51:46.423503
Pre: time 2019-01-28 09:55:01.847236: 
 	std: 0.0023268347
	best_train_sub_head_match: [(0, 5), (1, 2), (2, 13), (3, 9), (4, 12), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 18), (11, 7), (12, 16), (13, 19), (14, 4), (15, 15), (16, 6), (17, 3), (18, 1), (19, 11)]
	test_accs: [0.17816667, 0.17706667, 0.17455, 0.17783333, 0.18178333]
	train_accs: [0.17816667, 0.17706667, 0.17455, 0.17783333, 0.18178333]
	best_train_sub_head: 4
	worst: 0.17455
	avg: 0.17788
	best: 0.18178333

Starting e_i: 104
Model ind 579 epoch 104 head B head_i_epoch 0 batch 0: avg loss -1.467199 avg loss no lamb -1.467199 time 2019-01-28 09:55:04.402341
Model ind 579 epoch 104 head B head_i_epoch 0 batch 100: avg loss -1.497667 avg loss no lamb -1.497667 time 2019-01-28 09:57:55.670033
Model ind 579 epoch 104 head B head_i_epoch 0 batch 200: avg loss -1.505448 avg loss no lamb -1.505448 time 2019-01-28 10:00:47.747502
Model ind 579 epoch 104 head A head_i_epoch 0 batch 0: avg loss -3.021039 avg loss no lamb -3.021039 time 2019-01-28 10:03:39.352108
Model ind 579 epoch 104 head A head_i_epoch 0 batch 100: avg loss -3.064714 avg loss no lamb -3.064714 time 2019-01-28 10:06:32.835466
Model ind 579 epoch 104 head A head_i_epoch 0 batch 200: avg loss -3.027425 avg loss no lamb -3.027425 time 2019-01-28 10:09:26.119175
Pre: time 2019-01-28 10:12:44.051707: 
 	std: 0.0010802455
	best_train_sub_head_match: [(0, 5), (1, 11), (2, 15), (3, 9), (4, 12), (5, 17), (6, 8), (7, 10), (8, 1), (9, 14), (10, 19), (11, 7), (12, 16), (13, 18), (14, 4), (15, 13), (16, 6), (17, 3), (18, 0), (19, 2)]
	test_accs: [0.16895, 0.1709, 0.16843334, 0.17043333, 0.17113334]
	train_accs: [0.16895, 0.1709, 0.16843334, 0.17043333, 0.17113334]
	best_train_sub_head: 4
	worst: 0.16843334
	avg: 0.16997
	best: 0.17113334

Starting e_i: 105
Model ind 579 epoch 105 head B head_i_epoch 0 batch 0: avg loss -1.418289 avg loss no lamb -1.418289 time 2019-01-28 10:12:46.419529
Model ind 579 epoch 105 head B head_i_epoch 0 batch 100: avg loss -1.475976 avg loss no lamb -1.475976 time 2019-01-28 10:15:39.433212
Model ind 579 epoch 105 head B head_i_epoch 0 batch 200: avg loss -1.495707 avg loss no lamb -1.495707 time 2019-01-28 10:18:33.073021
Model ind 579 epoch 105 head A head_i_epoch 0 batch 0: avg loss -2.970604 avg loss no lamb -2.970604 time 2019-01-28 10:21:26.360437
Model ind 579 epoch 105 head A head_i_epoch 0 batch 100: avg loss -3.044483 avg loss no lamb -3.044483 time 2019-01-28 10:24:20.517176
Model ind 579 epoch 105 head A head_i_epoch 0 batch 200: avg loss -3.042825 avg loss no lamb -3.042825 time 2019-01-28 10:27:14.943688
Pre: time 2019-01-28 10:30:33.496411: 
 	std: 0.0014204995
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 3), (4, 4), (5, 9), (6, 7), (7, 8), (8, 6), (9, 1), (10, 18), (11, 5), (12, 16), (13, 11), (14, 10), (15, 14), (16, 12), (17, 17), (18, 15), (19, 19)]
	test_accs: [0.17588334, 0.17675, 0.17451666, 0.17826666, 0.17818333]
	train_accs: [0.17588334, 0.17675, 0.17451666, 0.17826666, 0.17818333]
	best_train_sub_head: 3
	worst: 0.17451666
	avg: 0.17672
	best: 0.17826666

Starting e_i: 106
Model ind 579 epoch 106 head B head_i_epoch 0 batch 0: avg loss -1.439404 avg loss no lamb -1.439404 time 2019-01-28 10:30:35.934448
Model ind 579 epoch 106 head B head_i_epoch 0 batch 100: avg loss -1.424442 avg loss no lamb -1.424442 time 2019-01-28 10:33:28.663007
Model ind 579 epoch 106 head B head_i_epoch 0 batch 200: avg loss -1.578729 avg loss no lamb -1.578729 time 2019-01-28 10:36:20.863827
Model ind 579 epoch 106 head A head_i_epoch 0 batch 0: avg loss -3.035434 avg loss no lamb -3.035434 time 2019-01-28 10:39:13.552942
Model ind 579 epoch 106 head A head_i_epoch 0 batch 100: avg loss -3.017996 avg loss no lamb -3.017996 time 2019-01-28 10:42:08.069886
Model ind 579 epoch 106 head A head_i_epoch 0 batch 200: avg loss -3.005432 avg loss no lamb -3.005432 time 2019-01-28 10:45:01.126669
Pre: time 2019-01-28 10:48:18.657906: 
 	std: 0.002520682
	best_train_sub_head_match: [(0, 11), (1, 12), (2, 15), (3, 9), (4, 13), (5, 0), (6, 17), (7, 10), (8, 4), (9, 1), (10, 19), (11, 7), (12, 16), (13, 18), (14, 2), (15, 14), (16, 6), (17, 5), (18, 3), (19, 8)]
	test_accs: [0.17115, 0.17236666, 0.16628334, 0.17071667, 0.17376667]
	train_accs: [0.17115, 0.17236666, 0.16628334, 0.17071667, 0.17376667]
	best_train_sub_head: 4
	worst: 0.16628334
	avg: 0.17085665
	best: 0.17376667

Starting e_i: 107
Model ind 579 epoch 107 head B head_i_epoch 0 batch 0: avg loss -1.389198 avg loss no lamb -1.389198 time 2019-01-28 10:48:21.081483
Model ind 579 epoch 107 head B head_i_epoch 0 batch 100: avg loss -1.492357 avg loss no lamb -1.492357 time 2019-01-28 10:51:12.453536
Model ind 579 epoch 107 head B head_i_epoch 0 batch 200: avg loss -1.444415 avg loss no lamb -1.444415 time 2019-01-28 10:54:04.780514
Model ind 579 epoch 107 head A head_i_epoch 0 batch 0: avg loss -2.933903 avg loss no lamb -2.933903 time 2019-01-28 10:56:57.025018
Model ind 579 epoch 107 head A head_i_epoch 0 batch 100: avg loss -3.046329 avg loss no lamb -3.046329 time 2019-01-28 10:59:51.386791
Model ind 579 epoch 107 head A head_i_epoch 0 batch 200: avg loss -3.029070 avg loss no lamb -3.029070 time 2019-01-28 11:02:46.529109
Pre: time 2019-01-28 11:06:01.480501: 
 	std: 0.0019773836
	best_train_sub_head_match: [(0, 3), (1, 14), (2, 13), (3, 9), (4, 12), (5, 17), (6, 8), (7, 10), (8, 1), (9, 0), (10, 19), (11, 7), (12, 16), (13, 18), (14, 2), (15, 15), (16, 6), (17, 5), (18, 4), (19, 11)]
	test_accs: [0.17651667, 0.17538333, 0.17875, 0.17371666, 0.17886667]
	train_accs: [0.17651667, 0.17538333, 0.17875, 0.17371666, 0.17886667]
	best_train_sub_head: 4
	worst: 0.17371666
	avg: 0.17664666
	best: 0.17886667

Starting e_i: 108
Model ind 579 epoch 108 head B head_i_epoch 0 batch 0: avg loss -1.473818 avg loss no lamb -1.473818 time 2019-01-28 11:06:03.845382
Model ind 579 epoch 108 head B head_i_epoch 0 batch 100: avg loss -1.525301 avg loss no lamb -1.525301 time 2019-01-28 11:08:52.703068
Model ind 579 epoch 108 head B head_i_epoch 0 batch 200: avg loss -1.562360 avg loss no lamb -1.562360 time 2019-01-28 11:11:42.832324
Model ind 579 epoch 108 head A head_i_epoch 0 batch 0: avg loss -3.000810 avg loss no lamb -3.000810 time 2019-01-28 11:14:33.125502
Model ind 579 epoch 108 head A head_i_epoch 0 batch 100: avg loss -3.043384 avg loss no lamb -3.043384 time 2019-01-28 11:17:24.683171
Model ind 579 epoch 108 head A head_i_epoch 0 batch 200: avg loss -3.087238 avg loss no lamb -3.087238 time 2019-01-28 11:20:16.309732
Pre: time 2019-01-28 11:23:32.674195: 
 	std: 0.0012788633
	best_train_sub_head_match: [(0, 18), (1, 5), (2, 14), (3, 0), (4, 16), (5, 3), (6, 12), (7, 6), (8, 13), (9, 10), (10, 4), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 11), (17, 17), (18, 1), (19, 8)]
	test_accs: [0.18018334, 0.17955, 0.17661667, 0.17906667, 0.1799]
	train_accs: [0.18018334, 0.17955, 0.17661667, 0.17906667, 0.1799]
	best_train_sub_head: 0
	worst: 0.17661667
	avg: 0.17906334
	best: 0.18018334

Starting e_i: 109
Model ind 579 epoch 109 head B head_i_epoch 0 batch 0: avg loss -1.416928 avg loss no lamb -1.416928 time 2019-01-28 11:23:35.132369
Model ind 579 epoch 109 head B head_i_epoch 0 batch 100: avg loss -1.462696 avg loss no lamb -1.462696 time 2019-01-28 11:26:28.218545
Model ind 579 epoch 109 head B head_i_epoch 0 batch 200: avg loss -1.523306 avg loss no lamb -1.523306 time 2019-01-28 11:29:22.734314
Model ind 579 epoch 109 head A head_i_epoch 0 batch 0: avg loss -2.967454 avg loss no lamb -2.967454 time 2019-01-28 11:32:15.809708
Model ind 579 epoch 109 head A head_i_epoch 0 batch 100: avg loss -3.028972 avg loss no lamb -3.028972 time 2019-01-28 11:35:10.124438
Model ind 579 epoch 109 head A head_i_epoch 0 batch 200: avg loss -3.053811 avg loss no lamb -3.053811 time 2019-01-28 11:38:05.795412
Pre: time 2019-01-28 11:41:24.564147: 
 	std: 0.0016453777
	best_train_sub_head_match: [(0, 5), (1, 2), (2, 13), (3, 9), (4, 16), (5, 17), (6, 8), (7, 10), (8, 1), (9, 0), (10, 18), (11, 7), (12, 14), (13, 19), (14, 4), (15, 15), (16, 6), (17, 11), (18, 3), (19, 12)]
	test_accs: [0.17733334, 0.17638333, 0.1734, 0.1748, 0.17785]
	train_accs: [0.17733334, 0.17638333, 0.1734, 0.1748, 0.17785]
	best_train_sub_head: 4
	worst: 0.1734
	avg: 0.17595333
	best: 0.17785

Starting e_i: 110
Model ind 579 epoch 110 head B head_i_epoch 0 batch 0: avg loss -1.406177 avg loss no lamb -1.406177 time 2019-01-28 11:41:27.047417
Model ind 579 epoch 110 head B head_i_epoch 0 batch 100: avg loss -1.500378 avg loss no lamb -1.500378 time 2019-01-28 11:44:20.103188
Model ind 579 epoch 110 head B head_i_epoch 0 batch 200: avg loss -1.490166 avg loss no lamb -1.490166 time 2019-01-28 11:47:13.405211
Model ind 579 epoch 110 head A head_i_epoch 0 batch 0: avg loss -3.014957 avg loss no lamb -3.014957 time 2019-01-28 11:50:05.514749
Model ind 579 epoch 110 head A head_i_epoch 0 batch 100: avg loss -3.004191 avg loss no lamb -3.004191 time 2019-01-28 11:53:00.199951
Model ind 579 epoch 110 head A head_i_epoch 0 batch 200: avg loss -2.991273 avg loss no lamb -2.991273 time 2019-01-28 11:55:54.249648
Pre: time 2019-01-28 11:59:11.913697: 
 	std: 0.0031721448
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 0), (3, 15), (4, 3), (5, 19), (6, 7), (7, 8), (8, 11), (9, 2), (10, 13), (11, 17), (12, 5), (13, 4), (14, 14), (15, 12), (16, 10), (17, 1), (18, 6), (19, 18)]
	test_accs: [0.18103333, 0.18188334, 0.17318334, 0.17973334, 0.18105]
	train_accs: [0.18103333, 0.18188334, 0.17318334, 0.17973334, 0.18105]
	best_train_sub_head: 1
	worst: 0.17318334
	avg: 0.17937666
	best: 0.18188334

Starting e_i: 111
Model ind 579 epoch 111 head B head_i_epoch 0 batch 0: avg loss -1.418222 avg loss no lamb -1.418222 time 2019-01-28 11:59:18.549669
Model ind 579 epoch 111 head B head_i_epoch 0 batch 100: avg loss -1.551584 avg loss no lamb -1.551584 time 2019-01-28 12:02:10.824176
Model ind 579 epoch 111 head B head_i_epoch 0 batch 200: avg loss -1.457565 avg loss no lamb -1.457565 time 2019-01-28 12:05:03.104710
Model ind 579 epoch 111 head A head_i_epoch 0 batch 0: avg loss -2.998451 avg loss no lamb -2.998451 time 2019-01-28 12:07:56.753611
Model ind 579 epoch 111 head A head_i_epoch 0 batch 100: avg loss -3.053159 avg loss no lamb -3.053159 time 2019-01-28 12:10:51.303556
Model ind 579 epoch 111 head A head_i_epoch 0 batch 200: avg loss -3.081603 avg loss no lamb -3.081603 time 2019-01-28 12:13:46.300809
Pre: time 2019-01-28 12:17:04.869972: 
 	std: 0.0022380159
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 5), (3, 9), (4, 12), (5, 17), (6, 13), (7, 10), (8, 14), (9, 0), (10, 19), (11, 7), (12, 16), (13, 18), (14, 1), (15, 15), (16, 6), (17, 11), (18, 3), (19, 8)]
	test_accs: [0.17955, 0.18015, 0.17488334, 0.17755, 0.18121667]
	train_accs: [0.17955, 0.18015, 0.17488334, 0.17755, 0.18121667]
	best_train_sub_head: 4
	worst: 0.17488334
	avg: 0.17867
	best: 0.18121667

Starting e_i: 112
Model ind 579 epoch 112 head B head_i_epoch 0 batch 0: avg loss -1.456236 avg loss no lamb -1.456236 time 2019-01-28 12:17:07.349682
Model ind 579 epoch 112 head B head_i_epoch 0 batch 100: avg loss -1.523236 avg loss no lamb -1.523236 time 2019-01-28 12:20:00.773595
Model ind 579 epoch 112 head B head_i_epoch 0 batch 200: avg loss -1.557650 avg loss no lamb -1.557650 time 2019-01-28 12:22:53.877086
Model ind 579 epoch 112 head A head_i_epoch 0 batch 0: avg loss -2.960329 avg loss no lamb -2.960329 time 2019-01-28 12:25:47.558523
Model ind 579 epoch 112 head A head_i_epoch 0 batch 100: avg loss -2.964643 avg loss no lamb -2.964643 time 2019-01-28 12:28:44.185308
Model ind 579 epoch 112 head A head_i_epoch 0 batch 200: avg loss -3.029163 avg loss no lamb -3.029163 time 2019-01-28 12:31:39.200850
Pre: time 2019-01-28 12:34:57.330086: 
 	std: 0.00445661
	best_train_sub_head_match: [(0, 5), (1, 2), (2, 13), (3, 9), (4, 16), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 19), (11, 7), (12, 1), (13, 18), (14, 4), (15, 15), (16, 6), (17, 11), (18, 3), (19, 12)]
	test_accs: [0.19101667, 0.18955, 0.18235, 0.18861666, 0.19621667]
	train_accs: [0.19101667, 0.18955, 0.18235, 0.18861666, 0.19621667]
	best_train_sub_head: 4
	worst: 0.18235
	avg: 0.18955
	best: 0.19621667

Starting e_i: 113
Model ind 579 epoch 113 head B head_i_epoch 0 batch 0: avg loss -1.347778 avg loss no lamb -1.347778 time 2019-01-28 12:35:03.810283
Model ind 579 epoch 113 head B head_i_epoch 0 batch 100: avg loss -1.580268 avg loss no lamb -1.580268 time 2019-01-28 12:37:57.090104
Model ind 579 epoch 113 head B head_i_epoch 0 batch 200: avg loss -1.495121 avg loss no lamb -1.495121 time 2019-01-28 12:40:50.184999
Model ind 579 epoch 113 head A head_i_epoch 0 batch 0: avg loss -2.973067 avg loss no lamb -2.973067 time 2019-01-28 12:43:42.702921
Model ind 579 epoch 113 head A head_i_epoch 0 batch 100: avg loss -3.032377 avg loss no lamb -3.032377 time 2019-01-28 12:46:37.775546
Model ind 579 epoch 113 head A head_i_epoch 0 batch 200: avg loss -3.053876 avg loss no lamb -3.053876 time 2019-01-28 12:49:32.005832
Pre: time 2019-01-28 12:52:49.405624: 
 	std: 0.002389425
	best_train_sub_head_match: [(0, 3), (1, 2), (2, 13), (3, 9), (4, 16), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 18), (11, 7), (12, 1), (13, 19), (14, 4), (15, 15), (16, 6), (17, 11), (18, 5), (19, 12)]
	test_accs: [0.19153333, 0.18821667, 0.18783334, 0.18603334, 0.1924]
	train_accs: [0.19153333, 0.18821667, 0.18783334, 0.18603334, 0.1924]
	best_train_sub_head: 4
	worst: 0.18603334
	avg: 0.18920334
	best: 0.1924

Starting e_i: 114
Model ind 579 epoch 114 head B head_i_epoch 0 batch 0: avg loss -1.413208 avg loss no lamb -1.413208 time 2019-01-28 12:52:51.817574
Model ind 579 epoch 114 head B head_i_epoch 0 batch 100: avg loss -1.505779 avg loss no lamb -1.505779 time 2019-01-28 12:55:41.594908
Model ind 579 epoch 114 head B head_i_epoch 0 batch 200: avg loss -1.607256 avg loss no lamb -1.607256 time 2019-01-28 12:58:31.443315
Model ind 579 epoch 114 head A head_i_epoch 0 batch 0: avg loss -2.996537 avg loss no lamb -2.996537 time 2019-01-28 13:01:22.185018
Model ind 579 epoch 114 head A head_i_epoch 0 batch 100: avg loss -3.043116 avg loss no lamb -3.043116 time 2019-01-28 13:04:16.672955
Model ind 579 epoch 114 head A head_i_epoch 0 batch 200: avg loss -3.032957 avg loss no lamb -3.032957 time 2019-01-28 13:07:12.319264
Pre: time 2019-01-28 13:10:30.218020: 
 	std: 0.00088871905
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 13), (4, 4), (5, 7), (6, 11), (7, 14), (8, 3), (9, 12), (10, 8), (11, 17), (12, 18), (13, 1), (14, 15), (15, 16), (16, 10), (17, 0), (18, 6), (19, 19)]
	test_accs: [0.18551667, 0.18685, 0.18411666, 0.18578333, 0.18513334]
	train_accs: [0.18551667, 0.18685, 0.18411666, 0.18578333, 0.18513334]
	best_train_sub_head: 1
	worst: 0.18411666
	avg: 0.18548
	best: 0.18685

Starting e_i: 115
Model ind 579 epoch 115 head B head_i_epoch 0 batch 0: avg loss -1.401517 avg loss no lamb -1.401517 time 2019-01-28 13:10:32.675078
Model ind 579 epoch 115 head B head_i_epoch 0 batch 100: avg loss -1.498449 avg loss no lamb -1.498449 time 2019-01-28 13:13:25.349509
Model ind 579 epoch 115 head B head_i_epoch 0 batch 200: avg loss -1.561497 avg loss no lamb -1.561497 time 2019-01-28 13:16:18.409632
Model ind 579 epoch 115 head A head_i_epoch 0 batch 0: avg loss -2.994855 avg loss no lamb -2.994855 time 2019-01-28 13:19:12.548382
Model ind 579 epoch 115 head A head_i_epoch 0 batch 100: avg loss -3.029553 avg loss no lamb -3.029553 time 2019-01-28 13:22:07.117057
Model ind 579 epoch 115 head A head_i_epoch 0 batch 200: avg loss -3.042873 avg loss no lamb -3.042873 time 2019-01-28 13:25:01.186123
Pre: time 2019-01-28 13:28:14.924454: 
 	std: 0.0024698973
	best_train_sub_head_match: [(0, 18), (1, 16), (2, 14), (3, 0), (4, 12), (5, 5), (6, 2), (7, 6), (8, 13), (9, 10), (10, 7), (11, 8), (12, 19), (13, 9), (14, 15), (15, 4), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.18725, 0.18563333, 0.18048333, 0.18666667, 0.18653333]
	train_accs: [0.18725, 0.18563333, 0.18048333, 0.18666667, 0.18653333]
	best_train_sub_head: 0
	worst: 0.18048333
	avg: 0.18531333
	best: 0.18725

Starting e_i: 116
Model ind 579 epoch 116 head B head_i_epoch 0 batch 0: avg loss -1.428271 avg loss no lamb -1.428271 time 2019-01-28 13:28:17.310861
Model ind 579 epoch 116 head B head_i_epoch 0 batch 100: avg loss -1.490474 avg loss no lamb -1.490474 time 2019-01-28 13:31:06.321980
Model ind 579 epoch 116 head B head_i_epoch 0 batch 200: avg loss -1.528273 avg loss no lamb -1.528273 time 2019-01-28 13:33:55.508489
Model ind 579 epoch 116 head A head_i_epoch 0 batch 0: avg loss -2.958430 avg loss no lamb -2.958430 time 2019-01-28 13:36:45.228785
Model ind 579 epoch 116 head A head_i_epoch 0 batch 100: avg loss -3.054215 avg loss no lamb -3.054215 time 2019-01-28 13:39:36.564072
Model ind 579 epoch 116 head A head_i_epoch 0 batch 200: avg loss -3.038187 avg loss no lamb -3.038187 time 2019-01-28 13:42:28.096500
Pre: time 2019-01-28 13:45:43.989663: 
 	std: 0.004002265
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 13), (3, 9), (4, 16), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 19), (11, 7), (12, 1), (13, 18), (14, 5), (15, 15), (16, 6), (17, 11), (18, 3), (19, 12)]
	test_accs: [0.17988333, 0.17823334, 0.17143333, 0.17715, 0.18371667]
	train_accs: [0.17988333, 0.17823334, 0.17143333, 0.17715, 0.18371667]
	best_train_sub_head: 4
	worst: 0.17143333
	avg: 0.17808333
	best: 0.18371667

Starting e_i: 117
Model ind 579 epoch 117 head B head_i_epoch 0 batch 0: avg loss -1.394455 avg loss no lamb -1.394455 time 2019-01-28 13:45:46.606457
Model ind 579 epoch 117 head B head_i_epoch 0 batch 100: avg loss -1.483021 avg loss no lamb -1.483021 time 2019-01-28 13:48:37.249282
Model ind 579 epoch 117 head B head_i_epoch 0 batch 200: avg loss -1.479983 avg loss no lamb -1.479983 time 2019-01-28 13:51:26.460789
Model ind 579 epoch 117 head A head_i_epoch 0 batch 0: avg loss -3.013393 avg loss no lamb -3.013393 time 2019-01-28 13:54:17.536030
Model ind 579 epoch 117 head A head_i_epoch 0 batch 100: avg loss -3.026162 avg loss no lamb -3.026162 time 2019-01-28 13:57:10.771894
Model ind 579 epoch 117 head A head_i_epoch 0 batch 200: avg loss -3.077332 avg loss no lamb -3.077332 time 2019-01-28 14:00:03.172568
Pre: time 2019-01-28 14:03:18.550842: 
 	std: 0.0035417934
	best_train_sub_head_match: [(0, 18), (1, 1), (2, 14), (3, 0), (4, 13), (5, 5), (6, 16), (7, 6), (8, 7), (9, 10), (10, 3), (11, 8), (12, 19), (13, 9), (14, 15), (15, 2), (16, 11), (17, 17), (18, 4), (19, 12)]
	test_accs: [0.19041666, 0.1836, 0.18003333, 0.18548334, 0.18775]
	train_accs: [0.19041666, 0.1836, 0.18003333, 0.18548334, 0.18775]
	best_train_sub_head: 0
	worst: 0.18003333
	avg: 0.18545666
	best: 0.19041666

Starting e_i: 118
Model ind 579 epoch 118 head B head_i_epoch 0 batch 0: avg loss -1.456435 avg loss no lamb -1.456435 time 2019-01-28 14:03:21.064448
Model ind 579 epoch 118 head B head_i_epoch 0 batch 100: avg loss -1.442640 avg loss no lamb -1.442640 time 2019-01-28 14:06:15.623059
Model ind 579 epoch 118 head B head_i_epoch 0 batch 200: avg loss -1.522730 avg loss no lamb -1.522730 time 2019-01-28 14:09:10.033898
Model ind 579 epoch 118 head A head_i_epoch 0 batch 0: avg loss -2.973747 avg loss no lamb -2.973747 time 2019-01-28 14:12:01.969227
Model ind 579 epoch 118 head A head_i_epoch 0 batch 100: avg loss -3.020419 avg loss no lamb -3.020419 time 2019-01-28 14:14:55.495984
Model ind 579 epoch 118 head A head_i_epoch 0 batch 200: avg loss -3.066800 avg loss no lamb -3.066800 time 2019-01-28 14:17:49.786300
Pre: time 2019-01-28 14:21:09.296321: 
 	std: 0.0026310238
	best_train_sub_head_match: [(0, 5), (1, 2), (2, 13), (3, 18), (4, 12), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 9), (11, 7), (12, 16), (13, 19), (14, 4), (15, 15), (16, 6), (17, 3), (18, 1), (19, 11)]
	test_accs: [0.188, 0.18533333, 0.18381667, 0.18645, 0.19151667]
	train_accs: [0.188, 0.18533333, 0.18381667, 0.18645, 0.19151667]
	best_train_sub_head: 4
	worst: 0.18381667
	avg: 0.18702333
	best: 0.19151667

Starting e_i: 119
Model ind 579 epoch 119 head B head_i_epoch 0 batch 0: avg loss -1.465294 avg loss no lamb -1.465294 time 2019-01-28 14:21:11.773565
Model ind 579 epoch 119 head B head_i_epoch 0 batch 100: avg loss -1.540370 avg loss no lamb -1.540370 time 2019-01-28 14:24:05.554188
Model ind 579 epoch 119 head B head_i_epoch 0 batch 200: avg loss -1.531169 avg loss no lamb -1.531169 time 2019-01-28 14:26:58.716638
Model ind 579 epoch 119 head A head_i_epoch 0 batch 0: avg loss -2.987548 avg loss no lamb -2.987548 time 2019-01-28 14:29:52.280355
Model ind 579 epoch 119 head A head_i_epoch 0 batch 100: avg loss -3.027275 avg loss no lamb -3.027275 time 2019-01-28 14:32:47.085183
Model ind 579 epoch 119 head A head_i_epoch 0 batch 200: avg loss -3.061204 avg loss no lamb -3.061204 time 2019-01-28 14:35:41.987192
Pre: time 2019-01-28 14:39:01.068089: 
 	std: 0.0018232864
	best_train_sub_head_match: [(0, 3), (1, 2), (2, 13), (3, 9), (4, 12), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 19), (11, 7), (12, 16), (13, 18), (14, 4), (15, 15), (16, 6), (17, 5), (18, 1), (19, 11)]
	test_accs: [0.1901, 0.1868, 0.18613334, 0.18821667, 0.19085]
	train_accs: [0.1901, 0.1868, 0.18613334, 0.18821667, 0.19085]
	best_train_sub_head: 4
	worst: 0.18613334
	avg: 0.18842001
	best: 0.19085

Starting e_i: 120
Model ind 579 epoch 120 head B head_i_epoch 0 batch 0: avg loss -1.489103 avg loss no lamb -1.489103 time 2019-01-28 14:39:03.464334
Model ind 579 epoch 120 head B head_i_epoch 0 batch 100: avg loss -1.448957 avg loss no lamb -1.448957 time 2019-01-28 14:41:57.550078
Model ind 579 epoch 120 head B head_i_epoch 0 batch 200: avg loss -1.478654 avg loss no lamb -1.478654 time 2019-01-28 14:44:50.890398
Model ind 579 epoch 120 head A head_i_epoch 0 batch 0: avg loss -2.990297 avg loss no lamb -2.990297 time 2019-01-28 14:47:44.233706
Model ind 579 epoch 120 head A head_i_epoch 0 batch 100: avg loss -3.003742 avg loss no lamb -3.003742 time 2019-01-28 14:50:38.588261
Model ind 579 epoch 120 head A head_i_epoch 0 batch 200: avg loss -3.120094 avg loss no lamb -3.120094 time 2019-01-28 14:53:32.468706
Pre: time 2019-01-28 14:56:50.364030: 
 	std: 0.0027295758
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 7), (7, 12), (8, 6), (9, 14), (10, 9), (11, 8), (12, 5), (13, 11), (14, 10), (15, 1), (16, 16), (17, 17), (18, 15), (19, 18)]
	test_accs: [0.18695, 0.1861, 0.18045, 0.1883, 0.1868]
	train_accs: [0.18695, 0.1861, 0.18045, 0.1883, 0.1868]
	best_train_sub_head: 3
	worst: 0.18045
	avg: 0.18572
	best: 0.1883

Starting e_i: 121
Model ind 579 epoch 121 head B head_i_epoch 0 batch 0: avg loss -1.398707 avg loss no lamb -1.398707 time 2019-01-28 14:56:58.071239
Model ind 579 epoch 121 head B head_i_epoch 0 batch 100: avg loss -1.450846 avg loss no lamb -1.450846 time 2019-01-28 14:59:50.380729
Model ind 579 epoch 121 head B head_i_epoch 0 batch 200: avg loss -1.541423 avg loss no lamb -1.541423 time 2019-01-28 15:02:43.436875
Model ind 579 epoch 121 head A head_i_epoch 0 batch 0: avg loss -3.032444 avg loss no lamb -3.032444 time 2019-01-28 15:05:37.028461
Model ind 579 epoch 121 head A head_i_epoch 0 batch 100: avg loss -3.000260 avg loss no lamb -3.000260 time 2019-01-28 15:08:31.499812
Model ind 579 epoch 121 head A head_i_epoch 0 batch 200: avg loss -3.050165 avg loss no lamb -3.050165 time 2019-01-28 15:11:26.323882
Pre: time 2019-01-28 15:14:44.436903: 
 	std: 0.0018385284
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 5), (6, 8), (7, 11), (8, 3), (9, 16), (10, 7), (11, 17), (12, 18), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.1872, 0.19101667, 0.18646666, 0.19076666, 0.18926667]
	train_accs: [0.1872, 0.19101667, 0.18646666, 0.19076666, 0.18926667]
	best_train_sub_head: 1
	worst: 0.18646666
	avg: 0.18894334
	best: 0.19101667

Starting e_i: 122
Model ind 579 epoch 122 head B head_i_epoch 0 batch 0: avg loss -1.474462 avg loss no lamb -1.474462 time 2019-01-28 15:14:46.931182
Model ind 579 epoch 122 head B head_i_epoch 0 batch 100: avg loss -1.529590 avg loss no lamb -1.529590 time 2019-01-28 15:17:41.129586
Model ind 579 epoch 122 head B head_i_epoch 0 batch 200: avg loss -1.545343 avg loss no lamb -1.545343 time 2019-01-28 15:20:35.097361
Model ind 579 epoch 122 head A head_i_epoch 0 batch 0: avg loss -2.982418 avg loss no lamb -2.982418 time 2019-01-28 15:23:26.978863
Model ind 579 epoch 122 head A head_i_epoch 0 batch 100: avg loss -3.025412 avg loss no lamb -3.025412 time 2019-01-28 15:26:21.063718
Model ind 579 epoch 122 head A head_i_epoch 0 batch 200: avg loss -3.042859 avg loss no lamb -3.042859 time 2019-01-28 15:29:15.611937
Pre: time 2019-01-28 15:32:37.596491: 
 	std: 0.0012050543
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 15), (3, 13), (4, 4), (5, 5), (6, 8), (7, 11), (8, 3), (9, 16), (10, 7), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.18956667, 0.19141667, 0.19035, 0.18943334, 0.18775]
	train_accs: [0.18956667, 0.19141667, 0.19035, 0.18943334, 0.18775]
	best_train_sub_head: 1
	worst: 0.18775
	avg: 0.18970333
	best: 0.19141667

Starting e_i: 123
Model ind 579 epoch 123 head B head_i_epoch 0 batch 0: avg loss -1.494609 avg loss no lamb -1.494609 time 2019-01-28 15:32:40.118809
Model ind 579 epoch 123 head B head_i_epoch 0 batch 100: avg loss -1.464671 avg loss no lamb -1.464671 time 2019-01-28 15:35:34.891402
Model ind 579 epoch 123 head B head_i_epoch 0 batch 200: avg loss -1.551412 avg loss no lamb -1.551412 time 2019-01-28 15:38:29.796647
Model ind 579 epoch 123 head A head_i_epoch 0 batch 0: avg loss -3.035031 avg loss no lamb -3.035031 time 2019-01-28 15:41:21.910721
Model ind 579 epoch 123 head A head_i_epoch 0 batch 100: avg loss -3.093409 avg loss no lamb -3.093409 time 2019-01-28 15:44:16.084230
Model ind 579 epoch 123 head A head_i_epoch 0 batch 200: avg loss -3.036716 avg loss no lamb -3.036716 time 2019-01-28 15:47:12.033456
Pre: time 2019-01-28 15:50:29.108313: 
 	std: 0.002165985
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 0), (3, 13), (4, 4), (5, 7), (6, 8), (7, 11), (8, 3), (9, 2), (10, 5), (11, 17), (12, 18), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.17875, 0.18216667, 0.17918333, 0.18153334, 0.1761]
	train_accs: [0.17875, 0.18216667, 0.17918333, 0.18153334, 0.1761]
	best_train_sub_head: 1
	worst: 0.1761
	avg: 0.17954667
	best: 0.18216667

Starting e_i: 124
Model ind 579 epoch 124 head B head_i_epoch 0 batch 0: avg loss -1.565925 avg loss no lamb -1.565925 time 2019-01-28 15:50:31.784351
Model ind 579 epoch 124 head B head_i_epoch 0 batch 100: avg loss -1.545484 avg loss no lamb -1.545484 time 2019-01-28 15:53:24.388553
Model ind 579 epoch 124 head B head_i_epoch 0 batch 200: avg loss -1.525417 avg loss no lamb -1.525417 time 2019-01-28 15:56:17.255467
Model ind 579 epoch 124 head A head_i_epoch 0 batch 0: avg loss -2.932266 avg loss no lamb -2.932266 time 2019-01-28 15:59:09.585231
Model ind 579 epoch 124 head A head_i_epoch 0 batch 100: avg loss -3.059318 avg loss no lamb -3.059318 time 2019-01-28 16:02:03.633669
Model ind 579 epoch 124 head A head_i_epoch 0 batch 200: avg loss -3.068755 avg loss no lamb -3.068755 time 2019-01-28 16:04:57.569264
Pre: time 2019-01-28 16:08:14.213710: 
 	std: 0.0023965116
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 15), (3, 9), (4, 13), (5, 17), (6, 8), (7, 10), (8, 1), (9, 5), (10, 19), (11, 7), (12, 14), (13, 18), (14, 16), (15, 0), (16, 6), (17, 11), (18, 3), (19, 12)]
	test_accs: [0.1724, 0.17041667, 0.16885, 0.17106667, 0.17595]
	train_accs: [0.1724, 0.17041667, 0.16885, 0.17106667, 0.17595]
	best_train_sub_head: 4
	worst: 0.16885
	avg: 0.17173666
	best: 0.17595

Starting e_i: 125
Model ind 579 epoch 125 head B head_i_epoch 0 batch 0: avg loss -1.467969 avg loss no lamb -1.467969 time 2019-01-28 16:08:16.595488
Model ind 579 epoch 125 head B head_i_epoch 0 batch 100: avg loss -1.588643 avg loss no lamb -1.588643 time 2019-01-28 16:11:06.946428
Model ind 579 epoch 125 head B head_i_epoch 0 batch 200: avg loss -1.525389 avg loss no lamb -1.525389 time 2019-01-28 16:13:56.403232
Model ind 579 epoch 125 head A head_i_epoch 0 batch 0: avg loss -3.000062 avg loss no lamb -3.000062 time 2019-01-28 16:16:46.931835
Model ind 579 epoch 125 head A head_i_epoch 0 batch 100: avg loss -3.048791 avg loss no lamb -3.048791 time 2019-01-28 16:19:40.352797
Model ind 579 epoch 125 head A head_i_epoch 0 batch 200: avg loss -3.077081 avg loss no lamb -3.077081 time 2019-01-28 16:22:35.569501
Pre: time 2019-01-28 16:25:53.996571: 
 	std: 0.0022764166
	best_train_sub_head_match: [(0, 13), (1, 1), (2, 14), (3, 0), (4, 2), (5, 3), (6, 16), (7, 6), (8, 7), (9, 10), (10, 19), (11, 8), (12, 18), (13, 9), (14, 15), (15, 4), (16, 11), (17, 17), (18, 5), (19, 12)]
	test_accs: [0.18878333, 0.18258333, 0.1878, 0.1845, 0.18478334]
	train_accs: [0.18878333, 0.18258333, 0.1878, 0.1845, 0.18478334]
	best_train_sub_head: 0
	worst: 0.18258333
	avg: 0.18569
	best: 0.18878333

Starting e_i: 126
Model ind 579 epoch 126 head B head_i_epoch 0 batch 0: avg loss -1.466809 avg loss no lamb -1.466809 time 2019-01-28 16:25:56.454026
Model ind 579 epoch 126 head B head_i_epoch 0 batch 100: avg loss -1.529394 avg loss no lamb -1.529394 time 2019-01-28 16:28:49.291437
Model ind 579 epoch 126 head B head_i_epoch 0 batch 200: avg loss -1.601751 avg loss no lamb -1.601751 time 2019-01-28 16:31:43.049335
Model ind 579 epoch 126 head A head_i_epoch 0 batch 0: avg loss -3.038488 avg loss no lamb -3.038488 time 2019-01-28 16:34:35.514549
Model ind 579 epoch 126 head A head_i_epoch 0 batch 100: avg loss -3.010449 avg loss no lamb -3.010449 time 2019-01-28 16:37:30.038500
Model ind 579 epoch 126 head A head_i_epoch 0 batch 200: avg loss -3.064324 avg loss no lamb -3.064324 time 2019-01-28 16:40:24.140072
Pre: time 2019-01-28 16:43:41.488170: 
 	std: 0.002789333
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 13), (3, 9), (4, 12), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 19), (11, 7), (12, 16), (13, 18), (14, 1), (15, 15), (16, 6), (17, 3), (18, 5), (19, 11)]
	test_accs: [0.18558334, 0.18603334, 0.17973334, 0.1855, 0.18808334]
	train_accs: [0.18558334, 0.18603334, 0.17973334, 0.1855, 0.18808334]
	best_train_sub_head: 4
	worst: 0.17973334
	avg: 0.18498668
	best: 0.18808334

Starting e_i: 127
Model ind 579 epoch 127 head B head_i_epoch 0 batch 0: avg loss -1.506037 avg loss no lamb -1.506037 time 2019-01-28 16:43:44.189609
Model ind 579 epoch 127 head B head_i_epoch 0 batch 100: avg loss -1.538385 avg loss no lamb -1.538385 time 2019-01-28 16:46:37.185859
Model ind 579 epoch 127 head B head_i_epoch 0 batch 200: avg loss -1.543527 avg loss no lamb -1.543527 time 2019-01-28 16:49:30.987235
Model ind 579 epoch 127 head A head_i_epoch 0 batch 0: avg loss -2.959310 avg loss no lamb -2.959310 time 2019-01-28 16:52:24.780850
Model ind 579 epoch 127 head A head_i_epoch 0 batch 100: avg loss -3.058335 avg loss no lamb -3.058335 time 2019-01-28 16:55:21.718153
Model ind 579 epoch 127 head A head_i_epoch 0 batch 200: avg loss -3.045768 avg loss no lamb -3.045768 time 2019-01-28 16:58:16.532370
Pre: time 2019-01-28 17:01:34.008289: 
 	std: 0.0030104993
	best_train_sub_head_match: [(0, 18), (1, 1), (2, 14), (3, 0), (4, 16), (5, 5), (6, 2), (7, 6), (8, 13), (9, 10), (10, 7), (11, 8), (12, 19), (13, 9), (14, 15), (15, 4), (16, 11), (17, 17), (18, 3), (19, 12)]
	test_accs: [0.1924, 0.18401666, 0.18721667, 0.18431666, 0.18688333]
	train_accs: [0.1924, 0.18401666, 0.18721667, 0.18431666, 0.18688333]
	best_train_sub_head: 0
	worst: 0.18401666
	avg: 0.18696666
	best: 0.1924

Starting e_i: 128
Model ind 579 epoch 128 head B head_i_epoch 0 batch 0: avg loss -1.490852 avg loss no lamb -1.490852 time 2019-01-28 17:01:36.523857
Model ind 579 epoch 128 head B head_i_epoch 0 batch 100: avg loss -1.540382 avg loss no lamb -1.540382 time 2019-01-28 17:04:29.128937
Model ind 579 epoch 128 head B head_i_epoch 0 batch 200: avg loss -1.563793 avg loss no lamb -1.563793 time 2019-01-28 17:07:22.858321
Model ind 579 epoch 128 head A head_i_epoch 0 batch 0: avg loss -2.985541 avg loss no lamb -2.985541 time 2019-01-28 17:10:17.167995
Model ind 579 epoch 128 head A head_i_epoch 0 batch 100: avg loss -3.056685 avg loss no lamb -3.056685 time 2019-01-28 17:13:13.230278
Model ind 579 epoch 128 head A head_i_epoch 0 batch 200: avg loss -3.084670 avg loss no lamb -3.084670 time 2019-01-28 17:16:09.592964
Pre: time 2019-01-28 17:19:29.097227: 
 	std: 0.002514477
	best_train_sub_head_match: [(0, 7), (1, 1), (2, 14), (3, 0), (4, 16), (5, 5), (6, 2), (7, 6), (8, 15), (9, 10), (10, 19), (11, 8), (12, 18), (13, 9), (14, 13), (15, 4), (16, 11), (17, 17), (18, 3), (19, 12)]
	test_accs: [0.18765, 0.18281667, 0.1812, 0.18091667, 0.1849]
	train_accs: [0.18765, 0.18281667, 0.1812, 0.18091667, 0.1849]
	best_train_sub_head: 0
	worst: 0.18091667
	avg: 0.18349665
	best: 0.18765

Starting e_i: 129
Model ind 579 epoch 129 head B head_i_epoch 0 batch 0: avg loss -1.455454 avg loss no lamb -1.455454 time 2019-01-28 17:19:31.746168
Model ind 579 epoch 129 head B head_i_epoch 0 batch 100: avg loss -1.540705 avg loss no lamb -1.540705 time 2019-01-28 17:22:26.733595
Model ind 579 epoch 129 head B head_i_epoch 0 batch 200: avg loss -1.570961 avg loss no lamb -1.570961 time 2019-01-28 17:25:21.078182
Model ind 579 epoch 129 head A head_i_epoch 0 batch 0: avg loss -2.936516 avg loss no lamb -2.936516 time 2019-01-28 17:28:14.388084
Model ind 579 epoch 129 head A head_i_epoch 0 batch 100: avg loss -3.061353 avg loss no lamb -3.061353 time 2019-01-28 17:31:09.007027
Model ind 579 epoch 129 head A head_i_epoch 0 batch 200: avg loss -3.091040 avg loss no lamb -3.091040 time 2019-01-28 17:34:04.606359
Pre: time 2019-01-28 17:37:23.521856: 
 	std: 0.0030941581
	best_train_sub_head_match: [(0, 7), (1, 5), (2, 14), (3, 0), (4, 13), (5, 4), (6, 2), (7, 6), (8, 3), (9, 10), (10, 19), (11, 8), (12, 18), (13, 9), (14, 15), (15, 16), (16, 11), (17, 17), (18, 1), (19, 12)]
	test_accs: [0.19241667, 0.18926667, 0.1843, 0.1868, 0.19203334]
	train_accs: [0.19241667, 0.18926667, 0.1843, 0.1868, 0.19203334]
	best_train_sub_head: 0
	worst: 0.1843
	avg: 0.18896334
	best: 0.19241667

Starting e_i: 130
Model ind 579 epoch 130 head B head_i_epoch 0 batch 0: avg loss -1.440964 avg loss no lamb -1.440964 time 2019-01-28 17:37:26.010109
Model ind 579 epoch 130 head B head_i_epoch 0 batch 100: avg loss -1.526952 avg loss no lamb -1.526952 time 2019-01-28 17:40:16.472408
Model ind 579 epoch 130 head B head_i_epoch 0 batch 200: avg loss -1.544002 avg loss no lamb -1.544002 time 2019-01-28 17:43:06.066624
Model ind 579 epoch 130 head A head_i_epoch 0 batch 0: avg loss -3.025700 avg loss no lamb -3.025700 time 2019-01-28 17:45:57.719438
Model ind 579 epoch 130 head A head_i_epoch 0 batch 100: avg loss -3.024032 avg loss no lamb -3.024032 time 2019-01-28 17:48:52.769201
Model ind 579 epoch 130 head A head_i_epoch 0 batch 200: avg loss -3.088653 avg loss no lamb -3.088653 time 2019-01-28 17:51:46.954405
Pre: time 2019-01-28 17:55:06.804990: 
 	std: 0.0023406167
	best_train_sub_head_match: [(0, 4), (1, 16), (2, 13), (3, 9), (4, 2), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 19), (11, 7), (12, 12), (13, 18), (14, 1), (15, 15), (16, 6), (17, 5), (18, 3), (19, 11)]
	test_accs: [0.19256666, 0.19518334, 0.1893, 0.19343333, 0.196]
	train_accs: [0.19256666, 0.19518334, 0.1893, 0.19343333, 0.196]
	best_train_sub_head: 4
	worst: 0.1893
	avg: 0.19329666
	best: 0.196

Starting e_i: 131
Model ind 579 epoch 131 head B head_i_epoch 0 batch 0: avg loss -1.493622 avg loss no lamb -1.493622 time 2019-01-28 17:55:14.715510
Model ind 579 epoch 131 head B head_i_epoch 0 batch 100: avg loss -1.555411 avg loss no lamb -1.555411 time 2019-01-28 17:58:08.055772
Model ind 579 epoch 131 head B head_i_epoch 0 batch 200: avg loss -1.641037 avg loss no lamb -1.641037 time 2019-01-28 18:01:03.765894
Model ind 579 epoch 131 head A head_i_epoch 0 batch 0: avg loss -2.996467 avg loss no lamb -2.996467 time 2019-01-28 18:03:57.788597
Model ind 579 epoch 131 head A head_i_epoch 0 batch 100: avg loss -3.088519 avg loss no lamb -3.088519 time 2019-01-28 18:06:52.852015
Model ind 579 epoch 131 head A head_i_epoch 0 batch 200: avg loss -3.092420 avg loss no lamb -3.092420 time 2019-01-28 18:09:47.575143
Pre: time 2019-01-28 18:13:05.406333: 
 	std: 0.002456813
	best_train_sub_head_match: [(0, 7), (1, 1), (2, 14), (3, 0), (4, 12), (5, 3), (6, 16), (7, 6), (8, 15), (9, 10), (10, 19), (11, 8), (12, 18), (13, 9), (14, 13), (15, 4), (16, 11), (17, 17), (18, 5), (19, 2)]
	test_accs: [0.19471666, 0.19296667, 0.1874, 0.19175, 0.19281666]
	train_accs: [0.19471666, 0.19296667, 0.1874, 0.19175, 0.19281666]
	best_train_sub_head: 0
	worst: 0.1874
	avg: 0.19193
	best: 0.19471666

Starting e_i: 132
Model ind 579 epoch 132 head B head_i_epoch 0 batch 0: avg loss -1.487481 avg loss no lamb -1.487481 time 2019-01-28 18:13:08.052330
Model ind 579 epoch 132 head B head_i_epoch 0 batch 100: avg loss -1.522239 avg loss no lamb -1.522239 time 2019-01-28 18:16:03.014382
Model ind 579 epoch 132 head B head_i_epoch 0 batch 200: avg loss -1.636442 avg loss no lamb -1.636442 time 2019-01-28 18:18:55.547551
Model ind 579 epoch 132 head A head_i_epoch 0 batch 0: avg loss -2.985343 avg loss no lamb -2.985343 time 2019-01-28 18:21:47.597452
Model ind 579 epoch 132 head A head_i_epoch 0 batch 100: avg loss -3.040900 avg loss no lamb -3.040900 time 2019-01-28 18:24:38.706259
Model ind 579 epoch 132 head A head_i_epoch 0 batch 200: avg loss -3.061851 avg loss no lamb -3.061851 time 2019-01-28 18:27:29.507389
Pre: time 2019-01-28 18:30:44.051770: 
 	std: 0.003287306
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 19), (6, 8), (7, 11), (8, 3), (9, 16), (10, 13), (11, 17), (12, 7), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.18703334, 0.19075, 0.1824, 0.19061667, 0.1846]
	train_accs: [0.18703334, 0.19075, 0.1824, 0.19061667, 0.1846]
	best_train_sub_head: 1
	worst: 0.1824
	avg: 0.18708
	best: 0.19075

Starting e_i: 133
Model ind 579 epoch 133 head B head_i_epoch 0 batch 0: avg loss -1.421218 avg loss no lamb -1.421218 time 2019-01-28 18:30:46.727100
Model ind 579 epoch 133 head B head_i_epoch 0 batch 100: avg loss -1.505966 avg loss no lamb -1.505966 time 2019-01-28 18:33:37.871506
Model ind 579 epoch 133 head B head_i_epoch 0 batch 200: avg loss -1.524196 avg loss no lamb -1.524196 time 2019-01-28 18:36:30.996676
Model ind 579 epoch 133 head A head_i_epoch 0 batch 0: avg loss -2.999298 avg loss no lamb -2.999298 time 2019-01-28 18:39:25.281115
Model ind 579 epoch 133 head A head_i_epoch 0 batch 100: avg loss -3.087022 avg loss no lamb -3.087022 time 2019-01-28 18:42:22.117072
Model ind 579 epoch 133 head A head_i_epoch 0 batch 200: avg loss -3.010872 avg loss no lamb -3.010872 time 2019-01-28 18:45:17.311648
Pre: time 2019-01-28 18:48:36.262189: 
 	std: 0.0036338922
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.19445, 0.19778334, 0.1879, 0.19605, 0.1976]
	train_accs: [0.19445, 0.19778334, 0.1879, 0.19605, 0.1976]
	best_train_sub_head: 1
	worst: 0.1879
	avg: 0.19475666
	best: 0.19778334

Starting e_i: 134
Model ind 579 epoch 134 head B head_i_epoch 0 batch 0: avg loss -1.658788 avg loss no lamb -1.658788 time 2019-01-28 18:48:43.665585
Model ind 579 epoch 134 head B head_i_epoch 0 batch 100: avg loss -1.542470 avg loss no lamb -1.542470 time 2019-01-28 18:51:37.985669
Model ind 579 epoch 134 head B head_i_epoch 0 batch 200: avg loss -1.588477 avg loss no lamb -1.588477 time 2019-01-28 18:54:33.529264
Model ind 579 epoch 134 head A head_i_epoch 0 batch 0: avg loss -3.104537 avg loss no lamb -3.104537 time 2019-01-28 18:57:29.102430
Model ind 579 epoch 134 head A head_i_epoch 0 batch 100: avg loss -3.091990 avg loss no lamb -3.091990 time 2019-01-28 19:00:26.640288
Model ind 579 epoch 134 head A head_i_epoch 0 batch 200: avg loss -3.015240 avg loss no lamb -3.015240 time 2019-01-28 19:03:24.733550
Pre: time 2019-01-28 19:06:54.526836: 
 	std: 0.0024865721
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 13), (7, 8), (8, 11), (9, 16), (10, 5), (11, 17), (12, 7), (13, 3), (14, 1), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.1893, 0.192, 0.18485, 0.18675, 0.18978333]
	train_accs: [0.1893, 0.192, 0.18485, 0.18675, 0.18978333]
	best_train_sub_head: 1
	worst: 0.18485
	avg: 0.18853667
	best: 0.192

Starting e_i: 135
Model ind 579 epoch 135 head B head_i_epoch 0 batch 0: avg loss -1.465109 avg loss no lamb -1.465109 time 2019-01-28 19:06:57.238760
Model ind 579 epoch 135 head B head_i_epoch 0 batch 100: avg loss -1.644105 avg loss no lamb -1.644105 time 2019-01-28 19:09:58.448614
Model ind 579 epoch 135 head B head_i_epoch 0 batch 200: avg loss -1.535160 avg loss no lamb -1.535160 time 2019-01-28 19:12:58.926986
Model ind 579 epoch 135 head A head_i_epoch 0 batch 0: avg loss -3.050007 avg loss no lamb -3.050007 time 2019-01-28 19:15:59.864764
Model ind 579 epoch 135 head A head_i_epoch 0 batch 100: avg loss -3.022938 avg loss no lamb -3.022938 time 2019-01-28 19:18:59.329320
Model ind 579 epoch 135 head A head_i_epoch 0 batch 200: avg loss -3.086082 avg loss no lamb -3.086082 time 2019-01-28 19:21:59.094554
Pre: time 2019-01-28 19:25:24.149381: 
 	std: 0.0047044833
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 0), (3, 15), (4, 4), (5, 19), (6, 13), (7, 8), (8, 11), (9, 2), (10, 17), (11, 5), (12, 7), (13, 3), (14, 14), (15, 12), (16, 10), (17, 1), (18, 6), (19, 18)]
	test_accs: [0.18378334, 0.1935, 0.17961666, 0.18863334, 0.18465]
	train_accs: [0.18378334, 0.1935, 0.17961666, 0.18863334, 0.18465]
	best_train_sub_head: 1
	worst: 0.17961666
	avg: 0.18603668
	best: 0.1935

Starting e_i: 136
Model ind 579 epoch 136 head B head_i_epoch 0 batch 0: avg loss -1.459915 avg loss no lamb -1.459915 time 2019-01-28 19:25:27.046449
Model ind 579 epoch 136 head B head_i_epoch 0 batch 100: avg loss -1.494724 avg loss no lamb -1.494724 time 2019-01-28 19:28:27.365411
Model ind 579 epoch 136 head B head_i_epoch 0 batch 200: avg loss -1.543205 avg loss no lamb -1.543205 time 2019-01-28 19:31:27.171595
Model ind 579 epoch 136 head A head_i_epoch 0 batch 0: avg loss -3.037510 avg loss no lamb -3.037510 time 2019-01-28 19:34:27.646568
Model ind 579 epoch 136 head A head_i_epoch 0 batch 100: avg loss -3.060966 avg loss no lamb -3.060966 time 2019-01-28 19:37:28.972914
Model ind 579 epoch 136 head A head_i_epoch 0 batch 200: avg loss -3.068018 avg loss no lamb -3.068018 time 2019-01-28 19:40:29.926375
Pre: time 2019-01-28 19:43:54.639816: 
 	std: 0.0029877024
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 2), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.18618333, 0.19291666, 0.18561667, 0.1919, 0.19056667]
	train_accs: [0.18618333, 0.19291666, 0.18561667, 0.1919, 0.19056667]
	best_train_sub_head: 1
	worst: 0.18561667
	avg: 0.18943667
	best: 0.19291666

Starting e_i: 137
Model ind 579 epoch 137 head B head_i_epoch 0 batch 0: avg loss -1.537844 avg loss no lamb -1.537844 time 2019-01-28 19:43:57.279379
Model ind 579 epoch 137 head B head_i_epoch 0 batch 100: avg loss -1.525754 avg loss no lamb -1.525754 time 2019-01-28 19:46:56.916370
Model ind 579 epoch 137 head B head_i_epoch 0 batch 200: avg loss -1.577966 avg loss no lamb -1.577966 time 2019-01-28 19:49:56.853261
Model ind 579 epoch 137 head A head_i_epoch 0 batch 0: avg loss -3.044899 avg loss no lamb -3.044899 time 2019-01-28 19:52:56.727924
Model ind 579 epoch 137 head A head_i_epoch 0 batch 100: avg loss -3.057479 avg loss no lamb -3.057479 time 2019-01-28 19:55:58.255377
Model ind 579 epoch 137 head A head_i_epoch 0 batch 200: avg loss -3.078229 avg loss no lamb -3.078229 time 2019-01-28 19:59:00.240092
Pre: time 2019-01-28 20:02:27.832354: 
 	std: 0.0010405297
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 2), (10, 8), (11, 17), (12, 13), (13, 5), (14, 14), (15, 12), (16, 10), (17, 1), (18, 6), (19, 18)]
	test_accs: [0.19421667, 0.19545, 0.19233334, 0.19341667, 0.19331667]
	train_accs: [0.19421667, 0.19545, 0.19233334, 0.19341667, 0.19331667]
	best_train_sub_head: 1
	worst: 0.19233334
	avg: 0.19374666
	best: 0.19545

Starting e_i: 138
Model ind 579 epoch 138 head B head_i_epoch 0 batch 0: avg loss -1.530337 avg loss no lamb -1.530337 time 2019-01-28 20:02:30.456676
Model ind 579 epoch 138 head B head_i_epoch 0 batch 100: avg loss -1.566693 avg loss no lamb -1.566693 time 2019-01-28 20:05:30.479412
Model ind 579 epoch 138 head B head_i_epoch 0 batch 200: avg loss -1.586570 avg loss no lamb -1.586570 time 2019-01-28 20:08:30.994810
Model ind 579 epoch 138 head A head_i_epoch 0 batch 0: avg loss -3.005992 avg loss no lamb -3.005992 time 2019-01-28 20:11:31.379021
Model ind 579 epoch 138 head A head_i_epoch 0 batch 100: avg loss -3.029615 avg loss no lamb -3.029615 time 2019-01-28 20:14:31.445948
Model ind 579 epoch 138 head A head_i_epoch 0 batch 200: avg loss -3.077075 avg loss no lamb -3.077075 time 2019-01-28 20:17:31.842166
Pre: time 2019-01-28 20:20:57.678290: 
 	std: 0.0013074338
	best_train_sub_head_match: [(0, 18), (1, 2), (2, 14), (3, 0), (4, 12), (5, 5), (6, 16), (7, 6), (8, 13), (9, 10), (10, 7), (11, 8), (12, 19), (13, 9), (14, 15), (15, 4), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.192, 0.18961667, 0.1898, 0.1906, 0.188]
	train_accs: [0.192, 0.18961667, 0.1898, 0.1906, 0.188]
	best_train_sub_head: 0
	worst: 0.188
	avg: 0.19000332
	best: 0.192

Starting e_i: 139
Model ind 579 epoch 139 head B head_i_epoch 0 batch 0: avg loss -1.471407 avg loss no lamb -1.471407 time 2019-01-28 20:21:00.920038
Model ind 579 epoch 139 head B head_i_epoch 0 batch 100: avg loss -1.489735 avg loss no lamb -1.489735 time 2019-01-28 20:24:01.522366
Model ind 579 epoch 139 head B head_i_epoch 0 batch 200: avg loss -1.510251 avg loss no lamb -1.510251 time 2019-01-28 20:27:00.546322
Model ind 579 epoch 139 head A head_i_epoch 0 batch 0: avg loss -3.010958 avg loss no lamb -3.010958 time 2019-01-28 20:29:59.731305
Model ind 579 epoch 139 head A head_i_epoch 0 batch 100: avg loss -3.085933 avg loss no lamb -3.085933 time 2019-01-28 20:33:00.417437
Model ind 579 epoch 139 head A head_i_epoch 0 batch 200: avg loss -3.074125 avg loss no lamb -3.074125 time 2019-01-28 20:36:01.035804
Pre: time 2019-01-28 20:39:28.026044: 
 	std: 0.002291789
	best_train_sub_head_match: [(0, 4), (1, 11), (2, 15), (3, 9), (4, 12), (5, 17), (6, 13), (7, 10), (8, 14), (9, 1), (10, 19), (11, 5), (12, 2), (13, 18), (14, 16), (15, 0), (16, 6), (17, 3), (18, 7), (19, 8)]
	test_accs: [0.1809, 0.18356666, 0.17825, 0.18388334, 0.18426667]
	train_accs: [0.1809, 0.18356666, 0.17825, 0.18388334, 0.18426667]
	best_train_sub_head: 4
	worst: 0.17825
	avg: 0.18217334
	best: 0.18426667

Starting e_i: 140
Model ind 579 epoch 140 head B head_i_epoch 0 batch 0: avg loss -1.488529 avg loss no lamb -1.488529 time 2019-01-28 20:39:31.166033
Model ind 579 epoch 140 head B head_i_epoch 0 batch 100: avg loss -1.582793 avg loss no lamb -1.582793 time 2019-01-28 20:42:31.309228
Model ind 579 epoch 140 head B head_i_epoch 0 batch 200: avg loss -1.457149 avg loss no lamb -1.457149 time 2019-01-28 20:45:28.885051
Model ind 579 epoch 140 head A head_i_epoch 0 batch 0: avg loss -3.074832 avg loss no lamb -3.074832 time 2019-01-28 20:48:26.511863
Model ind 579 epoch 140 head A head_i_epoch 0 batch 100: avg loss -3.008470 avg loss no lamb -3.008470 time 2019-01-28 20:51:25.485614
Model ind 579 epoch 140 head A head_i_epoch 0 batch 200: avg loss -3.074833 avg loss no lamb -3.074833 time 2019-01-28 20:54:25.276753
Pre: time 2019-01-28 20:57:48.270388: 
 	std: 0.0020788196
	best_train_sub_head_match: [(0, 19), (1, 2), (2, 0), (3, 15), (4, 4), (5, 7), (6, 12), (7, 11), (8, 9), (9, 5), (10, 8), (11, 17), (12, 13), (13, 3), (14, 14), (15, 16), (16, 10), (17, 1), (18, 6), (19, 18)]
	test_accs: [0.19071667, 0.19136667, 0.18863334, 0.18968333, 0.18545]
	train_accs: [0.19071667, 0.19136667, 0.18863334, 0.18968333, 0.18545]
	best_train_sub_head: 1
	worst: 0.18545
	avg: 0.18917
	best: 0.19136667

Starting e_i: 141
Model ind 579 epoch 141 head B head_i_epoch 0 batch 0: avg loss -1.541524 avg loss no lamb -1.541524 time 2019-01-28 20:57:55.633559
Model ind 579 epoch 141 head B head_i_epoch 0 batch 100: avg loss -1.624398 avg loss no lamb -1.624398 time 2019-01-28 21:00:53.220507
Model ind 579 epoch 141 head B head_i_epoch 0 batch 200: avg loss -1.703000 avg loss no lamb -1.703000 time 2019-01-28 21:03:51.691572
Model ind 579 epoch 141 head A head_i_epoch 0 batch 0: avg loss -3.045896 avg loss no lamb -3.045896 time 2019-01-28 21:06:50.398256
Model ind 579 epoch 141 head A head_i_epoch 0 batch 100: avg loss -3.103621 avg loss no lamb -3.103621 time 2019-01-28 21:09:51.879348
Model ind 579 epoch 141 head A head_i_epoch 0 batch 200: avg loss -3.143100 avg loss no lamb -3.143100 time 2019-01-28 21:12:52.368477
Pre: time 2019-01-28 21:16:17.484505: 
 	std: 0.0021611338
	best_train_sub_head_match: [(0, 18), (1, 16), (2, 14), (3, 0), (4, 12), (5, 3), (6, 2), (7, 6), (8, 13), (9, 10), (10, 7), (11, 8), (12, 19), (13, 9), (14, 15), (15, 4), (16, 5), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.20041667, 0.19665, 0.19388333, 0.19545, 0.19628334]
	train_accs: [0.20041667, 0.19665, 0.19388333, 0.19545, 0.19628334]
	best_train_sub_head: 0
	worst: 0.19388333
	avg: 0.19653668
	best: 0.20041667

Starting e_i: 142
Model ind 579 epoch 142 head B head_i_epoch 0 batch 0: avg loss -1.515216 avg loss no lamb -1.515216 time 2019-01-28 21:16:24.972355
Model ind 579 epoch 142 head B head_i_epoch 0 batch 100: avg loss -1.531520 avg loss no lamb -1.531520 time 2019-01-28 21:19:24.622664
Model ind 579 epoch 142 head B head_i_epoch 0 batch 200: avg loss -1.558453 avg loss no lamb -1.558453 time 2019-01-28 21:22:23.890954
Model ind 579 epoch 142 head A head_i_epoch 0 batch 0: avg loss -3.038127 avg loss no lamb -3.038127 time 2019-01-28 21:25:22.815062
Model ind 579 epoch 142 head A head_i_epoch 0 batch 100: avg loss -3.060817 avg loss no lamb -3.060817 time 2019-01-28 21:28:27.316523
Model ind 579 epoch 142 head A head_i_epoch 0 batch 200: avg loss -3.119922 avg loss no lamb -3.119922 time 2019-01-28 21:31:29.791383
Pre: time 2019-01-28 21:34:58.010947: 
 	std: 0.0029285655
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 5), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 2), (10, 8), (11, 17), (12, 13), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.19206667, 0.1948, 0.18658334, 0.19378333, 0.19363333]
	train_accs: [0.19206667, 0.1948, 0.18658334, 0.19378333, 0.19363333]
	best_train_sub_head: 1
	worst: 0.18658334
	avg: 0.19217333
	best: 0.1948

Starting e_i: 143
Model ind 579 epoch 143 head B head_i_epoch 0 batch 0: avg loss -1.519278 avg loss no lamb -1.519278 time 2019-01-28 21:35:00.646559
Model ind 579 epoch 143 head B head_i_epoch 0 batch 100: avg loss -1.569177 avg loss no lamb -1.569177 time 2019-01-28 21:37:59.347681
Model ind 579 epoch 143 head B head_i_epoch 0 batch 200: avg loss -1.539478 avg loss no lamb -1.539478 time 2019-01-28 21:40:58.575086
Model ind 579 epoch 143 head A head_i_epoch 0 batch 0: avg loss -3.072680 avg loss no lamb -3.072680 time 2019-01-28 21:44:00.720094
Model ind 579 epoch 143 head A head_i_epoch 0 batch 100: avg loss -3.132880 avg loss no lamb -3.132880 time 2019-01-28 21:47:01.938521
Model ind 579 epoch 143 head A head_i_epoch 0 batch 200: avg loss -3.113158 avg loss no lamb -3.113158 time 2019-01-28 21:50:00.743720
Pre: time 2019-01-28 21:53:24.344513: 
 	std: 0.0037074622
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 16), (3, 7), (4, 4), (5, 3), (6, 18), (7, 12), (8, 6), (9, 14), (10, 9), (11, 8), (12, 5), (13, 11), (14, 10), (15, 1), (16, 2), (17, 17), (18, 15), (19, 19)]
	test_accs: [0.19413333, 0.19801667, 0.18836667, 0.19848333, 0.19668333]
	train_accs: [0.19413333, 0.19801667, 0.18836667, 0.19848333, 0.19668333]
	best_train_sub_head: 3
	worst: 0.18836667
	avg: 0.19513667
	best: 0.19848333

Starting e_i: 144
Model ind 579 epoch 144 head B head_i_epoch 0 batch 0: avg loss -1.493984 avg loss no lamb -1.493984 time 2019-01-28 21:53:27.089762
Model ind 579 epoch 144 head B head_i_epoch 0 batch 100: avg loss -1.554237 avg loss no lamb -1.554237 time 2019-01-28 21:56:25.670750
Model ind 579 epoch 144 head B head_i_epoch 0 batch 200: avg loss -1.596441 avg loss no lamb -1.596441 time 2019-01-28 21:59:24.735850
Model ind 579 epoch 144 head A head_i_epoch 0 batch 0: avg loss -3.022774 avg loss no lamb -3.022774 time 2019-01-28 22:02:23.518975
Model ind 579 epoch 144 head A head_i_epoch 0 batch 100: avg loss -3.080277 avg loss no lamb -3.080277 time 2019-01-28 22:05:24.354824
Model ind 579 epoch 144 head A head_i_epoch 0 batch 200: avg loss -3.059272 avg loss no lamb -3.059272 time 2019-01-28 22:08:24.294215
Pre: time 2019-01-28 22:11:49.529513: 
 	std: 0.0040005767
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 2), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.1929, 0.19761667, 0.18625, 0.19668333, 0.19301666]
	train_accs: [0.1929, 0.19761667, 0.18625, 0.19668333, 0.19301666]
	best_train_sub_head: 1
	worst: 0.18625
	avg: 0.19329333
	best: 0.19761667

Starting e_i: 145
Model ind 579 epoch 145 head B head_i_epoch 0 batch 0: avg loss -1.427684 avg loss no lamb -1.427684 time 2019-01-28 22:11:52.540882
Model ind 579 epoch 145 head B head_i_epoch 0 batch 100: avg loss -1.443996 avg loss no lamb -1.443996 time 2019-01-28 22:14:50.850149
Model ind 579 epoch 145 head B head_i_epoch 0 batch 200: avg loss -1.503811 avg loss no lamb -1.503811 time 2019-01-28 22:17:49.148421
Model ind 579 epoch 145 head A head_i_epoch 0 batch 0: avg loss -3.052210 avg loss no lamb -3.052210 time 2019-01-28 22:20:48.266658
Model ind 579 epoch 145 head A head_i_epoch 0 batch 100: avg loss -3.087370 avg loss no lamb -3.087370 time 2019-01-28 22:23:46.078098
Model ind 579 epoch 145 head A head_i_epoch 0 batch 200: avg loss -3.040186 avg loss no lamb -3.040186 time 2019-01-28 22:26:41.390139
Pre: time 2019-01-28 22:29:59.174753: 
 	std: 0.003800242
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 13), (3, 9), (4, 12), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 19), (11, 5), (12, 16), (13, 18), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 11)]
	test_accs: [0.19436666, 0.19821666, 0.18856667, 0.19771667, 0.19875]
	train_accs: [0.19436666, 0.19821666, 0.18856667, 0.19771667, 0.19875]
	best_train_sub_head: 4
	worst: 0.18856667
	avg: 0.19552334
	best: 0.19875

Starting e_i: 146
Model ind 579 epoch 146 head B head_i_epoch 0 batch 0: avg loss -1.558762 avg loss no lamb -1.558762 time 2019-01-28 22:30:01.747478
Model ind 579 epoch 146 head B head_i_epoch 0 batch 100: avg loss -1.559269 avg loss no lamb -1.559269 time 2019-01-28 22:33:04.671248
Model ind 579 epoch 146 head B head_i_epoch 0 batch 200: avg loss -1.532864 avg loss no lamb -1.532864 time 2019-01-28 22:36:16.824595
Model ind 579 epoch 146 head A head_i_epoch 0 batch 0: avg loss -3.038191 avg loss no lamb -3.038191 time 2019-01-28 22:39:37.649766
Model ind 579 epoch 146 head A head_i_epoch 0 batch 100: avg loss -3.030226 avg loss no lamb -3.030226 time 2019-01-28 22:42:56.883976
Model ind 579 epoch 146 head A head_i_epoch 0 batch 200: avg loss -3.106803 avg loss no lamb -3.106803 time 2019-01-28 22:46:07.681836
Pre: time 2019-01-28 22:49:46.060891: 
 	std: 0.0019908298
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 19), (3, 15), (4, 4), (5, 7), (6, 2), (7, 11), (8, 3), (9, 14), (10, 8), (11, 17), (12, 13), (13, 1), (14, 0), (15, 12), (16, 10), (17, 5), (18, 6), (19, 18)]
	test_accs: [0.18536666, 0.19073333, 0.18701667, 0.19013333, 0.18771666]
	train_accs: [0.18536666, 0.19073333, 0.18701667, 0.19013333, 0.18771666]
	best_train_sub_head: 1
	worst: 0.18536666
	avg: 0.18819334
	best: 0.19073333

Starting e_i: 147
Model ind 579 epoch 147 head B head_i_epoch 0 batch 0: avg loss -1.503171 avg loss no lamb -1.503171 time 2019-01-28 22:49:49.282643
Model ind 579 epoch 147 head B head_i_epoch 0 batch 100: avg loss -1.538712 avg loss no lamb -1.538712 time 2019-01-28 22:52:58.205411
Model ind 579 epoch 147 head B head_i_epoch 0 batch 200: avg loss -1.546717 avg loss no lamb -1.546717 time 2019-01-28 22:56:06.402684
Model ind 579 epoch 147 head A head_i_epoch 0 batch 0: avg loss -3.052065 avg loss no lamb -3.052065 time 2019-01-28 22:59:17.898937
Model ind 579 epoch 147 head A head_i_epoch 0 batch 100: avg loss -3.093658 avg loss no lamb -3.093658 time 2019-01-28 23:02:31.609025
Model ind 579 epoch 147 head A head_i_epoch 0 batch 200: avg loss -3.109432 avg loss no lamb -3.109432 time 2019-01-28 23:05:43.951294
Pre: time 2019-01-28 23:09:23.230807: 
 	std: 0.002852865
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 16), (3, 19), (4, 4), (5, 3), (6, 7), (7, 12), (8, 6), (9, 14), (10, 9), (11, 8), (12, 5), (13, 11), (14, 10), (15, 1), (16, 2), (17, 17), (18, 15), (19, 18)]
	test_accs: [0.19626667, 0.20003334, 0.19303334, 0.20108333, 0.1977]
	train_accs: [0.19626667, 0.20003334, 0.19303334, 0.20108333, 0.1977]
	best_train_sub_head: 3
	worst: 0.19303334
	avg: 0.19762334
	best: 0.20108333

Starting e_i: 148
Model ind 579 epoch 148 head B head_i_epoch 0 batch 0: avg loss -1.441933 avg loss no lamb -1.441933 time 2019-01-28 23:09:31.201122
Model ind 579 epoch 148 head B head_i_epoch 0 batch 100: avg loss -1.506088 avg loss no lamb -1.506088 time 2019-01-28 23:12:40.613136
Model ind 579 epoch 148 head B head_i_epoch 0 batch 200: avg loss -1.576539 avg loss no lamb -1.576539 time 2019-01-28 23:15:50.823526
Model ind 579 epoch 148 head A head_i_epoch 0 batch 0: avg loss -3.073606 avg loss no lamb -3.073606 time 2019-01-28 23:19:00.188393
Model ind 579 epoch 148 head A head_i_epoch 0 batch 100: avg loss -3.084397 avg loss no lamb -3.084397 time 2019-01-28 23:22:10.702612
Model ind 579 epoch 148 head A head_i_epoch 0 batch 200: avg loss -3.100588 avg loss no lamb -3.100588 time 2019-01-28 23:25:21.406630
Pre: time 2019-01-28 23:29:01.584136: 
 	std: 0.0036215805
	best_train_sub_head_match: [(0, 4), (1, 16), (2, 13), (3, 9), (4, 12), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 19), (11, 7), (12, 2), (13, 18), (14, 1), (15, 15), (16, 6), (17, 3), (18, 5), (19, 11)]
	test_accs: [0.19858333, 0.2009, 0.19135, 0.1995, 0.2013]
	train_accs: [0.19858333, 0.2009, 0.19135, 0.1995, 0.2013]
	best_train_sub_head: 4
	worst: 0.19135
	avg: 0.19832666
	best: 0.2013

Starting e_i: 149
Model ind 579 epoch 149 head B head_i_epoch 0 batch 0: avg loss -1.584767 avg loss no lamb -1.584767 time 2019-01-28 23:29:10.090836
Model ind 579 epoch 149 head B head_i_epoch 0 batch 100: avg loss -1.523080 avg loss no lamb -1.523080 time 2019-01-28 23:32:18.365126
Model ind 579 epoch 149 head B head_i_epoch 0 batch 200: avg loss -1.542116 avg loss no lamb -1.542116 time 2019-01-28 23:35:18.570016
Model ind 579 epoch 149 head A head_i_epoch 0 batch 0: avg loss -2.998552 avg loss no lamb -2.998552 time 2019-01-28 23:38:32.747842
Model ind 579 epoch 149 head A head_i_epoch 0 batch 100: avg loss -3.148442 avg loss no lamb -3.148442 time 2019-01-28 23:41:40.924643
Model ind 579 epoch 149 head A head_i_epoch 0 batch 200: avg loss -3.070629 avg loss no lamb -3.070629 time 2019-01-28 23:44:40.300447
Pre: time 2019-01-28 23:47:59.049435: 
 	std: 0.002052224
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 16), (3, 7), (4, 4), (5, 3), (6, 18), (7, 12), (8, 6), (9, 14), (10, 9), (11, 8), (12, 5), (13, 11), (14, 10), (15, 1), (16, 2), (17, 17), (18, 15), (19, 19)]
	test_accs: [0.19645, 0.19956666, 0.19428334, 0.19965, 0.19843334]
	train_accs: [0.19645, 0.19956666, 0.19428334, 0.19965, 0.19843334]
	best_train_sub_head: 3
	worst: 0.19428334
	avg: 0.19767666
	best: 0.19965

Starting e_i: 150
Model ind 579 epoch 150 head B head_i_epoch 0 batch 0: avg loss -1.539451 avg loss no lamb -1.539451 time 2019-01-28 23:48:01.891165
Model ind 579 epoch 150 head B head_i_epoch 0 batch 100: avg loss -1.504426 avg loss no lamb -1.504426 time 2019-01-28 23:51:09.423152
Model ind 579 epoch 150 head B head_i_epoch 0 batch 200: avg loss -1.602577 avg loss no lamb -1.602577 time 2019-01-28 23:54:29.680446
Model ind 579 epoch 150 head A head_i_epoch 0 batch 0: avg loss -3.008912 avg loss no lamb -3.008912 time 2019-01-28 23:57:51.096840
Model ind 579 epoch 150 head A head_i_epoch 0 batch 100: avg loss -3.089200 avg loss no lamb -3.089200 time 2019-01-29 00:01:13.537165
Model ind 579 epoch 150 head A head_i_epoch 0 batch 200: avg loss -3.136305 avg loss no lamb -3.136305 time 2019-01-29 00:04:37.779447
Pre: time 2019-01-29 00:08:31.033540: 
 	std: 0.0032684938
	best_train_sub_head_match: [(0, 4), (1, 16), (2, 15), (3, 9), (4, 12), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 19), (11, 7), (12, 2), (13, 18), (14, 1), (15, 13), (16, 6), (17, 3), (18, 5), (19, 11)]
	test_accs: [0.19206667, 0.19385, 0.18555, 0.19375, 0.19431667]
	train_accs: [0.19206667, 0.19385, 0.18555, 0.19375, 0.19431667]
	best_train_sub_head: 4
	worst: 0.18555
	avg: 0.19190668
	best: 0.19431667

Starting e_i: 151
Model ind 579 epoch 151 head B head_i_epoch 0 batch 0: avg loss -1.513216 avg loss no lamb -1.513216 time 2019-01-29 00:08:39.249311
Model ind 579 epoch 151 head B head_i_epoch 0 batch 100: avg loss -1.593884 avg loss no lamb -1.593884 time 2019-01-29 00:12:04.491756
Model ind 579 epoch 151 head B head_i_epoch 0 batch 200: avg loss -1.498005 avg loss no lamb -1.498005 time 2019-01-29 00:15:10.204867
Model ind 579 epoch 151 head A head_i_epoch 0 batch 0: avg loss -3.082336 avg loss no lamb -3.082336 time 2019-01-29 00:18:28.897064
Model ind 579 epoch 151 head A head_i_epoch 0 batch 100: avg loss -3.148057 avg loss no lamb -3.148057 time 2019-01-29 00:21:47.498745
Model ind 579 epoch 151 head A head_i_epoch 0 batch 200: avg loss -3.079048 avg loss no lamb -3.079048 time 2019-01-29 00:25:05.498364
Pre: time 2019-01-29 00:28:50.044160: 
 	std: 0.0023710679
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 16), (3, 7), (4, 4), (5, 3), (6, 18), (7, 2), (8, 6), (9, 14), (10, 9), (11, 8), (12, 5), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 19)]
	test_accs: [0.20306666, 0.2049, 0.1988, 0.20553334, 0.20231667]
	train_accs: [0.20306666, 0.2049, 0.1988, 0.20553334, 0.20231667]
	best_train_sub_head: 3
	worst: 0.1988
	avg: 0.20292334
	best: 0.20553334

Starting e_i: 152
Model ind 579 epoch 152 head B head_i_epoch 0 batch 0: avg loss -1.485075 avg loss no lamb -1.485075 time 2019-01-29 00:28:58.174028
Model ind 579 epoch 152 head B head_i_epoch 0 batch 100: avg loss -1.448643 avg loss no lamb -1.448643 time 2019-01-29 00:32:13.737063
Model ind 579 epoch 152 head B head_i_epoch 0 batch 200: avg loss -1.586021 avg loss no lamb -1.586021 time 2019-01-29 00:35:31.861902
Model ind 579 epoch 152 head A head_i_epoch 0 batch 0: avg loss -3.079334 avg loss no lamb -3.079334 time 2019-01-29 00:38:48.474961
Model ind 579 epoch 152 head A head_i_epoch 0 batch 100: avg loss -3.071659 avg loss no lamb -3.071659 time 2019-01-29 00:42:06.841665
Model ind 579 epoch 152 head A head_i_epoch 0 batch 200: avg loss -3.046192 avg loss no lamb -3.046192 time 2019-01-29 00:45:27.218096
Pre: time 2019-01-29 00:49:21.478017: 
 	std: 0.00235106
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 13), (4, 4), (5, 7), (6, 12), (7, 11), (8, 3), (9, 0), (10, 8), (11, 17), (12, 18), (13, 14), (14, 15), (15, 16), (16, 10), (17, 1), (18, 6), (19, 19)]
	test_accs: [0.19643334, 0.20028333, 0.19516666, 0.19985, 0.19466667]
	train_accs: [0.19643334, 0.20028333, 0.19516666, 0.19985, 0.19466667]
	best_train_sub_head: 1
	worst: 0.19466667
	avg: 0.19727999
	best: 0.20028333

Starting e_i: 153
Model ind 579 epoch 153 head B head_i_epoch 0 batch 0: avg loss -1.522149 avg loss no lamb -1.522149 time 2019-01-29 00:49:25.078708
Model ind 579 epoch 153 head B head_i_epoch 0 batch 100: avg loss -1.564499 avg loss no lamb -1.564499 time 2019-01-29 00:52:50.535892
Model ind 579 epoch 153 head B head_i_epoch 0 batch 200: avg loss -1.588138 avg loss no lamb -1.588138 time 2019-01-29 00:56:17.563752
Model ind 579 epoch 153 head A head_i_epoch 0 batch 0: avg loss -2.971005 avg loss no lamb -2.971005 time 2019-01-29 00:59:44.662490
Model ind 579 epoch 153 head A head_i_epoch 0 batch 100: avg loss -3.082157 avg loss no lamb -3.082157 time 2019-01-29 01:03:14.683366
Model ind 579 epoch 153 head A head_i_epoch 0 batch 200: avg loss -3.052173 avg loss no lamb -3.052173 time 2019-01-29 01:06:43.817421
Pre: time 2019-01-29 01:10:38.630040: 
 	std: 0.0014437375
	best_train_sub_head_match: [(0, 18), (1, 2), (2, 14), (3, 0), (4, 12), (5, 5), (6, 16), (7, 6), (8, 13), (9, 10), (10, 7), (11, 8), (12, 19), (13, 9), (14, 15), (15, 4), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.19668333, 0.19526666, 0.1925, 0.19511667, 0.19361667]
	train_accs: [0.19668333, 0.19526666, 0.1925, 0.19511667, 0.19361667]
	best_train_sub_head: 0
	worst: 0.1925
	avg: 0.19463667
	best: 0.19668333

Starting e_i: 154
Model ind 579 epoch 154 head B head_i_epoch 0 batch 0: avg loss -1.523501 avg loss no lamb -1.523501 time 2019-01-29 01:10:42.476750
Model ind 579 epoch 154 head B head_i_epoch 0 batch 100: avg loss -1.565784 avg loss no lamb -1.565784 time 2019-01-29 01:14:10.432690
Model ind 579 epoch 154 head B head_i_epoch 0 batch 200: avg loss -1.633549 avg loss no lamb -1.633549 time 2019-01-29 01:17:36.983598
Model ind 579 epoch 154 head A head_i_epoch 0 batch 0: avg loss -3.055703 avg loss no lamb -3.055703 time 2019-01-29 01:21:06.607472
Model ind 579 epoch 154 head A head_i_epoch 0 batch 100: avg loss -3.047673 avg loss no lamb -3.047673 time 2019-01-29 01:24:36.493377
Model ind 579 epoch 154 head A head_i_epoch 0 batch 200: avg loss -3.106964 avg loss no lamb -3.106964 time 2019-01-29 01:28:09.343126
Pre: time 2019-01-29 01:32:11.653320: 
 	std: 0.0023749496
	best_train_sub_head_match: [(0, 9), (1, 0), (2, 15), (3, 12), (4, 4), (5, 7), (6, 11), (7, 5), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 13), (15, 2), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.20066667, 0.20478334, 0.1978, 0.20313333, 0.20088333]
	train_accs: [0.20066667, 0.20478334, 0.1978, 0.20313333, 0.20088333]
	best_train_sub_head: 1
	worst: 0.1978
	avg: 0.20145333
	best: 0.20478334

Starting e_i: 155
Model ind 579 epoch 155 head B head_i_epoch 0 batch 0: avg loss -1.488848 avg loss no lamb -1.488848 time 2019-01-29 01:32:15.295462
Model ind 579 epoch 155 head B head_i_epoch 0 batch 100: avg loss -1.564574 avg loss no lamb -1.564574 time 2019-01-29 01:35:46.306720
Model ind 579 epoch 155 head B head_i_epoch 0 batch 200: avg loss -1.637017 avg loss no lamb -1.637017 time 2019-01-29 01:39:12.512089
Model ind 579 epoch 155 head A head_i_epoch 0 batch 0: avg loss -3.022010 avg loss no lamb -3.022010 time 2019-01-29 01:42:41.370820
Model ind 579 epoch 155 head A head_i_epoch 0 batch 100: avg loss -3.080518 avg loss no lamb -3.080518 time 2019-01-29 01:46:09.266860
Model ind 579 epoch 155 head A head_i_epoch 0 batch 200: avg loss -3.137173 avg loss no lamb -3.137173 time 2019-01-29 01:49:36.198514
Pre: time 2019-01-29 01:53:28.943485: 
 	std: 0.0013684687
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 8), (7, 11), (8, 3), (9, 16), (10, 15), (11, 17), (12, 7), (13, 1), (14, 5), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.1919, 0.1945, 0.1911, 0.19405, 0.19413333]
	train_accs: [0.1919, 0.1945, 0.1911, 0.19405, 0.19413333]
	best_train_sub_head: 1
	worst: 0.1911
	avg: 0.19313666
	best: 0.1945

Starting e_i: 156
Model ind 579 epoch 156 head B head_i_epoch 0 batch 0: avg loss -1.524949 avg loss no lamb -1.524949 time 2019-01-29 01:53:31.701370
Model ind 579 epoch 156 head B head_i_epoch 0 batch 100: avg loss -1.517863 avg loss no lamb -1.517863 time 2019-01-29 01:56:33.969543
Model ind 579 epoch 156 head B head_i_epoch 0 batch 200: avg loss -1.634156 avg loss no lamb -1.634156 time 2019-01-29 01:59:34.969873
Model ind 579 epoch 156 head A head_i_epoch 0 batch 0: avg loss -3.052890 avg loss no lamb -3.052890 time 2019-01-29 02:02:35.923497
Model ind 579 epoch 156 head A head_i_epoch 0 batch 100: avg loss -3.069590 avg loss no lamb -3.069590 time 2019-01-29 02:05:37.119122
Model ind 579 epoch 156 head A head_i_epoch 0 batch 200: avg loss -3.079279 avg loss no lamb -3.079279 time 2019-01-29 02:08:37.974267
Pre: time 2019-01-29 02:12:05.293312: 
 	std: 0.0022677544
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 16), (3, 7), (4, 4), (5, 3), (6, 18), (7, 12), (8, 6), (9, 14), (10, 9), (11, 8), (12, 5), (13, 11), (14, 10), (15, 1), (16, 2), (17, 17), (18, 15), (19, 19)]
	test_accs: [0.19568333, 0.19903333, 0.1931, 0.19913334, 0.19606666]
	train_accs: [0.19568333, 0.19903333, 0.1931, 0.19913334, 0.19606666]
	best_train_sub_head: 3
	worst: 0.1931
	avg: 0.19660334
	best: 0.19913334

Starting e_i: 157
Model ind 579 epoch 157 head B head_i_epoch 0 batch 0: avg loss -1.508614 avg loss no lamb -1.508614 time 2019-01-29 02:12:08.565185
Model ind 579 epoch 157 head B head_i_epoch 0 batch 100: avg loss -1.589860 avg loss no lamb -1.589860 time 2019-01-29 02:15:08.467417
Model ind 579 epoch 157 head B head_i_epoch 0 batch 200: avg loss -1.592631 avg loss no lamb -1.592631 time 2019-01-29 02:18:09.767299
Model ind 579 epoch 157 head A head_i_epoch 0 batch 0: avg loss -3.026780 avg loss no lamb -3.026780 time 2019-01-29 02:21:11.681766
Model ind 579 epoch 157 head A head_i_epoch 0 batch 100: avg loss -3.069502 avg loss no lamb -3.069502 time 2019-01-29 02:24:13.373276
Model ind 579 epoch 157 head A head_i_epoch 0 batch 200: avg loss -3.104867 avg loss no lamb -3.104867 time 2019-01-29 02:27:16.847295
Pre: time 2019-01-29 02:30:44.853984: 
 	std: 0.0025262043
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 2), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.20113334, 0.20458333, 0.19723333, 0.20346667, 0.20215]
	train_accs: [0.20113334, 0.20458333, 0.19723333, 0.20346667, 0.20215]
	best_train_sub_head: 1
	worst: 0.19723333
	avg: 0.20171332
	best: 0.20458333

Starting e_i: 158
Model ind 579 epoch 158 head B head_i_epoch 0 batch 0: avg loss -1.474654 avg loss no lamb -1.474654 time 2019-01-29 02:30:47.671233
Model ind 579 epoch 158 head B head_i_epoch 0 batch 100: avg loss -1.572401 avg loss no lamb -1.572401 time 2019-01-29 02:33:48.341571
Model ind 579 epoch 158 head B head_i_epoch 0 batch 200: avg loss -1.589939 avg loss no lamb -1.589939 time 2019-01-29 02:36:48.481448
Model ind 579 epoch 158 head A head_i_epoch 0 batch 0: avg loss -3.037058 avg loss no lamb -3.037058 time 2019-01-29 02:39:49.314018
Model ind 579 epoch 158 head A head_i_epoch 0 batch 100: avg loss -3.055744 avg loss no lamb -3.055744 time 2019-01-29 02:42:51.355914
Model ind 579 epoch 158 head A head_i_epoch 0 batch 200: avg loss -3.105240 avg loss no lamb -3.105240 time 2019-01-29 02:45:52.243590
Pre: time 2019-01-29 02:49:19.346031: 
 	std: 0.0011060253
	best_train_sub_head_match: [(0, 9), (1, 4), (2, 0), (3, 13), (4, 3), (5, 7), (6, 12), (7, 11), (8, 5), (9, 2), (10, 8), (11, 17), (12, 18), (13, 1), (14, 15), (15, 16), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.19913334, 0.19986667, 0.197, 0.19983333, 0.19986667]
	train_accs: [0.19913334, 0.19986667, 0.197, 0.19983333, 0.19986667]
	best_train_sub_head: 1
	worst: 0.197
	avg: 0.19913998
	best: 0.19986667

Starting e_i: 159
Model ind 579 epoch 159 head B head_i_epoch 0 batch 0: avg loss -1.410293 avg loss no lamb -1.410293 time 2019-01-29 02:49:22.167569
Model ind 579 epoch 159 head B head_i_epoch 0 batch 100: avg loss -1.530609 avg loss no lamb -1.530609 time 2019-01-29 02:52:23.255926
Model ind 579 epoch 159 head B head_i_epoch 0 batch 200: avg loss -1.571445 avg loss no lamb -1.571445 time 2019-01-29 02:55:24.065252
Model ind 579 epoch 159 head A head_i_epoch 0 batch 0: avg loss -3.006011 avg loss no lamb -3.006011 time 2019-01-29 02:58:25.268643
Model ind 579 epoch 159 head A head_i_epoch 0 batch 100: avg loss -3.064724 avg loss no lamb -3.064724 time 2019-01-29 03:01:27.641266
Model ind 579 epoch 159 head A head_i_epoch 0 batch 200: avg loss -3.088588 avg loss no lamb -3.088588 time 2019-01-29 03:04:29.905562
Pre: time 2019-01-29 03:07:57.445172: 
 	std: 0.0027566506
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 16), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 2), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 18)]
	test_accs: [0.19556667, 0.19781667, 0.19041666, 0.19785, 0.19668333]
	train_accs: [0.19556667, 0.19781667, 0.19041666, 0.19785, 0.19668333]
	best_train_sub_head: 3
	worst: 0.19041666
	avg: 0.19566666
	best: 0.19785

Starting e_i: 160
Model ind 579 epoch 160 head B head_i_epoch 0 batch 0: avg loss -1.507194 avg loss no lamb -1.507194 time 2019-01-29 03:08:00.355539
Model ind 579 epoch 160 head B head_i_epoch 0 batch 100: avg loss -1.528301 avg loss no lamb -1.528301 time 2019-01-29 03:11:01.482445
Model ind 579 epoch 160 head B head_i_epoch 0 batch 200: avg loss -1.570197 avg loss no lamb -1.570197 time 2019-01-29 03:14:02.268203
Model ind 579 epoch 160 head A head_i_epoch 0 batch 0: avg loss -3.056453 avg loss no lamb -3.056453 time 2019-01-29 03:17:04.094282
Model ind 579 epoch 160 head A head_i_epoch 0 batch 100: avg loss -3.070730 avg loss no lamb -3.070730 time 2019-01-29 03:20:07.556958
Model ind 579 epoch 160 head A head_i_epoch 0 batch 200: avg loss -3.078490 avg loss no lamb -3.078490 time 2019-01-29 03:23:09.705278
Pre: time 2019-01-29 03:26:37.474259: 
 	std: 0.0021394957
	best_train_sub_head_match: [(0, 4), (1, 16), (2, 13), (3, 9), (4, 12), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 19), (11, 7), (12, 2), (13, 18), (14, 1), (15, 15), (16, 6), (17, 3), (18, 5), (19, 11)]
	test_accs: [0.19751666, 0.19683333, 0.19235, 0.19773333, 0.19823334]
	train_accs: [0.19751666, 0.19683333, 0.19235, 0.19773333, 0.19823334]
	best_train_sub_head: 4
	worst: 0.19235
	avg: 0.19653332
	best: 0.19823334

Starting e_i: 161
Model ind 579 epoch 161 head B head_i_epoch 0 batch 0: avg loss -1.533434 avg loss no lamb -1.533434 time 2019-01-29 03:26:44.172744
Model ind 579 epoch 161 head B head_i_epoch 0 batch 100: avg loss -1.559929 avg loss no lamb -1.559929 time 2019-01-29 03:29:44.509837
Model ind 579 epoch 161 head B head_i_epoch 0 batch 200: avg loss -1.602490 avg loss no lamb -1.602490 time 2019-01-29 03:32:45.574301
Model ind 579 epoch 161 head A head_i_epoch 0 batch 0: avg loss -3.088272 avg loss no lamb -3.088272 time 2019-01-29 03:35:46.294778
Model ind 579 epoch 161 head A head_i_epoch 0 batch 100: avg loss -3.116151 avg loss no lamb -3.116151 time 2019-01-29 03:38:49.224860
Model ind 579 epoch 161 head A head_i_epoch 0 batch 200: avg loss -3.067886 avg loss no lamb -3.067886 time 2019-01-29 03:41:52.458449
Pre: time 2019-01-29 03:45:22.040530: 
 	std: 0.00063601317
	best_train_sub_head_match: [(0, 5), (1, 1), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 15), (9, 10), (10, 7), (11, 8), (12, 19), (13, 18), (14, 13), (15, 16), (16, 9), (17, 17), (18, 3), (19, 11)]
	test_accs: [0.19241667, 0.19081667, 0.19066666, 0.19168334, 0.1912]
	train_accs: [0.19241667, 0.19081667, 0.19066666, 0.19168334, 0.1912]
	best_train_sub_head: 0
	worst: 0.19066666
	avg: 0.19135667
	best: 0.19241667

Starting e_i: 162
Model ind 579 epoch 162 head B head_i_epoch 0 batch 0: avg loss -1.557850 avg loss no lamb -1.557850 time 2019-01-29 03:45:25.079163
Model ind 579 epoch 162 head B head_i_epoch 0 batch 100: avg loss -1.585073 avg loss no lamb -1.585073 time 2019-01-29 03:48:27.443742
Model ind 579 epoch 162 head B head_i_epoch 0 batch 200: avg loss -1.623850 avg loss no lamb -1.623850 time 2019-01-29 03:51:30.582217
Model ind 579 epoch 162 head A head_i_epoch 0 batch 0: avg loss -3.010814 avg loss no lamb -3.010814 time 2019-01-29 03:54:33.260976
Model ind 579 epoch 162 head A head_i_epoch 0 batch 100: avg loss -3.062165 avg loss no lamb -3.062165 time 2019-01-29 03:57:37.554106
Model ind 579 epoch 162 head A head_i_epoch 0 batch 200: avg loss -3.099741 avg loss no lamb -3.099741 time 2019-01-29 04:00:40.396505
Pre: time 2019-01-29 04:04:08.626626: 
 	std: 0.0027031668
	best_train_sub_head_match: [(0, 18), (1, 2), (2, 14), (3, 0), (4, 12), (5, 3), (6, 16), (7, 6), (8, 15), (9, 10), (10, 7), (11, 8), (12, 19), (13, 9), (14, 13), (15, 4), (16, 5), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.20085, 0.19853333, 0.19298333, 0.19948334, 0.19698334]
	train_accs: [0.20085, 0.19853333, 0.19298333, 0.19948334, 0.19698334]
	best_train_sub_head: 0
	worst: 0.19298333
	avg: 0.19776666
	best: 0.20085

Starting e_i: 163
Model ind 579 epoch 163 head B head_i_epoch 0 batch 0: avg loss -1.520088 avg loss no lamb -1.520088 time 2019-01-29 04:04:11.466544
Model ind 579 epoch 163 head B head_i_epoch 0 batch 100: avg loss -1.582840 avg loss no lamb -1.582840 time 2019-01-29 04:07:14.351833
Model ind 579 epoch 163 head B head_i_epoch 0 batch 200: avg loss -1.664575 avg loss no lamb -1.664575 time 2019-01-29 04:10:15.994600
Model ind 579 epoch 163 head A head_i_epoch 0 batch 0: avg loss -3.008946 avg loss no lamb -3.008946 time 2019-01-29 04:13:17.439945
Model ind 579 epoch 163 head A head_i_epoch 0 batch 100: avg loss -3.114587 avg loss no lamb -3.114587 time 2019-01-29 04:16:20.368596
Model ind 579 epoch 163 head A head_i_epoch 0 batch 200: avg loss -3.104899 avg loss no lamb -3.104899 time 2019-01-29 04:19:23.936435
Pre: time 2019-01-29 04:22:53.852859: 
 	std: 0.0041477303
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 13), (3, 9), (4, 12), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 19), (11, 5), (12, 16), (13, 18), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 11)]
	test_accs: [0.19543333, 0.19528334, 0.18493333, 0.19465, 0.1957]
	train_accs: [0.19543333, 0.19528334, 0.18493333, 0.19465, 0.1957]
	best_train_sub_head: 4
	worst: 0.18493333
	avg: 0.19319999
	best: 0.1957

Starting e_i: 164
Model ind 579 epoch 164 head B head_i_epoch 0 batch 0: avg loss -1.484373 avg loss no lamb -1.484373 time 2019-01-29 04:22:57.074873
Model ind 579 epoch 164 head B head_i_epoch 0 batch 100: avg loss -1.574984 avg loss no lamb -1.574984 time 2019-01-29 04:26:00.692764
Model ind 579 epoch 164 head B head_i_epoch 0 batch 200: avg loss -1.534160 avg loss no lamb -1.534160 time 2019-01-29 04:29:00.370516
Model ind 579 epoch 164 head A head_i_epoch 0 batch 0: avg loss -3.028866 avg loss no lamb -3.028866 time 2019-01-29 04:31:59.470516
Model ind 579 epoch 164 head A head_i_epoch 0 batch 100: avg loss -3.093828 avg loss no lamb -3.093828 time 2019-01-29 04:34:59.860973
Model ind 579 epoch 164 head A head_i_epoch 0 batch 200: avg loss -3.087428 avg loss no lamb -3.087428 time 2019-01-29 04:37:59.565124
Pre: time 2019-01-29 04:41:24.167549: 
 	std: 0.0035822554
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 0), (3, 13), (4, 4), (5, 7), (6, 12), (7, 11), (8, 3), (9, 5), (10, 8), (11, 17), (12, 18), (13, 1), (14, 15), (15, 2), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.19816667, 0.20548333, 0.196, 0.20431666, 0.20078333]
	train_accs: [0.19816667, 0.20548333, 0.196, 0.20431666, 0.20078333]
	best_train_sub_head: 1
	worst: 0.196
	avg: 0.20095
	best: 0.20548333

Starting e_i: 165
Model ind 579 epoch 165 head B head_i_epoch 0 batch 0: avg loss -1.535305 avg loss no lamb -1.535305 time 2019-01-29 04:41:27.163976
Model ind 579 epoch 165 head B head_i_epoch 0 batch 100: avg loss -1.507264 avg loss no lamb -1.507264 time 2019-01-29 04:44:26.186636
Model ind 579 epoch 165 head B head_i_epoch 0 batch 200: avg loss -1.480821 avg loss no lamb -1.480821 time 2019-01-29 04:47:25.474912
Model ind 579 epoch 165 head A head_i_epoch 0 batch 0: avg loss -3.074826 avg loss no lamb -3.074826 time 2019-01-29 04:50:25.728839
Model ind 579 epoch 165 head A head_i_epoch 0 batch 100: avg loss -3.096321 avg loss no lamb -3.096321 time 2019-01-29 04:53:25.950159
Model ind 579 epoch 165 head A head_i_epoch 0 batch 200: avg loss -3.104698 avg loss no lamb -3.104698 time 2019-01-29 04:56:26.881296
Pre: time 2019-01-29 04:59:52.071495: 
 	std: 0.002782551
	best_train_sub_head_match: [(0, 4), (1, 16), (2, 13), (3, 9), (4, 12), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 19), (11, 7), (12, 2), (13, 18), (14, 1), (15, 15), (16, 6), (17, 3), (18, 5), (19, 11)]
	test_accs: [0.20105, 0.20351666, 0.19665, 0.20386666, 0.2039]
	train_accs: [0.20105, 0.20351666, 0.19665, 0.20386666, 0.2039]
	best_train_sub_head: 4
	worst: 0.19665
	avg: 0.20179668
	best: 0.2039

Starting e_i: 166
Model ind 579 epoch 166 head B head_i_epoch 0 batch 0: avg loss -1.553224 avg loss no lamb -1.553224 time 2019-01-29 04:59:54.728144
Model ind 579 epoch 166 head B head_i_epoch 0 batch 100: avg loss -1.572828 avg loss no lamb -1.572828 time 2019-01-29 05:02:54.091661
Model ind 579 epoch 166 head B head_i_epoch 0 batch 200: avg loss -1.519153 avg loss no lamb -1.519153 time 2019-01-29 05:05:53.234227
Model ind 579 epoch 166 head A head_i_epoch 0 batch 0: avg loss -3.014378 avg loss no lamb -3.014378 time 2019-01-29 05:08:52.307274
Model ind 579 epoch 166 head A head_i_epoch 0 batch 100: avg loss -3.052552 avg loss no lamb -3.052552 time 2019-01-29 05:11:52.990665
Model ind 579 epoch 166 head A head_i_epoch 0 batch 200: avg loss -3.079838 avg loss no lamb -3.079838 time 2019-01-29 05:14:53.996067
Pre: time 2019-01-29 05:18:19.528208: 
 	std: 0.004679404
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 19), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 7), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.1977, 0.20391667, 0.19001667, 0.20113334, 0.1993]
	train_accs: [0.1977, 0.20391667, 0.19001667, 0.20113334, 0.1993]
	best_train_sub_head: 1
	worst: 0.19001667
	avg: 0.19841334
	best: 0.20391667

Starting e_i: 167
Model ind 579 epoch 167 head B head_i_epoch 0 batch 0: avg loss -1.490453 avg loss no lamb -1.490453 time 2019-01-29 05:18:22.538891
Model ind 579 epoch 167 head B head_i_epoch 0 batch 100: avg loss -1.558654 avg loss no lamb -1.558654 time 2019-01-29 05:21:21.541702
Model ind 579 epoch 167 head B head_i_epoch 0 batch 200: avg loss -1.567668 avg loss no lamb -1.567668 time 2019-01-29 05:24:20.595088
Model ind 579 epoch 167 head A head_i_epoch 0 batch 0: avg loss -3.029780 avg loss no lamb -3.029780 time 2019-01-29 05:27:19.867853
Model ind 579 epoch 167 head A head_i_epoch 0 batch 100: avg loss -3.112753 avg loss no lamb -3.112753 time 2019-01-29 05:30:20.300485
Model ind 579 epoch 167 head A head_i_epoch 0 batch 200: avg loss -3.116451 avg loss no lamb -3.116451 time 2019-01-29 05:33:20.383466
Pre: time 2019-01-29 05:36:44.929036: 
 	std: 0.0032321746
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 12), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 19), (11, 13), (12, 16), (13, 18), (14, 1), (15, 15), (16, 6), (17, 3), (18, 5), (19, 11)]
	test_accs: [0.19976667, 0.20381667, 0.19585, 0.20313333, 0.20455]
	train_accs: [0.19976667, 0.20381667, 0.19585, 0.20313333, 0.20455]
	best_train_sub_head: 4
	worst: 0.19585
	avg: 0.20142333
	best: 0.20455

Starting e_i: 168
Model ind 579 epoch 168 head B head_i_epoch 0 batch 0: avg loss -1.558915 avg loss no lamb -1.558915 time 2019-01-29 05:36:47.673772
Model ind 579 epoch 168 head B head_i_epoch 0 batch 100: avg loss -1.612629 avg loss no lamb -1.612629 time 2019-01-29 05:39:47.411480
Model ind 579 epoch 168 head B head_i_epoch 0 batch 200: avg loss -1.618147 avg loss no lamb -1.618147 time 2019-01-29 05:42:46.357779
Model ind 579 epoch 168 head A head_i_epoch 0 batch 0: avg loss -3.045208 avg loss no lamb -3.045208 time 2019-01-29 05:45:45.786991
Model ind 579 epoch 168 head A head_i_epoch 0 batch 100: avg loss -3.023386 avg loss no lamb -3.023386 time 2019-01-29 05:48:46.517850
Model ind 579 epoch 168 head A head_i_epoch 0 batch 200: avg loss -3.104267 avg loss no lamb -3.104267 time 2019-01-29 05:51:46.325524
Pre: time 2019-01-29 05:55:12.545574: 
 	std: 0.0032439933
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 0), (3, 13), (4, 4), (5, 19), (6, 8), (7, 11), (8, 3), (9, 2), (10, 15), (11, 17), (12, 7), (13, 1), (14, 5), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.20333333, 0.20678334, 0.19775, 0.2062, 0.20486666]
	train_accs: [0.20333333, 0.20678334, 0.19775, 0.2062, 0.20486666]
	best_train_sub_head: 1
	worst: 0.19775
	avg: 0.20378666
	best: 0.20678334

Starting e_i: 169
Model ind 579 epoch 169 head B head_i_epoch 0 batch 0: avg loss -1.613499 avg loss no lamb -1.613499 time 2019-01-29 05:55:20.739808
Model ind 579 epoch 169 head B head_i_epoch 0 batch 100: avg loss -1.551940 avg loss no lamb -1.551940 time 2019-01-29 05:58:20.455902
Model ind 579 epoch 169 head B head_i_epoch 0 batch 200: avg loss -1.603932 avg loss no lamb -1.603932 time 2019-01-29 06:01:17.945150
Model ind 579 epoch 169 head A head_i_epoch 0 batch 0: avg loss -3.022129 avg loss no lamb -3.022129 time 2019-01-29 06:04:16.273054
Model ind 579 epoch 169 head A head_i_epoch 0 batch 100: avg loss -3.126897 avg loss no lamb -3.126897 time 2019-01-29 06:07:15.355722
Model ind 579 epoch 169 head A head_i_epoch 0 batch 200: avg loss -3.091000 avg loss no lamb -3.091000 time 2019-01-29 06:10:14.009786
Pre: time 2019-01-29 06:13:38.814631: 
 	std: 0.0026319292
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 2), (10, 8), (11, 17), (12, 13), (13, 1), (14, 5), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.19926667, 0.20231667, 0.19501667, 0.20056666, 0.20193334]
	train_accs: [0.19926667, 0.20231667, 0.19501667, 0.20056666, 0.20193334]
	best_train_sub_head: 1
	worst: 0.19501667
	avg: 0.19982
	best: 0.20231667

Starting e_i: 170
Model ind 579 epoch 170 head B head_i_epoch 0 batch 0: avg loss -1.520635 avg loss no lamb -1.520635 time 2019-01-29 06:13:41.524019
Model ind 579 epoch 170 head B head_i_epoch 0 batch 100: avg loss -1.468196 avg loss no lamb -1.468196 time 2019-01-29 06:16:40.725676
Model ind 579 epoch 170 head B head_i_epoch 0 batch 200: avg loss -1.570937 avg loss no lamb -1.570937 time 2019-01-29 06:19:38.635895
Model ind 579 epoch 170 head A head_i_epoch 0 batch 0: avg loss -3.022167 avg loss no lamb -3.022167 time 2019-01-29 06:22:36.940921
Model ind 579 epoch 170 head A head_i_epoch 0 batch 100: avg loss -3.114167 avg loss no lamb -3.114167 time 2019-01-29 06:25:35.809492
Model ind 579 epoch 170 head A head_i_epoch 0 batch 200: avg loss -3.095582 avg loss no lamb -3.095582 time 2019-01-29 06:28:35.424495
Pre: time 2019-01-29 06:31:59.634650: 
 	std: 0.0025230036
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 16), (3, 19), (4, 4), (5, 3), (6, 7), (7, 12), (8, 6), (9, 14), (10, 9), (11, 8), (12, 5), (13, 11), (14, 10), (15, 1), (16, 2), (17, 17), (18, 15), (19, 18)]
	test_accs: [0.19801667, 0.20011666, 0.19405, 0.20133333, 0.19715]
	train_accs: [0.19801667, 0.20011666, 0.19405, 0.20133333, 0.19715]
	best_train_sub_head: 3
	worst: 0.19405
	avg: 0.19813333
	best: 0.20133333

Starting e_i: 171
Model ind 579 epoch 171 head B head_i_epoch 0 batch 0: avg loss -1.524928 avg loss no lamb -1.524928 time 2019-01-29 06:32:06.319079
Model ind 579 epoch 171 head B head_i_epoch 0 batch 100: avg loss -1.664895 avg loss no lamb -1.664895 time 2019-01-29 06:35:05.414656
Model ind 579 epoch 171 head B head_i_epoch 0 batch 200: avg loss -1.577519 avg loss no lamb -1.577519 time 2019-01-29 06:38:03.953434
Model ind 579 epoch 171 head A head_i_epoch 0 batch 0: avg loss -3.016147 avg loss no lamb -3.016147 time 2019-01-29 06:41:01.597664
Model ind 579 epoch 171 head A head_i_epoch 0 batch 100: avg loss -3.079784 avg loss no lamb -3.079784 time 2019-01-29 06:44:01.629960
Model ind 579 epoch 171 head A head_i_epoch 0 batch 200: avg loss -3.152181 avg loss no lamb -3.152181 time 2019-01-29 06:47:00.955379
Pre: time 2019-01-29 06:50:25.055338: 
 	std: 0.004297784
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 18)]
	test_accs: [0.20625, 0.2082, 0.19668333, 0.20821667, 0.20603333]
	train_accs: [0.20625, 0.2082, 0.19668333, 0.20821667, 0.20603333]
	best_train_sub_head: 3
	worst: 0.19668333
	avg: 0.20507666
	best: 0.20821667

Starting e_i: 172
Model ind 579 epoch 172 head B head_i_epoch 0 batch 0: avg loss -1.540583 avg loss no lamb -1.540583 time 2019-01-29 06:50:31.481902
Model ind 579 epoch 172 head B head_i_epoch 0 batch 100: avg loss -1.492986 avg loss no lamb -1.492986 time 2019-01-29 06:53:29.507540
Model ind 579 epoch 172 head B head_i_epoch 0 batch 200: avg loss -1.579406 avg loss no lamb -1.579406 time 2019-01-29 06:56:27.373493
Model ind 579 epoch 172 head A head_i_epoch 0 batch 0: avg loss -3.036461 avg loss no lamb -3.036461 time 2019-01-29 06:59:25.521723
Model ind 579 epoch 172 head A head_i_epoch 0 batch 100: avg loss -3.012597 avg loss no lamb -3.012597 time 2019-01-29 07:02:25.246070
Model ind 579 epoch 172 head A head_i_epoch 0 batch 200: avg loss -3.121533 avg loss no lamb -3.121533 time 2019-01-29 07:05:25.785482
Pre: time 2019-01-29 07:08:50.445708: 
 	std: 0.0026629423
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 7), (7, 8), (8, 6), (9, 14), (10, 9), (11, 13), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 5), (19, 18)]
	test_accs: [0.20048334, 0.20183334, 0.19595, 0.20365, 0.20243333]
	train_accs: [0.20048334, 0.20183334, 0.19595, 0.20365, 0.20243333]
	best_train_sub_head: 3
	worst: 0.19595
	avg: 0.20087
	best: 0.20365

Starting e_i: 173
Model ind 579 epoch 173 head B head_i_epoch 0 batch 0: avg loss -1.565683 avg loss no lamb -1.565683 time 2019-01-29 07:08:53.196370
Model ind 579 epoch 173 head B head_i_epoch 0 batch 100: avg loss -1.600629 avg loss no lamb -1.600629 time 2019-01-29 07:11:51.519670
Model ind 579 epoch 173 head B head_i_epoch 0 batch 200: avg loss -1.560849 avg loss no lamb -1.560849 time 2019-01-29 07:14:50.594920
Model ind 579 epoch 173 head A head_i_epoch 0 batch 0: avg loss -3.084218 avg loss no lamb -3.084218 time 2019-01-29 07:17:51.140047
Model ind 579 epoch 173 head A head_i_epoch 0 batch 100: avg loss -3.054008 avg loss no lamb -3.054008 time 2019-01-29 07:20:51.940344
Model ind 579 epoch 173 head A head_i_epoch 0 batch 200: avg loss -3.053813 avg loss no lamb -3.053813 time 2019-01-29 07:23:52.879985
Pre: time 2019-01-29 07:27:17.671020: 
 	std: 0.0033389782
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 13), (3, 9), (4, 12), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 19), (11, 7), (12, 16), (13, 18), (14, 1), (15, 15), (16, 6), (17, 3), (18, 5), (19, 11)]
	test_accs: [0.20328334, 0.20753333, 0.20008333, 0.20806667, 0.20878333]
	train_accs: [0.20328334, 0.20753333, 0.20008333, 0.20806667, 0.20878333]
	best_train_sub_head: 4
	worst: 0.20008333
	avg: 0.20555
	best: 0.20878333

Starting e_i: 174
Model ind 579 epoch 174 head B head_i_epoch 0 batch 0: avg loss -1.564603 avg loss no lamb -1.564603 time 2019-01-29 07:27:25.204599
Model ind 579 epoch 174 head B head_i_epoch 0 batch 100: avg loss -1.584676 avg loss no lamb -1.584676 time 2019-01-29 07:30:23.146203
Model ind 579 epoch 174 head B head_i_epoch 0 batch 200: avg loss -1.570589 avg loss no lamb -1.570589 time 2019-01-29 07:33:22.097478
Model ind 579 epoch 174 head A head_i_epoch 0 batch 0: avg loss -3.062430 avg loss no lamb -3.062430 time 2019-01-29 07:36:19.967466
Model ind 579 epoch 174 head A head_i_epoch 0 batch 100: avg loss -3.059673 avg loss no lamb -3.059673 time 2019-01-29 07:39:19.965867
Model ind 579 epoch 174 head A head_i_epoch 0 batch 200: avg loss -3.138497 avg loss no lamb -3.138497 time 2019-01-29 07:42:19.896104
Pre: time 2019-01-29 07:45:45.681772: 
 	std: 0.004785375
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 7), (7, 8), (8, 6), (9, 14), (10, 9), (11, 15), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 5), (19, 18)]
	test_accs: [0.19813333, 0.20098333, 0.19008334, 0.20396666, 0.20138334]
	train_accs: [0.19813333, 0.20098333, 0.19008334, 0.20396666, 0.20138334]
	best_train_sub_head: 3
	worst: 0.19008334
	avg: 0.19891001
	best: 0.20396666

Starting e_i: 175
Model ind 579 epoch 175 head B head_i_epoch 0 batch 0: avg loss -1.521689 avg loss no lamb -1.521689 time 2019-01-29 07:45:48.765657
Model ind 579 epoch 175 head B head_i_epoch 0 batch 100: avg loss -1.579765 avg loss no lamb -1.579765 time 2019-01-29 07:48:48.152308
Model ind 579 epoch 175 head B head_i_epoch 0 batch 200: avg loss -1.634362 avg loss no lamb -1.634362 time 2019-01-29 07:51:46.524996
Model ind 579 epoch 175 head A head_i_epoch 0 batch 0: avg loss -3.079834 avg loss no lamb -3.079834 time 2019-01-29 07:54:44.929368
Model ind 579 epoch 175 head A head_i_epoch 0 batch 100: avg loss -3.139880 avg loss no lamb -3.139880 time 2019-01-29 07:57:44.872124
Model ind 579 epoch 175 head A head_i_epoch 0 batch 200: avg loss -3.170945 avg loss no lamb -3.170945 time 2019-01-29 08:00:44.891582
Pre: time 2019-01-29 08:04:08.101181: 
 	std: 0.0025036202
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 13), (3, 18), (4, 12), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 9), (11, 5), (12, 16), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 11)]
	test_accs: [0.20311667, 0.20453334, 0.19973333, 0.20493333, 0.20735]
	train_accs: [0.20311667, 0.20453334, 0.19973333, 0.20493333, 0.20735]
	best_train_sub_head: 4
	worst: 0.19973333
	avg: 0.20393333
	best: 0.20735

Starting e_i: 176
Model ind 579 epoch 176 head B head_i_epoch 0 batch 0: avg loss -1.484321 avg loss no lamb -1.484321 time 2019-01-29 08:04:10.884938
Model ind 579 epoch 176 head B head_i_epoch 0 batch 100: avg loss -1.563160 avg loss no lamb -1.563160 time 2019-01-29 08:07:08.633683
Model ind 579 epoch 176 head B head_i_epoch 0 batch 200: avg loss -1.621234 avg loss no lamb -1.621234 time 2019-01-29 08:10:06.226125
Model ind 579 epoch 176 head A head_i_epoch 0 batch 0: avg loss -3.054991 avg loss no lamb -3.054991 time 2019-01-29 08:13:04.492216
Model ind 579 epoch 176 head A head_i_epoch 0 batch 100: avg loss -3.085557 avg loss no lamb -3.085557 time 2019-01-29 08:16:04.207733
Model ind 579 epoch 176 head A head_i_epoch 0 batch 200: avg loss -3.095948 avg loss no lamb -3.095948 time 2019-01-29 08:19:03.141187
Pre: time 2019-01-29 08:22:28.173579: 
 	std: 0.0017336559
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 15), (3, 9), (4, 12), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 19), (11, 7), (12, 16), (13, 18), (14, 1), (15, 13), (16, 6), (17, 3), (18, 5), (19, 11)]
	test_accs: [0.19861667, 0.19693333, 0.19391666, 0.19655, 0.19865]
	train_accs: [0.19861667, 0.19693333, 0.19391666, 0.19655, 0.19865]
	best_train_sub_head: 4
	worst: 0.19391666
	avg: 0.19693334
	best: 0.19865

Starting e_i: 177
Model ind 579 epoch 177 head B head_i_epoch 0 batch 0: avg loss -1.549820 avg loss no lamb -1.549820 time 2019-01-29 08:22:30.927108
Model ind 579 epoch 177 head B head_i_epoch 0 batch 100: avg loss -1.637054 avg loss no lamb -1.637054 time 2019-01-29 08:25:28.940885
Model ind 579 epoch 177 head B head_i_epoch 0 batch 200: avg loss -1.626105 avg loss no lamb -1.626105 time 2019-01-29 08:28:28.253121
Model ind 579 epoch 177 head A head_i_epoch 0 batch 0: avg loss -3.072944 avg loss no lamb -3.072944 time 2019-01-29 08:31:27.250704
Model ind 579 epoch 177 head A head_i_epoch 0 batch 100: avg loss -3.114843 avg loss no lamb -3.114843 time 2019-01-29 08:34:26.665569
Model ind 579 epoch 177 head A head_i_epoch 0 batch 200: avg loss -3.127413 avg loss no lamb -3.127413 time 2019-01-29 08:37:26.651711
Pre: time 2019-01-29 08:40:49.689944: 
 	std: 0.0023217648
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 7), (13, 1), (14, 14), (15, 12), (16, 10), (17, 5), (18, 6), (19, 18)]
	test_accs: [0.1897, 0.19421667, 0.18825, 0.1938, 0.19071667]
	train_accs: [0.1897, 0.19421667, 0.18825, 0.1938, 0.19071667]
	best_train_sub_head: 1
	worst: 0.18825
	avg: 0.19133666
	best: 0.19421667

Starting e_i: 178
Model ind 579 epoch 178 head B head_i_epoch 0 batch 0: avg loss -1.506677 avg loss no lamb -1.506677 time 2019-01-29 08:40:52.448975
Model ind 579 epoch 178 head B head_i_epoch 0 batch 100: avg loss -1.547526 avg loss no lamb -1.547526 time 2019-01-29 08:43:49.992741
Model ind 579 epoch 178 head B head_i_epoch 0 batch 200: avg loss -1.607273 avg loss no lamb -1.607273 time 2019-01-29 08:46:48.056730
Model ind 579 epoch 178 head A head_i_epoch 0 batch 0: avg loss -3.055565 avg loss no lamb -3.055565 time 2019-01-29 08:49:46.376584
Model ind 579 epoch 178 head A head_i_epoch 0 batch 100: avg loss -3.094856 avg loss no lamb -3.094856 time 2019-01-29 08:52:47.155635
Model ind 579 epoch 178 head A head_i_epoch 0 batch 200: avg loss -3.169045 avg loss no lamb -3.169045 time 2019-01-29 08:55:46.827137
Pre: time 2019-01-29 08:59:10.168827: 
 	std: 0.003172156
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 7), (7, 8), (8, 6), (9, 1), (10, 9), (11, 15), (12, 16), (13, 11), (14, 10), (15, 5), (16, 12), (17, 17), (18, 14), (19, 18)]
	test_accs: [0.20145, 0.20473333, 0.19618334, 0.2049, 0.20255]
	train_accs: [0.20145, 0.20473333, 0.19618334, 0.2049, 0.20255]
	best_train_sub_head: 3
	worst: 0.19618334
	avg: 0.20196334
	best: 0.2049

Starting e_i: 179
Model ind 579 epoch 179 head B head_i_epoch 0 batch 0: avg loss -1.517343 avg loss no lamb -1.517343 time 2019-01-29 08:59:12.845895
Model ind 579 epoch 179 head B head_i_epoch 0 batch 100: avg loss -1.544554 avg loss no lamb -1.544554 time 2019-01-29 09:02:11.581794
Model ind 579 epoch 179 head B head_i_epoch 0 batch 200: avg loss -1.578593 avg loss no lamb -1.578593 time 2019-01-29 09:05:10.534326
Model ind 579 epoch 179 head A head_i_epoch 0 batch 0: avg loss -3.017515 avg loss no lamb -3.017515 time 2019-01-29 09:08:08.976064
Model ind 579 epoch 179 head A head_i_epoch 0 batch 100: avg loss -3.151823 avg loss no lamb -3.151823 time 2019-01-29 09:11:10.040509
Model ind 579 epoch 179 head A head_i_epoch 0 batch 200: avg loss -3.117431 avg loss no lamb -3.117431 time 2019-01-29 09:14:09.680070
Pre: time 2019-01-29 09:17:36.876042: 
 	std: 0.0030060073
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 15), (3, 9), (4, 12), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 19), (11, 5), (12, 16), (13, 18), (14, 1), (15, 13), (16, 6), (17, 3), (18, 7), (19, 11)]
	test_accs: [0.19548333, 0.20178333, 0.1981, 0.2013, 0.20405]
	train_accs: [0.19548333, 0.20178333, 0.1981, 0.2013, 0.20405]
	best_train_sub_head: 4
	worst: 0.19548333
	avg: 0.20014334
	best: 0.20405

Starting e_i: 180
Model ind 579 epoch 180 head B head_i_epoch 0 batch 0: avg loss -1.458805 avg loss no lamb -1.458805 time 2019-01-29 09:17:39.618546
Model ind 579 epoch 180 head B head_i_epoch 0 batch 100: avg loss -1.683790 avg loss no lamb -1.683790 time 2019-01-29 09:20:38.668125
Model ind 579 epoch 180 head B head_i_epoch 0 batch 200: avg loss -1.609908 avg loss no lamb -1.609908 time 2019-01-29 09:23:38.216677
Model ind 579 epoch 180 head A head_i_epoch 0 batch 0: avg loss -3.018652 avg loss no lamb -3.018652 time 2019-01-29 09:26:37.061391
Model ind 579 epoch 180 head A head_i_epoch 0 batch 100: avg loss -3.080313 avg loss no lamb -3.080313 time 2019-01-29 09:29:37.432985
Model ind 579 epoch 180 head A head_i_epoch 0 batch 200: avg loss -3.105583 avg loss no lamb -3.105583 time 2019-01-29 09:32:38.238281
Pre: time 2019-01-29 09:36:02.438462: 
 	std: 0.0045255967
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 16), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 2), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 18)]
	test_accs: [0.20096667, 0.20631666, 0.19438334, 0.20696667, 0.20255]
	train_accs: [0.20096667, 0.20631666, 0.19438334, 0.20696667, 0.20255]
	best_train_sub_head: 3
	worst: 0.19438334
	avg: 0.20223665
	best: 0.20696667

Starting e_i: 181
Model ind 579 epoch 181 head B head_i_epoch 0 batch 0: avg loss -1.556746 avg loss no lamb -1.556746 time 2019-01-29 09:36:10.921333
Model ind 579 epoch 181 head B head_i_epoch 0 batch 100: avg loss -1.549467 avg loss no lamb -1.549467 time 2019-01-29 09:39:11.001004
Model ind 579 epoch 181 head B head_i_epoch 0 batch 200: avg loss -1.607967 avg loss no lamb -1.607967 time 2019-01-29 09:42:10.431123
Model ind 579 epoch 181 head A head_i_epoch 0 batch 0: avg loss -3.094248 avg loss no lamb -3.094248 time 2019-01-29 09:45:10.421045
Model ind 579 epoch 181 head A head_i_epoch 0 batch 100: avg loss -3.104489 avg loss no lamb -3.104489 time 2019-01-29 09:48:12.335935
Model ind 579 epoch 181 head A head_i_epoch 0 batch 200: avg loss -3.146508 avg loss no lamb -3.146508 time 2019-01-29 09:51:12.760959
Pre: time 2019-01-29 09:54:38.785645: 
 	std: 0.002377807
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 2), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.20548333, 0.20883334, 0.20255, 0.20881666, 0.20745]
	train_accs: [0.20548333, 0.20883334, 0.20255, 0.20881666, 0.20745]
	best_train_sub_head: 1
	worst: 0.20255
	avg: 0.20662665
	best: 0.20883334

Starting e_i: 182
Model ind 579 epoch 182 head B head_i_epoch 0 batch 0: avg loss -1.533213 avg loss no lamb -1.533213 time 2019-01-29 09:54:47.765921
Model ind 579 epoch 182 head B head_i_epoch 0 batch 100: avg loss -1.597415 avg loss no lamb -1.597415 time 2019-01-29 09:57:47.492958
Model ind 579 epoch 182 head B head_i_epoch 0 batch 200: avg loss -1.579047 avg loss no lamb -1.579047 time 2019-01-29 10:00:46.950765
Model ind 579 epoch 182 head A head_i_epoch 0 batch 0: avg loss -3.053111 avg loss no lamb -3.053111 time 2019-01-29 10:03:45.515046
Model ind 579 epoch 182 head A head_i_epoch 0 batch 100: avg loss -3.063501 avg loss no lamb -3.063501 time 2019-01-29 10:06:44.818244
Model ind 579 epoch 182 head A head_i_epoch 0 batch 200: avg loss -3.121982 avg loss no lamb -3.121982 time 2019-01-29 10:09:44.425507
Pre: time 2019-01-29 10:13:10.177042: 
 	std: 0.0033021034
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.20405, 0.20828333, 0.19851667, 0.20656666, 0.2045]
	train_accs: [0.20405, 0.20828333, 0.19851667, 0.20656666, 0.2045]
	best_train_sub_head: 1
	worst: 0.19851667
	avg: 0.20438333
	best: 0.20828333

Starting e_i: 183
Model ind 579 epoch 183 head B head_i_epoch 0 batch 0: avg loss -1.548472 avg loss no lamb -1.548472 time 2019-01-29 10:13:12.895073
Model ind 579 epoch 183 head B head_i_epoch 0 batch 100: avg loss -1.534693 avg loss no lamb -1.534693 time 2019-01-29 10:16:11.564258
Model ind 579 epoch 183 head B head_i_epoch 0 batch 200: avg loss -1.566707 avg loss no lamb -1.566707 time 2019-01-29 10:19:10.321823
Model ind 579 epoch 183 head A head_i_epoch 0 batch 0: avg loss -3.069757 avg loss no lamb -3.069757 time 2019-01-29 10:22:09.559371
Model ind 579 epoch 183 head A head_i_epoch 0 batch 100: avg loss -3.111708 avg loss no lamb -3.111708 time 2019-01-29 10:25:10.285292
Model ind 579 epoch 183 head A head_i_epoch 0 batch 200: avg loss -3.148643 avg loss no lamb -3.148643 time 2019-01-29 10:28:10.514402
Pre: time 2019-01-29 10:31:36.796461: 
 	std: 0.0045125294
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 13), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.19493334, 0.20275, 0.19098334, 0.20236667, 0.19925]
	train_accs: [0.19493334, 0.20275, 0.19098334, 0.20236667, 0.19925]
	best_train_sub_head: 1
	worst: 0.19098334
	avg: 0.19805667
	best: 0.20275

Starting e_i: 184
Model ind 579 epoch 184 head B head_i_epoch 0 batch 0: avg loss -1.520945 avg loss no lamb -1.520945 time 2019-01-29 10:31:39.683403
Model ind 579 epoch 184 head B head_i_epoch 0 batch 100: avg loss -1.612157 avg loss no lamb -1.612157 time 2019-01-29 10:34:38.154118
Model ind 579 epoch 184 head B head_i_epoch 0 batch 200: avg loss -1.575286 avg loss no lamb -1.575286 time 2019-01-29 10:37:36.433391
Model ind 579 epoch 184 head A head_i_epoch 0 batch 0: avg loss -3.077552 avg loss no lamb -3.077552 time 2019-01-29 10:40:35.810760
Model ind 579 epoch 184 head A head_i_epoch 0 batch 100: avg loss -3.132012 avg loss no lamb -3.132012 time 2019-01-29 10:43:35.539287
Model ind 579 epoch 184 head A head_i_epoch 0 batch 200: avg loss -3.117910 avg loss no lamb -3.117910 time 2019-01-29 10:46:34.649678
Pre: time 2019-01-29 10:49:58.869090: 
 	std: 0.004088596
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 2), (10, 8), (11, 17), (12, 13), (13, 1), (14, 5), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.19938333, 0.20255, 0.19148333, 0.20221667, 0.20115]
	train_accs: [0.19938333, 0.20255, 0.19148333, 0.20221667, 0.20115]
	best_train_sub_head: 1
	worst: 0.19148333
	avg: 0.19935666
	best: 0.20255

Starting e_i: 185
Model ind 579 epoch 185 head B head_i_epoch 0 batch 0: avg loss -1.587733 avg loss no lamb -1.587733 time 2019-01-29 10:50:01.816416
Model ind 579 epoch 185 head B head_i_epoch 0 batch 100: avg loss -1.545911 avg loss no lamb -1.545911 time 2019-01-29 10:53:00.686787
Model ind 579 epoch 185 head B head_i_epoch 0 batch 200: avg loss -1.582118 avg loss no lamb -1.582118 time 2019-01-29 10:56:00.040282
Model ind 579 epoch 185 head A head_i_epoch 0 batch 0: avg loss -3.085749 avg loss no lamb -3.085749 time 2019-01-29 10:58:58.281945
Model ind 579 epoch 185 head A head_i_epoch 0 batch 100: avg loss -3.134028 avg loss no lamb -3.134028 time 2019-01-29 11:01:58.313662
Model ind 579 epoch 185 head A head_i_epoch 0 batch 200: avg loss -3.141185 avg loss no lamb -3.141185 time 2019-01-29 11:04:57.539511
Pre: time 2019-01-29 11:08:21.815577: 
 	std: 0.0041043824
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 16), (3, 19), (4, 4), (5, 3), (6, 7), (7, 2), (8, 6), (9, 14), (10, 9), (11, 8), (12, 5), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 18)]
	test_accs: [0.20155, 0.20708333, 0.19658333, 0.20725, 0.20591667]
	train_accs: [0.20155, 0.20708333, 0.19658333, 0.20725, 0.20591667]
	best_train_sub_head: 3
	worst: 0.19658333
	avg: 0.20367667
	best: 0.20725

Starting e_i: 186
Model ind 579 epoch 186 head B head_i_epoch 0 batch 0: avg loss -1.561122 avg loss no lamb -1.561122 time 2019-01-29 11:08:24.539319
Model ind 579 epoch 186 head B head_i_epoch 0 batch 100: avg loss -1.577548 avg loss no lamb -1.577548 time 2019-01-29 11:11:23.906128
Model ind 579 epoch 186 head B head_i_epoch 0 batch 200: avg loss -1.607494 avg loss no lamb -1.607494 time 2019-01-29 11:14:22.723990
Model ind 579 epoch 186 head A head_i_epoch 0 batch 0: avg loss -3.017793 avg loss no lamb -3.017793 time 2019-01-29 11:17:21.369864
Model ind 579 epoch 186 head A head_i_epoch 0 batch 100: avg loss -3.085222 avg loss no lamb -3.085222 time 2019-01-29 11:20:20.140630
Model ind 579 epoch 186 head A head_i_epoch 0 batch 200: avg loss -3.134726 avg loss no lamb -3.134726 time 2019-01-29 11:23:19.375436
Pre: time 2019-01-29 11:26:43.520986: 
 	std: 0.0032328414
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 5), (19, 19)]
	test_accs: [0.20481667, 0.20691666, 0.19878334, 0.2082, 0.20498334]
	train_accs: [0.20481667, 0.20691666, 0.19878334, 0.2082, 0.20498334]
	best_train_sub_head: 3
	worst: 0.19878334
	avg: 0.20474
	best: 0.2082

Starting e_i: 187
Model ind 579 epoch 187 head B head_i_epoch 0 batch 0: avg loss -1.541423 avg loss no lamb -1.541423 time 2019-01-29 11:26:46.368146
Model ind 579 epoch 187 head B head_i_epoch 0 batch 100: avg loss -1.605185 avg loss no lamb -1.605185 time 2019-01-29 11:29:43.374584
Model ind 579 epoch 187 head B head_i_epoch 0 batch 200: avg loss -1.661615 avg loss no lamb -1.661615 time 2019-01-29 11:32:41.546482
Model ind 579 epoch 187 head A head_i_epoch 0 batch 0: avg loss -3.053179 avg loss no lamb -3.053179 time 2019-01-29 11:35:40.217525
Model ind 579 epoch 187 head A head_i_epoch 0 batch 100: avg loss -3.088965 avg loss no lamb -3.088965 time 2019-01-29 11:38:39.168392
Model ind 579 epoch 187 head A head_i_epoch 0 batch 200: avg loss -3.127254 avg loss no lamb -3.127254 time 2019-01-29 11:41:39.073823
Pre: time 2019-01-29 11:45:02.351738: 
 	std: 0.0039026267
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.2057, 0.20755, 0.19695, 0.2074, 0.20418334]
	train_accs: [0.2057, 0.20755, 0.19695, 0.2074, 0.20418334]
	best_train_sub_head: 1
	worst: 0.19695
	avg: 0.20435667
	best: 0.20755

Starting e_i: 188
Model ind 579 epoch 188 head B head_i_epoch 0 batch 0: avg loss -1.656712 avg loss no lamb -1.656712 time 2019-01-29 11:45:05.479741
Model ind 579 epoch 188 head B head_i_epoch 0 batch 100: avg loss -1.597589 avg loss no lamb -1.597589 time 2019-01-29 11:48:03.284437
Model ind 579 epoch 188 head B head_i_epoch 0 batch 200: avg loss -1.588050 avg loss no lamb -1.588050 time 2019-01-29 11:51:00.871915
Model ind 579 epoch 188 head A head_i_epoch 0 batch 0: avg loss -3.099053 avg loss no lamb -3.099053 time 2019-01-29 11:53:59.203116
Model ind 579 epoch 188 head A head_i_epoch 0 batch 100: avg loss -3.095338 avg loss no lamb -3.095338 time 2019-01-29 11:56:58.696666
Model ind 579 epoch 188 head A head_i_epoch 0 batch 200: avg loss -3.144592 avg loss no lamb -3.144592 time 2019-01-29 11:59:58.454622
Pre: time 2019-01-29 12:03:21.421203: 
 	std: 0.0029396769
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 8), (8, 6), (9, 14), (10, 9), (11, 5), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 19)]
	test_accs: [0.20966667, 0.20895, 0.20308334, 0.21158333, 0.21023333]
	train_accs: [0.20966667, 0.20895, 0.20308334, 0.21158333, 0.21023333]
	best_train_sub_head: 3
	worst: 0.20308334
	avg: 0.20870332
	best: 0.21158333

Starting e_i: 189
Model ind 579 epoch 189 head B head_i_epoch 0 batch 0: avg loss -1.474480 avg loss no lamb -1.474480 time 2019-01-29 12:03:27.535310
Model ind 579 epoch 189 head B head_i_epoch 0 batch 100: avg loss -1.607474 avg loss no lamb -1.607474 time 2019-01-29 12:06:25.926106
Model ind 579 epoch 189 head B head_i_epoch 0 batch 200: avg loss -1.662755 avg loss no lamb -1.662755 time 2019-01-29 12:09:24.412576
Model ind 579 epoch 189 head A head_i_epoch 0 batch 0: avg loss -3.098529 avg loss no lamb -3.098529 time 2019-01-29 12:12:23.176196
Model ind 579 epoch 189 head A head_i_epoch 0 batch 100: avg loss -3.161177 avg loss no lamb -3.161177 time 2019-01-29 12:15:22.399960
Model ind 579 epoch 189 head A head_i_epoch 0 batch 200: avg loss -3.180785 avg loss no lamb -3.180785 time 2019-01-29 12:18:21.799435
Pre: time 2019-01-29 12:21:46.065675: 
 	std: 0.0047128703
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 15), (3, 9), (4, 12), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 19), (11, 5), (12, 16), (13, 18), (14, 1), (15, 13), (16, 6), (17, 3), (18, 7), (19, 11)]
	test_accs: [0.19838333, 0.19945, 0.18843333, 0.20075, 0.20121667]
	train_accs: [0.19838333, 0.19945, 0.18843333, 0.20075, 0.20121667]
	best_train_sub_head: 4
	worst: 0.18843333
	avg: 0.19764666
	best: 0.20121667

Starting e_i: 190
Model ind 579 epoch 190 head B head_i_epoch 0 batch 0: avg loss -1.560670 avg loss no lamb -1.560670 time 2019-01-29 12:21:48.768666
Model ind 579 epoch 190 head B head_i_epoch 0 batch 100: avg loss -1.579755 avg loss no lamb -1.579755 time 2019-01-29 12:24:47.648273
Model ind 579 epoch 190 head B head_i_epoch 0 batch 200: avg loss -1.593199 avg loss no lamb -1.593199 time 2019-01-29 12:27:45.809455
Model ind 579 epoch 190 head A head_i_epoch 0 batch 0: avg loss -3.117283 avg loss no lamb -3.117283 time 2019-01-29 12:30:43.959492
Model ind 579 epoch 190 head A head_i_epoch 0 batch 100: avg loss -3.140901 avg loss no lamb -3.140901 time 2019-01-29 12:33:43.419104
Model ind 579 epoch 190 head A head_i_epoch 0 batch 200: avg loss -3.175176 avg loss no lamb -3.175176 time 2019-01-29 12:36:43.154008
Pre: time 2019-01-29 12:40:07.320834: 
 	std: 0.003160722
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 18)]
	test_accs: [0.20528333, 0.2079, 0.20053333, 0.20991667, 0.2068]
	train_accs: [0.20528333, 0.2079, 0.20053333, 0.20991667, 0.2068]
	best_train_sub_head: 3
	worst: 0.20053333
	avg: 0.20608667
	best: 0.20991667

Starting e_i: 191
Model ind 579 epoch 191 head B head_i_epoch 0 batch 0: avg loss -1.488171 avg loss no lamb -1.488171 time 2019-01-29 12:40:14.005234
Model ind 579 epoch 191 head B head_i_epoch 0 batch 100: avg loss -1.550430 avg loss no lamb -1.550430 time 2019-01-29 12:43:13.013530
Model ind 579 epoch 191 head B head_i_epoch 0 batch 200: avg loss -1.589358 avg loss no lamb -1.589358 time 2019-01-29 12:46:10.972186
Model ind 579 epoch 191 head A head_i_epoch 0 batch 0: avg loss -3.083303 avg loss no lamb -3.083303 time 2019-01-29 12:49:09.151055
Model ind 579 epoch 191 head A head_i_epoch 0 batch 100: avg loss -3.076344 avg loss no lamb -3.076344 time 2019-01-29 12:52:08.767527
Model ind 579 epoch 191 head A head_i_epoch 0 batch 200: avg loss -3.142051 avg loss no lamb -3.142051 time 2019-01-29 12:55:07.820892
Pre: time 2019-01-29 12:58:32.678556: 
 	std: 0.004269122
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 18)]
	test_accs: [0.2123, 0.21351667, 0.20236667, 0.21405, 0.2108]
	train_accs: [0.2123, 0.21351667, 0.20236667, 0.21405, 0.2108]
	best_train_sub_head: 3
	worst: 0.20236667
	avg: 0.21060666
	best: 0.21405

Starting e_i: 192
Model ind 579 epoch 192 head B head_i_epoch 0 batch 0: avg loss -1.624275 avg loss no lamb -1.624275 time 2019-01-29 12:58:39.237937
Model ind 579 epoch 192 head B head_i_epoch 0 batch 100: avg loss -1.621124 avg loss no lamb -1.621124 time 2019-01-29 13:01:37.656033
Model ind 579 epoch 192 head B head_i_epoch 0 batch 200: avg loss -1.586096 avg loss no lamb -1.586096 time 2019-01-29 13:04:35.229376
Model ind 579 epoch 192 head A head_i_epoch 0 batch 0: avg loss -3.078116 avg loss no lamb -3.078116 time 2019-01-29 13:07:33.467715
Model ind 579 epoch 192 head A head_i_epoch 0 batch 100: avg loss -3.121642 avg loss no lamb -3.121642 time 2019-01-29 13:10:33.226540
Model ind 579 epoch 192 head A head_i_epoch 0 batch 200: avg loss -3.173195 avg loss no lamb -3.173195 time 2019-01-29 13:13:32.338369
Pre: time 2019-01-29 13:16:56.574040: 
 	std: 0.0040109092
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 16), (3, 19), (4, 4), (5, 3), (6, 7), (7, 8), (8, 6), (9, 14), (10, 9), (11, 13), (12, 2), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 18)]
	test_accs: [0.20691666, 0.21031667, 0.20011666, 0.21168333, 0.20656666]
	train_accs: [0.20691666, 0.21031667, 0.20011666, 0.21168333, 0.20656666]
	best_train_sub_head: 3
	worst: 0.20011666
	avg: 0.20711999
	best: 0.21168333

Starting e_i: 193
Model ind 579 epoch 193 head B head_i_epoch 0 batch 0: avg loss -1.548354 avg loss no lamb -1.548354 time 2019-01-29 13:16:59.341392
Model ind 579 epoch 193 head B head_i_epoch 0 batch 100: avg loss -1.673766 avg loss no lamb -1.673766 time 2019-01-29 13:19:57.523836
Model ind 579 epoch 193 head B head_i_epoch 0 batch 200: avg loss -1.577633 avg loss no lamb -1.577633 time 2019-01-29 13:22:55.831608
Model ind 579 epoch 193 head A head_i_epoch 0 batch 0: avg loss -3.033136 avg loss no lamb -3.033136 time 2019-01-29 13:25:53.624130
Model ind 579 epoch 193 head A head_i_epoch 0 batch 100: avg loss -3.065183 avg loss no lamb -3.065183 time 2019-01-29 13:28:53.333346
Model ind 579 epoch 193 head A head_i_epoch 0 batch 200: avg loss -3.123175 avg loss no lamb -3.123175 time 2019-01-29 13:31:53.866234
Pre: time 2019-01-29 13:35:20.903927: 
 	std: 0.0021945033
	best_train_sub_head_match: [(0, 4), (1, 16), (2, 8), (3, 9), (4, 2), (5, 17), (6, 12), (7, 10), (8, 14), (9, 15), (10, 19), (11, 5), (12, 0), (13, 18), (14, 1), (15, 13), (16, 6), (17, 3), (18, 7), (19, 11)]
	test_accs: [0.2108, 0.21208334, 0.20696667, 0.21211667, 0.21331666]
	train_accs: [0.2108, 0.21208334, 0.20696667, 0.21211667, 0.21331666]
	best_train_sub_head: 4
	worst: 0.20696667
	avg: 0.21105666
	best: 0.21331666

Starting e_i: 194
Model ind 579 epoch 194 head B head_i_epoch 0 batch 0: avg loss -1.480004 avg loss no lamb -1.480004 time 2019-01-29 13:35:24.294090
Model ind 579 epoch 194 head B head_i_epoch 0 batch 100: avg loss -1.579133 avg loss no lamb -1.579133 time 2019-01-29 13:38:32.767927
Model ind 579 epoch 194 head B head_i_epoch 0 batch 200: avg loss -1.569170 avg loss no lamb -1.569170 time 2019-01-29 13:41:35.327413
Model ind 579 epoch 194 head A head_i_epoch 0 batch 0: avg loss -3.085566 avg loss no lamb -3.085566 time 2019-01-29 13:44:34.036263
Model ind 579 epoch 194 head A head_i_epoch 0 batch 100: avg loss -3.085460 avg loss no lamb -3.085460 time 2019-01-29 13:47:34.828996
Model ind 579 epoch 194 head A head_i_epoch 0 batch 200: avg loss -3.192410 avg loss no lamb -3.192410 time 2019-01-29 13:50:38.863086
Pre: time 2019-01-29 13:54:18.740576: 
 	std: 0.0023782875
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 15), (3, 9), (4, 12), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 19), (11, 5), (12, 16), (13, 18), (14, 1), (15, 13), (16, 6), (17, 3), (18, 7), (19, 11)]
	test_accs: [0.20061667, 0.2026, 0.19945, 0.20515, 0.20541666]
	train_accs: [0.20061667, 0.2026, 0.19945, 0.20515, 0.20541666]
	best_train_sub_head: 4
	worst: 0.19945
	avg: 0.20264666
	best: 0.20541666

Starting e_i: 195
Model ind 579 epoch 195 head B head_i_epoch 0 batch 0: avg loss -1.492662 avg loss no lamb -1.492662 time 2019-01-29 13:54:22.440932
Model ind 579 epoch 195 head B head_i_epoch 0 batch 100: avg loss -1.584912 avg loss no lamb -1.584912 time 2019-01-29 13:57:33.939274
Model ind 579 epoch 195 head B head_i_epoch 0 batch 200: avg loss -1.631909 avg loss no lamb -1.631909 time 2019-01-29 14:00:46.542015
Model ind 579 epoch 195 head A head_i_epoch 0 batch 0: avg loss -3.081845 avg loss no lamb -3.081845 time 2019-01-29 14:03:59.710834
Model ind 579 epoch 195 head A head_i_epoch 0 batch 100: avg loss -3.122879 avg loss no lamb -3.122879 time 2019-01-29 14:07:11.010546
Model ind 579 epoch 195 head A head_i_epoch 0 batch 200: avg loss -3.124021 avg loss no lamb -3.124021 time 2019-01-29 14:10:25.359651
Pre: time 2019-01-29 14:14:06.330938: 
 	std: 0.00450849
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 16), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 2), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 18)]
	test_accs: [0.2029, 0.20635, 0.19573334, 0.2087, 0.20611666]
	train_accs: [0.2029, 0.20635, 0.19573334, 0.2087, 0.20611666]
	best_train_sub_head: 3
	worst: 0.19573334
	avg: 0.20395999
	best: 0.2087

Starting e_i: 196
Model ind 579 epoch 196 head B head_i_epoch 0 batch 0: avg loss -1.536663 avg loss no lamb -1.536663 time 2019-01-29 14:14:09.696355
Model ind 579 epoch 196 head B head_i_epoch 0 batch 100: avg loss -1.692681 avg loss no lamb -1.692681 time 2019-01-29 14:17:20.233418
Model ind 579 epoch 196 head B head_i_epoch 0 batch 200: avg loss -1.560493 avg loss no lamb -1.560493 time 2019-01-29 14:20:32.603953
Model ind 579 epoch 196 head A head_i_epoch 0 batch 0: avg loss -3.058177 avg loss no lamb -3.058177 time 2019-01-29 14:23:44.497869
Model ind 579 epoch 196 head A head_i_epoch 0 batch 100: avg loss -3.105415 avg loss no lamb -3.105415 time 2019-01-29 14:26:56.715283
Model ind 579 epoch 196 head A head_i_epoch 0 batch 200: avg loss -3.151290 avg loss no lamb -3.151290 time 2019-01-29 14:30:08.317850
Pre: time 2019-01-29 14:33:44.899962: 
 	std: 0.0036094976
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 7), (13, 1), (14, 14), (15, 12), (16, 10), (17, 5), (18, 6), (19, 18)]
	test_accs: [0.1974, 0.2014, 0.19151667, 0.20126666, 0.19873333]
	train_accs: [0.1974, 0.2014, 0.19151667, 0.20126666, 0.19873333]
	best_train_sub_head: 1
	worst: 0.19151667
	avg: 0.19806333
	best: 0.2014

Starting e_i: 197
Model ind 579 epoch 197 head B head_i_epoch 0 batch 0: avg loss -1.571517 avg loss no lamb -1.571517 time 2019-01-29 14:33:48.237559
Model ind 579 epoch 197 head B head_i_epoch 0 batch 100: avg loss -1.610167 avg loss no lamb -1.610167 time 2019-01-29 14:36:58.148047
Model ind 579 epoch 197 head B head_i_epoch 0 batch 200: avg loss -1.629921 avg loss no lamb -1.629921 time 2019-01-29 14:40:08.787330
Model ind 579 epoch 197 head A head_i_epoch 0 batch 0: avg loss -3.122652 avg loss no lamb -3.122652 time 2019-01-29 14:43:20.962399
Model ind 579 epoch 197 head A head_i_epoch 0 batch 100: avg loss -3.132257 avg loss no lamb -3.132257 time 2019-01-29 14:46:34.181599
Model ind 579 epoch 197 head A head_i_epoch 0 batch 200: avg loss -3.151132 avg loss no lamb -3.151132 time 2019-01-29 14:49:44.850392
Pre: time 2019-01-29 14:53:24.228288: 
 	std: 0.0017763101
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 15), (3, 18), (4, 12), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 9), (11, 5), (12, 16), (13, 19), (14, 1), (15, 13), (16, 6), (17, 3), (18, 7), (19, 11)]
	test_accs: [0.19661666, 0.19803333, 0.19715, 0.19901666, 0.20165]
	train_accs: [0.19661666, 0.19803333, 0.19715, 0.19901666, 0.20165]
	best_train_sub_head: 4
	worst: 0.19661666
	avg: 0.19849333
	best: 0.20165

Starting e_i: 198
Model ind 579 epoch 198 head B head_i_epoch 0 batch 0: avg loss -1.487425 avg loss no lamb -1.487425 time 2019-01-29 14:53:27.822760
Model ind 579 epoch 198 head B head_i_epoch 0 batch 100: avg loss -1.608454 avg loss no lamb -1.608454 time 2019-01-29 14:56:37.626160
Model ind 579 epoch 198 head B head_i_epoch 0 batch 200: avg loss -1.570306 avg loss no lamb -1.570306 time 2019-01-29 14:59:48.761554
Model ind 579 epoch 198 head A head_i_epoch 0 batch 0: avg loss -3.091301 avg loss no lamb -3.091301 time 2019-01-29 15:02:58.178209
Model ind 579 epoch 198 head A head_i_epoch 0 batch 100: avg loss -3.146542 avg loss no lamb -3.146542 time 2019-01-29 15:06:09.987695
Model ind 579 epoch 198 head A head_i_epoch 0 batch 200: avg loss -3.145021 avg loss no lamb -3.145021 time 2019-01-29 15:09:22.649918
Pre: time 2019-01-29 15:13:05.268876: 
 	std: 0.002755451
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 18)]
	test_accs: [0.20148334, 0.2071, 0.2007, 0.20735, 0.20406666]
	train_accs: [0.20148334, 0.2071, 0.2007, 0.20735, 0.20406666]
	best_train_sub_head: 3
	worst: 0.2007
	avg: 0.20414
	best: 0.20735

Starting e_i: 199
Model ind 579 epoch 199 head B head_i_epoch 0 batch 0: avg loss -1.596826 avg loss no lamb -1.596826 time 2019-01-29 15:13:08.702516
Model ind 579 epoch 199 head B head_i_epoch 0 batch 100: avg loss -1.579447 avg loss no lamb -1.579447 time 2019-01-29 15:16:23.292750
Model ind 579 epoch 199 head B head_i_epoch 0 batch 200: avg loss -1.532294 avg loss no lamb -1.532294 time 2019-01-29 15:19:34.522263
Model ind 579 epoch 199 head A head_i_epoch 0 batch 0: avg loss -3.102130 avg loss no lamb -3.102130 time 2019-01-29 15:22:43.049726
Model ind 579 epoch 199 head A head_i_epoch 0 batch 100: avg loss -3.063980 avg loss no lamb -3.063980 time 2019-01-29 15:25:54.203342
Model ind 579 epoch 199 head A head_i_epoch 0 batch 200: avg loss -3.133029 avg loss no lamb -3.133029 time 2019-01-29 15:29:04.344226
Pre: time 2019-01-29 15:32:42.338341: 
 	std: 0.004432842
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 15), (3, 9), (4, 12), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 19), (11, 5), (12, 16), (13, 18), (14, 1), (15, 13), (16, 6), (17, 3), (18, 7), (19, 11)]
	test_accs: [0.20313333, 0.20586666, 0.19531667, 0.20571667, 0.20805]
	train_accs: [0.20313333, 0.20586666, 0.19531667, 0.20571667, 0.20805]
	best_train_sub_head: 4
	worst: 0.19531667
	avg: 0.20361666
	best: 0.20805

Starting e_i: 200
Model ind 579 epoch 200 head B head_i_epoch 0 batch 0: avg loss -1.516320 avg loss no lamb -1.516320 time 2019-01-29 15:32:45.692667
Model ind 579 epoch 200 head B head_i_epoch 0 batch 100: avg loss -1.592817 avg loss no lamb -1.592817 time 2019-01-29 15:35:55.340311
Model ind 579 epoch 200 head B head_i_epoch 0 batch 200: avg loss -1.552223 avg loss no lamb -1.552223 time 2019-01-29 15:39:04.606460
Model ind 579 epoch 200 head A head_i_epoch 0 batch 0: avg loss -3.134699 avg loss no lamb -3.134699 time 2019-01-29 15:42:14.360086
Model ind 579 epoch 200 head A head_i_epoch 0 batch 100: avg loss -3.187559 avg loss no lamb -3.187559 time 2019-01-29 15:45:24.588928
Model ind 579 epoch 200 head A head_i_epoch 0 batch 200: avg loss -3.171633 avg loss no lamb -3.171633 time 2019-01-29 15:48:36.379956
Pre: time 2019-01-29 15:52:10.749758: 
 	std: 0.0035267186
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 13), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.20223333, 0.20733333, 0.19676666, 0.20501667, 0.20293333]
	train_accs: [0.20223333, 0.20733333, 0.19676666, 0.20501667, 0.20293333]
	best_train_sub_head: 1
	worst: 0.19676666
	avg: 0.20285666
	best: 0.20733333

Starting e_i: 201
Model ind 579 epoch 201 head B head_i_epoch 0 batch 0: avg loss -1.567623 avg loss no lamb -1.567623 time 2019-01-29 15:52:18.752726
Model ind 579 epoch 201 head B head_i_epoch 0 batch 100: avg loss -1.661202 avg loss no lamb -1.661202 time 2019-01-29 15:55:28.946030
Model ind 579 epoch 201 head B head_i_epoch 0 batch 200: avg loss -1.616019 avg loss no lamb -1.616019 time 2019-01-29 15:58:38.302010
Model ind 579 epoch 201 head A head_i_epoch 0 batch 0: avg loss -3.081775 avg loss no lamb -3.081775 time 2019-01-29 16:01:46.110812
Model ind 579 epoch 201 head A head_i_epoch 0 batch 100: avg loss -3.106750 avg loss no lamb -3.106750 time 2019-01-29 16:04:55.976019
Model ind 579 epoch 201 head A head_i_epoch 0 batch 200: avg loss -3.102241 avg loss no lamb -3.102241 time 2019-01-29 16:08:06.033820
Pre: time 2019-01-29 16:11:43.088048: 
 	std: 0.0037187329
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 15), (3, 9), (4, 12), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 5), (12, 16), (13, 18), (14, 1), (15, 13), (16, 6), (17, 3), (18, 19), (19, 8)]
	test_accs: [0.20831667, 0.21013333, 0.20085, 0.2104, 0.21076667]
	train_accs: [0.20831667, 0.21013333, 0.20085, 0.2104, 0.21076667]
	best_train_sub_head: 4
	worst: 0.20085
	avg: 0.20809333
	best: 0.21076667

Starting e_i: 202
Model ind 579 epoch 202 head B head_i_epoch 0 batch 0: avg loss -1.495227 avg loss no lamb -1.495227 time 2019-01-29 16:11:46.427530
Model ind 579 epoch 202 head B head_i_epoch 0 batch 100: avg loss -1.623195 avg loss no lamb -1.623195 time 2019-01-29 16:14:56.055134
Model ind 579 epoch 202 head B head_i_epoch 0 batch 200: avg loss -1.599989 avg loss no lamb -1.599989 time 2019-01-29 16:18:06.918717
Model ind 579 epoch 202 head A head_i_epoch 0 batch 0: avg loss -3.096008 avg loss no lamb -3.096008 time 2019-01-29 16:21:15.474970
Model ind 579 epoch 202 head A head_i_epoch 0 batch 100: avg loss -3.138882 avg loss no lamb -3.138882 time 2019-01-29 16:24:26.889295
Model ind 579 epoch 202 head A head_i_epoch 0 batch 200: avg loss -3.169884 avg loss no lamb -3.169884 time 2019-01-29 16:27:37.887169
Pre: time 2019-01-29 16:31:13.567174: 
 	std: 0.004004394
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 15), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.20951666, 0.21361667, 0.20258333, 0.21248333, 0.2067]
	train_accs: [0.20951666, 0.21361667, 0.20258333, 0.21248333, 0.2067]
	best_train_sub_head: 1
	worst: 0.20258333
	avg: 0.20898
	best: 0.21361667

Starting e_i: 203
Model ind 579 epoch 203 head B head_i_epoch 0 batch 0: avg loss -1.597774 avg loss no lamb -1.597774 time 2019-01-29 16:31:16.637117
Model ind 579 epoch 203 head B head_i_epoch 0 batch 100: avg loss -1.653276 avg loss no lamb -1.653276 time 2019-01-29 16:34:23.897769
Model ind 579 epoch 203 head B head_i_epoch 0 batch 200: avg loss -1.643761 avg loss no lamb -1.643761 time 2019-01-29 16:37:32.321116
Model ind 579 epoch 203 head A head_i_epoch 0 batch 0: avg loss -3.076637 avg loss no lamb -3.076637 time 2019-01-29 16:40:40.989191
Model ind 579 epoch 203 head A head_i_epoch 0 batch 100: avg loss -3.100499 avg loss no lamb -3.100499 time 2019-01-29 16:43:49.569176
Model ind 579 epoch 203 head A head_i_epoch 0 batch 200: avg loss -3.179817 avg loss no lamb -3.179817 time 2019-01-29 16:46:58.732640
Pre: time 2019-01-29 16:50:36.123239: 
 	std: 0.001336039
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 11), (3, 7), (4, 4), (5, 3), (6, 18), (7, 8), (8, 6), (9, 14), (10, 9), (11, 15), (12, 2), (13, 5), (14, 10), (15, 16), (16, 12), (17, 17), (18, 1), (19, 19)]
	test_accs: [0.19198333, 0.19443333, 0.19121666, 0.19461666, 0.19333333]
	train_accs: [0.19198333, 0.19443333, 0.19121666, 0.19461666, 0.19333333]
	best_train_sub_head: 3
	worst: 0.19121666
	avg: 0.19311666
	best: 0.19461666

Starting e_i: 204
Model ind 579 epoch 204 head B head_i_epoch 0 batch 0: avg loss -1.427523 avg loss no lamb -1.427523 time 2019-01-29 16:50:39.253610
Model ind 579 epoch 204 head B head_i_epoch 0 batch 100: avg loss -1.546829 avg loss no lamb -1.546829 time 2019-01-29 16:53:48.050883
Model ind 579 epoch 204 head B head_i_epoch 0 batch 200: avg loss -1.671043 avg loss no lamb -1.671043 time 2019-01-29 16:56:56.403231
Model ind 579 epoch 204 head A head_i_epoch 0 batch 0: avg loss -3.079912 avg loss no lamb -3.079912 time 2019-01-29 17:00:06.005813
Model ind 579 epoch 204 head A head_i_epoch 0 batch 100: avg loss -3.111921 avg loss no lamb -3.111921 time 2019-01-29 17:03:14.556376
Model ind 579 epoch 204 head A head_i_epoch 0 batch 200: avg loss -3.147071 avg loss no lamb -3.147071 time 2019-01-29 17:06:24.246881
Pre: time 2019-01-29 17:10:00.612996: 
 	std: 0.0026754441
	best_train_sub_head_match: [(0, 18), (1, 16), (2, 14), (3, 0), (4, 12), (5, 5), (6, 2), (7, 6), (8, 15), (9, 10), (10, 7), (11, 8), (12, 19), (13, 9), (14, 13), (15, 4), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.20536667, 0.20313333, 0.19723333, 0.20261666, 0.20173334]
	train_accs: [0.20536667, 0.20313333, 0.19723333, 0.20261666, 0.20173334]
	best_train_sub_head: 0
	worst: 0.19723333
	avg: 0.20201667
	best: 0.20536667

Starting e_i: 205
Model ind 579 epoch 205 head B head_i_epoch 0 batch 0: avg loss -1.542073 avg loss no lamb -1.542073 time 2019-01-29 17:10:03.824564
Model ind 579 epoch 205 head B head_i_epoch 0 batch 100: avg loss -1.601393 avg loss no lamb -1.601393 time 2019-01-29 17:13:12.489319
Model ind 579 epoch 205 head B head_i_epoch 0 batch 200: avg loss -1.572665 avg loss no lamb -1.572665 time 2019-01-29 17:16:20.667236
Model ind 579 epoch 205 head A head_i_epoch 0 batch 0: avg loss -3.076910 avg loss no lamb -3.076910 time 2019-01-29 17:19:29.936359
Model ind 579 epoch 205 head A head_i_epoch 0 batch 100: avg loss -3.091491 avg loss no lamb -3.091491 time 2019-01-29 17:22:38.804326
Model ind 579 epoch 205 head A head_i_epoch 0 batch 200: avg loss -3.179587 avg loss no lamb -3.179587 time 2019-01-29 17:25:47.797533
Pre: time 2019-01-29 17:29:23.826953: 
 	std: 0.004419814
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 7), (7, 8), (8, 6), (9, 14), (10, 9), (11, 15), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 5), (19, 18)]
	test_accs: [0.20528333, 0.20895, 0.19825, 0.21053334, 0.20893334]
	train_accs: [0.20528333, 0.20895, 0.19825, 0.21053334, 0.20893334]
	best_train_sub_head: 3
	worst: 0.19825
	avg: 0.20639
	best: 0.21053334

Starting e_i: 206
Model ind 579 epoch 206 head B head_i_epoch 0 batch 0: avg loss -1.483595 avg loss no lamb -1.483595 time 2019-01-29 17:29:26.876784
Model ind 579 epoch 206 head B head_i_epoch 0 batch 100: avg loss -1.573602 avg loss no lamb -1.573602 time 2019-01-29 17:32:36.026069
Model ind 579 epoch 206 head B head_i_epoch 0 batch 200: avg loss -1.633481 avg loss no lamb -1.633481 time 2019-01-29 17:35:44.169544
Model ind 579 epoch 206 head A head_i_epoch 0 batch 0: avg loss -3.080209 avg loss no lamb -3.080209 time 2019-01-29 17:38:54.068573
Model ind 579 epoch 206 head A head_i_epoch 0 batch 100: avg loss -3.122000 avg loss no lamb -3.122000 time 2019-01-29 17:42:03.578770
Model ind 579 epoch 206 head A head_i_epoch 0 batch 200: avg loss -3.151147 avg loss no lamb -3.151147 time 2019-01-29 17:45:12.832486
Pre: time 2019-01-29 17:48:48.495378: 
 	std: 0.0028027238
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 16), (3, 19), (4, 4), (5, 3), (6, 7), (7, 2), (8, 6), (9, 14), (10, 9), (11, 8), (12, 5), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 18)]
	test_accs: [0.21248333, 0.2128, 0.20568334, 0.2129, 0.21253334]
	train_accs: [0.21248333, 0.2128, 0.20568334, 0.2129, 0.21253334]
	best_train_sub_head: 3
	worst: 0.20568334
	avg: 0.21127999
	best: 0.2129

Starting e_i: 207
Model ind 579 epoch 207 head B head_i_epoch 0 batch 0: avg loss -1.509786 avg loss no lamb -1.509786 time 2019-01-29 17:48:52.004349
Model ind 579 epoch 207 head B head_i_epoch 0 batch 100: avg loss -1.613494 avg loss no lamb -1.613494 time 2019-01-29 17:52:00.585067
Model ind 579 epoch 207 head B head_i_epoch 0 batch 200: avg loss -1.575959 avg loss no lamb -1.575959 time 2019-01-29 17:55:11.698963
Model ind 579 epoch 207 head A head_i_epoch 0 batch 0: avg loss -3.154184 avg loss no lamb -3.154184 time 2019-01-29 17:58:21.215435
Model ind 579 epoch 207 head A head_i_epoch 0 batch 100: avg loss -3.129580 avg loss no lamb -3.129580 time 2019-01-29 18:01:31.073412
Model ind 579 epoch 207 head A head_i_epoch 0 batch 200: avg loss -3.137132 avg loss no lamb -3.137132 time 2019-01-29 18:04:40.041591
Pre: time 2019-01-29 18:08:15.400784: 
 	std: 0.004960759
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 19), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 7), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.20096667, 0.20703334, 0.19358334, 0.2068, 0.20396666]
	train_accs: [0.20096667, 0.20703334, 0.19358334, 0.2068, 0.20396666]
	best_train_sub_head: 1
	worst: 0.19358334
	avg: 0.20246999
	best: 0.20703334

Starting e_i: 208
Model ind 579 epoch 208 head B head_i_epoch 0 batch 0: avg loss -1.504323 avg loss no lamb -1.504323 time 2019-01-29 18:08:18.667792
Model ind 579 epoch 208 head B head_i_epoch 0 batch 100: avg loss -1.626737 avg loss no lamb -1.626737 time 2019-01-29 18:11:26.867751
Model ind 579 epoch 208 head B head_i_epoch 0 batch 200: avg loss -1.612918 avg loss no lamb -1.612918 time 2019-01-29 18:14:35.471757
Model ind 579 epoch 208 head A head_i_epoch 0 batch 0: avg loss -3.135963 avg loss no lamb -3.135963 time 2019-01-29 18:17:44.117021
Model ind 579 epoch 208 head A head_i_epoch 0 batch 100: avg loss -3.104773 avg loss no lamb -3.104773 time 2019-01-29 18:20:54.555518
Model ind 579 epoch 208 head A head_i_epoch 0 batch 200: avg loss -3.172649 avg loss no lamb -3.172649 time 2019-01-29 18:24:03.401700
Pre: time 2019-01-29 18:27:39.692924: 
 	std: 0.004374345
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 19), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 7), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.2125, 0.21636666, 0.20423333, 0.21603334, 0.21195]
	train_accs: [0.2125, 0.21636666, 0.20423333, 0.21603334, 0.21195]
	best_train_sub_head: 1
	worst: 0.20423333
	avg: 0.21221666
	best: 0.21636666

Starting e_i: 209
Model ind 579 epoch 209 head B head_i_epoch 0 batch 0: avg loss -1.547489 avg loss no lamb -1.547489 time 2019-01-29 18:27:46.545223
Model ind 579 epoch 209 head B head_i_epoch 0 batch 100: avg loss -1.620195 avg loss no lamb -1.620195 time 2019-01-29 18:30:54.909045
Model ind 579 epoch 209 head B head_i_epoch 0 batch 200: avg loss -1.628137 avg loss no lamb -1.628137 time 2019-01-29 18:34:04.628320
Model ind 579 epoch 209 head A head_i_epoch 0 batch 0: avg loss -3.067184 avg loss no lamb -3.067184 time 2019-01-29 18:37:13.894149
Model ind 579 epoch 209 head A head_i_epoch 0 batch 100: avg loss -3.100546 avg loss no lamb -3.100546 time 2019-01-29 18:40:23.783135
Model ind 579 epoch 209 head A head_i_epoch 0 batch 200: avg loss -3.100221 avg loss no lamb -3.100221 time 2019-01-29 18:43:32.249895
Pre: time 2019-01-29 18:47:06.967690: 
 	std: 0.0021293343
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 15), (3, 9), (4, 12), (5, 17), (6, 8), (7, 10), (8, 14), (9, 0), (10, 19), (11, 5), (12, 16), (13, 18), (14, 1), (15, 13), (16, 6), (17, 3), (18, 7), (19, 11)]
	test_accs: [0.19981667, 0.202, 0.19775, 0.20281667, 0.20356667]
	train_accs: [0.19981667, 0.202, 0.19775, 0.20281667, 0.20356667]
	best_train_sub_head: 4
	worst: 0.19775
	avg: 0.20119
	best: 0.20356667

Starting e_i: 210
Model ind 579 epoch 210 head B head_i_epoch 0 batch 0: avg loss -1.518699 avg loss no lamb -1.518699 time 2019-01-29 18:47:10.244138
Model ind 579 epoch 210 head B head_i_epoch 0 batch 100: avg loss -1.670670 avg loss no lamb -1.670670 time 2019-01-29 18:50:16.514483
Model ind 579 epoch 210 head B head_i_epoch 0 batch 200: avg loss -1.623092 avg loss no lamb -1.623092 time 2019-01-29 18:53:22.458798
Model ind 579 epoch 210 head A head_i_epoch 0 batch 0: avg loss -3.040372 avg loss no lamb -3.040372 time 2019-01-29 18:56:28.764503
Model ind 579 epoch 210 head A head_i_epoch 0 batch 100: avg loss -3.120858 avg loss no lamb -3.120858 time 2019-01-29 18:59:37.918097
Model ind 579 epoch 210 head A head_i_epoch 0 batch 200: avg loss -3.135634 avg loss no lamb -3.135634 time 2019-01-29 19:02:43.461444
Pre: time 2019-01-29 19:06:15.711296: 
 	std: 0.0012013705
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 8), (7, 11), (8, 3), (9, 16), (10, 15), (11, 17), (12, 7), (13, 1), (14, 5), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.20216666, 0.20583333, 0.20326667, 0.2037, 0.20415]
	train_accs: [0.20216666, 0.20583333, 0.20326667, 0.2037, 0.20415]
	best_train_sub_head: 1
	worst: 0.20216666
	avg: 0.20382333
	best: 0.20583333

Starting e_i: 211
Model ind 579 epoch 211 head B head_i_epoch 0 batch 0: avg loss -1.510016 avg loss no lamb -1.510016 time 2019-01-29 19:06:22.689535
Model ind 579 epoch 211 head B head_i_epoch 0 batch 100: avg loss -1.610689 avg loss no lamb -1.610689 time 2019-01-29 19:09:28.795516
Model ind 579 epoch 211 head B head_i_epoch 0 batch 200: avg loss -1.548729 avg loss no lamb -1.548729 time 2019-01-29 19:12:36.467586
Model ind 579 epoch 211 head A head_i_epoch 0 batch 0: avg loss -3.107563 avg loss no lamb -3.107563 time 2019-01-29 19:15:42.856278
Model ind 579 epoch 211 head A head_i_epoch 0 batch 100: avg loss -3.094956 avg loss no lamb -3.094956 time 2019-01-29 19:18:52.073983
Model ind 579 epoch 211 head A head_i_epoch 0 batch 200: avg loss -3.157116 avg loss no lamb -3.157116 time 2019-01-29 19:21:59.664696
Pre: time 2019-01-29 19:25:35.363379: 
 	std: 0.001967401
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 16), (3, 5), (4, 4), (5, 3), (6, 18), (7, 8), (8, 6), (9, 14), (10, 9), (11, 7), (12, 2), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 19)]
	test_accs: [0.21493334, 0.2155, 0.21053334, 0.2161, 0.2146]
	train_accs: [0.21493334, 0.2155, 0.21053334, 0.2161, 0.2146]
	best_train_sub_head: 3
	worst: 0.21053334
	avg: 0.21433333
	best: 0.2161

Starting e_i: 212
Model ind 579 epoch 212 head B head_i_epoch 0 batch 0: avg loss -1.560299 avg loss no lamb -1.560299 time 2019-01-29 19:25:38.524369
Model ind 579 epoch 212 head B head_i_epoch 0 batch 100: avg loss -1.595670 avg loss no lamb -1.595670 time 2019-01-29 19:28:45.514043
Model ind 579 epoch 212 head B head_i_epoch 0 batch 200: avg loss -1.669400 avg loss no lamb -1.669400 time 2019-01-29 19:31:54.816751
Model ind 579 epoch 212 head A head_i_epoch 0 batch 0: avg loss -3.141204 avg loss no lamb -3.141204 time 2019-01-29 19:35:02.994685
Model ind 579 epoch 212 head A head_i_epoch 0 batch 100: avg loss -3.105926 avg loss no lamb -3.105926 time 2019-01-29 19:38:11.408009
Model ind 579 epoch 212 head A head_i_epoch 0 batch 200: avg loss -3.170012 avg loss no lamb -3.170012 time 2019-01-29 19:41:21.561484
Pre: time 2019-01-29 19:44:57.670235: 
 	std: 0.001151907
	best_train_sub_head_match: [(0, 13), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 8), (8, 6), (9, 14), (10, 9), (11, 15), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.21385, 0.21426667, 0.21133333, 0.2144, 0.21273333]
	train_accs: [0.21385, 0.21426667, 0.21133333, 0.2144, 0.21273333]
	best_train_sub_head: 3
	worst: 0.21133333
	avg: 0.21331668
	best: 0.2144

Starting e_i: 213
Model ind 579 epoch 213 head B head_i_epoch 0 batch 0: avg loss -1.591145 avg loss no lamb -1.591145 time 2019-01-29 19:45:01.024347
Model ind 579 epoch 213 head B head_i_epoch 0 batch 100: avg loss -1.677700 avg loss no lamb -1.677700 time 2019-01-29 19:48:09.692541
Model ind 579 epoch 213 head B head_i_epoch 0 batch 200: avg loss -1.585920 avg loss no lamb -1.585920 time 2019-01-29 19:51:16.702798
Model ind 579 epoch 213 head A head_i_epoch 0 batch 0: avg loss -3.058295 avg loss no lamb -3.058295 time 2019-01-29 19:54:23.935514
Model ind 579 epoch 213 head A head_i_epoch 0 batch 100: avg loss -3.114466 avg loss no lamb -3.114466 time 2019-01-29 19:57:32.247065
Model ind 579 epoch 213 head A head_i_epoch 0 batch 200: avg loss -3.161860 avg loss no lamb -3.161860 time 2019-01-29 20:00:40.410908
Pre: time 2019-01-29 20:04:14.655108: 
 	std: 0.0022260554
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.21198334, 0.21303333, 0.20675, 0.21215, 0.21158333]
	train_accs: [0.21198334, 0.21303333, 0.20675, 0.21215, 0.21158333]
	best_train_sub_head: 1
	worst: 0.20675
	avg: 0.21110001
	best: 0.21303333

Starting e_i: 214
Model ind 579 epoch 214 head B head_i_epoch 0 batch 0: avg loss -1.471388 avg loss no lamb -1.471388 time 2019-01-29 20:04:18.115298
Model ind 579 epoch 214 head B head_i_epoch 0 batch 100: avg loss -1.615654 avg loss no lamb -1.615654 time 2019-01-29 20:07:25.344845
Model ind 579 epoch 214 head B head_i_epoch 0 batch 200: avg loss -1.620256 avg loss no lamb -1.620256 time 2019-01-29 20:10:31.789569
Model ind 579 epoch 214 head A head_i_epoch 0 batch 0: avg loss -3.099768 avg loss no lamb -3.099768 time 2019-01-29 20:13:38.986285
Model ind 579 epoch 214 head A head_i_epoch 0 batch 100: avg loss -3.084765 avg loss no lamb -3.084765 time 2019-01-29 20:16:46.335867
Model ind 579 epoch 214 head A head_i_epoch 0 batch 200: avg loss -3.177973 avg loss no lamb -3.177973 time 2019-01-29 20:19:52.674039
Pre: time 2019-01-29 20:23:27.314585: 
 	std: 0.0020930115
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 5), (4, 4), (5, 3), (6, 18), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 19)]
	test_accs: [0.20973334, 0.21453333, 0.2111, 0.21523333, 0.21363333]
	train_accs: [0.20973334, 0.21453333, 0.2111, 0.21523333, 0.21363333]
	best_train_sub_head: 3
	worst: 0.20973334
	avg: 0.21284667
	best: 0.21523333

Starting e_i: 215
Model ind 579 epoch 215 head B head_i_epoch 0 batch 0: avg loss -1.608379 avg loss no lamb -1.608379 time 2019-01-29 20:23:30.588948
Model ind 579 epoch 215 head B head_i_epoch 0 batch 100: avg loss -1.685431 avg loss no lamb -1.685431 time 2019-01-29 20:26:37.165139
Model ind 579 epoch 215 head B head_i_epoch 0 batch 200: avg loss -1.610214 avg loss no lamb -1.610214 time 2019-01-29 20:29:43.762636
Model ind 579 epoch 215 head A head_i_epoch 0 batch 0: avg loss -3.134932 avg loss no lamb -3.134932 time 2019-01-29 20:32:50.027368
Model ind 579 epoch 215 head A head_i_epoch 0 batch 100: avg loss -3.085971 avg loss no lamb -3.085971 time 2019-01-29 20:35:59.111355
Model ind 579 epoch 215 head A head_i_epoch 0 batch 200: avg loss -3.150359 avg loss no lamb -3.150359 time 2019-01-29 20:39:07.381455
Pre: time 2019-01-29 20:42:40.897194: 
 	std: 0.0035230475
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 7), (13, 1), (14, 5), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.212, 0.2133, 0.20396666, 0.21295, 0.21258333]
	train_accs: [0.212, 0.2133, 0.20396666, 0.21295, 0.21258333]
	best_train_sub_head: 1
	worst: 0.20396666
	avg: 0.21096
	best: 0.2133

Starting e_i: 216
Model ind 579 epoch 216 head B head_i_epoch 0 batch 0: avg loss -1.626297 avg loss no lamb -1.626297 time 2019-01-29 20:42:44.044204
Model ind 579 epoch 216 head B head_i_epoch 0 batch 100: avg loss -1.639293 avg loss no lamb -1.639293 time 2019-01-29 20:45:49.097443
Model ind 579 epoch 216 head B head_i_epoch 0 batch 200: avg loss -1.604122 avg loss no lamb -1.604122 time 2019-01-29 20:48:55.917181
Model ind 579 epoch 216 head A head_i_epoch 0 batch 0: avg loss -3.136851 avg loss no lamb -3.136851 time 2019-01-29 20:52:01.336193
Model ind 579 epoch 216 head A head_i_epoch 0 batch 100: avg loss -3.143652 avg loss no lamb -3.143652 time 2019-01-29 20:55:08.655991
Model ind 579 epoch 216 head A head_i_epoch 0 batch 200: avg loss -3.163486 avg loss no lamb -3.163486 time 2019-01-29 20:58:16.350866
Pre: time 2019-01-29 21:01:50.186823: 
 	std: 0.0046294928
	best_train_sub_head_match: [(0, 13), (1, 16), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 7), (9, 10), (10, 19), (11, 8), (12, 18), (13, 9), (14, 15), (15, 5), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.22081667, 0.21861666, 0.20785, 0.21848333, 0.21901667]
	train_accs: [0.22081667, 0.21861666, 0.20785, 0.21848333, 0.21901667]
	best_train_sub_head: 0
	worst: 0.20785
	avg: 0.21695666
	best: 0.22081667

Starting e_i: 217
Model ind 579 epoch 217 head B head_i_epoch 0 batch 0: avg loss -1.603824 avg loss no lamb -1.603824 time 2019-01-29 21:01:57.527308
Model ind 579 epoch 217 head B head_i_epoch 0 batch 100: avg loss -1.566883 avg loss no lamb -1.566883 time 2019-01-29 21:05:05.037826
Model ind 579 epoch 217 head B head_i_epoch 0 batch 200: avg loss -1.608742 avg loss no lamb -1.608742 time 2019-01-29 21:08:12.634524
Model ind 579 epoch 217 head A head_i_epoch 0 batch 0: avg loss -3.098736 avg loss no lamb -3.098736 time 2019-01-29 21:11:16.886750
Model ind 579 epoch 217 head A head_i_epoch 0 batch 100: avg loss -3.082485 avg loss no lamb -3.082485 time 2019-01-29 21:14:24.322194
Model ind 579 epoch 217 head A head_i_epoch 0 batch 200: avg loss -3.130670 avg loss no lamb -3.130670 time 2019-01-29 21:17:33.956616
Pre: time 2019-01-29 21:21:08.559766: 
 	std: 0.0035642663
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 7), (7, 8), (8, 6), (9, 14), (10, 9), (11, 5), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 18)]
	test_accs: [0.21368334, 0.21611667, 0.20758334, 0.21743333, 0.21651667]
	train_accs: [0.21368334, 0.21611667, 0.20758334, 0.21743333, 0.21651667]
	best_train_sub_head: 3
	worst: 0.20758334
	avg: 0.21426669
	best: 0.21743333

Starting e_i: 218
Model ind 579 epoch 218 head B head_i_epoch 0 batch 0: avg loss -1.488242 avg loss no lamb -1.488242 time 2019-01-29 21:21:11.697452
Model ind 579 epoch 218 head B head_i_epoch 0 batch 100: avg loss -1.677717 avg loss no lamb -1.677717 time 2019-01-29 21:24:18.575770
Model ind 579 epoch 218 head B head_i_epoch 0 batch 200: avg loss -1.584050 avg loss no lamb -1.584050 time 2019-01-29 21:27:24.873251
Model ind 579 epoch 218 head A head_i_epoch 0 batch 0: avg loss -3.099460 avg loss no lamb -3.099460 time 2019-01-29 21:30:31.918499
Model ind 579 epoch 218 head A head_i_epoch 0 batch 100: avg loss -3.111811 avg loss no lamb -3.111811 time 2019-01-29 21:33:40.013906
Model ind 579 epoch 218 head A head_i_epoch 0 batch 200: avg loss -3.197017 avg loss no lamb -3.197017 time 2019-01-29 21:36:47.936931
Pre: time 2019-01-29 21:40:22.702250: 
 	std: 0.004268141
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.21718334, 0.22236666, 0.2105, 0.2218, 0.21705]
	train_accs: [0.21718334, 0.22236666, 0.2105, 0.2218, 0.21705]
	best_train_sub_head: 1
	worst: 0.2105
	avg: 0.21778
	best: 0.22236666

Starting e_i: 219
Model ind 579 epoch 219 head B head_i_epoch 0 batch 0: avg loss -1.634485 avg loss no lamb -1.634485 time 2019-01-29 21:40:28.961168
Model ind 579 epoch 219 head B head_i_epoch 0 batch 100: avg loss -1.613806 avg loss no lamb -1.613806 time 2019-01-29 21:43:37.007179
Model ind 579 epoch 219 head B head_i_epoch 0 batch 200: avg loss -1.602957 avg loss no lamb -1.602957 time 2019-01-29 21:46:43.638319
Model ind 579 epoch 219 head A head_i_epoch 0 batch 0: avg loss -3.118829 avg loss no lamb -3.118829 time 2019-01-29 21:49:51.001835
Model ind 579 epoch 219 head A head_i_epoch 0 batch 100: avg loss -3.161260 avg loss no lamb -3.161260 time 2019-01-29 21:52:57.523694
Model ind 579 epoch 219 head A head_i_epoch 0 batch 200: avg loss -3.210235 avg loss no lamb -3.210235 time 2019-01-29 21:56:05.031733
Pre: time 2019-01-29 21:59:38.350943: 
 	std: 0.005234504
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 2), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.2245, 0.22571667, 0.2117, 0.22526667, 0.22245]
	train_accs: [0.2245, 0.22571667, 0.2117, 0.22526667, 0.22245]
	best_train_sub_head: 1
	worst: 0.2117
	avg: 0.22192666
	best: 0.22571667

Starting e_i: 220
Model ind 579 epoch 220 head B head_i_epoch 0 batch 0: avg loss -1.625458 avg loss no lamb -1.625458 time 2019-01-29 21:59:45.194646
Model ind 579 epoch 220 head B head_i_epoch 0 batch 100: avg loss -1.622850 avg loss no lamb -1.622850 time 2019-01-29 22:02:52.396114
Model ind 579 epoch 220 head B head_i_epoch 0 batch 200: avg loss -1.559910 avg loss no lamb -1.559910 time 2019-01-29 22:06:00.126191
Model ind 579 epoch 220 head A head_i_epoch 0 batch 0: avg loss -3.075750 avg loss no lamb -3.075750 time 2019-01-29 22:09:08.619690
Model ind 579 epoch 220 head A head_i_epoch 0 batch 100: avg loss -3.137215 avg loss no lamb -3.137215 time 2019-01-29 22:12:15.432465
Model ind 579 epoch 220 head A head_i_epoch 0 batch 200: avg loss -3.144869 avg loss no lamb -3.144869 time 2019-01-29 22:15:22.349108
Pre: time 2019-01-29 22:18:56.294717: 
 	std: 0.0060391556
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 18)]
	test_accs: [0.21708333, 0.2207, 0.20468333, 0.22133334, 0.21775]
	train_accs: [0.21708333, 0.2207, 0.20468333, 0.22133334, 0.21775]
	best_train_sub_head: 3
	worst: 0.20468333
	avg: 0.21631
	best: 0.22133334

Starting e_i: 221
Model ind 579 epoch 221 head B head_i_epoch 0 batch 0: avg loss -1.575551 avg loss no lamb -1.575551 time 2019-01-29 22:19:03.285661
Model ind 579 epoch 221 head B head_i_epoch 0 batch 100: avg loss -1.656562 avg loss no lamb -1.656562 time 2019-01-29 22:22:09.506953
Model ind 579 epoch 221 head B head_i_epoch 0 batch 200: avg loss -1.680475 avg loss no lamb -1.680475 time 2019-01-29 22:25:16.451975
Model ind 579 epoch 221 head A head_i_epoch 0 batch 0: avg loss -3.110322 avg loss no lamb -3.110322 time 2019-01-29 22:28:23.027928
Model ind 579 epoch 221 head A head_i_epoch 0 batch 100: avg loss -3.191303 avg loss no lamb -3.191303 time 2019-01-29 22:31:29.448875
Model ind 579 epoch 221 head A head_i_epoch 0 batch 200: avg loss -3.164730 avg loss no lamb -3.164730 time 2019-01-29 22:34:36.973257
Pre: time 2019-01-29 22:38:12.152261: 
 	std: 0.003566914
	best_train_sub_head_match: [(0, 9), (1, 5), (2, 0), (3, 13), (4, 4), (5, 7), (6, 12), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 15), (15, 2), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.21213333, 0.21536666, 0.2053, 0.21455, 0.21073334]
	train_accs: [0.21213333, 0.21536666, 0.2053, 0.21455, 0.21073334]
	best_train_sub_head: 1
	worst: 0.2053
	avg: 0.21161667
	best: 0.21536666

Starting e_i: 222
Model ind 579 epoch 222 head B head_i_epoch 0 batch 0: avg loss -1.537000 avg loss no lamb -1.537000 time 2019-01-29 22:38:15.088762
Model ind 579 epoch 222 head B head_i_epoch 0 batch 100: avg loss -1.642226 avg loss no lamb -1.642226 time 2019-01-29 22:41:23.758528
Model ind 579 epoch 222 head B head_i_epoch 0 batch 200: avg loss -1.607177 avg loss no lamb -1.607177 time 2019-01-29 22:44:33.244659
Model ind 579 epoch 222 head A head_i_epoch 0 batch 0: avg loss -3.055743 avg loss no lamb -3.055743 time 2019-01-29 22:47:41.359048
Model ind 579 epoch 222 head A head_i_epoch 0 batch 100: avg loss -3.145659 avg loss no lamb -3.145659 time 2019-01-29 22:50:52.068405
Model ind 579 epoch 222 head A head_i_epoch 0 batch 200: avg loss -3.148255 avg loss no lamb -3.148255 time 2019-01-29 22:54:00.700352
Pre: time 2019-01-29 22:57:33.634469: 
 	std: 0.004304893
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 19), (3, 13), (4, 4), (5, 7), (6, 8), (7, 11), (8, 3), (9, 2), (10, 15), (11, 17), (12, 5), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.21126667, 0.21471667, 0.20301667, 0.21443333, 0.2129]
	train_accs: [0.21126667, 0.21471667, 0.20301667, 0.21443333, 0.2129]
	best_train_sub_head: 1
	worst: 0.20301667
	avg: 0.21126667
	best: 0.21471667

Starting e_i: 223
Model ind 579 epoch 223 head B head_i_epoch 0 batch 0: avg loss -1.584555 avg loss no lamb -1.584555 time 2019-01-29 22:57:36.604843
Model ind 579 epoch 223 head B head_i_epoch 0 batch 100: avg loss -1.672775 avg loss no lamb -1.672775 time 2019-01-29 23:00:41.927506
Model ind 579 epoch 223 head B head_i_epoch 0 batch 200: avg loss -1.651917 avg loss no lamb -1.651917 time 2019-01-29 23:03:47.752609
Model ind 579 epoch 223 head A head_i_epoch 0 batch 0: avg loss -3.062480 avg loss no lamb -3.062480 time 2019-01-29 23:06:53.931089
Model ind 579 epoch 223 head A head_i_epoch 0 batch 100: avg loss -3.143440 avg loss no lamb -3.143440 time 2019-01-29 23:10:01.954646
Model ind 579 epoch 223 head A head_i_epoch 0 batch 200: avg loss -3.119441 avg loss no lamb -3.119441 time 2019-01-29 23:13:08.660825
Pre: time 2019-01-29 23:16:41.710372: 
 	std: 0.004393904
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 16), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 2), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 18)]
	test_accs: [0.21398333, 0.21815, 0.20625, 0.2182, 0.2156]
	train_accs: [0.21398333, 0.21815, 0.20625, 0.2182, 0.2156]
	best_train_sub_head: 3
	worst: 0.20625
	avg: 0.21443668
	best: 0.2182

Starting e_i: 224
Model ind 579 epoch 224 head B head_i_epoch 0 batch 0: avg loss -1.470787 avg loss no lamb -1.470787 time 2019-01-29 23:16:44.829836
Model ind 579 epoch 224 head B head_i_epoch 0 batch 100: avg loss -1.582796 avg loss no lamb -1.582796 time 2019-01-29 23:19:51.258169
Model ind 579 epoch 224 head B head_i_epoch 0 batch 200: avg loss -1.583907 avg loss no lamb -1.583907 time 2019-01-29 23:22:54.914631
Model ind 579 epoch 224 head A head_i_epoch 0 batch 0: avg loss -3.148526 avg loss no lamb -3.148526 time 2019-01-29 23:26:01.813155
Model ind 579 epoch 224 head A head_i_epoch 0 batch 100: avg loss -3.126030 avg loss no lamb -3.126030 time 2019-01-29 23:29:08.381360
Model ind 579 epoch 224 head A head_i_epoch 0 batch 200: avg loss -3.186604 avg loss no lamb -3.186604 time 2019-01-29 23:32:16.920406
Pre: time 2019-01-29 23:35:50.470890: 
 	std: 0.002999815
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 5), (19, 19)]
	test_accs: [0.20486666, 0.2082, 0.20036666, 0.20878333, 0.20603333]
	train_accs: [0.20486666, 0.2082, 0.20036666, 0.20878333, 0.20603333]
	best_train_sub_head: 3
	worst: 0.20036666
	avg: 0.20565
	best: 0.20878333

Starting e_i: 225
Model ind 579 epoch 225 head B head_i_epoch 0 batch 0: avg loss -1.588588 avg loss no lamb -1.588588 time 2019-01-29 23:35:53.814465
Model ind 579 epoch 225 head B head_i_epoch 0 batch 100: avg loss -1.599311 avg loss no lamb -1.599311 time 2019-01-29 23:39:00.040474
Model ind 579 epoch 225 head B head_i_epoch 0 batch 200: avg loss -1.574503 avg loss no lamb -1.574503 time 2019-01-29 23:42:05.104326
Model ind 579 epoch 225 head A head_i_epoch 0 batch 0: avg loss -3.107915 avg loss no lamb -3.107915 time 2019-01-29 23:45:10.484847
Model ind 579 epoch 225 head A head_i_epoch 0 batch 100: avg loss -3.141080 avg loss no lamb -3.141080 time 2019-01-29 23:48:16.674398
Model ind 579 epoch 225 head A head_i_epoch 0 batch 200: avg loss -3.199721 avg loss no lamb -3.199721 time 2019-01-29 23:51:23.840479
Pre: time 2019-01-29 23:54:56.017233: 
 	std: 0.005088253
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 18)]
	test_accs: [0.21468334, 0.22035, 0.20656666, 0.2205, 0.21476667]
	train_accs: [0.21468334, 0.22035, 0.20656666, 0.2205, 0.21476667]
	best_train_sub_head: 3
	worst: 0.20656666
	avg: 0.21537332
	best: 0.2205

Starting e_i: 226
Model ind 579 epoch 226 head B head_i_epoch 0 batch 0: avg loss -1.540966 avg loss no lamb -1.540966 time 2019-01-29 23:54:59.120628
Model ind 579 epoch 226 head B head_i_epoch 0 batch 100: avg loss -1.574377 avg loss no lamb -1.574377 time 2019-01-29 23:58:04.203345
Model ind 579 epoch 226 head B head_i_epoch 0 batch 200: avg loss -1.620060 avg loss no lamb -1.620060 time 2019-01-30 00:01:09.712826
Model ind 579 epoch 226 head A head_i_epoch 0 batch 0: avg loss -3.118588 avg loss no lamb -3.118588 time 2019-01-30 00:04:16.234789
Model ind 579 epoch 226 head A head_i_epoch 0 batch 100: avg loss -3.106603 avg loss no lamb -3.106603 time 2019-01-30 00:07:23.036580
Model ind 579 epoch 226 head A head_i_epoch 0 batch 200: avg loss -3.170123 avg loss no lamb -3.170123 time 2019-01-30 00:10:30.266754
Pre: time 2019-01-30 00:14:03.477639: 
 	std: 0.004669278
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.21975, 0.22356667, 0.21078333, 0.2235, 0.22016667]
	train_accs: [0.21975, 0.22356667, 0.21078333, 0.2235, 0.22016667]
	best_train_sub_head: 1
	worst: 0.21078333
	avg: 0.21955332
	best: 0.22356667

Starting e_i: 227
Model ind 579 epoch 227 head B head_i_epoch 0 batch 0: avg loss -1.581735 avg loss no lamb -1.581735 time 2019-01-30 00:14:06.659052
Model ind 579 epoch 227 head B head_i_epoch 0 batch 100: avg loss -1.576834 avg loss no lamb -1.576834 time 2019-01-30 00:17:12.922733
Model ind 579 epoch 227 head B head_i_epoch 0 batch 200: avg loss -1.575160 avg loss no lamb -1.575160 time 2019-01-30 00:20:18.321547
Model ind 579 epoch 227 head A head_i_epoch 0 batch 0: avg loss -3.097037 avg loss no lamb -3.097037 time 2019-01-30 00:23:23.794802
Model ind 579 epoch 227 head A head_i_epoch 0 batch 100: avg loss -3.121253 avg loss no lamb -3.121253 time 2019-01-30 00:26:31.942916
Model ind 579 epoch 227 head A head_i_epoch 0 batch 200: avg loss -3.214119 avg loss no lamb -3.214119 time 2019-01-30 00:29:38.851639
Pre: time 2019-01-30 00:33:10.843402: 
 	std: 0.0039965343
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 8), (8, 6), (9, 14), (10, 9), (11, 13), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 5), (19, 19)]
	test_accs: [0.21565, 0.21753334, 0.20696667, 0.21781667, 0.2159]
	train_accs: [0.21565, 0.21753334, 0.20696667, 0.21781667, 0.2159]
	best_train_sub_head: 3
	worst: 0.20696667
	avg: 0.21477333
	best: 0.21781667

Starting e_i: 228
Model ind 579 epoch 228 head B head_i_epoch 0 batch 0: avg loss -1.626475 avg loss no lamb -1.626475 time 2019-01-30 00:33:13.592690
Model ind 579 epoch 228 head B head_i_epoch 0 batch 100: avg loss -1.675690 avg loss no lamb -1.675690 time 2019-01-30 00:36:18.561365
Model ind 579 epoch 228 head B head_i_epoch 0 batch 200: avg loss -1.601759 avg loss no lamb -1.601759 time 2019-01-30 00:39:22.524254
Model ind 579 epoch 228 head A head_i_epoch 0 batch 0: avg loss -3.086044 avg loss no lamb -3.086044 time 2019-01-30 00:42:26.158319
Model ind 579 epoch 228 head A head_i_epoch 0 batch 100: avg loss -3.079883 avg loss no lamb -3.079883 time 2019-01-30 00:45:31.628558
Model ind 579 epoch 228 head A head_i_epoch 0 batch 200: avg loss -3.177413 avg loss no lamb -3.177413 time 2019-01-30 00:48:37.264176
Pre: time 2019-01-30 00:52:09.775389: 
 	std: 0.004206142
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.21263333, 0.21603334, 0.20451666, 0.21585, 0.2135]
	train_accs: [0.21263333, 0.21603334, 0.20451666, 0.21585, 0.2135]
	best_train_sub_head: 1
	worst: 0.20451666
	avg: 0.21250665
	best: 0.21603334

Starting e_i: 229
Model ind 579 epoch 229 head B head_i_epoch 0 batch 0: avg loss -1.570431 avg loss no lamb -1.570431 time 2019-01-30 00:52:12.761602
Model ind 579 epoch 229 head B head_i_epoch 0 batch 100: avg loss -1.635876 avg loss no lamb -1.635876 time 2019-01-30 00:55:19.983978
Model ind 579 epoch 229 head B head_i_epoch 0 batch 200: avg loss -1.650175 avg loss no lamb -1.650175 time 2019-01-30 00:58:26.542083
Model ind 579 epoch 229 head A head_i_epoch 0 batch 0: avg loss -3.163120 avg loss no lamb -3.163120 time 2019-01-30 01:01:31.426300
Model ind 579 epoch 229 head A head_i_epoch 0 batch 100: avg loss -3.133759 avg loss no lamb -3.133759 time 2019-01-30 01:04:37.518048
Model ind 579 epoch 229 head A head_i_epoch 0 batch 200: avg loss -3.152105 avg loss no lamb -3.152105 time 2019-01-30 01:07:44.670961
Pre: time 2019-01-30 01:11:18.904820: 
 	std: 0.0039440473
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 16), (3, 19), (4, 4), (5, 3), (6, 7), (7, 8), (8, 6), (9, 14), (10, 9), (11, 15), (12, 2), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 5), (19, 18)]
	test_accs: [0.21236667, 0.21313334, 0.20365, 0.21516667, 0.21108334]
	train_accs: [0.21236667, 0.21313334, 0.20365, 0.21516667, 0.21108334]
	best_train_sub_head: 3
	worst: 0.20365
	avg: 0.21108
	best: 0.21516667

Starting e_i: 230
Model ind 579 epoch 230 head B head_i_epoch 0 batch 0: avg loss -1.535802 avg loss no lamb -1.535802 time 2019-01-30 01:11:21.817562
Model ind 579 epoch 230 head B head_i_epoch 0 batch 100: avg loss -1.605709 avg loss no lamb -1.605709 time 2019-01-30 01:14:26.724173
Model ind 579 epoch 230 head B head_i_epoch 0 batch 200: avg loss -1.688492 avg loss no lamb -1.688492 time 2019-01-30 01:17:31.951838
Model ind 579 epoch 230 head A head_i_epoch 0 batch 0: avg loss -3.106724 avg loss no lamb -3.106724 time 2019-01-30 01:20:36.473001
Model ind 579 epoch 230 head A head_i_epoch 0 batch 100: avg loss -3.147731 avg loss no lamb -3.147731 time 2019-01-30 01:23:42.221006
Model ind 579 epoch 230 head A head_i_epoch 0 batch 200: avg loss -3.140425 avg loss no lamb -3.140425 time 2019-01-30 01:26:47.650194
Pre: time 2019-01-30 01:30:20.573921: 
 	std: 0.00467456
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 18)]
	test_accs: [0.21125, 0.21393333, 0.20203333, 0.2155, 0.21001667]
	train_accs: [0.21125, 0.21393333, 0.20203333, 0.2155, 0.21001667]
	best_train_sub_head: 3
	worst: 0.20203333
	avg: 0.21054669
	best: 0.2155

Starting e_i: 231
Model ind 579 epoch 231 head B head_i_epoch 0 batch 0: avg loss -1.532780 avg loss no lamb -1.532780 time 2019-01-30 01:30:27.848355
Model ind 579 epoch 231 head B head_i_epoch 0 batch 100: avg loss -1.634097 avg loss no lamb -1.634097 time 2019-01-30 01:33:31.890717
Model ind 579 epoch 231 head B head_i_epoch 0 batch 200: avg loss -1.703654 avg loss no lamb -1.703654 time 2019-01-30 01:36:36.598614
Model ind 579 epoch 231 head A head_i_epoch 0 batch 0: avg loss -3.141717 avg loss no lamb -3.141717 time 2019-01-30 01:39:41.252418
Model ind 579 epoch 231 head A head_i_epoch 0 batch 100: avg loss -3.153397 avg loss no lamb -3.153397 time 2019-01-30 01:42:47.010408
Model ind 579 epoch 231 head A head_i_epoch 0 batch 200: avg loss -3.098162 avg loss no lamb -3.098162 time 2019-01-30 01:45:52.576207
Pre: time 2019-01-30 01:49:26.008864: 
 	std: 0.005850199
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 18)]
	test_accs: [0.21798334, 0.22098333, 0.2058, 0.22231667, 0.21776667]
	train_accs: [0.21798334, 0.22098333, 0.2058, 0.22231667, 0.21776667]
	best_train_sub_head: 3
	worst: 0.2058
	avg: 0.21697001
	best: 0.22231667

Starting e_i: 232
Model ind 579 epoch 232 head B head_i_epoch 0 batch 0: avg loss -1.654558 avg loss no lamb -1.654558 time 2019-01-30 01:49:29.042269
Model ind 579 epoch 232 head B head_i_epoch 0 batch 100: avg loss -1.648494 avg loss no lamb -1.648494 time 2019-01-30 01:52:34.161960
Model ind 579 epoch 232 head B head_i_epoch 0 batch 200: avg loss -1.666752 avg loss no lamb -1.666752 time 2019-01-30 01:55:39.748658
Model ind 579 epoch 232 head A head_i_epoch 0 batch 0: avg loss -3.147570 avg loss no lamb -3.147570 time 2019-01-30 01:58:46.011333
Model ind 579 epoch 232 head A head_i_epoch 0 batch 100: avg loss -3.180817 avg loss no lamb -3.180817 time 2019-01-30 02:01:51.520952
Model ind 579 epoch 232 head A head_i_epoch 0 batch 200: avg loss -3.146951 avg loss no lamb -3.146951 time 2019-01-30 02:04:57.214190
Pre: time 2019-01-30 02:08:29.259979: 
 	std: 0.0044470634
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 18)]
	test_accs: [0.21613333, 0.21858333, 0.20715, 0.21931666, 0.21283333]
	train_accs: [0.21613333, 0.21858333, 0.20715, 0.21931666, 0.21283333]
	best_train_sub_head: 3
	worst: 0.20715
	avg: 0.21480331
	best: 0.21931666

Starting e_i: 233
Model ind 579 epoch 233 head B head_i_epoch 0 batch 0: avg loss -1.629153 avg loss no lamb -1.629153 time 2019-01-30 02:08:32.145226
Model ind 579 epoch 233 head B head_i_epoch 0 batch 100: avg loss -1.617910 avg loss no lamb -1.617910 time 2019-01-30 02:11:36.543113
Model ind 579 epoch 233 head B head_i_epoch 0 batch 200: avg loss -1.582742 avg loss no lamb -1.582742 time 2019-01-30 02:14:40.763577
Model ind 579 epoch 233 head A head_i_epoch 0 batch 0: avg loss -3.114197 avg loss no lamb -3.114197 time 2019-01-30 02:17:45.445430
Model ind 579 epoch 233 head A head_i_epoch 0 batch 100: avg loss -3.126319 avg loss no lamb -3.126319 time 2019-01-30 02:20:52.892252
Model ind 579 epoch 233 head A head_i_epoch 0 batch 200: avg loss -3.215812 avg loss no lamb -3.215812 time 2019-01-30 02:23:59.727843
Pre: time 2019-01-30 02:27:31.089845: 
 	std: 0.0046037748
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.22205, 0.22516666, 0.21221666, 0.22385, 0.2191]
	train_accs: [0.22205, 0.22516666, 0.21221666, 0.22385, 0.2191]
	best_train_sub_head: 1
	worst: 0.21221666
	avg: 0.22047667
	best: 0.22516666

Starting e_i: 234
Model ind 579 epoch 234 head B head_i_epoch 0 batch 0: avg loss -1.609981 avg loss no lamb -1.609981 time 2019-01-30 02:27:34.012303
Model ind 579 epoch 234 head B head_i_epoch 0 batch 100: avg loss -1.628386 avg loss no lamb -1.628386 time 2019-01-30 02:30:38.936853
Model ind 579 epoch 234 head B head_i_epoch 0 batch 200: avg loss -1.676591 avg loss no lamb -1.676591 time 2019-01-30 02:33:42.841129
Model ind 579 epoch 234 head A head_i_epoch 0 batch 0: avg loss -3.119046 avg loss no lamb -3.119046 time 2019-01-30 02:36:46.890342
Model ind 579 epoch 234 head A head_i_epoch 0 batch 100: avg loss -3.165700 avg loss no lamb -3.165700 time 2019-01-30 02:39:52.388470
Model ind 579 epoch 234 head A head_i_epoch 0 batch 200: avg loss -3.131272 avg loss no lamb -3.131272 time 2019-01-30 02:42:57.965830
Pre: time 2019-01-30 02:46:29.362317: 
 	std: 0.0013301079
	best_train_sub_head_match: [(0, 19), (1, 2), (2, 6), (3, 11), (4, 3), (5, 1), (6, 12), (7, 18), (8, 14), (9, 17), (10, 4), (11, 5), (12, 8), (13, 15), (14, 13), (15, 7), (16, 9), (17, 0), (18, 10), (19, 16)]
	test_accs: [0.21183333, 0.21455, 0.21561667, 0.21528333, 0.21433334]
	train_accs: [0.21183333, 0.21455, 0.21561667, 0.21528333, 0.21433334]
	best_train_sub_head: 2
	worst: 0.21183333
	avg: 0.21432333
	best: 0.21561667

Starting e_i: 235
Model ind 579 epoch 235 head B head_i_epoch 0 batch 0: avg loss -1.571195 avg loss no lamb -1.571195 time 2019-01-30 02:46:32.397409
Model ind 579 epoch 235 head B head_i_epoch 0 batch 100: avg loss -1.559670 avg loss no lamb -1.559670 time 2019-01-30 02:49:36.780799
Model ind 579 epoch 235 head B head_i_epoch 0 batch 200: avg loss -1.694954 avg loss no lamb -1.694954 time 2019-01-30 02:52:40.609619
Model ind 579 epoch 235 head A head_i_epoch 0 batch 0: avg loss -3.122330 avg loss no lamb -3.122330 time 2019-01-30 02:55:46.204189
Model ind 579 epoch 235 head A head_i_epoch 0 batch 100: avg loss -3.144386 avg loss no lamb -3.144386 time 2019-01-30 02:58:52.773185
Model ind 579 epoch 235 head A head_i_epoch 0 batch 200: avg loss -3.205517 avg loss no lamb -3.205517 time 2019-01-30 03:01:59.647010
Pre: time 2019-01-30 03:05:31.801820: 
 	std: 0.003145429
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 13), (13, 1), (14, 5), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.21671666, 0.22033334, 0.21176666, 0.22015, 0.21601667]
	train_accs: [0.21671666, 0.22033334, 0.21176666, 0.22015, 0.21601667]
	best_train_sub_head: 1
	worst: 0.21176666
	avg: 0.21699667
	best: 0.22033334

Starting e_i: 236
Model ind 579 epoch 236 head B head_i_epoch 0 batch 0: avg loss -1.578246 avg loss no lamb -1.578246 time 2019-01-30 03:05:34.920535
Model ind 579 epoch 236 head B head_i_epoch 0 batch 100: avg loss -1.569588 avg loss no lamb -1.569588 time 2019-01-30 03:08:39.617262
Model ind 579 epoch 236 head B head_i_epoch 0 batch 200: avg loss -1.716199 avg loss no lamb -1.716199 time 2019-01-30 03:11:44.352248
Model ind 579 epoch 236 head A head_i_epoch 0 batch 0: avg loss -3.135602 avg loss no lamb -3.135602 time 2019-01-30 03:14:48.109491
Model ind 579 epoch 236 head A head_i_epoch 0 batch 100: avg loss -3.156954 avg loss no lamb -3.156954 time 2019-01-30 03:17:53.998211
Model ind 579 epoch 236 head A head_i_epoch 0 batch 200: avg loss -3.193492 avg loss no lamb -3.193492 time 2019-01-30 03:20:59.073310
Pre: time 2019-01-30 03:24:31.518040: 
 	std: 0.0035965669
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 13), (4, 4), (5, 19), (6, 8), (7, 11), (8, 3), (9, 16), (10, 15), (11, 17), (12, 7), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.21663333, 0.21943334, 0.20911667, 0.21826667, 0.2161]
	train_accs: [0.21663333, 0.21943334, 0.20911667, 0.21826667, 0.2161]
	best_train_sub_head: 1
	worst: 0.20911667
	avg: 0.21591
	best: 0.21943334

Starting e_i: 237
Model ind 579 epoch 237 head B head_i_epoch 0 batch 0: avg loss -1.492147 avg loss no lamb -1.492147 time 2019-01-30 03:24:34.505504
Model ind 579 epoch 237 head B head_i_epoch 0 batch 100: avg loss -1.627304 avg loss no lamb -1.627304 time 2019-01-30 03:27:39.270102
Model ind 579 epoch 237 head B head_i_epoch 0 batch 200: avg loss -1.594461 avg loss no lamb -1.594461 time 2019-01-30 03:30:43.585337
Model ind 579 epoch 237 head A head_i_epoch 0 batch 0: avg loss -3.101895 avg loss no lamb -3.101895 time 2019-01-30 03:33:48.976304
Model ind 579 epoch 237 head A head_i_epoch 0 batch 100: avg loss -3.106785 avg loss no lamb -3.106785 time 2019-01-30 03:36:55.881486
Model ind 579 epoch 237 head A head_i_epoch 0 batch 200: avg loss -3.222292 avg loss no lamb -3.222292 time 2019-01-30 03:40:01.911071
Pre: time 2019-01-30 03:43:33.559180: 
 	std: 0.0023667507
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 5), (4, 4), (5, 3), (6, 18), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 19)]
	test_accs: [0.21746667, 0.22108333, 0.21508333, 0.22125, 0.21748333]
	train_accs: [0.21746667, 0.22108333, 0.21508333, 0.22125, 0.21748333]
	best_train_sub_head: 3
	worst: 0.21508333
	avg: 0.21847335
	best: 0.22125

Starting e_i: 238
Model ind 579 epoch 238 head B head_i_epoch 0 batch 0: avg loss -1.645590 avg loss no lamb -1.645590 time 2019-01-30 03:43:36.750489
Model ind 579 epoch 238 head B head_i_epoch 0 batch 100: avg loss -1.641588 avg loss no lamb -1.641588 time 2019-01-30 03:46:41.634144
Model ind 579 epoch 238 head B head_i_epoch 0 batch 200: avg loss -1.612201 avg loss no lamb -1.612201 time 2019-01-30 03:49:46.371642
Model ind 579 epoch 238 head A head_i_epoch 0 batch 0: avg loss -3.133773 avg loss no lamb -3.133773 time 2019-01-30 03:52:50.917045
Model ind 579 epoch 238 head A head_i_epoch 0 batch 100: avg loss -3.162488 avg loss no lamb -3.162488 time 2019-01-30 03:55:57.093398
Model ind 579 epoch 238 head A head_i_epoch 0 batch 200: avg loss -3.215472 avg loss no lamb -3.215472 time 2019-01-30 03:59:04.021673
Pre: time 2019-01-30 04:02:34.409707: 
 	std: 0.0029357488
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 8), (7, 11), (8, 3), (9, 16), (10, 5), (11, 17), (12, 7), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.21503334, 0.21846667, 0.20963334, 0.21646667, 0.21445]
	train_accs: [0.21503334, 0.21846667, 0.20963334, 0.21646667, 0.21445]
	best_train_sub_head: 1
	worst: 0.20963334
	avg: 0.21480998
	best: 0.21846667

Starting e_i: 239
Model ind 579 epoch 239 head B head_i_epoch 0 batch 0: avg loss -1.549487 avg loss no lamb -1.549487 time 2019-01-30 04:02:37.330611
Model ind 579 epoch 239 head B head_i_epoch 0 batch 100: avg loss -1.588715 avg loss no lamb -1.588715 time 2019-01-30 04:05:41.757840
Model ind 579 epoch 239 head B head_i_epoch 0 batch 200: avg loss -1.654192 avg loss no lamb -1.654192 time 2019-01-30 04:08:46.553645
Model ind 579 epoch 239 head A head_i_epoch 0 batch 0: avg loss -3.138393 avg loss no lamb -3.138393 time 2019-01-30 04:11:55.159268
Model ind 579 epoch 239 head A head_i_epoch 0 batch 100: avg loss -3.174180 avg loss no lamb -3.174180 time 2019-01-30 04:15:04.816104
Model ind 579 epoch 239 head A head_i_epoch 0 batch 200: avg loss -3.195046 avg loss no lamb -3.195046 time 2019-01-30 04:18:10.701336
Pre: time 2019-01-30 04:21:40.781996: 
 	std: 0.0041963286
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 19), (3, 13), (4, 4), (5, 7), (6, 12), (7, 11), (8, 3), (9, 0), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 2), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.2106, 0.21165, 0.20048334, 0.2115, 0.2078]
	train_accs: [0.2106, 0.21165, 0.20048334, 0.2115, 0.2078]
	best_train_sub_head: 1
	worst: 0.20048334
	avg: 0.20840666
	best: 0.21165

Starting e_i: 240
Model ind 579 epoch 240 head B head_i_epoch 0 batch 0: avg loss -1.560308 avg loss no lamb -1.560308 time 2019-01-30 04:21:43.873495
Model ind 579 epoch 240 head B head_i_epoch 0 batch 100: avg loss -1.640875 avg loss no lamb -1.640875 time 2019-01-30 04:24:48.051910
Model ind 579 epoch 240 head B head_i_epoch 0 batch 200: avg loss -1.652144 avg loss no lamb -1.652144 time 2019-01-30 04:27:53.468110
Model ind 579 epoch 240 head A head_i_epoch 0 batch 0: avg loss -3.134377 avg loss no lamb -3.134377 time 2019-01-30 04:30:57.554916
Model ind 579 epoch 240 head A head_i_epoch 0 batch 100: avg loss -3.145979 avg loss no lamb -3.145979 time 2019-01-30 04:34:04.253523
Model ind 579 epoch 240 head A head_i_epoch 0 batch 200: avg loss -3.140064 avg loss no lamb -3.140064 time 2019-01-30 04:37:09.074061
Pre: time 2019-01-30 04:40:41.951389: 
 	std: 0.003584834
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 5), (3, 15), (4, 4), (5, 19), (6, 13), (7, 11), (8, 3), (9, 2), (10, 8), (11, 17), (12, 7), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.22071667, 0.22276667, 0.21256667, 0.22088334, 0.2175]
	train_accs: [0.22071667, 0.22276667, 0.21256667, 0.22088334, 0.2175]
	best_train_sub_head: 1
	worst: 0.21256667
	avg: 0.21888666
	best: 0.22276667

Starting e_i: 241
Model ind 579 epoch 241 head B head_i_epoch 0 batch 0: avg loss -1.512589 avg loss no lamb -1.512589 time 2019-01-30 04:40:49.118889
Model ind 579 epoch 241 head B head_i_epoch 0 batch 100: avg loss -1.610924 avg loss no lamb -1.610924 time 2019-01-30 04:43:52.669947
Model ind 579 epoch 241 head B head_i_epoch 0 batch 200: avg loss -1.661434 avg loss no lamb -1.661434 time 2019-01-30 04:46:55.829494
Model ind 579 epoch 241 head A head_i_epoch 0 batch 0: avg loss -3.119195 avg loss no lamb -3.119195 time 2019-01-30 04:49:59.350134
Model ind 579 epoch 241 head A head_i_epoch 0 batch 100: avg loss -3.186761 avg loss no lamb -3.186761 time 2019-01-30 04:53:04.649246
Model ind 579 epoch 241 head A head_i_epoch 0 batch 200: avg loss -3.123333 avg loss no lamb -3.123333 time 2019-01-30 04:56:12.497278
Pre: time 2019-01-30 04:59:44.229452: 
 	std: 0.005225374
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 13), (4, 4), (5, 19), (6, 8), (7, 11), (8, 3), (9, 16), (10, 15), (11, 17), (12, 7), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.21443333, 0.2151, 0.20135, 0.21491666, 0.21086666]
	train_accs: [0.21443333, 0.2151, 0.20135, 0.21491666, 0.21086666]
	best_train_sub_head: 1
	worst: 0.20135
	avg: 0.21133332
	best: 0.2151

Starting e_i: 242
Model ind 579 epoch 242 head B head_i_epoch 0 batch 0: avg loss -1.599117 avg loss no lamb -1.599117 time 2019-01-30 04:59:47.318467
Model ind 579 epoch 242 head B head_i_epoch 0 batch 100: avg loss -1.593897 avg loss no lamb -1.593897 time 2019-01-30 05:02:53.089167
Model ind 579 epoch 242 head B head_i_epoch 0 batch 200: avg loss -1.611810 avg loss no lamb -1.611810 time 2019-01-30 05:05:58.208074
Model ind 579 epoch 242 head A head_i_epoch 0 batch 0: avg loss -3.112582 avg loss no lamb -3.112582 time 2019-01-30 05:09:03.638945
Model ind 579 epoch 242 head A head_i_epoch 0 batch 100: avg loss -3.201872 avg loss no lamb -3.201872 time 2019-01-30 05:12:10.055755
Model ind 579 epoch 242 head A head_i_epoch 0 batch 200: avg loss -3.166080 avg loss no lamb -3.166080 time 2019-01-30 05:15:16.456609
Pre: time 2019-01-30 05:18:48.896234: 
 	std: 0.0029821112
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 8), (7, 11), (8, 3), (9, 16), (10, 15), (11, 17), (12, 7), (13, 1), (14, 5), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.21461667, 0.21871667, 0.2098, 0.21685, 0.21476667]
	train_accs: [0.21461667, 0.21871667, 0.2098, 0.21685, 0.21476667]
	best_train_sub_head: 1
	worst: 0.2098
	avg: 0.21495
	best: 0.21871667

Starting e_i: 243
Model ind 579 epoch 243 head B head_i_epoch 0 batch 0: avg loss -1.636081 avg loss no lamb -1.636081 time 2019-01-30 05:18:52.159117
Model ind 579 epoch 243 head B head_i_epoch 0 batch 100: avg loss -1.564398 avg loss no lamb -1.564398 time 2019-01-30 05:21:55.475736
Model ind 579 epoch 243 head B head_i_epoch 0 batch 200: avg loss -1.632658 avg loss no lamb -1.632658 time 2019-01-30 05:24:59.641058
Model ind 579 epoch 243 head A head_i_epoch 0 batch 0: avg loss -3.147385 avg loss no lamb -3.147385 time 2019-01-30 05:28:04.338693
Model ind 579 epoch 243 head A head_i_epoch 0 batch 100: avg loss -3.162287 avg loss no lamb -3.162287 time 2019-01-30 05:31:09.843453
Model ind 579 epoch 243 head A head_i_epoch 0 batch 200: avg loss -3.151054 avg loss no lamb -3.151054 time 2019-01-30 05:34:16.523837
Pre: time 2019-01-30 05:37:46.680037: 
 	std: 0.004318855
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.21613333, 0.22113334, 0.2084, 0.21881667, 0.21486667]
	train_accs: [0.21613333, 0.22113334, 0.2084, 0.21881667, 0.21486667]
	best_train_sub_head: 1
	worst: 0.2084
	avg: 0.21587
	best: 0.22113334

Starting e_i: 244
Model ind 579 epoch 244 head B head_i_epoch 0 batch 0: avg loss -1.560670 avg loss no lamb -1.560670 time 2019-01-30 05:37:49.836002
Model ind 579 epoch 244 head B head_i_epoch 0 batch 100: avg loss -1.589394 avg loss no lamb -1.589394 time 2019-01-30 05:40:52.498788
Model ind 579 epoch 244 head B head_i_epoch 0 batch 200: avg loss -1.636885 avg loss no lamb -1.636885 time 2019-01-30 05:43:55.470172
Model ind 579 epoch 244 head A head_i_epoch 0 batch 0: avg loss -3.148827 avg loss no lamb -3.148827 time 2019-01-30 05:46:57.666524
Model ind 579 epoch 244 head A head_i_epoch 0 batch 100: avg loss -3.131742 avg loss no lamb -3.131742 time 2019-01-30 05:50:02.551812
Model ind 579 epoch 244 head A head_i_epoch 0 batch 200: avg loss -3.176066 avg loss no lamb -3.176066 time 2019-01-30 05:53:07.457160
Pre: time 2019-01-30 05:56:40.122029: 
 	std: 0.0021838283
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 7), (6, 8), (7, 11), (8, 3), (9, 16), (10, 18), (11, 17), (12, 5), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.21415, 0.21833333, 0.21188334, 0.21658333, 0.21538334]
	train_accs: [0.21415, 0.21833333, 0.21188334, 0.21658333, 0.21538334]
	best_train_sub_head: 1
	worst: 0.21188334
	avg: 0.21526666
	best: 0.21833333

Starting e_i: 245
Model ind 579 epoch 245 head B head_i_epoch 0 batch 0: avg loss -1.498395 avg loss no lamb -1.498395 time 2019-01-30 05:56:42.999224
Model ind 579 epoch 245 head B head_i_epoch 0 batch 100: avg loss -1.644818 avg loss no lamb -1.644818 time 2019-01-30 05:59:47.257231
Model ind 579 epoch 245 head B head_i_epoch 0 batch 200: avg loss -1.688916 avg loss no lamb -1.688916 time 2019-01-30 06:02:52.023458
Model ind 579 epoch 245 head A head_i_epoch 0 batch 0: avg loss -3.076525 avg loss no lamb -3.076525 time 2019-01-30 06:05:55.544079
Model ind 579 epoch 245 head A head_i_epoch 0 batch 100: avg loss -3.166660 avg loss no lamb -3.166660 time 2019-01-30 06:09:00.737711
Model ind 579 epoch 245 head A head_i_epoch 0 batch 200: avg loss -3.194666 avg loss no lamb -3.194666 time 2019-01-30 06:12:06.418904
Pre: time 2019-01-30 06:15:37.450899: 
 	std: 0.0024888536
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.21556666, 0.21951666, 0.21246667, 0.21863334, 0.21703333]
	train_accs: [0.21556666, 0.21951666, 0.21246667, 0.21863334, 0.21703333]
	best_train_sub_head: 1
	worst: 0.21246667
	avg: 0.21664333
	best: 0.21951666

Starting e_i: 246
Model ind 579 epoch 246 head B head_i_epoch 0 batch 0: avg loss -1.487451 avg loss no lamb -1.487451 time 2019-01-30 06:15:40.706068
Model ind 579 epoch 246 head B head_i_epoch 0 batch 100: avg loss -1.583142 avg loss no lamb -1.583142 time 2019-01-30 06:18:43.676298
Model ind 579 epoch 246 head B head_i_epoch 0 batch 200: avg loss -1.639400 avg loss no lamb -1.639400 time 2019-01-30 06:21:47.789775
Model ind 579 epoch 246 head A head_i_epoch 0 batch 0: avg loss -3.164772 avg loss no lamb -3.164772 time 2019-01-30 06:24:51.291255
Model ind 579 epoch 246 head A head_i_epoch 0 batch 100: avg loss -3.145292 avg loss no lamb -3.145292 time 2019-01-30 06:27:55.776475
Model ind 579 epoch 246 head A head_i_epoch 0 batch 200: avg loss -3.219229 avg loss no lamb -3.219229 time 2019-01-30 06:31:00.556458
Pre: time 2019-01-30 06:34:30.307226: 
 	std: 0.00425457
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.22055, 0.22275, 0.21108334, 0.2223, 0.22003333]
	train_accs: [0.22055, 0.22275, 0.21108334, 0.2223, 0.22003333]
	best_train_sub_head: 1
	worst: 0.21108334
	avg: 0.21934333
	best: 0.22275

Starting e_i: 247
Model ind 579 epoch 247 head B head_i_epoch 0 batch 0: avg loss -1.519405 avg loss no lamb -1.519405 time 2019-01-30 06:34:33.126977
Model ind 579 epoch 247 head B head_i_epoch 0 batch 100: avg loss -1.580677 avg loss no lamb -1.580677 time 2019-01-30 06:37:37.116998
Model ind 579 epoch 247 head B head_i_epoch 0 batch 200: avg loss -1.628101 avg loss no lamb -1.628101 time 2019-01-30 06:40:42.140184
Model ind 579 epoch 247 head A head_i_epoch 0 batch 0: avg loss -3.088982 avg loss no lamb -3.088982 time 2019-01-30 06:43:45.738144
Model ind 579 epoch 247 head A head_i_epoch 0 batch 100: avg loss -3.207179 avg loss no lamb -3.207179 time 2019-01-30 06:46:51.824594
Model ind 579 epoch 247 head A head_i_epoch 0 batch 200: avg loss -3.214595 avg loss no lamb -3.214595 time 2019-01-30 06:49:58.638539
Pre: time 2019-01-30 06:53:30.289657: 
 	std: 0.004551475
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 13), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 5), (19, 18)]
	test_accs: [0.21536666, 0.21828334, 0.20651667, 0.21838333, 0.21813333]
	train_accs: [0.21536666, 0.21828334, 0.20651667, 0.21838333, 0.21813333]
	best_train_sub_head: 3
	worst: 0.20651667
	avg: 0.21533665
	best: 0.21838333

Starting e_i: 248
Model ind 579 epoch 248 head B head_i_epoch 0 batch 0: avg loss -1.592070 avg loss no lamb -1.592070 time 2019-01-30 06:53:33.300957
Model ind 579 epoch 248 head B head_i_epoch 0 batch 100: avg loss -1.620344 avg loss no lamb -1.620344 time 2019-01-30 06:56:36.225836
Model ind 579 epoch 248 head B head_i_epoch 0 batch 200: avg loss -1.628583 avg loss no lamb -1.628583 time 2019-01-30 06:59:39.838709
Model ind 579 epoch 248 head A head_i_epoch 0 batch 0: avg loss -3.198802 avg loss no lamb -3.198802 time 2019-01-30 07:02:44.353744
Model ind 579 epoch 248 head A head_i_epoch 0 batch 100: avg loss -3.152992 avg loss no lamb -3.152992 time 2019-01-30 07:05:49.296918
Model ind 579 epoch 248 head A head_i_epoch 0 batch 200: avg loss -3.124653 avg loss no lamb -3.124653 time 2019-01-30 07:08:54.650752
Pre: time 2019-01-30 07:12:26.520674: 
 	std: 0.0041669365
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.22403333, 0.22633334, 0.215, 0.22593333, 0.22446667]
	train_accs: [0.22403333, 0.22633334, 0.215, 0.22593333, 0.22446667]
	best_train_sub_head: 1
	worst: 0.215
	avg: 0.22315332
	best: 0.22633334

Starting e_i: 249
Model ind 579 epoch 249 head B head_i_epoch 0 batch 0: avg loss -1.538244 avg loss no lamb -1.538244 time 2019-01-30 07:12:33.665906
Model ind 579 epoch 249 head B head_i_epoch 0 batch 100: avg loss -1.668850 avg loss no lamb -1.668850 time 2019-01-30 07:15:39.300646
Model ind 579 epoch 249 head B head_i_epoch 0 batch 200: avg loss -1.682356 avg loss no lamb -1.682356 time 2019-01-30 07:18:42.920183
Model ind 579 epoch 249 head A head_i_epoch 0 batch 0: avg loss -3.179617 avg loss no lamb -3.179617 time 2019-01-30 07:21:46.841344
Model ind 579 epoch 249 head A head_i_epoch 0 batch 100: avg loss -3.160488 avg loss no lamb -3.160488 time 2019-01-30 07:24:50.961527
Model ind 579 epoch 249 head A head_i_epoch 0 batch 200: avg loss -3.206658 avg loss no lamb -3.206658 time 2019-01-30 07:27:55.473437
Pre: time 2019-01-30 07:31:25.912469: 
 	std: 0.0036432643
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 13), (3, 9), (4, 12), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 5), (12, 16), (13, 18), (14, 1), (15, 15), (16, 6), (17, 3), (18, 19), (19, 8)]
	test_accs: [0.21125, 0.21446666, 0.20565, 0.2135, 0.21616666]
	train_accs: [0.21125, 0.21446666, 0.20565, 0.2135, 0.21616666]
	best_train_sub_head: 4
	worst: 0.20565
	avg: 0.21220665
	best: 0.21616666

Starting e_i: 250
Model ind 579 epoch 250 head B head_i_epoch 0 batch 0: avg loss -1.509498 avg loss no lamb -1.509498 time 2019-01-30 07:31:28.868120
Model ind 579 epoch 250 head B head_i_epoch 0 batch 100: avg loss -1.595116 avg loss no lamb -1.595116 time 2019-01-30 07:34:32.627879
Model ind 579 epoch 250 head B head_i_epoch 0 batch 200: avg loss -1.580588 avg loss no lamb -1.580588 time 2019-01-30 07:37:37.503983
Model ind 579 epoch 250 head A head_i_epoch 0 batch 0: avg loss -3.129407 avg loss no lamb -3.129407 time 2019-01-30 07:40:41.069095
Model ind 579 epoch 250 head A head_i_epoch 0 batch 100: avg loss -3.201333 avg loss no lamb -3.201333 time 2019-01-30 07:43:46.687037
Model ind 579 epoch 250 head A head_i_epoch 0 batch 200: avg loss -3.142878 avg loss no lamb -3.142878 time 2019-01-30 07:46:51.610619
Pre: time 2019-01-30 07:50:21.985073: 
 	std: 0.004486742
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 13), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.22175, 0.22401667, 0.21155, 0.22305, 0.2191]
	train_accs: [0.22175, 0.22401667, 0.21155, 0.22305, 0.2191]
	best_train_sub_head: 1
	worst: 0.21155
	avg: 0.21989334
	best: 0.22401667

Starting e_i: 251
Model ind 579 epoch 251 head B head_i_epoch 0 batch 0: avg loss -1.560006 avg loss no lamb -1.560006 time 2019-01-30 07:50:28.803892
Model ind 579 epoch 251 head B head_i_epoch 0 batch 100: avg loss -1.673021 avg loss no lamb -1.673021 time 2019-01-30 07:53:32.994936
Model ind 579 epoch 251 head B head_i_epoch 0 batch 200: avg loss -1.585750 avg loss no lamb -1.585750 time 2019-01-30 07:56:37.911927
Model ind 579 epoch 251 head A head_i_epoch 0 batch 0: avg loss -3.132582 avg loss no lamb -3.132582 time 2019-01-30 07:59:41.373728
Model ind 579 epoch 251 head A head_i_epoch 0 batch 100: avg loss -3.104522 avg loss no lamb -3.104522 time 2019-01-30 08:02:46.479535
Model ind 579 epoch 251 head A head_i_epoch 0 batch 200: avg loss -3.199472 avg loss no lamb -3.199472 time 2019-01-30 08:05:50.622225
Pre: time 2019-01-30 08:09:22.989960: 
 	std: 0.004424535
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 13), (13, 1), (14, 5), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.21725, 0.22246666, 0.20993334, 0.22146666, 0.21855]
	train_accs: [0.21725, 0.22246666, 0.20993334, 0.22146666, 0.21855]
	best_train_sub_head: 1
	worst: 0.20993334
	avg: 0.21793333
	best: 0.22246666

Starting e_i: 252
Model ind 579 epoch 252 head B head_i_epoch 0 batch 0: avg loss -1.596441 avg loss no lamb -1.596441 time 2019-01-30 08:09:26.396588
Model ind 579 epoch 252 head B head_i_epoch 0 batch 100: avg loss -1.541446 avg loss no lamb -1.541446 time 2019-01-30 08:12:30.037252
Model ind 579 epoch 252 head B head_i_epoch 0 batch 200: avg loss -1.615097 avg loss no lamb -1.615097 time 2019-01-30 08:15:34.215755
Model ind 579 epoch 252 head A head_i_epoch 0 batch 0: avg loss -3.118342 avg loss no lamb -3.118342 time 2019-01-30 08:18:37.690861
Model ind 579 epoch 252 head A head_i_epoch 0 batch 100: avg loss -3.221165 avg loss no lamb -3.221165 time 2019-01-30 08:21:42.930544
Model ind 579 epoch 252 head A head_i_epoch 0 batch 200: avg loss -3.155439 avg loss no lamb -3.155439 time 2019-01-30 08:24:49.067656
Pre: time 2019-01-30 08:28:20.212099: 
 	std: 0.0025390624
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 8), (8, 6), (9, 14), (10, 9), (11, 13), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 5), (19, 19)]
	test_accs: [0.21901667, 0.22138333, 0.21471667, 0.22161667, 0.21781667]
	train_accs: [0.21901667, 0.22138333, 0.21471667, 0.22161667, 0.21781667]
	best_train_sub_head: 3
	worst: 0.21471667
	avg: 0.21891001
	best: 0.22161667

Starting e_i: 253
Model ind 579 epoch 253 head B head_i_epoch 0 batch 0: avg loss -1.597999 avg loss no lamb -1.597999 time 2019-01-30 08:28:23.578811
Model ind 579 epoch 253 head B head_i_epoch 0 batch 100: avg loss -1.674308 avg loss no lamb -1.674308 time 2019-01-30 08:31:27.775117
Model ind 579 epoch 253 head B head_i_epoch 0 batch 200: avg loss -1.677840 avg loss no lamb -1.677840 time 2019-01-30 08:34:31.687378
Model ind 579 epoch 253 head A head_i_epoch 0 batch 0: avg loss -3.177207 avg loss no lamb -3.177207 time 2019-01-30 08:37:34.875349
Model ind 579 epoch 253 head A head_i_epoch 0 batch 100: avg loss -3.166124 avg loss no lamb -3.166124 time 2019-01-30 08:40:38.758087
Model ind 579 epoch 253 head A head_i_epoch 0 batch 200: avg loss -3.134877 avg loss no lamb -3.134877 time 2019-01-30 08:43:43.562673
Pre: time 2019-01-30 08:47:12.951911: 
 	std: 0.003763858
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 8), (7, 11), (8, 3), (9, 16), (10, 13), (11, 17), (12, 7), (13, 1), (14, 5), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.21891667, 0.22083333, 0.21075, 0.22068334, 0.21951666]
	train_accs: [0.21891667, 0.22083333, 0.21075, 0.22068334, 0.21951666]
	best_train_sub_head: 1
	worst: 0.21075
	avg: 0.21814
	best: 0.22083333

Starting e_i: 254
Model ind 579 epoch 254 head B head_i_epoch 0 batch 0: avg loss -1.579697 avg loss no lamb -1.579697 time 2019-01-30 08:47:15.848555
Model ind 579 epoch 254 head B head_i_epoch 0 batch 100: avg loss -1.647929 avg loss no lamb -1.647929 time 2019-01-30 08:50:19.596448
Model ind 579 epoch 254 head B head_i_epoch 0 batch 200: avg loss -1.687553 avg loss no lamb -1.687553 time 2019-01-30 08:53:23.434660
Model ind 579 epoch 254 head A head_i_epoch 0 batch 0: avg loss -3.101712 avg loss no lamb -3.101712 time 2019-01-30 08:56:26.887020
Model ind 579 epoch 254 head A head_i_epoch 0 batch 100: avg loss -3.152704 avg loss no lamb -3.152704 time 2019-01-30 08:59:33.101478
Model ind 579 epoch 254 head A head_i_epoch 0 batch 200: avg loss -3.153884 avg loss no lamb -3.153884 time 2019-01-30 09:02:38.760316
Pre: time 2019-01-30 09:06:12.271547: 
 	std: 0.0049586277
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 13), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.21856667, 0.22216667, 0.20875, 0.22193334, 0.21553333]
	train_accs: [0.21856667, 0.22216667, 0.20875, 0.22193334, 0.21553333]
	best_train_sub_head: 1
	worst: 0.20875
	avg: 0.21739002
	best: 0.22216667

Starting e_i: 255
Model ind 579 epoch 255 head B head_i_epoch 0 batch 0: avg loss -1.499014 avg loss no lamb -1.499014 time 2019-01-30 09:06:15.371532
Model ind 579 epoch 255 head B head_i_epoch 0 batch 100: avg loss -1.595926 avg loss no lamb -1.595926 time 2019-01-30 09:09:19.807952
Model ind 579 epoch 255 head B head_i_epoch 0 batch 200: avg loss -1.728996 avg loss no lamb -1.728996 time 2019-01-30 09:12:24.287924
Model ind 579 epoch 255 head A head_i_epoch 0 batch 0: avg loss -3.109465 avg loss no lamb -3.109465 time 2019-01-30 09:15:27.788247
Model ind 579 epoch 255 head A head_i_epoch 0 batch 100: avg loss -3.180003 avg loss no lamb -3.180003 time 2019-01-30 09:18:34.465785
Model ind 579 epoch 255 head A head_i_epoch 0 batch 200: avg loss -3.205126 avg loss no lamb -3.205126 time 2019-01-30 09:21:39.269664
Pre: time 2019-01-30 09:25:08.834679: 
 	std: 0.004837109
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.2217, 0.22426666, 0.21091667, 0.22358334, 0.21925]
	train_accs: [0.2217, 0.22426666, 0.21091667, 0.22358334, 0.21925]
	best_train_sub_head: 1
	worst: 0.21091667
	avg: 0.21994333
	best: 0.22426666

Starting e_i: 256
Model ind 579 epoch 256 head B head_i_epoch 0 batch 0: avg loss -1.502494 avg loss no lamb -1.502494 time 2019-01-30 09:25:11.834924
Model ind 579 epoch 256 head B head_i_epoch 0 batch 100: avg loss -1.659729 avg loss no lamb -1.659729 time 2019-01-30 09:28:15.086624
Model ind 579 epoch 256 head B head_i_epoch 0 batch 200: avg loss -1.583669 avg loss no lamb -1.583669 time 2019-01-30 09:31:17.542043
Model ind 579 epoch 256 head A head_i_epoch 0 batch 0: avg loss -3.166814 avg loss no lamb -3.166814 time 2019-01-30 09:34:20.570908
Model ind 579 epoch 256 head A head_i_epoch 0 batch 100: avg loss -3.169947 avg loss no lamb -3.169947 time 2019-01-30 09:37:30.562404
Model ind 579 epoch 256 head A head_i_epoch 0 batch 200: avg loss -3.224717 avg loss no lamb -3.224717 time 2019-01-30 09:40:39.073512
Pre: time 2019-01-30 09:44:09.624467: 
 	std: 0.0045017614
	best_train_sub_head_match: [(0, 13), (1, 15), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 18)]
	test_accs: [0.22023334, 0.22298333, 0.21158333, 0.2237, 0.22286667]
	train_accs: [0.22023334, 0.22298333, 0.21158333, 0.2237, 0.22286667]
	best_train_sub_head: 3
	worst: 0.21158333
	avg: 0.22027333
	best: 0.2237

Starting e_i: 257
Model ind 579 epoch 257 head B head_i_epoch 0 batch 0: avg loss -1.599471 avg loss no lamb -1.599471 time 2019-01-30 09:44:12.837385
Model ind 579 epoch 257 head B head_i_epoch 0 batch 100: avg loss -1.642001 avg loss no lamb -1.642001 time 2019-01-30 09:47:16.453506
Model ind 579 epoch 257 head B head_i_epoch 0 batch 200: avg loss -1.643714 avg loss no lamb -1.643714 time 2019-01-30 09:50:20.118620
Model ind 579 epoch 257 head A head_i_epoch 0 batch 0: avg loss -3.129792 avg loss no lamb -3.129792 time 2019-01-30 09:53:23.173891
Model ind 579 epoch 257 head A head_i_epoch 0 batch 100: avg loss -3.117963 avg loss no lamb -3.117963 time 2019-01-30 09:56:28.657063
Model ind 579 epoch 257 head A head_i_epoch 0 batch 200: avg loss -3.206757 avg loss no lamb -3.206757 time 2019-01-30 09:59:32.568888
Pre: time 2019-01-30 10:03:03.212570: 
 	std: 0.002763185
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 15), (3, 13), (4, 4), (5, 5), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2211, 0.22266667, 0.21481666, 0.22156666, 0.21921666]
	train_accs: [0.2211, 0.22266667, 0.21481666, 0.22156666, 0.21921666]
	best_train_sub_head: 1
	worst: 0.21481666
	avg: 0.21987334
	best: 0.22266667

Starting e_i: 258
Model ind 579 epoch 258 head B head_i_epoch 0 batch 0: avg loss -1.567866 avg loss no lamb -1.567866 time 2019-01-30 10:03:06.151350
Model ind 579 epoch 258 head B head_i_epoch 0 batch 100: avg loss -1.606283 avg loss no lamb -1.606283 time 2019-01-30 10:06:09.190688
Model ind 579 epoch 258 head B head_i_epoch 0 batch 200: avg loss -1.628023 avg loss no lamb -1.628023 time 2019-01-30 10:09:11.751118
Model ind 579 epoch 258 head A head_i_epoch 0 batch 0: avg loss -3.116917 avg loss no lamb -3.116917 time 2019-01-30 10:12:15.618420
Model ind 579 epoch 258 head A head_i_epoch 0 batch 100: avg loss -3.179475 avg loss no lamb -3.179475 time 2019-01-30 10:15:20.213348
Model ind 579 epoch 258 head A head_i_epoch 0 batch 200: avg loss -3.201111 avg loss no lamb -3.201111 time 2019-01-30 10:18:24.632270
Pre: time 2019-01-30 10:21:56.423530: 
 	std: 0.004151797
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 8), (8, 6), (9, 14), (10, 9), (11, 5), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 19)]
	test_accs: [0.22013333, 0.22108333, 0.21031667, 0.22163333, 0.21775]
	train_accs: [0.22013333, 0.22108333, 0.21031667, 0.22163333, 0.21775]
	best_train_sub_head: 3
	worst: 0.21031667
	avg: 0.21818332
	best: 0.22163333

Starting e_i: 259
Model ind 579 epoch 259 head B head_i_epoch 0 batch 0: avg loss -1.533785 avg loss no lamb -1.533785 time 2019-01-30 10:21:59.334533
Model ind 579 epoch 259 head B head_i_epoch 0 batch 100: avg loss -1.629196 avg loss no lamb -1.629196 time 2019-01-30 10:25:03.863733
Model ind 579 epoch 259 head B head_i_epoch 0 batch 200: avg loss -1.647514 avg loss no lamb -1.647514 time 2019-01-30 10:28:08.065535
Model ind 579 epoch 259 head A head_i_epoch 0 batch 0: avg loss -3.160330 avg loss no lamb -3.160330 time 2019-01-30 10:31:11.942381
Model ind 579 epoch 259 head A head_i_epoch 0 batch 100: avg loss -3.215976 avg loss no lamb -3.215976 time 2019-01-30 10:34:16.843043
Model ind 579 epoch 259 head A head_i_epoch 0 batch 200: avg loss -3.241692 avg loss no lamb -3.241692 time 2019-01-30 10:37:21.284060
Pre: time 2019-01-30 10:40:51.252974: 
 	std: 0.00480839
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 2), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.22603333, 0.22845, 0.21505, 0.22743334, 0.22435]
	train_accs: [0.22603333, 0.22845, 0.21505, 0.22743334, 0.22435]
	best_train_sub_head: 1
	worst: 0.21505
	avg: 0.22426334
	best: 0.22845

Starting e_i: 260
Model ind 579 epoch 260 head B head_i_epoch 0 batch 0: avg loss -1.645398 avg loss no lamb -1.645398 time 2019-01-30 10:40:58.592992
Model ind 579 epoch 260 head B head_i_epoch 0 batch 100: avg loss -1.662682 avg loss no lamb -1.662682 time 2019-01-30 10:44:01.498128
Model ind 579 epoch 260 head B head_i_epoch 0 batch 200: avg loss -1.719865 avg loss no lamb -1.719865 time 2019-01-30 10:47:03.401593
Model ind 579 epoch 260 head A head_i_epoch 0 batch 0: avg loss -3.092268 avg loss no lamb -3.092268 time 2019-01-30 10:50:07.012821
Model ind 579 epoch 260 head A head_i_epoch 0 batch 100: avg loss -3.207346 avg loss no lamb -3.207346 time 2019-01-30 10:53:11.483142
Model ind 579 epoch 260 head A head_i_epoch 0 batch 200: avg loss -3.233667 avg loss no lamb -3.233667 time 2019-01-30 10:56:16.656462
Pre: time 2019-01-30 10:59:46.555445: 
 	std: 0.004418628
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.21818334, 0.21975, 0.20818333, 0.22038333, 0.2164]
	train_accs: [0.21818334, 0.21975, 0.20818333, 0.22038333, 0.2164]
	best_train_sub_head: 3
	worst: 0.20818333
	avg: 0.21658
	best: 0.22038333

Starting e_i: 261
Model ind 579 epoch 261 head B head_i_epoch 0 batch 0: avg loss -1.659844 avg loss no lamb -1.659844 time 2019-01-30 10:59:53.002400
Model ind 579 epoch 261 head B head_i_epoch 0 batch 100: avg loss -1.724676 avg loss no lamb -1.724676 time 2019-01-30 11:02:55.932901
Model ind 579 epoch 261 head B head_i_epoch 0 batch 200: avg loss -1.742476 avg loss no lamb -1.742476 time 2019-01-30 11:05:58.995809
Model ind 579 epoch 261 head A head_i_epoch 0 batch 0: avg loss -3.119122 avg loss no lamb -3.119122 time 2019-01-30 11:09:02.495489
Model ind 579 epoch 261 head A head_i_epoch 0 batch 100: avg loss -3.217228 avg loss no lamb -3.217228 time 2019-01-30 11:12:08.194692
Model ind 579 epoch 261 head A head_i_epoch 0 batch 200: avg loss -3.193785 avg loss no lamb -3.193785 time 2019-01-30 11:15:13.213580
Pre: time 2019-01-30 11:18:44.525015: 
 	std: 0.004415456
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 7), (13, 1), (14, 5), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.21841666, 0.22218333, 0.21001667, 0.22201666, 0.21793333]
	train_accs: [0.21841666, 0.22218333, 0.21001667, 0.22201666, 0.21793333]
	best_train_sub_head: 1
	worst: 0.21001667
	avg: 0.21811333
	best: 0.22218333

Starting e_i: 262
Model ind 579 epoch 262 head B head_i_epoch 0 batch 0: avg loss -1.633143 avg loss no lamb -1.633143 time 2019-01-30 11:18:47.898423
Model ind 579 epoch 262 head B head_i_epoch 0 batch 100: avg loss -1.630783 avg loss no lamb -1.630783 time 2019-01-30 11:21:52.784745
Model ind 579 epoch 262 head B head_i_epoch 0 batch 200: avg loss -1.672888 avg loss no lamb -1.672888 time 2019-01-30 11:24:56.840122
Model ind 579 epoch 262 head A head_i_epoch 0 batch 0: avg loss -3.114179 avg loss no lamb -3.114179 time 2019-01-30 11:28:01.228523
Model ind 579 epoch 262 head A head_i_epoch 0 batch 100: avg loss -3.182583 avg loss no lamb -3.182583 time 2019-01-30 11:31:04.569824
Model ind 579 epoch 262 head A head_i_epoch 0 batch 200: avg loss -3.209337 avg loss no lamb -3.209337 time 2019-01-30 11:34:09.821762
Pre: time 2019-01-30 11:37:40.430702: 
 	std: 0.004757794
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 19), (4, 4), (5, 3), (6, 13), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 18)]
	test_accs: [0.2217, 0.22411667, 0.2113, 0.22425, 0.22061667]
	train_accs: [0.2217, 0.22411667, 0.2113, 0.22425, 0.22061667]
	best_train_sub_head: 3
	worst: 0.2113
	avg: 0.22039667
	best: 0.22425

Starting e_i: 263
Model ind 579 epoch 263 head B head_i_epoch 0 batch 0: avg loss -1.525954 avg loss no lamb -1.525954 time 2019-01-30 11:37:43.662016
Model ind 579 epoch 263 head B head_i_epoch 0 batch 100: avg loss -1.682254 avg loss no lamb -1.682254 time 2019-01-30 11:40:47.048133
Model ind 579 epoch 263 head B head_i_epoch 0 batch 200: avg loss -1.694614 avg loss no lamb -1.694614 time 2019-01-30 11:43:49.541887
Model ind 579 epoch 263 head A head_i_epoch 0 batch 0: avg loss -3.199960 avg loss no lamb -3.199960 time 2019-01-30 11:46:54.435767
Model ind 579 epoch 263 head A head_i_epoch 0 batch 100: avg loss -3.123645 avg loss no lamb -3.123645 time 2019-01-30 11:49:59.235720
Model ind 579 epoch 263 head A head_i_epoch 0 batch 200: avg loss -3.235486 avg loss no lamb -3.235486 time 2019-01-30 11:53:02.756748
Pre: time 2019-01-30 11:56:34.095201: 
 	std: 0.0031637964
	best_train_sub_head_match: [(0, 18), (1, 16), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 15), (9, 10), (10, 7), (11, 8), (12, 19), (13, 9), (14, 13), (15, 5), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.21556666, 0.21553333, 0.20758334, 0.21541667, 0.2116]
	train_accs: [0.21556666, 0.21553333, 0.20758334, 0.21541667, 0.2116]
	best_train_sub_head: 0
	worst: 0.20758334
	avg: 0.21314001
	best: 0.21556666

Starting e_i: 264
Model ind 579 epoch 264 head B head_i_epoch 0 batch 0: avg loss -1.597425 avg loss no lamb -1.597425 time 2019-01-30 11:56:37.374147
Model ind 579 epoch 264 head B head_i_epoch 0 batch 100: avg loss -1.666991 avg loss no lamb -1.666991 time 2019-01-30 11:59:40.942990
Model ind 579 epoch 264 head B head_i_epoch 0 batch 200: avg loss -1.709207 avg loss no lamb -1.709207 time 2019-01-30 12:02:43.442546
Model ind 579 epoch 264 head A head_i_epoch 0 batch 0: avg loss -3.085470 avg loss no lamb -3.085470 time 2019-01-30 12:05:48.418468
Model ind 579 epoch 264 head A head_i_epoch 0 batch 100: avg loss -3.200051 avg loss no lamb -3.200051 time 2019-01-30 12:08:54.279018
Model ind 579 epoch 264 head A head_i_epoch 0 batch 200: avg loss -3.176580 avg loss no lamb -3.176580 time 2019-01-30 12:11:58.953394
Pre: time 2019-01-30 12:15:31.250654: 
 	std: 0.0038906683
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 19), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 7), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.22611667, 0.2283, 0.21768333, 0.22721666, 0.22738333]
	train_accs: [0.22611667, 0.2283, 0.21768333, 0.22721666, 0.22738333]
	best_train_sub_head: 1
	worst: 0.21768333
	avg: 0.22534001
	best: 0.2283

Starting e_i: 265
Model ind 579 epoch 265 head B head_i_epoch 0 batch 0: avg loss -1.556227 avg loss no lamb -1.556227 time 2019-01-30 12:15:34.428843
Model ind 579 epoch 265 head B head_i_epoch 0 batch 100: avg loss -1.564460 avg loss no lamb -1.564460 time 2019-01-30 12:18:38.354507
Model ind 579 epoch 265 head B head_i_epoch 0 batch 200: avg loss -1.656390 avg loss no lamb -1.656390 time 2019-01-30 12:21:40.633239
Model ind 579 epoch 265 head A head_i_epoch 0 batch 0: avg loss -3.104222 avg loss no lamb -3.104222 time 2019-01-30 12:24:43.149991
Model ind 579 epoch 265 head A head_i_epoch 0 batch 100: avg loss -3.191536 avg loss no lamb -3.191536 time 2019-01-30 12:27:47.943437
Model ind 579 epoch 265 head A head_i_epoch 0 batch 200: avg loss -3.130454 avg loss no lamb -3.130454 time 2019-01-30 12:30:51.350123
Pre: time 2019-01-30 12:34:21.974124: 
 	std: 0.0039358097
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 18)]
	test_accs: [0.22786666, 0.23016667, 0.21991667, 0.23055, 0.2249]
	train_accs: [0.22786666, 0.23016667, 0.21991667, 0.23055, 0.2249]
	best_train_sub_head: 3
	worst: 0.21991667
	avg: 0.22668
	best: 0.23055

Starting e_i: 266
Model ind 579 epoch 266 head B head_i_epoch 0 batch 0: avg loss -1.582691 avg loss no lamb -1.582691 time 2019-01-30 12:34:29.885786
Model ind 579 epoch 266 head B head_i_epoch 0 batch 100: avg loss -1.698239 avg loss no lamb -1.698239 time 2019-01-30 12:37:33.415958
Model ind 579 epoch 266 head B head_i_epoch 0 batch 200: avg loss -1.654763 avg loss no lamb -1.654763 time 2019-01-30 12:40:36.385954
Model ind 579 epoch 266 head A head_i_epoch 0 batch 0: avg loss -3.143350 avg loss no lamb -3.143350 time 2019-01-30 12:43:39.834915
Model ind 579 epoch 266 head A head_i_epoch 0 batch 100: avg loss -3.203926 avg loss no lamb -3.203926 time 2019-01-30 12:46:44.325653
Model ind 579 epoch 266 head A head_i_epoch 0 batch 200: avg loss -3.180657 avg loss no lamb -3.180657 time 2019-01-30 12:49:48.080461
Pre: time 2019-01-30 12:53:18.579557: 
 	std: 0.0047686505
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 15), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.2219, 0.22513333, 0.21195, 0.2247, 0.22146666]
	train_accs: [0.2219, 0.22513333, 0.21195, 0.2247, 0.22146666]
	best_train_sub_head: 1
	worst: 0.21195
	avg: 0.22103
	best: 0.22513333

Starting e_i: 267
Model ind 579 epoch 267 head B head_i_epoch 0 batch 0: avg loss -1.674583 avg loss no lamb -1.674583 time 2019-01-30 12:53:22.157018
Model ind 579 epoch 267 head B head_i_epoch 0 batch 100: avg loss -1.657890 avg loss no lamb -1.657890 time 2019-01-30 12:56:24.372360
Model ind 579 epoch 267 head B head_i_epoch 0 batch 200: avg loss -1.637103 avg loss no lamb -1.637103 time 2019-01-30 12:59:27.198987
Model ind 579 epoch 267 head A head_i_epoch 0 batch 0: avg loss -3.151130 avg loss no lamb -3.151130 time 2019-01-30 13:02:28.451939
Model ind 579 epoch 267 head A head_i_epoch 0 batch 100: avg loss -3.174970 avg loss no lamb -3.174970 time 2019-01-30 13:05:32.634384
Model ind 579 epoch 267 head A head_i_epoch 0 batch 200: avg loss -3.183973 avg loss no lamb -3.183973 time 2019-01-30 13:08:35.342771
Pre: time 2019-01-30 13:12:05.582887: 
 	std: 0.005000209
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 7), (13, 1), (14, 5), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.2247, 0.22623333, 0.21278334, 0.22586666, 0.22158334]
	train_accs: [0.2247, 0.22623333, 0.21278334, 0.22586666, 0.22158334]
	best_train_sub_head: 1
	worst: 0.21278334
	avg: 0.22223334
	best: 0.22623333

Starting e_i: 268
Model ind 579 epoch 268 head B head_i_epoch 0 batch 0: avg loss -1.565327 avg loss no lamb -1.565327 time 2019-01-30 13:12:08.677983
Model ind 579 epoch 268 head B head_i_epoch 0 batch 100: avg loss -1.655847 avg loss no lamb -1.655847 time 2019-01-30 13:15:13.006099
Model ind 579 epoch 268 head B head_i_epoch 0 batch 200: avg loss -1.659424 avg loss no lamb -1.659424 time 2019-01-30 13:18:20.840988
Model ind 579 epoch 268 head A head_i_epoch 0 batch 0: avg loss -3.097349 avg loss no lamb -3.097349 time 2019-01-30 13:21:27.587242
Model ind 579 epoch 268 head A head_i_epoch 0 batch 100: avg loss -3.224581 avg loss no lamb -3.224581 time 2019-01-30 13:24:31.894747
Model ind 579 epoch 268 head A head_i_epoch 0 batch 200: avg loss -3.178650 avg loss no lamb -3.178650 time 2019-01-30 13:27:36.303424
Pre: time 2019-01-30 13:31:06.078323: 
 	std: 0.0040877843
	best_train_sub_head_match: [(0, 13), (1, 15), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 18)]
	test_accs: [0.22335, 0.22491667, 0.21411666, 0.22528334, 0.22128333]
	train_accs: [0.22335, 0.22491667, 0.21411666, 0.22528334, 0.22128333]
	best_train_sub_head: 3
	worst: 0.21411666
	avg: 0.22179
	best: 0.22528334

Starting e_i: 269
Model ind 579 epoch 269 head B head_i_epoch 0 batch 0: avg loss -1.671863 avg loss no lamb -1.671863 time 2019-01-30 13:31:09.387287
Model ind 579 epoch 269 head B head_i_epoch 0 batch 100: avg loss -1.621592 avg loss no lamb -1.621592 time 2019-01-30 13:34:11.526154
Model ind 579 epoch 269 head B head_i_epoch 0 batch 200: avg loss -1.617506 avg loss no lamb -1.617506 time 2019-01-30 13:37:13.958309
Model ind 579 epoch 269 head A head_i_epoch 0 batch 0: avg loss -3.152888 avg loss no lamb -3.152888 time 2019-01-30 13:40:15.396311
Model ind 579 epoch 269 head A head_i_epoch 0 batch 100: avg loss -3.242372 avg loss no lamb -3.242372 time 2019-01-30 13:43:19.812155
Model ind 579 epoch 269 head A head_i_epoch 0 batch 200: avg loss -3.218564 avg loss no lamb -3.218564 time 2019-01-30 13:46:23.385681
Pre: time 2019-01-30 13:49:53.266078: 
 	std: 0.004607677
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 18)]
	test_accs: [0.22583333, 0.22793333, 0.21558334, 0.22806667, 0.2251]
	train_accs: [0.22583333, 0.22793333, 0.21558334, 0.22806667, 0.2251]
	best_train_sub_head: 3
	worst: 0.21558334
	avg: 0.22450332
	best: 0.22806667

Starting e_i: 270
Model ind 579 epoch 270 head B head_i_epoch 0 batch 0: avg loss -1.558109 avg loss no lamb -1.558109 time 2019-01-30 13:49:56.397160
Model ind 579 epoch 270 head B head_i_epoch 0 batch 100: avg loss -1.644034 avg loss no lamb -1.644034 time 2019-01-30 13:52:59.957259
Model ind 579 epoch 270 head B head_i_epoch 0 batch 200: avg loss -1.617959 avg loss no lamb -1.617959 time 2019-01-30 13:56:03.164399
Model ind 579 epoch 270 head A head_i_epoch 0 batch 0: avg loss -3.147381 avg loss no lamb -3.147381 time 2019-01-30 13:59:07.212569
Model ind 579 epoch 270 head A head_i_epoch 0 batch 100: avg loss -3.162710 avg loss no lamb -3.162710 time 2019-01-30 14:02:11.613105
Model ind 579 epoch 270 head A head_i_epoch 0 batch 200: avg loss -3.209600 avg loss no lamb -3.209600 time 2019-01-30 14:05:15.915609
Pre: time 2019-01-30 14:08:47.052068: 
 	std: 0.0038093762
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 7), (7, 8), (8, 6), (9, 14), (10, 9), (11, 15), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 5), (19, 18)]
	test_accs: [0.22161667, 0.22405, 0.21415, 0.22456667, 0.22311667]
	train_accs: [0.22161667, 0.22405, 0.21415, 0.22456667, 0.22311667]
	best_train_sub_head: 3
	worst: 0.21415
	avg: 0.2215
	best: 0.22456667

Starting e_i: 271
Model ind 579 epoch 271 head B head_i_epoch 0 batch 0: avg loss -1.622950 avg loss no lamb -1.622950 time 2019-01-30 14:08:53.875194
Model ind 579 epoch 271 head B head_i_epoch 0 batch 100: avg loss -1.598372 avg loss no lamb -1.598372 time 2019-01-30 14:11:57.596973
Model ind 579 epoch 271 head B head_i_epoch 0 batch 200: avg loss -1.636370 avg loss no lamb -1.636370 time 2019-01-30 14:15:02.238898
Model ind 579 epoch 271 head A head_i_epoch 0 batch 0: avg loss -3.170817 avg loss no lamb -3.170817 time 2019-01-30 14:18:07.053183
Model ind 579 epoch 271 head A head_i_epoch 0 batch 100: avg loss -3.167317 avg loss no lamb -3.167317 time 2019-01-30 14:21:12.451790
Model ind 579 epoch 271 head A head_i_epoch 0 batch 200: avg loss -3.201768 avg loss no lamb -3.201768 time 2019-01-30 14:24:17.482811
Pre: time 2019-01-30 14:27:46.566051: 
 	std: 0.0041344925
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.22771667, 0.23061667, 0.21928333, 0.22926667, 0.22978333]
	train_accs: [0.22771667, 0.23061667, 0.21928333, 0.22926667, 0.22978333]
	best_train_sub_head: 1
	worst: 0.21928333
	avg: 0.22733334
	best: 0.23061667

Starting e_i: 272
Model ind 579 epoch 272 head B head_i_epoch 0 batch 0: avg loss -1.589663 avg loss no lamb -1.589663 time 2019-01-30 14:27:54.059455
Model ind 579 epoch 272 head B head_i_epoch 0 batch 100: avg loss -1.592620 avg loss no lamb -1.592620 time 2019-01-30 14:30:55.758396
Model ind 579 epoch 272 head B head_i_epoch 0 batch 200: avg loss -1.645570 avg loss no lamb -1.645570 time 2019-01-30 14:33:58.820955
Model ind 579 epoch 272 head A head_i_epoch 0 batch 0: avg loss -3.121563 avg loss no lamb -3.121563 time 2019-01-30 14:37:02.683300
Model ind 579 epoch 272 head A head_i_epoch 0 batch 100: avg loss -3.256700 avg loss no lamb -3.256700 time 2019-01-30 14:40:06.858945
Model ind 579 epoch 272 head A head_i_epoch 0 batch 200: avg loss -3.188634 avg loss no lamb -3.188634 time 2019-01-30 14:43:10.008818
Pre: time 2019-01-30 14:46:39.424965: 
 	std: 0.0040850593
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 15), (3, 9), (4, 12), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 5), (12, 1), (13, 18), (14, 16), (15, 13), (16, 6), (17, 3), (18, 19), (19, 8)]
	test_accs: [0.22706667, 0.22803333, 0.21786667, 0.22836667, 0.22853333]
	train_accs: [0.22706667, 0.22803333, 0.21786667, 0.22836667, 0.22853333]
	best_train_sub_head: 4
	worst: 0.21786667
	avg: 0.22597332
	best: 0.22853333

Starting e_i: 273
Model ind 579 epoch 273 head B head_i_epoch 0 batch 0: avg loss -1.590362 avg loss no lamb -1.590362 time 2019-01-30 14:46:42.370404
Model ind 579 epoch 273 head B head_i_epoch 0 batch 100: avg loss -1.559048 avg loss no lamb -1.559048 time 2019-01-30 14:49:45.648664
Model ind 579 epoch 273 head B head_i_epoch 0 batch 200: avg loss -1.690625 avg loss no lamb -1.690625 time 2019-01-30 14:52:48.057230
Model ind 579 epoch 273 head A head_i_epoch 0 batch 0: avg loss -3.126608 avg loss no lamb -3.126608 time 2019-01-30 14:55:52.349403
Model ind 579 epoch 273 head A head_i_epoch 0 batch 100: avg loss -3.176958 avg loss no lamb -3.176958 time 2019-01-30 14:58:59.027490
Model ind 579 epoch 273 head A head_i_epoch 0 batch 200: avg loss -3.233412 avg loss no lamb -3.233412 time 2019-01-30 15:02:04.246926
Pre: time 2019-01-30 15:05:33.687100: 
 	std: 0.003631106
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 19), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 7), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.22233333, 0.22528334, 0.21555, 0.22528334, 0.22395]
	train_accs: [0.22233333, 0.22528334, 0.21555, 0.22528334, 0.22395]
	best_train_sub_head: 1
	worst: 0.21555
	avg: 0.22247998
	best: 0.22528334

Starting e_i: 274
Model ind 579 epoch 274 head B head_i_epoch 0 batch 0: avg loss -1.575144 avg loss no lamb -1.575144 time 2019-01-30 15:05:37.018241
Model ind 579 epoch 274 head B head_i_epoch 0 batch 100: avg loss -1.603860 avg loss no lamb -1.603860 time 2019-01-30 15:08:41.302031
Model ind 579 epoch 274 head B head_i_epoch 0 batch 200: avg loss -1.619666 avg loss no lamb -1.619666 time 2019-01-30 15:11:45.726471
Model ind 579 epoch 274 head A head_i_epoch 0 batch 0: avg loss -3.144199 avg loss no lamb -3.144199 time 2019-01-30 15:14:49.421131
Model ind 579 epoch 274 head A head_i_epoch 0 batch 100: avg loss -3.186971 avg loss no lamb -3.186971 time 2019-01-30 15:17:53.504200
Model ind 579 epoch 274 head A head_i_epoch 0 batch 200: avg loss -3.197672 avg loss no lamb -3.197672 time 2019-01-30 15:20:59.827064
Pre: time 2019-01-30 15:24:30.776691: 
 	std: 0.0048178798
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 15), (3, 9), (4, 12), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 5), (12, 16), (13, 18), (14, 1), (15, 13), (16, 6), (17, 3), (18, 19), (19, 8)]
	test_accs: [0.2256, 0.22761667, 0.2153, 0.22761667, 0.22785]
	train_accs: [0.2256, 0.22761667, 0.2153, 0.22761667, 0.22785]
	best_train_sub_head: 4
	worst: 0.2153
	avg: 0.22479665
	best: 0.22785

Starting e_i: 275
Model ind 579 epoch 275 head B head_i_epoch 0 batch 0: avg loss -1.591096 avg loss no lamb -1.591096 time 2019-01-30 15:24:33.744312
Model ind 579 epoch 275 head B head_i_epoch 0 batch 100: avg loss -1.605699 avg loss no lamb -1.605699 time 2019-01-30 15:27:38.881415
Model ind 579 epoch 275 head B head_i_epoch 0 batch 200: avg loss -1.638414 avg loss no lamb -1.638414 time 2019-01-30 15:30:43.141291
Model ind 579 epoch 275 head A head_i_epoch 0 batch 0: avg loss -3.115959 avg loss no lamb -3.115959 time 2019-01-30 15:33:47.848863
Model ind 579 epoch 275 head A head_i_epoch 0 batch 100: avg loss -3.216975 avg loss no lamb -3.216975 time 2019-01-30 15:36:54.490456
Model ind 579 epoch 275 head A head_i_epoch 0 batch 200: avg loss -3.239630 avg loss no lamb -3.239630 time 2019-01-30 15:39:59.935632
Pre: time 2019-01-30 15:43:31.794929: 
 	std: 0.004561849
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.23168333, 0.23285, 0.22085, 0.23266667, 0.23151666]
	train_accs: [0.23168333, 0.23285, 0.22085, 0.23266667, 0.23151666]
	best_train_sub_head: 1
	worst: 0.22085
	avg: 0.22991332
	best: 0.23285

Starting e_i: 276
Model ind 579 epoch 276 head B head_i_epoch 0 batch 0: avg loss -1.676822 avg loss no lamb -1.676822 time 2019-01-30 15:43:39.952172
Model ind 579 epoch 276 head B head_i_epoch 0 batch 100: avg loss -1.539927 avg loss no lamb -1.539927 time 2019-01-30 15:46:42.241688
Model ind 579 epoch 276 head B head_i_epoch 0 batch 200: avg loss -1.613452 avg loss no lamb -1.613452 time 2019-01-30 15:49:46.181538
Model ind 579 epoch 276 head A head_i_epoch 0 batch 0: avg loss -3.182513 avg loss no lamb -3.182513 time 2019-01-30 15:52:49.990195
Model ind 579 epoch 276 head A head_i_epoch 0 batch 100: avg loss -3.151232 avg loss no lamb -3.151232 time 2019-01-30 15:55:55.279402
Model ind 579 epoch 276 head A head_i_epoch 0 batch 200: avg loss -3.180940 avg loss no lamb -3.180940 time 2019-01-30 15:58:59.659843
Pre: time 2019-01-30 16:02:32.091986: 
 	std: 0.004416865
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.22968334, 0.2323, 0.22026667, 0.23223333, 0.22883333]
	train_accs: [0.22968334, 0.2323, 0.22026667, 0.23223333, 0.22883333]
	best_train_sub_head: 1
	worst: 0.22026667
	avg: 0.22866336
	best: 0.2323

Starting e_i: 277
Model ind 579 epoch 277 head B head_i_epoch 0 batch 0: avg loss -1.576206 avg loss no lamb -1.576206 time 2019-01-30 16:02:35.384925
Model ind 579 epoch 277 head B head_i_epoch 0 batch 100: avg loss -1.593949 avg loss no lamb -1.593949 time 2019-01-30 16:05:39.720726
Model ind 579 epoch 277 head B head_i_epoch 0 batch 200: avg loss -1.589676 avg loss no lamb -1.589676 time 2019-01-30 16:08:42.987671
Model ind 579 epoch 277 head A head_i_epoch 0 batch 0: avg loss -3.174665 avg loss no lamb -3.174665 time 2019-01-30 16:11:46.274812
Model ind 579 epoch 277 head A head_i_epoch 0 batch 100: avg loss -3.229640 avg loss no lamb -3.229640 time 2019-01-30 16:14:49.758000
Model ind 579 epoch 277 head A head_i_epoch 0 batch 200: avg loss -3.202490 avg loss no lamb -3.202490 time 2019-01-30 16:17:52.982714
Pre: time 2019-01-30 16:21:23.512544: 
 	std: 0.0041936273
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.22705, 0.22858334, 0.21763334, 0.22851667, 0.22293334]
	train_accs: [0.22705, 0.22858334, 0.21763334, 0.22851667, 0.22293334]
	best_train_sub_head: 1
	worst: 0.21763334
	avg: 0.22494332
	best: 0.22858334

Starting e_i: 278
Model ind 579 epoch 278 head B head_i_epoch 0 batch 0: avg loss -1.677188 avg loss no lamb -1.677188 time 2019-01-30 16:21:26.627417
Model ind 579 epoch 278 head B head_i_epoch 0 batch 100: avg loss -1.674680 avg loss no lamb -1.674680 time 2019-01-30 16:24:32.167782
Model ind 579 epoch 278 head B head_i_epoch 0 batch 200: avg loss -1.636071 avg loss no lamb -1.636071 time 2019-01-30 16:27:36.142205
Model ind 579 epoch 278 head A head_i_epoch 0 batch 0: avg loss -3.133575 avg loss no lamb -3.133575 time 2019-01-30 16:30:39.742551
Model ind 579 epoch 278 head A head_i_epoch 0 batch 100: avg loss -3.228718 avg loss no lamb -3.228718 time 2019-01-30 16:33:43.437083
Model ind 579 epoch 278 head A head_i_epoch 0 batch 200: avg loss -3.253962 avg loss no lamb -3.253962 time 2019-01-30 16:36:47.961345
Pre: time 2019-01-30 16:40:18.912213: 
 	std: 0.0037568097
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.2224, 0.22595, 0.21551667, 0.22563334, 0.22196667]
	train_accs: [0.2224, 0.22595, 0.21551667, 0.22563334, 0.22196667]
	best_train_sub_head: 1
	worst: 0.21551667
	avg: 0.22229333
	best: 0.22595

Starting e_i: 279
Model ind 579 epoch 279 head B head_i_epoch 0 batch 0: avg loss -1.602814 avg loss no lamb -1.602814 time 2019-01-30 16:40:22.060425
Model ind 579 epoch 279 head B head_i_epoch 0 batch 100: avg loss -1.634312 avg loss no lamb -1.634312 time 2019-01-30 16:43:25.342394
Model ind 579 epoch 279 head B head_i_epoch 0 batch 200: avg loss -1.638671 avg loss no lamb -1.638671 time 2019-01-30 16:46:27.790274
Model ind 579 epoch 279 head A head_i_epoch 0 batch 0: avg loss -3.166666 avg loss no lamb -3.166666 time 2019-01-30 16:49:30.617571
Model ind 579 epoch 279 head A head_i_epoch 0 batch 100: avg loss -3.173129 avg loss no lamb -3.173129 time 2019-01-30 16:52:35.051768
Model ind 579 epoch 279 head A head_i_epoch 0 batch 200: avg loss -3.256840 avg loss no lamb -3.256840 time 2019-01-30 16:55:38.437657
Pre: time 2019-01-30 16:59:08.497429: 
 	std: 0.002419887
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 19), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 7), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.2243, 0.22728333, 0.22018333, 0.22618334, 0.22466667]
	train_accs: [0.2243, 0.22728333, 0.22018333, 0.22618334, 0.22466667]
	best_train_sub_head: 1
	worst: 0.22018333
	avg: 0.22452334
	best: 0.22728333

Starting e_i: 280
Model ind 579 epoch 280 head B head_i_epoch 0 batch 0: avg loss -1.670768 avg loss no lamb -1.670768 time 2019-01-30 16:59:11.555306
Model ind 579 epoch 280 head B head_i_epoch 0 batch 100: avg loss -1.624725 avg loss no lamb -1.624725 time 2019-01-30 17:02:13.718003
Model ind 579 epoch 280 head B head_i_epoch 0 batch 200: avg loss -1.632132 avg loss no lamb -1.632132 time 2019-01-30 17:05:18.071821
Model ind 579 epoch 280 head A head_i_epoch 0 batch 0: avg loss -3.140499 avg loss no lamb -3.140499 time 2019-01-30 17:08:20.431935
Model ind 579 epoch 280 head A head_i_epoch 0 batch 100: avg loss -3.146399 avg loss no lamb -3.146399 time 2019-01-30 17:11:24.322472
Model ind 579 epoch 280 head A head_i_epoch 0 batch 200: avg loss -3.216615 avg loss no lamb -3.216615 time 2019-01-30 17:14:27.299908
Pre: time 2019-01-30 17:17:56.127517: 
 	std: 0.0031768922
	best_train_sub_head_match: [(0, 5), (1, 0), (2, 14), (3, 15), (4, 12), (5, 4), (6, 2), (7, 6), (8, 18), (9, 10), (10, 7), (11, 8), (12, 19), (13, 9), (14, 13), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.22043334, 0.2203, 0.21193333, 0.21956667, 0.21796666]
	train_accs: [0.22043334, 0.2203, 0.21193333, 0.21956667, 0.21796666]
	best_train_sub_head: 0
	worst: 0.21193333
	avg: 0.21804002
	best: 0.22043334

Starting e_i: 281
Model ind 579 epoch 281 head B head_i_epoch 0 batch 0: avg loss -1.646313 avg loss no lamb -1.646313 time 2019-01-30 17:18:04.270637
Model ind 579 epoch 281 head B head_i_epoch 0 batch 100: avg loss -1.647039 avg loss no lamb -1.647039 time 2019-01-30 17:21:08.205369
Model ind 579 epoch 281 head B head_i_epoch 0 batch 200: avg loss -1.643484 avg loss no lamb -1.643484 time 2019-01-30 17:24:11.231716
Model ind 579 epoch 281 head A head_i_epoch 0 batch 0: avg loss -3.144593 avg loss no lamb -3.144593 time 2019-01-30 17:27:14.204517
Model ind 579 epoch 281 head A head_i_epoch 0 batch 100: avg loss -3.191730 avg loss no lamb -3.191730 time 2019-01-30 17:30:18.337600
Model ind 579 epoch 281 head A head_i_epoch 0 batch 200: avg loss -3.250573 avg loss no lamb -3.250573 time 2019-01-30 17:33:22.831741
Pre: time 2019-01-30 17:36:53.867892: 
 	std: 0.0039747367
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 15), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 2), (10, 8), (11, 17), (12, 5), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.22466667, 0.22706667, 0.21578333, 0.22581667, 0.2237]
	train_accs: [0.22466667, 0.22706667, 0.21578333, 0.22581667, 0.2237]
	best_train_sub_head: 1
	worst: 0.21578333
	avg: 0.22340667
	best: 0.22706667

Starting e_i: 282
Model ind 579 epoch 282 head B head_i_epoch 0 batch 0: avg loss -1.654834 avg loss no lamb -1.654834 time 2019-01-30 17:36:57.291598
Model ind 579 epoch 282 head B head_i_epoch 0 batch 100: avg loss -1.697193 avg loss no lamb -1.697193 time 2019-01-30 17:40:00.836419
Model ind 579 epoch 282 head B head_i_epoch 0 batch 200: avg loss -1.630238 avg loss no lamb -1.630238 time 2019-01-30 17:43:03.629695
Model ind 579 epoch 282 head A head_i_epoch 0 batch 0: avg loss -3.177541 avg loss no lamb -3.177541 time 2019-01-30 17:46:07.174431
Model ind 579 epoch 282 head A head_i_epoch 0 batch 100: avg loss -3.211592 avg loss no lamb -3.211592 time 2019-01-30 17:49:11.318108
Model ind 579 epoch 282 head A head_i_epoch 0 batch 200: avg loss -3.236662 avg loss no lamb -3.236662 time 2019-01-30 17:52:16.052226
Pre: time 2019-01-30 17:55:46.590151: 
 	std: 0.0038808258
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.22203334, 0.22346666, 0.21278334, 0.2226, 0.22101666]
	train_accs: [0.22203334, 0.22346666, 0.21278334, 0.2226, 0.22101666]
	best_train_sub_head: 1
	worst: 0.21278334
	avg: 0.22038
	best: 0.22346666

Starting e_i: 283
Model ind 579 epoch 283 head B head_i_epoch 0 batch 0: avg loss -1.559975 avg loss no lamb -1.559975 time 2019-01-30 17:55:49.603466
Model ind 579 epoch 283 head B head_i_epoch 0 batch 100: avg loss -1.644366 avg loss no lamb -1.644366 time 2019-01-30 17:58:52.184380
Model ind 579 epoch 283 head B head_i_epoch 0 batch 200: avg loss -1.703867 avg loss no lamb -1.703867 time 2019-01-30 18:01:56.335346
Model ind 579 epoch 283 head A head_i_epoch 0 batch 0: avg loss -3.125277 avg loss no lamb -3.125277 time 2019-01-30 18:05:00.556095
Model ind 579 epoch 283 head A head_i_epoch 0 batch 100: avg loss -3.172552 avg loss no lamb -3.172552 time 2019-01-30 18:08:06.833646
Model ind 579 epoch 283 head A head_i_epoch 0 batch 200: avg loss -3.224150 avg loss no lamb -3.224150 time 2019-01-30 18:11:11.274909
Pre: time 2019-01-30 18:14:42.103828: 
 	std: 0.0034250945
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 16), (7, 6), (8, 8), (9, 10), (10, 7), (11, 2), (12, 19), (13, 9), (14, 15), (15, 5), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.22995, 0.22905, 0.22071667, 0.22881667, 0.22518334]
	train_accs: [0.22995, 0.22905, 0.22071667, 0.22881667, 0.22518334]
	best_train_sub_head: 0
	worst: 0.22071667
	avg: 0.22674334
	best: 0.22995

Starting e_i: 284
Model ind 579 epoch 284 head B head_i_epoch 0 batch 0: avg loss -1.589185 avg loss no lamb -1.589185 time 2019-01-30 18:14:45.134716
Model ind 579 epoch 284 head B head_i_epoch 0 batch 100: avg loss -1.699891 avg loss no lamb -1.699891 time 2019-01-30 18:17:49.099583
Model ind 579 epoch 284 head B head_i_epoch 0 batch 200: avg loss -1.741854 avg loss no lamb -1.741854 time 2019-01-30 18:20:54.007839
Model ind 579 epoch 284 head A head_i_epoch 0 batch 0: avg loss -3.105115 avg loss no lamb -3.105115 time 2019-01-30 18:23:57.627334
Model ind 579 epoch 284 head A head_i_epoch 0 batch 100: avg loss -3.170715 avg loss no lamb -3.170715 time 2019-01-30 18:27:02.565714
Model ind 579 epoch 284 head A head_i_epoch 0 batch 200: avg loss -3.194797 avg loss no lamb -3.194797 time 2019-01-30 18:30:06.485159
Pre: time 2019-01-30 18:33:36.055632: 
 	std: 0.0040261433
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.22648333, 0.229, 0.21805, 0.22866666, 0.22725]
	train_accs: [0.22648333, 0.229, 0.21805, 0.22866666, 0.22725]
	best_train_sub_head: 1
	worst: 0.21805
	avg: 0.22589
	best: 0.229

Starting e_i: 285
Model ind 579 epoch 285 head B head_i_epoch 0 batch 0: avg loss -1.576290 avg loss no lamb -1.576290 time 2019-01-30 18:33:39.068691
Model ind 579 epoch 285 head B head_i_epoch 0 batch 100: avg loss -1.637278 avg loss no lamb -1.637278 time 2019-01-30 18:36:41.871813
Model ind 579 epoch 285 head B head_i_epoch 0 batch 200: avg loss -1.667730 avg loss no lamb -1.667730 time 2019-01-30 18:39:44.727729
Model ind 579 epoch 285 head A head_i_epoch 0 batch 0: avg loss -3.160768 avg loss no lamb -3.160768 time 2019-01-30 18:42:47.751431
Model ind 579 epoch 285 head A head_i_epoch 0 batch 100: avg loss -3.247069 avg loss no lamb -3.247069 time 2019-01-30 18:45:51.002729
Model ind 579 epoch 285 head A head_i_epoch 0 batch 200: avg loss -3.213334 avg loss no lamb -3.213334 time 2019-01-30 18:48:55.784924
Pre: time 2019-01-30 18:52:25.692250: 
 	std: 0.0045156623
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 16), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 2), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 18)]
	test_accs: [0.22835, 0.22916667, 0.21728334, 0.22918333, 0.2266]
	train_accs: [0.22835, 0.22916667, 0.21728334, 0.22918333, 0.2266]
	best_train_sub_head: 3
	worst: 0.21728334
	avg: 0.22611669
	best: 0.22918333

Starting e_i: 286
Model ind 579 epoch 286 head B head_i_epoch 0 batch 0: avg loss -1.639645 avg loss no lamb -1.639645 time 2019-01-30 18:52:28.703803
Model ind 579 epoch 286 head B head_i_epoch 0 batch 100: avg loss -1.582485 avg loss no lamb -1.582485 time 2019-01-30 18:55:32.980436
Model ind 579 epoch 286 head B head_i_epoch 0 batch 200: avg loss -1.706092 avg loss no lamb -1.706092 time 2019-01-30 18:58:36.073615
Model ind 579 epoch 286 head A head_i_epoch 0 batch 0: avg loss -3.133713 avg loss no lamb -3.133713 time 2019-01-30 19:01:39.158695
Model ind 579 epoch 286 head A head_i_epoch 0 batch 100: avg loss -3.264275 avg loss no lamb -3.264275 time 2019-01-30 19:04:43.886833
Model ind 579 epoch 286 head A head_i_epoch 0 batch 200: avg loss -3.208183 avg loss no lamb -3.208183 time 2019-01-30 19:07:49.329012
Pre: time 2019-01-30 19:11:19.678729: 
 	std: 0.004555372
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.22053333, 0.22486667, 0.21231666, 0.22466667, 0.2213]
	train_accs: [0.22053333, 0.22486667, 0.21231666, 0.22466667, 0.2213]
	best_train_sub_head: 1
	worst: 0.21231666
	avg: 0.22073665
	best: 0.22486667

Starting e_i: 287
Model ind 579 epoch 287 head B head_i_epoch 0 batch 0: avg loss -1.492385 avg loss no lamb -1.492385 time 2019-01-30 19:11:22.816217
Model ind 579 epoch 287 head B head_i_epoch 0 batch 100: avg loss -1.581107 avg loss no lamb -1.581107 time 2019-01-30 19:14:27.051207
Model ind 579 epoch 287 head B head_i_epoch 0 batch 200: avg loss -1.742785 avg loss no lamb -1.742785 time 2019-01-30 19:17:30.865255
Model ind 579 epoch 287 head A head_i_epoch 0 batch 0: avg loss -3.236892 avg loss no lamb -3.236892 time 2019-01-30 19:20:33.866352
Model ind 579 epoch 287 head A head_i_epoch 0 batch 100: avg loss -3.181627 avg loss no lamb -3.181627 time 2019-01-30 19:23:38.294260
Model ind 579 epoch 287 head A head_i_epoch 0 batch 200: avg loss -3.193678 avg loss no lamb -3.193678 time 2019-01-30 19:26:42.857478
Pre: time 2019-01-30 19:30:13.878609: 
 	std: 0.005189319
	best_train_sub_head_match: [(0, 18), (1, 5), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 13), (9, 10), (10, 7), (11, 8), (12, 19), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2299, 0.22988333, 0.21631667, 0.22923334, 0.22718333]
	train_accs: [0.2299, 0.22988333, 0.21631667, 0.22923334, 0.22718333]
	best_train_sub_head: 0
	worst: 0.21631667
	avg: 0.22650333
	best: 0.2299

Starting e_i: 288
Model ind 579 epoch 288 head B head_i_epoch 0 batch 0: avg loss -1.651197 avg loss no lamb -1.651197 time 2019-01-30 19:30:17.067040
Model ind 579 epoch 288 head B head_i_epoch 0 batch 100: avg loss -1.581470 avg loss no lamb -1.581470 time 2019-01-30 19:33:20.392300
Model ind 579 epoch 288 head B head_i_epoch 0 batch 200: avg loss -1.642076 avg loss no lamb -1.642076 time 2019-01-30 19:36:23.278187
Model ind 579 epoch 288 head A head_i_epoch 0 batch 0: avg loss -3.138804 avg loss no lamb -3.138804 time 2019-01-30 19:39:25.113219
Model ind 579 epoch 288 head A head_i_epoch 0 batch 100: avg loss -3.178757 avg loss no lamb -3.178757 time 2019-01-30 19:42:30.043118
Model ind 579 epoch 288 head A head_i_epoch 0 batch 200: avg loss -3.224501 avg loss no lamb -3.224501 time 2019-01-30 19:45:34.480592
Pre: time 2019-01-30 19:49:05.272343: 
 	std: 0.004812145
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 16), (3, 7), (4, 4), (5, 3), (6, 18), (7, 8), (8, 6), (9, 14), (10, 9), (11, 13), (12, 2), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 5), (19, 19)]
	test_accs: [0.22968334, 0.23026666, 0.21813333, 0.23076667, 0.22978333]
	train_accs: [0.22968334, 0.23026666, 0.21813333, 0.23076667, 0.22978333]
	best_train_sub_head: 3
	worst: 0.21813333
	avg: 0.22772665
	best: 0.23076667

Starting e_i: 289
Model ind 579 epoch 289 head B head_i_epoch 0 batch 0: avg loss -1.664547 avg loss no lamb -1.664547 time 2019-01-30 19:49:08.757137
Model ind 579 epoch 289 head B head_i_epoch 0 batch 100: avg loss -1.624583 avg loss no lamb -1.624583 time 2019-01-30 19:52:11.149623
Model ind 579 epoch 289 head B head_i_epoch 0 batch 200: avg loss -1.711140 avg loss no lamb -1.711140 time 2019-01-30 19:55:14.307751
Model ind 579 epoch 289 head A head_i_epoch 0 batch 0: avg loss -3.160261 avg loss no lamb -3.160261 time 2019-01-30 19:58:17.726368
Model ind 579 epoch 289 head A head_i_epoch 0 batch 100: avg loss -3.223201 avg loss no lamb -3.223201 time 2019-01-30 20:01:23.013363
Model ind 579 epoch 289 head A head_i_epoch 0 batch 200: avg loss -3.202959 avg loss no lamb -3.202959 time 2019-01-30 20:04:27.947473
Pre: time 2019-01-30 20:07:59.417460: 
 	std: 0.0041647004
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.22558333, 0.22736667, 0.2164, 0.22736667, 0.22196667]
	train_accs: [0.22558333, 0.22736667, 0.2164, 0.22736667, 0.22196667]
	best_train_sub_head: 1
	worst: 0.2164
	avg: 0.22373667
	best: 0.22736667

Starting e_i: 290
Model ind 579 epoch 290 head B head_i_epoch 0 batch 0: avg loss -1.539778 avg loss no lamb -1.539778 time 2019-01-30 20:08:02.584280
Model ind 579 epoch 290 head B head_i_epoch 0 batch 100: avg loss -1.611015 avg loss no lamb -1.611015 time 2019-01-30 20:11:07.349193
Model ind 579 epoch 290 head B head_i_epoch 0 batch 200: avg loss -1.649365 avg loss no lamb -1.649365 time 2019-01-30 20:14:12.776927
Model ind 579 epoch 290 head A head_i_epoch 0 batch 0: avg loss -3.152851 avg loss no lamb -3.152851 time 2019-01-30 20:17:15.718286
Model ind 579 epoch 290 head A head_i_epoch 0 batch 100: avg loss -3.130393 avg loss no lamb -3.130393 time 2019-01-30 20:20:21.055312
Model ind 579 epoch 290 head A head_i_epoch 0 batch 200: avg loss -3.211503 avg loss no lamb -3.211503 time 2019-01-30 20:23:24.620538
Pre: time 2019-01-30 20:26:55.172932: 
 	std: 0.003903657
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 13), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.22503333, 0.22716667, 0.21651667, 0.22675, 0.22528334]
	train_accs: [0.22503333, 0.22716667, 0.21651667, 0.22675, 0.22528334]
	best_train_sub_head: 1
	worst: 0.21651667
	avg: 0.22415002
	best: 0.22716667

Starting e_i: 291
Model ind 579 epoch 291 head B head_i_epoch 0 batch 0: avg loss -1.596046 avg loss no lamb -1.596046 time 2019-01-30 20:27:04.124736
Model ind 579 epoch 291 head B head_i_epoch 0 batch 100: avg loss -1.624435 avg loss no lamb -1.624435 time 2019-01-30 20:30:06.888499
Model ind 579 epoch 291 head B head_i_epoch 0 batch 200: avg loss -1.611639 avg loss no lamb -1.611639 time 2019-01-30 20:33:09.554636
Model ind 579 epoch 291 head A head_i_epoch 0 batch 0: avg loss -3.221413 avg loss no lamb -3.221413 time 2019-01-30 20:36:11.775990
Model ind 579 epoch 291 head A head_i_epoch 0 batch 100: avg loss -3.213982 avg loss no lamb -3.213982 time 2019-01-30 20:39:14.912542
Model ind 579 epoch 291 head A head_i_epoch 0 batch 200: avg loss -3.198718 avg loss no lamb -3.198718 time 2019-01-30 20:42:19.231382
Pre: time 2019-01-30 20:45:50.212590: 
 	std: 0.0041220384
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.22861667, 0.2298, 0.21893333, 0.23003334, 0.22748333]
	train_accs: [0.22861667, 0.2298, 0.21893333, 0.23003334, 0.22748333]
	best_train_sub_head: 3
	worst: 0.21893333
	avg: 0.22697334
	best: 0.23003334

Starting e_i: 292
Model ind 579 epoch 292 head B head_i_epoch 0 batch 0: avg loss -1.578693 avg loss no lamb -1.578693 time 2019-01-30 20:45:53.355035
Model ind 579 epoch 292 head B head_i_epoch 0 batch 100: avg loss -1.646154 avg loss no lamb -1.646154 time 2019-01-30 20:48:56.458424
Model ind 579 epoch 292 head B head_i_epoch 0 batch 200: avg loss -1.649549 avg loss no lamb -1.649549 time 2019-01-30 20:52:00.419329
Model ind 579 epoch 292 head A head_i_epoch 0 batch 0: avg loss -3.181968 avg loss no lamb -3.181968 time 2019-01-30 20:55:03.300750
Model ind 579 epoch 292 head A head_i_epoch 0 batch 100: avg loss -3.229776 avg loss no lamb -3.229776 time 2019-01-30 20:58:09.138899
Model ind 579 epoch 292 head A head_i_epoch 0 batch 200: avg loss -3.204427 avg loss no lamb -3.204427 time 2019-01-30 21:01:13.419485
Pre: time 2019-01-30 21:04:43.219887: 
 	std: 0.005427138
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 19), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 7), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.22696666, 0.23161666, 0.21673334, 0.23121667, 0.22866666]
	train_accs: [0.22696666, 0.23161666, 0.21673334, 0.23121667, 0.22866666]
	best_train_sub_head: 1
	worst: 0.21673334
	avg: 0.22704001
	best: 0.23161666

Starting e_i: 293
Model ind 579 epoch 293 head B head_i_epoch 0 batch 0: avg loss -1.662969 avg loss no lamb -1.662969 time 2019-01-30 21:04:46.722277
Model ind 579 epoch 293 head B head_i_epoch 0 batch 100: avg loss -1.688908 avg loss no lamb -1.688908 time 2019-01-30 21:07:49.961056
Model ind 579 epoch 293 head B head_i_epoch 0 batch 200: avg loss -1.679278 avg loss no lamb -1.679278 time 2019-01-30 21:10:53.195119
Model ind 579 epoch 293 head A head_i_epoch 0 batch 0: avg loss -3.171778 avg loss no lamb -3.171778 time 2019-01-30 21:13:57.409913
Model ind 579 epoch 293 head A head_i_epoch 0 batch 100: avg loss -3.206714 avg loss no lamb -3.206714 time 2019-01-30 21:17:03.047080
Model ind 579 epoch 293 head A head_i_epoch 0 batch 200: avg loss -3.311536 avg loss no lamb -3.311536 time 2019-01-30 21:20:07.967085
Pre: time 2019-01-30 21:23:38.847438: 
 	std: 0.004603316
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.22511667, 0.22636667, 0.21406667, 0.22621667, 0.22295]
	train_accs: [0.22511667, 0.22636667, 0.21406667, 0.22621667, 0.22295]
	best_train_sub_head: 1
	worst: 0.21406667
	avg: 0.22294334
	best: 0.22636667

Starting e_i: 294
Model ind 579 epoch 294 head B head_i_epoch 0 batch 0: avg loss -1.641208 avg loss no lamb -1.641208 time 2019-01-30 21:23:42.207538
Model ind 579 epoch 294 head B head_i_epoch 0 batch 100: avg loss -1.674941 avg loss no lamb -1.674941 time 2019-01-30 21:26:47.466272
Model ind 579 epoch 294 head B head_i_epoch 0 batch 200: avg loss -1.573386 avg loss no lamb -1.573386 time 2019-01-30 21:29:51.237002
Model ind 579 epoch 294 head A head_i_epoch 0 batch 0: avg loss -3.118865 avg loss no lamb -3.118865 time 2019-01-30 21:32:57.384550
Model ind 579 epoch 294 head A head_i_epoch 0 batch 100: avg loss -3.263862 avg loss no lamb -3.263862 time 2019-01-30 21:36:04.804908
Model ind 579 epoch 294 head A head_i_epoch 0 batch 200: avg loss -3.279289 avg loss no lamb -3.279289 time 2019-01-30 21:39:12.319367
Pre: time 2019-01-30 21:42:45.438493: 
 	std: 0.0044888454
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.22266667, 0.22551666, 0.21296667, 0.22463334, 0.22233333]
	train_accs: [0.22266667, 0.22551666, 0.21296667, 0.22463334, 0.22233333]
	best_train_sub_head: 1
	worst: 0.21296667
	avg: 0.22162333
	best: 0.22551666

Starting e_i: 295
Model ind 579 epoch 295 head B head_i_epoch 0 batch 0: avg loss -1.598775 avg loss no lamb -1.598775 time 2019-01-30 21:42:48.893931
Model ind 579 epoch 295 head B head_i_epoch 0 batch 100: avg loss -1.631182 avg loss no lamb -1.631182 time 2019-01-30 21:45:53.687392
Model ind 579 epoch 295 head B head_i_epoch 0 batch 200: avg loss -1.704438 avg loss no lamb -1.704438 time 2019-01-30 21:48:58.477558
Model ind 579 epoch 295 head A head_i_epoch 0 batch 0: avg loss -3.202937 avg loss no lamb -3.202937 time 2019-01-30 21:52:04.038344
Model ind 579 epoch 295 head A head_i_epoch 0 batch 100: avg loss -3.244694 avg loss no lamb -3.244694 time 2019-01-30 21:55:09.218576
Model ind 579 epoch 295 head A head_i_epoch 0 batch 200: avg loss -3.230560 avg loss no lamb -3.230560 time 2019-01-30 21:58:16.166874
Pre: time 2019-01-30 22:01:48.564148: 
 	std: 0.0043906784
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 13), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 5), (19, 18)]
	test_accs: [0.23248333, 0.23375, 0.22246666, 0.23451667, 0.23221667]
	train_accs: [0.23248333, 0.23375, 0.22246666, 0.23451667, 0.23221667]
	best_train_sub_head: 3
	worst: 0.22246666
	avg: 0.23108666
	best: 0.23451667

Starting e_i: 296
Model ind 579 epoch 296 head B head_i_epoch 0 batch 0: avg loss -1.632485 avg loss no lamb -1.632485 time 2019-01-30 22:01:56.080688
Model ind 579 epoch 296 head B head_i_epoch 0 batch 100: avg loss -1.677796 avg loss no lamb -1.677796 time 2019-01-30 22:05:00.974452
Model ind 579 epoch 296 head B head_i_epoch 0 batch 200: avg loss -1.694270 avg loss no lamb -1.694270 time 2019-01-30 22:08:07.807021
Model ind 579 epoch 296 head A head_i_epoch 0 batch 0: avg loss -3.145580 avg loss no lamb -3.145580 time 2019-01-30 22:11:13.315694
Model ind 579 epoch 296 head A head_i_epoch 0 batch 100: avg loss -3.192327 avg loss no lamb -3.192327 time 2019-01-30 22:14:20.353647
Model ind 579 epoch 296 head A head_i_epoch 0 batch 200: avg loss -3.243750 avg loss no lamb -3.243750 time 2019-01-30 22:17:27.720182
Pre: time 2019-01-30 22:20:58.955451: 
 	std: 0.005150531
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.23188333, 0.23385, 0.22045, 0.23481667, 0.23063333]
	train_accs: [0.23188333, 0.23385, 0.22045, 0.23481667, 0.23063333]
	best_train_sub_head: 3
	worst: 0.22045
	avg: 0.23032668
	best: 0.23481667

Starting e_i: 297
Model ind 579 epoch 297 head B head_i_epoch 0 batch 0: avg loss -1.639660 avg loss no lamb -1.639660 time 2019-01-30 22:21:06.766802
Model ind 579 epoch 297 head B head_i_epoch 0 batch 100: avg loss -1.606915 avg loss no lamb -1.606915 time 2019-01-30 22:24:09.584777
Model ind 579 epoch 297 head B head_i_epoch 0 batch 200: avg loss -1.716225 avg loss no lamb -1.716225 time 2019-01-30 22:27:12.552790
Model ind 579 epoch 297 head A head_i_epoch 0 batch 0: avg loss -3.136473 avg loss no lamb -3.136473 time 2019-01-30 22:30:15.059235
Model ind 579 epoch 297 head A head_i_epoch 0 batch 100: avg loss -3.239584 avg loss no lamb -3.239584 time 2019-01-30 22:33:20.169394
Model ind 579 epoch 297 head A head_i_epoch 0 batch 200: avg loss -3.255229 avg loss no lamb -3.255229 time 2019-01-30 22:36:23.999187
Pre: time 2019-01-30 22:39:52.991790: 
 	std: 0.004126625
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.23545, 0.23668334, 0.22628333, 0.23803334, 0.2338]
	train_accs: [0.23545, 0.23668334, 0.22628333, 0.23803334, 0.2338]
	best_train_sub_head: 3
	worst: 0.22628333
	avg: 0.23404999
	best: 0.23803334

Starting e_i: 298
Model ind 579 epoch 298 head B head_i_epoch 0 batch 0: avg loss -1.572489 avg loss no lamb -1.572489 time 2019-01-30 22:40:00.270911
Model ind 579 epoch 298 head B head_i_epoch 0 batch 100: avg loss -1.617587 avg loss no lamb -1.617587 time 2019-01-30 22:43:03.982294
Model ind 579 epoch 298 head B head_i_epoch 0 batch 200: avg loss -1.653828 avg loss no lamb -1.653828 time 2019-01-30 22:46:07.481674
Model ind 579 epoch 298 head A head_i_epoch 0 batch 0: avg loss -3.160342 avg loss no lamb -3.160342 time 2019-01-30 22:49:10.874851
Model ind 579 epoch 298 head A head_i_epoch 0 batch 100: avg loss -3.240091 avg loss no lamb -3.240091 time 2019-01-30 22:52:16.634774
Model ind 579 epoch 298 head A head_i_epoch 0 batch 200: avg loss -3.162448 avg loss no lamb -3.162448 time 2019-01-30 22:55:22.264322
Pre: time 2019-01-30 22:58:53.228741: 
 	std: 0.004637638
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 19), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 7), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.23026666, 0.23111667, 0.21895, 0.23101667, 0.22933333]
	train_accs: [0.23026666, 0.23111667, 0.21895, 0.23101667, 0.22933333]
	best_train_sub_head: 1
	worst: 0.21895
	avg: 0.22813666
	best: 0.23111667

Starting e_i: 299
Model ind 579 epoch 299 head B head_i_epoch 0 batch 0: avg loss -1.498888 avg loss no lamb -1.498888 time 2019-01-30 22:58:56.354081
Model ind 579 epoch 299 head B head_i_epoch 0 batch 100: avg loss -1.596451 avg loss no lamb -1.596451 time 2019-01-30 23:01:59.811785
Model ind 579 epoch 299 head B head_i_epoch 0 batch 200: avg loss -1.684769 avg loss no lamb -1.684769 time 2019-01-30 23:05:02.792498
Model ind 579 epoch 299 head A head_i_epoch 0 batch 0: avg loss -3.108566 avg loss no lamb -3.108566 time 2019-01-30 23:08:05.921432
Model ind 579 epoch 299 head A head_i_epoch 0 batch 100: avg loss -3.258720 avg loss no lamb -3.258720 time 2019-01-30 23:11:11.346208
Model ind 579 epoch 299 head A head_i_epoch 0 batch 200: avg loss -3.180421 avg loss no lamb -3.180421 time 2019-01-30 23:14:17.084728
Pre: time 2019-01-30 23:17:49.575847: 
 	std: 0.003630955
	best_train_sub_head_match: [(0, 18), (1, 2), (2, 14), (3, 0), (4, 12), (5, 4), (6, 16), (7, 6), (8, 13), (9, 10), (10, 7), (11, 8), (12, 19), (13, 9), (14, 15), (15, 5), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.22638333, 0.22555, 0.21668333, 0.22615, 0.22341667]
	train_accs: [0.22638333, 0.22555, 0.21668333, 0.22615, 0.22341667]
	best_train_sub_head: 0
	worst: 0.21668333
	avg: 0.22363667
	best: 0.22638333

Starting e_i: 300
Model ind 579 epoch 300 head B head_i_epoch 0 batch 0: avg loss -1.549950 avg loss no lamb -1.549950 time 2019-01-30 23:17:52.858156
Model ind 579 epoch 300 head B head_i_epoch 0 batch 100: avg loss -1.716311 avg loss no lamb -1.716311 time 2019-01-30 23:20:57.143638
Model ind 579 epoch 300 head B head_i_epoch 0 batch 200: avg loss -1.710846 avg loss no lamb -1.710846 time 2019-01-30 23:24:01.440110
Model ind 579 epoch 300 head A head_i_epoch 0 batch 0: avg loss -3.142229 avg loss no lamb -3.142229 time 2019-01-30 23:27:05.194588
Model ind 579 epoch 300 head A head_i_epoch 0 batch 100: avg loss -3.239692 avg loss no lamb -3.239692 time 2019-01-30 23:30:11.738198
Model ind 579 epoch 300 head A head_i_epoch 0 batch 200: avg loss -3.226052 avg loss no lamb -3.226052 time 2019-01-30 23:33:19.145380
Pre: time 2019-01-30 23:36:53.124125: 
 	std: 0.004580298
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.23063333, 0.23101667, 0.21915, 0.23105, 0.22671667]
	train_accs: [0.23063333, 0.23101667, 0.21915, 0.23105, 0.22671667]
	best_train_sub_head: 3
	worst: 0.21915
	avg: 0.22771335
	best: 0.23105

Starting e_i: 301
Model ind 579 epoch 301 head B head_i_epoch 0 batch 0: avg loss -1.609679 avg loss no lamb -1.609679 time 2019-01-30 23:37:00.385741
Model ind 579 epoch 301 head B head_i_epoch 0 batch 100: avg loss -1.743472 avg loss no lamb -1.743472 time 2019-01-30 23:40:07.048344
Model ind 579 epoch 301 head B head_i_epoch 0 batch 200: avg loss -1.659011 avg loss no lamb -1.659011 time 2019-01-30 23:43:14.329450
Model ind 579 epoch 301 head A head_i_epoch 0 batch 0: avg loss -3.184764 avg loss no lamb -3.184764 time 2019-01-30 23:46:19.947335
Model ind 579 epoch 301 head A head_i_epoch 0 batch 100: avg loss -3.232853 avg loss no lamb -3.232853 time 2019-01-30 23:49:27.385719
Model ind 579 epoch 301 head A head_i_epoch 0 batch 200: avg loss -3.187831 avg loss no lamb -3.187831 time 2019-01-30 23:52:28.841906
Pre: time 2019-01-30 23:55:53.000801: 
 	std: 0.0027314336
	best_train_sub_head_match: [(0, 18), (1, 16), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 13), (9, 10), (10, 7), (11, 8), (12, 19), (13, 9), (14, 15), (15, 5), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.22676666, 0.22555, 0.21916667, 0.22531667, 0.2225]
	train_accs: [0.22676666, 0.22555, 0.21916667, 0.22531667, 0.2225]
	best_train_sub_head: 0
	worst: 0.21916667
	avg: 0.22385998
	best: 0.22676666

Starting e_i: 302
Model ind 579 epoch 302 head B head_i_epoch 0 batch 0: avg loss -1.559853 avg loss no lamb -1.559853 time 2019-01-30 23:55:56.566125
Model ind 579 epoch 302 head B head_i_epoch 0 batch 100: avg loss -1.588522 avg loss no lamb -1.588522 time 2019-01-30 23:58:53.290816
Model ind 579 epoch 302 head B head_i_epoch 0 batch 200: avg loss -1.712333 avg loss no lamb -1.712333 time 2019-01-31 00:01:50.190971
Model ind 579 epoch 302 head A head_i_epoch 0 batch 0: avg loss -3.130359 avg loss no lamb -3.130359 time 2019-01-31 00:04:46.912703
Model ind 579 epoch 302 head A head_i_epoch 0 batch 100: avg loss -3.197910 avg loss no lamb -3.197910 time 2019-01-31 00:07:45.000533
Model ind 579 epoch 302 head A head_i_epoch 0 batch 200: avg loss -3.204952 avg loss no lamb -3.204952 time 2019-01-31 00:10:43.253392
Pre: time 2019-01-31 00:14:05.557368: 
 	std: 0.0042132656
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.22558333, 0.22945, 0.21773334, 0.2288, 0.22696666]
	train_accs: [0.22558333, 0.22945, 0.21773334, 0.2288, 0.22696666]
	best_train_sub_head: 1
	worst: 0.21773334
	avg: 0.22570667
	best: 0.22945

Starting e_i: 303
Model ind 579 epoch 303 head B head_i_epoch 0 batch 0: avg loss -1.669443 avg loss no lamb -1.669443 time 2019-01-31 00:14:08.521610
Model ind 579 epoch 303 head B head_i_epoch 0 batch 100: avg loss -1.685706 avg loss no lamb -1.685706 time 2019-01-31 00:17:07.137571
Model ind 579 epoch 303 head B head_i_epoch 0 batch 200: avg loss -1.638501 avg loss no lamb -1.638501 time 2019-01-31 00:20:04.317096
Model ind 579 epoch 303 head A head_i_epoch 0 batch 0: avg loss -3.207152 avg loss no lamb -3.207152 time 2019-01-31 00:23:02.372447
Model ind 579 epoch 303 head A head_i_epoch 0 batch 100: avg loss -3.240413 avg loss no lamb -3.240413 time 2019-01-31 00:26:01.564059
Model ind 579 epoch 303 head A head_i_epoch 0 batch 200: avg loss -3.168234 avg loss no lamb -3.168234 time 2019-01-31 00:29:00.713497
Pre: time 2019-01-31 00:32:25.022290: 
 	std: 0.0038596543
	best_train_sub_head_match: [(0, 18), (1, 16), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 13), (9, 10), (10, 7), (11, 8), (12, 19), (13, 9), (14, 15), (15, 5), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23328333, 0.23155, 0.22233333, 0.23168333, 0.22955]
	train_accs: [0.23328333, 0.23155, 0.22233333, 0.23168333, 0.22955]
	best_train_sub_head: 0
	worst: 0.22233333
	avg: 0.22967999
	best: 0.23328333

Starting e_i: 304
Model ind 579 epoch 304 head B head_i_epoch 0 batch 0: avg loss -1.563135 avg loss no lamb -1.563135 time 2019-01-31 00:32:28.097865
Model ind 579 epoch 304 head B head_i_epoch 0 batch 100: avg loss -1.679887 avg loss no lamb -1.679887 time 2019-01-31 00:35:26.198401
Model ind 579 epoch 304 head B head_i_epoch 0 batch 200: avg loss -1.717986 avg loss no lamb -1.717986 time 2019-01-31 00:38:24.575115
Model ind 579 epoch 304 head A head_i_epoch 0 batch 0: avg loss -3.108368 avg loss no lamb -3.108368 time 2019-01-31 00:41:21.721261
Model ind 579 epoch 304 head A head_i_epoch 0 batch 100: avg loss -3.203715 avg loss no lamb -3.203715 time 2019-01-31 00:44:19.924847
Model ind 579 epoch 304 head A head_i_epoch 0 batch 200: avg loss -3.150900 avg loss no lamb -3.150900 time 2019-01-31 00:47:21.276093
Pre: time 2019-01-31 00:50:48.066758: 
 	std: 0.0029588751
	best_train_sub_head_match: [(0, 13), (1, 16), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 5), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.22553334, 0.2251, 0.21766667, 0.22451666, 0.22148333]
	train_accs: [0.22553334, 0.2251, 0.21766667, 0.22451666, 0.22148333]
	best_train_sub_head: 0
	worst: 0.21766667
	avg: 0.22286001
	best: 0.22553334

Starting e_i: 305
Model ind 579 epoch 305 head B head_i_epoch 0 batch 0: avg loss -1.570036 avg loss no lamb -1.570036 time 2019-01-31 00:50:51.035971
Model ind 579 epoch 305 head B head_i_epoch 0 batch 100: avg loss -1.642855 avg loss no lamb -1.642855 time 2019-01-31 00:53:48.309867
Model ind 579 epoch 305 head B head_i_epoch 0 batch 200: avg loss -1.669254 avg loss no lamb -1.669254 time 2019-01-31 00:56:44.117008
Model ind 579 epoch 305 head A head_i_epoch 0 batch 0: avg loss -3.153773 avg loss no lamb -3.153773 time 2019-01-31 00:59:40.389578
Model ind 579 epoch 305 head A head_i_epoch 0 batch 100: avg loss -3.207100 avg loss no lamb -3.207100 time 2019-01-31 01:02:38.645598
Model ind 579 epoch 305 head A head_i_epoch 0 batch 200: avg loss -3.197527 avg loss no lamb -3.197527 time 2019-01-31 01:05:35.539810
Pre: time 2019-01-31 01:08:57.817445: 
 	std: 0.0046485187
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 19), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 7), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.22798334, 0.23073334, 0.21808334, 0.2301, 0.22905]
	train_accs: [0.22798334, 0.23073334, 0.21808334, 0.2301, 0.22905]
	best_train_sub_head: 1
	worst: 0.21808334
	avg: 0.22719002
	best: 0.23073334

Starting e_i: 306
Model ind 579 epoch 306 head B head_i_epoch 0 batch 0: avg loss -1.511938 avg loss no lamb -1.511938 time 2019-01-31 01:09:00.761494
Model ind 579 epoch 306 head B head_i_epoch 0 batch 100: avg loss -1.660085 avg loss no lamb -1.660085 time 2019-01-31 01:11:56.980492
Model ind 579 epoch 306 head B head_i_epoch 0 batch 200: avg loss -1.690648 avg loss no lamb -1.690648 time 2019-01-31 01:14:52.707444
Model ind 579 epoch 306 head A head_i_epoch 0 batch 0: avg loss -3.161643 avg loss no lamb -3.161643 time 2019-01-31 01:17:50.019138
Model ind 579 epoch 306 head A head_i_epoch 0 batch 100: avg loss -3.248956 avg loss no lamb -3.248956 time 2019-01-31 01:20:46.896243
Model ind 579 epoch 306 head A head_i_epoch 0 batch 200: avg loss -3.173954 avg loss no lamb -3.173954 time 2019-01-31 01:23:43.992904
Pre: time 2019-01-31 01:27:05.245555: 
 	std: 0.004178337
	best_train_sub_head_match: [(0, 4), (1, 16), (2, 8), (3, 9), (4, 12), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 5), (12, 13), (13, 18), (14, 1), (15, 15), (16, 6), (17, 3), (18, 19), (19, 2)]
	test_accs: [0.22958334, 0.22983333, 0.21946667, 0.22955, 0.23053333]
	train_accs: [0.22958334, 0.22983333, 0.21946667, 0.22955, 0.23053333]
	best_train_sub_head: 4
	worst: 0.21946667
	avg: 0.22779334
	best: 0.23053333

Starting e_i: 307
Model ind 579 epoch 307 head B head_i_epoch 0 batch 0: avg loss -1.667297 avg loss no lamb -1.667297 time 2019-01-31 01:27:08.141942
Model ind 579 epoch 307 head B head_i_epoch 0 batch 100: avg loss -1.681846 avg loss no lamb -1.681846 time 2019-01-31 01:30:04.757211
Model ind 579 epoch 307 head B head_i_epoch 0 batch 200: avg loss -1.632592 avg loss no lamb -1.632592 time 2019-01-31 01:33:01.711253
Model ind 579 epoch 307 head A head_i_epoch 0 batch 0: avg loss -3.179043 avg loss no lamb -3.179043 time 2019-01-31 01:36:00.522630
Model ind 579 epoch 307 head A head_i_epoch 0 batch 100: avg loss -3.247058 avg loss no lamb -3.247058 time 2019-01-31 01:38:58.825249
Model ind 579 epoch 307 head A head_i_epoch 0 batch 200: avg loss -3.222651 avg loss no lamb -3.222651 time 2019-01-31 01:41:57.028847
Pre: time 2019-01-31 01:45:19.948850: 
 	std: 0.0029982324
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.22768334, 0.22841667, 0.22086667, 0.22933333, 0.22698334]
	train_accs: [0.22768334, 0.22841667, 0.22086667, 0.22933333, 0.22698334]
	best_train_sub_head: 3
	worst: 0.22086667
	avg: 0.22665668
	best: 0.22933333

Starting e_i: 308
Model ind 579 epoch 308 head B head_i_epoch 0 batch 0: avg loss -1.624537 avg loss no lamb -1.624537 time 2019-01-31 01:45:23.172350
Model ind 579 epoch 308 head B head_i_epoch 0 batch 100: avg loss -1.739041 avg loss no lamb -1.739041 time 2019-01-31 01:48:20.144341
Model ind 579 epoch 308 head B head_i_epoch 0 batch 200: avg loss -1.614287 avg loss no lamb -1.614287 time 2019-01-31 01:51:16.498590
Model ind 579 epoch 308 head A head_i_epoch 0 batch 0: avg loss -3.173905 avg loss no lamb -3.173905 time 2019-01-31 01:54:13.791107
Model ind 579 epoch 308 head A head_i_epoch 0 batch 100: avg loss -3.199203 avg loss no lamb -3.199203 time 2019-01-31 01:57:11.435062
Model ind 579 epoch 308 head A head_i_epoch 0 batch 200: avg loss -3.228842 avg loss no lamb -3.228842 time 2019-01-31 02:00:08.095397
Pre: time 2019-01-31 02:03:29.937213: 
 	std: 0.0029867997
	best_train_sub_head_match: [(0, 18), (1, 16), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 13), (9, 10), (10, 7), (11, 8), (12, 19), (13, 9), (14, 15), (15, 5), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23321667, 0.23053333, 0.2242, 0.23075, 0.22918333]
	train_accs: [0.23321667, 0.23053333, 0.2242, 0.23075, 0.22918333]
	best_train_sub_head: 0
	worst: 0.2242
	avg: 0.22957666
	best: 0.23321667

Starting e_i: 309
Model ind 579 epoch 309 head B head_i_epoch 0 batch 0: avg loss -1.535374 avg loss no lamb -1.535374 time 2019-01-31 02:03:32.945335
Model ind 579 epoch 309 head B head_i_epoch 0 batch 100: avg loss -1.663958 avg loss no lamb -1.663958 time 2019-01-31 02:06:30.398768
Model ind 579 epoch 309 head B head_i_epoch 0 batch 200: avg loss -1.691199 avg loss no lamb -1.691199 time 2019-01-31 02:09:26.179314
Model ind 579 epoch 309 head A head_i_epoch 0 batch 0: avg loss -3.184345 avg loss no lamb -3.184345 time 2019-01-31 02:12:22.525026
Model ind 579 epoch 309 head A head_i_epoch 0 batch 100: avg loss -3.232505 avg loss no lamb -3.232505 time 2019-01-31 02:15:20.339025
Model ind 579 epoch 309 head A head_i_epoch 0 batch 200: avg loss -3.252743 avg loss no lamb -3.252743 time 2019-01-31 02:18:16.981736
Pre: time 2019-01-31 02:21:38.163726: 
 	std: 0.0036192653
	best_train_sub_head_match: [(0, 4), (1, 16), (2, 13), (3, 9), (4, 2), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 5), (12, 12), (13, 18), (14, 1), (15, 15), (16, 6), (17, 3), (18, 19), (19, 8)]
	test_accs: [0.2301, 0.23085, 0.22166666, 0.2307, 0.23106667]
	train_accs: [0.2301, 0.23085, 0.22166666, 0.2307, 0.23106667]
	best_train_sub_head: 4
	worst: 0.22166666
	avg: 0.22887668
	best: 0.23106667

Starting e_i: 310
Model ind 579 epoch 310 head B head_i_epoch 0 batch 0: avg loss -1.610009 avg loss no lamb -1.610009 time 2019-01-31 02:21:41.197486
Model ind 579 epoch 310 head B head_i_epoch 0 batch 100: avg loss -1.705645 avg loss no lamb -1.705645 time 2019-01-31 02:24:36.184706
Model ind 579 epoch 310 head B head_i_epoch 0 batch 200: avg loss -1.699995 avg loss no lamb -1.699995 time 2019-01-31 02:27:32.646768
Model ind 579 epoch 310 head A head_i_epoch 0 batch 0: avg loss -3.207683 avg loss no lamb -3.207683 time 2019-01-31 02:30:28.635435
Model ind 579 epoch 310 head A head_i_epoch 0 batch 100: avg loss -3.178222 avg loss no lamb -3.178222 time 2019-01-31 02:33:25.360021
Model ind 579 epoch 310 head A head_i_epoch 0 batch 200: avg loss -3.203430 avg loss no lamb -3.203430 time 2019-01-31 02:36:21.818858
Pre: time 2019-01-31 02:39:43.314372: 
 	std: 0.0043739458
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 19), (4, 4), (5, 3), (6, 13), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 18)]
	test_accs: [0.23338333, 0.23473333, 0.22343333, 0.23478334, 0.23428333]
	train_accs: [0.23338333, 0.23473333, 0.22343333, 0.23478334, 0.23428333]
	best_train_sub_head: 3
	worst: 0.22343333
	avg: 0.23212333
	best: 0.23478334

Starting e_i: 311
Model ind 579 epoch 311 head B head_i_epoch 0 batch 0: avg loss -1.649530 avg loss no lamb -1.649530 time 2019-01-31 02:39:50.942961
Model ind 579 epoch 311 head B head_i_epoch 0 batch 100: avg loss -1.668197 avg loss no lamb -1.668197 time 2019-01-31 02:42:46.275855
Model ind 579 epoch 311 head B head_i_epoch 0 batch 200: avg loss -1.612320 avg loss no lamb -1.612320 time 2019-01-31 02:45:41.426127
Model ind 579 epoch 311 head A head_i_epoch 0 batch 0: avg loss -3.163439 avg loss no lamb -3.163439 time 2019-01-31 02:48:37.658432
Model ind 579 epoch 311 head A head_i_epoch 0 batch 100: avg loss -3.229920 avg loss no lamb -3.229920 time 2019-01-31 02:51:34.837920
Model ind 579 epoch 311 head A head_i_epoch 0 batch 200: avg loss -3.232751 avg loss no lamb -3.232751 time 2019-01-31 02:54:32.683929
Pre: time 2019-01-31 02:57:57.385611: 
 	std: 0.0036855324
	best_train_sub_head_match: [(0, 13), (1, 15), (2, 2), (3, 5), (4, 4), (5, 3), (6, 18), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.22978333, 0.23195, 0.22238334, 0.23281667, 0.23]
	train_accs: [0.22978333, 0.23195, 0.22238334, 0.23281667, 0.23]
	best_train_sub_head: 3
	worst: 0.22238334
	avg: 0.22938666
	best: 0.23281667

Starting e_i: 312
Model ind 579 epoch 312 head B head_i_epoch 0 batch 0: avg loss -1.629500 avg loss no lamb -1.629500 time 2019-01-31 02:58:00.367374
Model ind 579 epoch 312 head B head_i_epoch 0 batch 100: avg loss -1.723283 avg loss no lamb -1.723283 time 2019-01-31 03:00:57.462672
Model ind 579 epoch 312 head B head_i_epoch 0 batch 200: avg loss -1.655718 avg loss no lamb -1.655718 time 2019-01-31 03:03:52.652040
Model ind 579 epoch 312 head A head_i_epoch 0 batch 0: avg loss -3.229851 avg loss no lamb -3.229851 time 2019-01-31 03:06:48.119103
Model ind 579 epoch 312 head A head_i_epoch 0 batch 100: avg loss -3.178312 avg loss no lamb -3.178312 time 2019-01-31 03:09:45.496562
Model ind 579 epoch 312 head A head_i_epoch 0 batch 200: avg loss -3.227344 avg loss no lamb -3.227344 time 2019-01-31 03:12:44.577002
Pre: time 2019-01-31 03:16:07.071210: 
 	std: 0.0036263922
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 13), (13, 14), (14, 0), (15, 12), (16, 10), (17, 1), (18, 6), (19, 18)]
	test_accs: [0.22651666, 0.22755, 0.21793333, 0.22735, 0.22625]
	train_accs: [0.22651666, 0.22755, 0.21793333, 0.22735, 0.22625]
	best_train_sub_head: 1
	worst: 0.21793333
	avg: 0.22512
	best: 0.22755

Starting e_i: 313
Model ind 579 epoch 313 head B head_i_epoch 0 batch 0: avg loss -1.648916 avg loss no lamb -1.648916 time 2019-01-31 03:16:10.057268
Model ind 579 epoch 313 head B head_i_epoch 0 batch 100: avg loss -1.684420 avg loss no lamb -1.684420 time 2019-01-31 03:19:06.303904
Model ind 579 epoch 313 head B head_i_epoch 0 batch 200: avg loss -1.619136 avg loss no lamb -1.619136 time 2019-01-31 03:22:03.183112
Model ind 579 epoch 313 head A head_i_epoch 0 batch 0: avg loss -3.223370 avg loss no lamb -3.223370 time 2019-01-31 03:24:58.684879
Model ind 579 epoch 313 head A head_i_epoch 0 batch 100: avg loss -3.195362 avg loss no lamb -3.195362 time 2019-01-31 03:27:56.574803
Model ind 579 epoch 313 head A head_i_epoch 0 batch 200: avg loss -3.275543 avg loss no lamb -3.275543 time 2019-01-31 03:30:55.257008
Pre: time 2019-01-31 03:34:17.476571: 
 	std: 0.004846607
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 7), (3, 9), (4, 12), (5, 17), (6, 13), (7, 10), (8, 14), (9, 0), (10, 11), (11, 5), (12, 1), (13, 18), (14, 16), (15, 15), (16, 6), (17, 3), (18, 19), (19, 8)]
	test_accs: [0.23088333, 0.23155, 0.21958333, 0.2308, 0.23295]
	train_accs: [0.23088333, 0.23155, 0.21958333, 0.2308, 0.23295]
	best_train_sub_head: 4
	worst: 0.21958333
	avg: 0.22915332
	best: 0.23295

Starting e_i: 314
Model ind 579 epoch 314 head B head_i_epoch 0 batch 0: avg loss -1.555804 avg loss no lamb -1.555804 time 2019-01-31 03:34:20.670491
Model ind 579 epoch 314 head B head_i_epoch 0 batch 100: avg loss -1.632562 avg loss no lamb -1.632562 time 2019-01-31 03:37:16.091890
Model ind 579 epoch 314 head B head_i_epoch 0 batch 200: avg loss -1.639829 avg loss no lamb -1.639829 time 2019-01-31 03:40:12.469287
Model ind 579 epoch 314 head A head_i_epoch 0 batch 0: avg loss -3.150041 avg loss no lamb -3.150041 time 2019-01-31 03:43:08.046060
Model ind 579 epoch 314 head A head_i_epoch 0 batch 100: avg loss -3.223687 avg loss no lamb -3.223687 time 2019-01-31 03:46:06.358510
Model ind 579 epoch 314 head A head_i_epoch 0 batch 200: avg loss -3.265963 avg loss no lamb -3.265963 time 2019-01-31 03:49:05.288999
Pre: time 2019-01-31 03:52:27.995280: 
 	std: 0.003995741
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.22598334, 0.23008333, 0.2197, 0.23078333, 0.2283]
	train_accs: [0.22598334, 0.23008333, 0.2197, 0.23078333, 0.2283]
	best_train_sub_head: 3
	worst: 0.2197
	avg: 0.22697
	best: 0.23078333

Starting e_i: 315
Model ind 579 epoch 315 head B head_i_epoch 0 batch 0: avg loss -1.594563 avg loss no lamb -1.594563 time 2019-01-31 03:52:31.002763
Model ind 579 epoch 315 head B head_i_epoch 0 batch 100: avg loss -1.601609 avg loss no lamb -1.601609 time 2019-01-31 03:55:27.611218
Model ind 579 epoch 315 head B head_i_epoch 0 batch 200: avg loss -1.616327 avg loss no lamb -1.616327 time 2019-01-31 03:58:25.235794
Model ind 579 epoch 315 head A head_i_epoch 0 batch 0: avg loss -3.201882 avg loss no lamb -3.201882 time 2019-01-31 04:01:22.867940
Model ind 579 epoch 315 head A head_i_epoch 0 batch 100: avg loss -3.207541 avg loss no lamb -3.207541 time 2019-01-31 04:04:21.134398
Model ind 579 epoch 315 head A head_i_epoch 0 batch 200: avg loss -3.257110 avg loss no lamb -3.257110 time 2019-01-31 04:07:20.468583
Pre: time 2019-01-31 04:10:41.366962: 
 	std: 0.004358658
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 5), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.23088333, 0.2328, 0.22111666, 0.23248333, 0.2313]
	train_accs: [0.23088333, 0.2328, 0.22111666, 0.23248333, 0.2313]
	best_train_sub_head: 1
	worst: 0.22111666
	avg: 0.22971669
	best: 0.2328

Starting e_i: 316
Model ind 579 epoch 316 head B head_i_epoch 0 batch 0: avg loss -1.659390 avg loss no lamb -1.659390 time 2019-01-31 04:10:44.204524
Model ind 579 epoch 316 head B head_i_epoch 0 batch 100: avg loss -1.694851 avg loss no lamb -1.694851 time 2019-01-31 04:13:40.504441
Model ind 579 epoch 316 head B head_i_epoch 0 batch 200: avg loss -1.707218 avg loss no lamb -1.707218 time 2019-01-31 04:16:36.735831
Model ind 579 epoch 316 head A head_i_epoch 0 batch 0: avg loss -3.189070 avg loss no lamb -3.189070 time 2019-01-31 04:19:32.566690
Model ind 579 epoch 316 head A head_i_epoch 0 batch 100: avg loss -3.238421 avg loss no lamb -3.238421 time 2019-01-31 04:22:31.283499
Model ind 579 epoch 316 head A head_i_epoch 0 batch 200: avg loss -3.230335 avg loss no lamb -3.230335 time 2019-01-31 04:25:29.361014
Pre: time 2019-01-31 04:28:52.359490: 
 	std: 0.0037735112
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 19), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 7), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.22403333, 0.22653334, 0.21638334, 0.22648333, 0.22503333]
	train_accs: [0.22403333, 0.22653334, 0.21638334, 0.22648333, 0.22503333]
	best_train_sub_head: 1
	worst: 0.21638334
	avg: 0.22369333
	best: 0.22653334

Starting e_i: 317
Model ind 579 epoch 317 head B head_i_epoch 0 batch 0: avg loss -1.548069 avg loss no lamb -1.548069 time 2019-01-31 04:28:55.257988
Model ind 579 epoch 317 head B head_i_epoch 0 batch 100: avg loss -1.681033 avg loss no lamb -1.681033 time 2019-01-31 04:31:51.690467
Model ind 579 epoch 317 head B head_i_epoch 0 batch 200: avg loss -1.640689 avg loss no lamb -1.640689 time 2019-01-31 04:34:47.936246
Model ind 579 epoch 317 head A head_i_epoch 0 batch 0: avg loss -3.205271 avg loss no lamb -3.205271 time 2019-01-31 04:37:42.992850
Model ind 579 epoch 317 head A head_i_epoch 0 batch 100: avg loss -3.217477 avg loss no lamb -3.217477 time 2019-01-31 04:40:40.743669
Model ind 579 epoch 317 head A head_i_epoch 0 batch 200: avg loss -3.309042 avg loss no lamb -3.309042 time 2019-01-31 04:43:39.160356
Pre: time 2019-01-31 04:47:00.024483: 
 	std: 0.004737525
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.2283, 0.23015, 0.21756667, 0.23008333, 0.22846666]
	train_accs: [0.2283, 0.23015, 0.21756667, 0.23008333, 0.22846666]
	best_train_sub_head: 1
	worst: 0.21756667
	avg: 0.22691333
	best: 0.23015

Starting e_i: 318
Model ind 579 epoch 318 head B head_i_epoch 0 batch 0: avg loss -1.685187 avg loss no lamb -1.685187 time 2019-01-31 04:47:03.011115
Model ind 579 epoch 318 head B head_i_epoch 0 batch 100: avg loss -1.756033 avg loss no lamb -1.756033 time 2019-01-31 04:49:59.144351
Model ind 579 epoch 318 head B head_i_epoch 0 batch 200: avg loss -1.682742 avg loss no lamb -1.682742 time 2019-01-31 04:52:56.727819
Model ind 579 epoch 318 head A head_i_epoch 0 batch 0: avg loss -3.201753 avg loss no lamb -3.201753 time 2019-01-31 04:55:53.713371
Model ind 579 epoch 318 head A head_i_epoch 0 batch 100: avg loss -3.254058 avg loss no lamb -3.254058 time 2019-01-31 04:58:52.007513
Model ind 579 epoch 318 head A head_i_epoch 0 batch 200: avg loss -3.244883 avg loss no lamb -3.244883 time 2019-01-31 05:01:50.474918
Pre: time 2019-01-31 05:05:10.846014: 
 	std: 0.004617494
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 13), (3, 9), (4, 12), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 5), (12, 16), (13, 18), (14, 1), (15, 15), (16, 6), (17, 3), (18, 19), (19, 8)]
	test_accs: [0.22678334, 0.22738333, 0.21635, 0.22783333, 0.229]
	train_accs: [0.22678334, 0.22738333, 0.21635, 0.22783333, 0.229]
	best_train_sub_head: 4
	worst: 0.21635
	avg: 0.22546999
	best: 0.229

Starting e_i: 319
Model ind 579 epoch 319 head B head_i_epoch 0 batch 0: avg loss -1.654232 avg loss no lamb -1.654232 time 2019-01-31 05:05:14.048203
Model ind 579 epoch 319 head B head_i_epoch 0 batch 100: avg loss -1.638770 avg loss no lamb -1.638770 time 2019-01-31 05:08:10.120479
Model ind 579 epoch 319 head B head_i_epoch 0 batch 200: avg loss -1.663033 avg loss no lamb -1.663033 time 2019-01-31 05:11:06.729591
Model ind 579 epoch 319 head A head_i_epoch 0 batch 0: avg loss -3.190203 avg loss no lamb -3.190203 time 2019-01-31 05:14:03.190140
Model ind 579 epoch 319 head A head_i_epoch 0 batch 100: avg loss -3.266632 avg loss no lamb -3.266632 time 2019-01-31 05:17:01.174181
Model ind 579 epoch 319 head A head_i_epoch 0 batch 200: avg loss -3.219792 avg loss no lamb -3.219792 time 2019-01-31 05:19:58.327182
Pre: time 2019-01-31 05:23:19.475567: 
 	std: 0.004144493
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 15), (3, 9), (4, 12), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 5), (12, 1), (13, 18), (14, 16), (15, 13), (16, 6), (17, 3), (18, 19), (19, 8)]
	test_accs: [0.22716667, 0.22875, 0.21798334, 0.2282, 0.22883333]
	train_accs: [0.22716667, 0.22875, 0.21798334, 0.2282, 0.22883333]
	best_train_sub_head: 4
	worst: 0.21798334
	avg: 0.22618668
	best: 0.22883333

Starting e_i: 320
Model ind 579 epoch 320 head B head_i_epoch 0 batch 0: avg loss -1.606036 avg loss no lamb -1.606036 time 2019-01-31 05:23:22.395812
Model ind 579 epoch 320 head B head_i_epoch 0 batch 100: avg loss -1.652597 avg loss no lamb -1.652597 time 2019-01-31 05:26:18.753859
Model ind 579 epoch 320 head B head_i_epoch 0 batch 200: avg loss -1.655001 avg loss no lamb -1.655001 time 2019-01-31 05:29:14.897151
Model ind 579 epoch 320 head A head_i_epoch 0 batch 0: avg loss -3.224143 avg loss no lamb -3.224143 time 2019-01-31 05:32:10.248290
Model ind 579 epoch 320 head A head_i_epoch 0 batch 100: avg loss -3.240368 avg loss no lamb -3.240368 time 2019-01-31 05:35:08.148492
Model ind 579 epoch 320 head A head_i_epoch 0 batch 200: avg loss -3.235376 avg loss no lamb -3.235376 time 2019-01-31 05:38:04.995648
Pre: time 2019-01-31 05:41:27.058079: 
 	std: 0.003798514
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 13), (4, 4), (5, 19), (6, 8), (7, 11), (8, 3), (9, 16), (10, 15), (11, 17), (12, 7), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.22595, 0.22806667, 0.21781667, 0.22748333, 0.22711666]
	train_accs: [0.22595, 0.22806667, 0.21781667, 0.22748333, 0.22711666]
	best_train_sub_head: 1
	worst: 0.21781667
	avg: 0.22528668
	best: 0.22806667

Starting e_i: 321
Model ind 579 epoch 321 head B head_i_epoch 0 batch 0: avg loss -1.668650 avg loss no lamb -1.668650 time 2019-01-31 05:41:34.137562
Model ind 579 epoch 321 head B head_i_epoch 0 batch 100: avg loss -1.598353 avg loss no lamb -1.598353 time 2019-01-31 05:44:32.245086
Model ind 579 epoch 321 head B head_i_epoch 0 batch 200: avg loss -1.646666 avg loss no lamb -1.646666 time 2019-01-31 05:47:30.541768
Model ind 579 epoch 321 head A head_i_epoch 0 batch 0: avg loss -3.202899 avg loss no lamb -3.202899 time 2019-01-31 05:50:26.923054
Model ind 579 epoch 321 head A head_i_epoch 0 batch 100: avg loss -3.258104 avg loss no lamb -3.258104 time 2019-01-31 05:53:25.570893
Model ind 579 epoch 321 head A head_i_epoch 0 batch 200: avg loss -3.212784 avg loss no lamb -3.212784 time 2019-01-31 05:56:23.260542
Pre: time 2019-01-31 05:59:44.489944: 
 	std: 0.0044301646
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.22908333, 0.23101667, 0.2193, 0.23113333, 0.22953333]
	train_accs: [0.22908333, 0.23101667, 0.2193, 0.23113333, 0.22953333]
	best_train_sub_head: 3
	worst: 0.2193
	avg: 0.22801332
	best: 0.23113333

Starting e_i: 322
Model ind 579 epoch 322 head B head_i_epoch 0 batch 0: avg loss -1.618557 avg loss no lamb -1.618557 time 2019-01-31 05:59:47.370896
Model ind 579 epoch 322 head B head_i_epoch 0 batch 100: avg loss -1.645495 avg loss no lamb -1.645495 time 2019-01-31 06:02:43.935834
Model ind 579 epoch 322 head B head_i_epoch 0 batch 200: avg loss -1.639551 avg loss no lamb -1.639551 time 2019-01-31 06:05:39.796065
Model ind 579 epoch 322 head A head_i_epoch 0 batch 0: avg loss -3.206789 avg loss no lamb -3.206789 time 2019-01-31 06:08:37.057457
Model ind 579 epoch 322 head A head_i_epoch 0 batch 100: avg loss -3.240496 avg loss no lamb -3.240496 time 2019-01-31 06:11:34.993030
Model ind 579 epoch 322 head A head_i_epoch 0 batch 200: avg loss -3.223200 avg loss no lamb -3.223200 time 2019-01-31 06:14:33.265277
Pre: time 2019-01-31 06:17:54.321416: 
 	std: 0.004447736
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 13), (3, 9), (4, 12), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 5), (12, 1), (13, 18), (14, 16), (15, 15), (16, 6), (17, 3), (18, 19), (19, 8)]
	test_accs: [0.23011667, 0.23126666, 0.21985, 0.23078333, 0.23146667]
	train_accs: [0.23011667, 0.23126666, 0.21985, 0.23078333, 0.23146667]
	best_train_sub_head: 4
	worst: 0.21985
	avg: 0.22869667
	best: 0.23146667

Starting e_i: 323
Model ind 579 epoch 323 head B head_i_epoch 0 batch 0: avg loss -1.672179 avg loss no lamb -1.672179 time 2019-01-31 06:17:57.341111
Model ind 579 epoch 323 head B head_i_epoch 0 batch 100: avg loss -1.649083 avg loss no lamb -1.649083 time 2019-01-31 06:20:53.769365
Model ind 579 epoch 323 head B head_i_epoch 0 batch 200: avg loss -1.652600 avg loss no lamb -1.652600 time 2019-01-31 06:23:52.406230
Model ind 579 epoch 323 head A head_i_epoch 0 batch 0: avg loss -3.225883 avg loss no lamb -3.225883 time 2019-01-31 06:26:49.348162
Model ind 579 epoch 323 head A head_i_epoch 0 batch 100: avg loss -3.209496 avg loss no lamb -3.209496 time 2019-01-31 06:29:47.132315
Model ind 579 epoch 323 head A head_i_epoch 0 batch 200: avg loss -3.231814 avg loss no lamb -3.231814 time 2019-01-31 06:32:43.239322
Pre: time 2019-01-31 06:36:05.712678: 
 	std: 0.003656565
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 5), (4, 4), (5, 3), (6, 18), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 13), (13, 11), (14, 10), (15, 16), (16, 12), (17, 17), (18, 1), (19, 19)]
	test_accs: [0.22786666, 0.22818333, 0.21915, 0.22858334, 0.22845]
	train_accs: [0.22786666, 0.22818333, 0.21915, 0.22858334, 0.22845]
	best_train_sub_head: 3
	worst: 0.21915
	avg: 0.22644667
	best: 0.22858334

Starting e_i: 324
Model ind 579 epoch 324 head B head_i_epoch 0 batch 0: avg loss -1.650574 avg loss no lamb -1.650574 time 2019-01-31 06:36:09.268441
Model ind 579 epoch 324 head B head_i_epoch 0 batch 100: avg loss -1.694437 avg loss no lamb -1.694437 time 2019-01-31 06:39:06.186357
Model ind 579 epoch 324 head B head_i_epoch 0 batch 200: avg loss -1.682398 avg loss no lamb -1.682398 time 2019-01-31 06:42:02.956277
Model ind 579 epoch 324 head A head_i_epoch 0 batch 0: avg loss -3.265058 avg loss no lamb -3.265058 time 2019-01-31 06:45:00.100340
Model ind 579 epoch 324 head A head_i_epoch 0 batch 100: avg loss -3.247409 avg loss no lamb -3.247409 time 2019-01-31 06:47:57.140953
Model ind 579 epoch 324 head A head_i_epoch 0 batch 200: avg loss -3.234079 avg loss no lamb -3.234079 time 2019-01-31 06:50:54.432618
Pre: time 2019-01-31 06:54:16.817210: 
 	std: 0.004214535
	best_train_sub_head_match: [(0, 13), (1, 15), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 18)]
	test_accs: [0.23048334, 0.23185, 0.22076666, 0.23208334, 0.2301]
	train_accs: [0.23048334, 0.23185, 0.22076666, 0.23208334, 0.2301]
	best_train_sub_head: 3
	worst: 0.22076666
	avg: 0.22905667
	best: 0.23208334

Starting e_i: 325
Model ind 579 epoch 325 head B head_i_epoch 0 batch 0: avg loss -1.601396 avg loss no lamb -1.601396 time 2019-01-31 06:54:20.255235
Model ind 579 epoch 325 head B head_i_epoch 0 batch 100: avg loss -1.697570 avg loss no lamb -1.697570 time 2019-01-31 06:57:16.629305
Model ind 579 epoch 325 head B head_i_epoch 0 batch 200: avg loss -1.666183 avg loss no lamb -1.666183 time 2019-01-31 07:00:12.006593
Model ind 579 epoch 325 head A head_i_epoch 0 batch 0: avg loss -3.204956 avg loss no lamb -3.204956 time 2019-01-31 07:03:07.813475
Model ind 579 epoch 325 head A head_i_epoch 0 batch 100: avg loss -3.264619 avg loss no lamb -3.264619 time 2019-01-31 07:06:05.462508
Model ind 579 epoch 325 head A head_i_epoch 0 batch 200: avg loss -3.316478 avg loss no lamb -3.316478 time 2019-01-31 07:09:03.260204
Pre: time 2019-01-31 07:12:26.222327: 
 	std: 0.00453561
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.23281667, 0.23408334, 0.22201666, 0.23378333, 0.23226666]
	train_accs: [0.23281667, 0.23408334, 0.22201666, 0.23378333, 0.23226666]
	best_train_sub_head: 1
	worst: 0.22201666
	avg: 0.23099335
	best: 0.23408334

Starting e_i: 326
Model ind 579 epoch 326 head B head_i_epoch 0 batch 0: avg loss -1.593763 avg loss no lamb -1.593763 time 2019-01-31 07:12:29.791074
Model ind 579 epoch 326 head B head_i_epoch 0 batch 100: avg loss -1.635851 avg loss no lamb -1.635851 time 2019-01-31 07:15:25.839979
Model ind 579 epoch 326 head B head_i_epoch 0 batch 200: avg loss -1.682660 avg loss no lamb -1.682660 time 2019-01-31 07:18:23.045391
Model ind 579 epoch 326 head A head_i_epoch 0 batch 0: avg loss -3.208994 avg loss no lamb -3.208994 time 2019-01-31 07:21:20.065278
Model ind 579 epoch 326 head A head_i_epoch 0 batch 100: avg loss -3.188751 avg loss no lamb -3.188751 time 2019-01-31 07:24:17.838348
Model ind 579 epoch 326 head A head_i_epoch 0 batch 200: avg loss -3.228611 avg loss no lamb -3.228611 time 2019-01-31 07:27:15.010724
Pre: time 2019-01-31 07:30:36.385587: 
 	std: 0.00339305
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.22926667, 0.22951667, 0.22093333, 0.22951667, 0.22935]
	train_accs: [0.22926667, 0.22951667, 0.22093333, 0.22951667, 0.22935]
	best_train_sub_head: 1
	worst: 0.22093333
	avg: 0.22771665
	best: 0.22951667

Starting e_i: 327
Model ind 579 epoch 327 head B head_i_epoch 0 batch 0: avg loss -1.580160 avg loss no lamb -1.580160 time 2019-01-31 07:30:39.335553
Model ind 579 epoch 327 head B head_i_epoch 0 batch 100: avg loss -1.629772 avg loss no lamb -1.629772 time 2019-01-31 07:33:35.297000
Model ind 579 epoch 327 head B head_i_epoch 0 batch 200: avg loss -1.636706 avg loss no lamb -1.636706 time 2019-01-31 07:36:32.127560
Model ind 579 epoch 327 head A head_i_epoch 0 batch 0: avg loss -3.255583 avg loss no lamb -3.255583 time 2019-01-31 07:39:27.848555
Model ind 579 epoch 327 head A head_i_epoch 0 batch 100: avg loss -3.257326 avg loss no lamb -3.257326 time 2019-01-31 07:42:24.727731
Model ind 579 epoch 327 head A head_i_epoch 0 batch 200: avg loss -3.236188 avg loss no lamb -3.236188 time 2019-01-31 07:45:23.274505
Pre: time 2019-01-31 07:48:47.086067: 
 	std: 0.0036137963
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23466666, 0.23341666, 0.22483334, 0.2339, 0.2331]
	train_accs: [0.23466666, 0.23341666, 0.22483334, 0.2339, 0.2331]
	best_train_sub_head: 0
	worst: 0.22483334
	avg: 0.23198333
	best: 0.23466666

Starting e_i: 328
Model ind 579 epoch 328 head B head_i_epoch 0 batch 0: avg loss -1.649853 avg loss no lamb -1.649853 time 2019-01-31 07:48:50.642973
Model ind 579 epoch 328 head B head_i_epoch 0 batch 100: avg loss -1.662985 avg loss no lamb -1.662985 time 2019-01-31 07:51:46.903895
Model ind 579 epoch 328 head B head_i_epoch 0 batch 200: avg loss -1.638973 avg loss no lamb -1.638973 time 2019-01-31 07:54:43.343508
Model ind 579 epoch 328 head A head_i_epoch 0 batch 0: avg loss -3.235613 avg loss no lamb -3.235613 time 2019-01-31 07:57:39.825983
Model ind 579 epoch 328 head A head_i_epoch 0 batch 100: avg loss -3.280268 avg loss no lamb -3.280268 time 2019-01-31 08:00:36.540066
Model ind 579 epoch 328 head A head_i_epoch 0 batch 200: avg loss -3.264671 avg loss no lamb -3.264671 time 2019-01-31 08:03:33.636243
Pre: time 2019-01-31 08:06:53.938806: 
 	std: 0.0042525474
	best_train_sub_head_match: [(0, 13), (1, 15), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 18)]
	test_accs: [0.23421666, 0.23531666, 0.22438334, 0.23565, 0.23456667]
	train_accs: [0.23421666, 0.23531666, 0.22438334, 0.23565, 0.23456667]
	best_train_sub_head: 3
	worst: 0.22438334
	avg: 0.23282667
	best: 0.23565

Starting e_i: 329
Model ind 579 epoch 329 head B head_i_epoch 0 batch 0: avg loss -1.619897 avg loss no lamb -1.619897 time 2019-01-31 08:06:57.049422
Model ind 579 epoch 329 head B head_i_epoch 0 batch 100: avg loss -1.689440 avg loss no lamb -1.689440 time 2019-01-31 08:09:54.942027
Model ind 579 epoch 329 head B head_i_epoch 0 batch 200: avg loss -1.681914 avg loss no lamb -1.681914 time 2019-01-31 08:12:51.132370
Model ind 579 epoch 329 head A head_i_epoch 0 batch 0: avg loss -3.175892 avg loss no lamb -3.175892 time 2019-01-31 08:15:47.244331
Model ind 579 epoch 329 head A head_i_epoch 0 batch 100: avg loss -3.298683 avg loss no lamb -3.298683 time 2019-01-31 08:18:47.253161
Model ind 579 epoch 329 head A head_i_epoch 0 batch 200: avg loss -3.252776 avg loss no lamb -3.252776 time 2019-01-31 08:21:44.075430
Pre: time 2019-01-31 08:25:06.821650: 
 	std: 0.004864034
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.23571667, 0.2373, 0.22423333, 0.23621666, 0.23605]
	train_accs: [0.23571667, 0.2373, 0.22423333, 0.23621666, 0.23605]
	best_train_sub_head: 1
	worst: 0.22423333
	avg: 0.23390333
	best: 0.2373

Starting e_i: 330
Model ind 579 epoch 330 head B head_i_epoch 0 batch 0: avg loss -1.669241 avg loss no lamb -1.669241 time 2019-01-31 08:25:10.137807
Model ind 579 epoch 330 head B head_i_epoch 0 batch 100: avg loss -1.621998 avg loss no lamb -1.621998 time 2019-01-31 08:28:06.301609
Model ind 579 epoch 330 head B head_i_epoch 0 batch 200: avg loss -1.636023 avg loss no lamb -1.636023 time 2019-01-31 08:31:02.259171
Model ind 579 epoch 330 head A head_i_epoch 0 batch 0: avg loss -3.202184 avg loss no lamb -3.202184 time 2019-01-31 08:33:57.938581
Model ind 579 epoch 330 head A head_i_epoch 0 batch 100: avg loss -3.197568 avg loss no lamb -3.197568 time 2019-01-31 08:36:54.217197
Model ind 579 epoch 330 head A head_i_epoch 0 batch 200: avg loss -3.220338 avg loss no lamb -3.220338 time 2019-01-31 08:39:50.503542
Pre: time 2019-01-31 08:43:12.120832: 
 	std: 0.0044275518
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 15), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.23205, 0.2328, 0.22116667, 0.23268333, 0.23088333]
	train_accs: [0.23205, 0.2328, 0.22116667, 0.23268333, 0.23088333]
	best_train_sub_head: 1
	worst: 0.22116667
	avg: 0.22991666
	best: 0.2328

Starting e_i: 331
Model ind 579 epoch 331 head B head_i_epoch 0 batch 0: avg loss -1.593957 avg loss no lamb -1.593957 time 2019-01-31 08:43:19.146235
Model ind 579 epoch 331 head B head_i_epoch 0 batch 100: avg loss -1.687431 avg loss no lamb -1.687431 time 2019-01-31 08:46:16.321158
Model ind 579 epoch 331 head B head_i_epoch 0 batch 200: avg loss -1.694432 avg loss no lamb -1.694432 time 2019-01-31 08:49:14.404507
Model ind 579 epoch 331 head A head_i_epoch 0 batch 0: avg loss -3.253279 avg loss no lamb -3.253279 time 2019-01-31 08:52:09.992852
Model ind 579 epoch 331 head A head_i_epoch 0 batch 100: avg loss -3.271654 avg loss no lamb -3.271654 time 2019-01-31 08:55:08.139950
Model ind 579 epoch 331 head A head_i_epoch 0 batch 200: avg loss -3.210284 avg loss no lamb -3.210284 time 2019-01-31 08:58:07.208297
Pre: time 2019-01-31 09:01:29.919115: 
 	std: 0.0051066657
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 13), (19, 18)]
	test_accs: [0.23625, 0.23663333, 0.22355, 0.23673333, 0.23545]
	train_accs: [0.23625, 0.23663333, 0.22355, 0.23673333, 0.23545]
	best_train_sub_head: 3
	worst: 0.22355
	avg: 0.23372333
	best: 0.23673333

Starting e_i: 332
Model ind 579 epoch 332 head B head_i_epoch 0 batch 0: avg loss -1.654939 avg loss no lamb -1.654939 time 2019-01-31 09:01:33.157177
Model ind 579 epoch 332 head B head_i_epoch 0 batch 100: avg loss -1.612014 avg loss no lamb -1.612014 time 2019-01-31 09:04:29.581448
Model ind 579 epoch 332 head B head_i_epoch 0 batch 200: avg loss -1.652085 avg loss no lamb -1.652085 time 2019-01-31 09:07:26.377209
Model ind 579 epoch 332 head A head_i_epoch 0 batch 0: avg loss -3.204459 avg loss no lamb -3.204459 time 2019-01-31 09:10:21.808458
Model ind 579 epoch 332 head A head_i_epoch 0 batch 100: avg loss -3.250973 avg loss no lamb -3.250973 time 2019-01-31 09:13:19.362346
Model ind 579 epoch 332 head A head_i_epoch 0 batch 200: avg loss -3.227597 avg loss no lamb -3.227597 time 2019-01-31 09:16:16.167434
Pre: time 2019-01-31 09:19:38.415960: 
 	std: 0.004747624
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.23316666, 0.23403333, 0.22118333, 0.23241666, 0.23213333]
	train_accs: [0.23316666, 0.23403333, 0.22118333, 0.23241666, 0.23213333]
	best_train_sub_head: 1
	worst: 0.22118333
	avg: 0.23058668
	best: 0.23403333

Starting e_i: 333
Model ind 579 epoch 333 head B head_i_epoch 0 batch 0: avg loss -1.544356 avg loss no lamb -1.544356 time 2019-01-31 09:19:41.658194
Model ind 579 epoch 333 head B head_i_epoch 0 batch 100: avg loss -1.683908 avg loss no lamb -1.683908 time 2019-01-31 09:22:38.304739
Model ind 579 epoch 333 head B head_i_epoch 0 batch 200: avg loss -1.652253 avg loss no lamb -1.652253 time 2019-01-31 09:25:34.805758
Model ind 579 epoch 333 head A head_i_epoch 0 batch 0: avg loss -3.196776 avg loss no lamb -3.196776 time 2019-01-31 09:28:30.449300
Model ind 579 epoch 333 head A head_i_epoch 0 batch 100: avg loss -3.227556 avg loss no lamb -3.227556 time 2019-01-31 09:31:27.649796
Model ind 579 epoch 333 head A head_i_epoch 0 batch 200: avg loss -3.213016 avg loss no lamb -3.213016 time 2019-01-31 09:34:26.342593
Pre: time 2019-01-31 09:37:47.577007: 
 	std: 0.0043489034
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 5), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.23763333, 0.23913333, 0.22721666, 0.2382, 0.23661667]
	train_accs: [0.23763333, 0.23913333, 0.22721666, 0.2382, 0.23661667]
	best_train_sub_head: 1
	worst: 0.22721666
	avg: 0.23576
	best: 0.23913333

Starting e_i: 334
Model ind 579 epoch 334 head B head_i_epoch 0 batch 0: avg loss -1.677226 avg loss no lamb -1.677226 time 2019-01-31 09:37:55.735526
Model ind 579 epoch 334 head B head_i_epoch 0 batch 100: avg loss -1.596746 avg loss no lamb -1.596746 time 2019-01-31 09:40:52.612641
Model ind 579 epoch 334 head B head_i_epoch 0 batch 200: avg loss -1.650991 avg loss no lamb -1.650991 time 2019-01-31 09:43:48.754743
Model ind 579 epoch 334 head A head_i_epoch 0 batch 0: avg loss -3.121423 avg loss no lamb -3.121423 time 2019-01-31 09:46:45.558932
Model ind 579 epoch 334 head A head_i_epoch 0 batch 100: avg loss -3.212082 avg loss no lamb -3.212082 time 2019-01-31 09:49:43.191809
Model ind 579 epoch 334 head A head_i_epoch 0 batch 200: avg loss -3.283305 avg loss no lamb -3.283305 time 2019-01-31 09:52:39.253817
Pre: time 2019-01-31 09:56:01.255142: 
 	std: 0.004154408
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 15), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.23181666, 0.23378333, 0.22248334, 0.23305, 0.23228334]
	train_accs: [0.23181666, 0.23378333, 0.22248334, 0.23305, 0.23228334]
	best_train_sub_head: 1
	worst: 0.22248334
	avg: 0.23068333
	best: 0.23378333

Starting e_i: 335
Model ind 579 epoch 335 head B head_i_epoch 0 batch 0: avg loss -1.591839 avg loss no lamb -1.591839 time 2019-01-31 09:56:04.862677
Model ind 579 epoch 335 head B head_i_epoch 0 batch 100: avg loss -1.635896 avg loss no lamb -1.635896 time 2019-01-31 09:59:00.485412
Model ind 579 epoch 335 head B head_i_epoch 0 batch 200: avg loss -1.679700 avg loss no lamb -1.679700 time 2019-01-31 10:01:56.450425
Model ind 579 epoch 335 head A head_i_epoch 0 batch 0: avg loss -3.210139 avg loss no lamb -3.210139 time 2019-01-31 10:04:52.602139
Model ind 579 epoch 335 head A head_i_epoch 0 batch 100: avg loss -3.252393 avg loss no lamb -3.252393 time 2019-01-31 10:07:50.015950
Model ind 579 epoch 335 head A head_i_epoch 0 batch 200: avg loss -3.245360 avg loss no lamb -3.245360 time 2019-01-31 10:10:47.958048
Pre: time 2019-01-31 10:14:09.006699: 
 	std: 0.004697986
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 2), (10, 8), (11, 17), (12, 5), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.23085, 0.2326, 0.21966666, 0.23115, 0.2305]
	train_accs: [0.23085, 0.2326, 0.21966666, 0.23115, 0.2305]
	best_train_sub_head: 1
	worst: 0.21966666
	avg: 0.22895333
	best: 0.2326

Starting e_i: 336
Model ind 579 epoch 336 head B head_i_epoch 0 batch 0: avg loss -1.622225 avg loss no lamb -1.622225 time 2019-01-31 10:14:12.690729
Model ind 579 epoch 336 head B head_i_epoch 0 batch 100: avg loss -1.673937 avg loss no lamb -1.673937 time 2019-01-31 10:17:08.262784
Model ind 579 epoch 336 head B head_i_epoch 0 batch 200: avg loss -1.692231 avg loss no lamb -1.692231 time 2019-01-31 10:20:04.065272
Model ind 579 epoch 336 head A head_i_epoch 0 batch 0: avg loss -3.194286 avg loss no lamb -3.194286 time 2019-01-31 10:23:00.299507
Model ind 579 epoch 336 head A head_i_epoch 0 batch 100: avg loss -3.284626 avg loss no lamb -3.284626 time 2019-01-31 10:25:56.982408
Model ind 579 epoch 336 head A head_i_epoch 0 batch 200: avg loss -3.171985 avg loss no lamb -3.171985 time 2019-01-31 10:28:55.315593
Pre: time 2019-01-31 10:32:19.871602: 
 	std: 0.0040341434
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.23493333, 0.23678334, 0.22551666, 0.2348, 0.23526667]
	train_accs: [0.23493333, 0.23678334, 0.22551666, 0.2348, 0.23526667]
	best_train_sub_head: 1
	worst: 0.22551666
	avg: 0.23346
	best: 0.23678334

Starting e_i: 337
Model ind 579 epoch 337 head B head_i_epoch 0 batch 0: avg loss -1.588120 avg loss no lamb -1.588120 time 2019-01-31 10:32:23.628196
Model ind 579 epoch 337 head B head_i_epoch 0 batch 100: avg loss -1.712124 avg loss no lamb -1.712124 time 2019-01-31 10:35:20.220573
Model ind 579 epoch 337 head B head_i_epoch 0 batch 200: avg loss -1.670753 avg loss no lamb -1.670753 time 2019-01-31 10:38:18.571406
Model ind 579 epoch 337 head A head_i_epoch 0 batch 0: avg loss -3.155236 avg loss no lamb -3.155236 time 2019-01-31 10:41:16.611730
Model ind 579 epoch 337 head A head_i_epoch 0 batch 100: avg loss -3.318952 avg loss no lamb -3.318952 time 2019-01-31 10:44:15.681472
Model ind 579 epoch 337 head A head_i_epoch 0 batch 200: avg loss -3.261094 avg loss no lamb -3.261094 time 2019-01-31 10:47:12.305335
Pre: time 2019-01-31 10:50:35.558726: 
 	std: 0.0038562615
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.22951667, 0.23356667, 0.2225, 0.23246667, 0.22965]
	train_accs: [0.22951667, 0.23356667, 0.2225, 0.23246667, 0.22965]
	best_train_sub_head: 1
	worst: 0.2225
	avg: 0.22954002
	best: 0.23356667

Starting e_i: 338
Model ind 579 epoch 338 head B head_i_epoch 0 batch 0: avg loss -1.617948 avg loss no lamb -1.617948 time 2019-01-31 10:50:38.609642
Model ind 579 epoch 338 head B head_i_epoch 0 batch 100: avg loss -1.668030 avg loss no lamb -1.668030 time 2019-01-31 10:53:36.595446
Model ind 579 epoch 338 head B head_i_epoch 0 batch 200: avg loss -1.711326 avg loss no lamb -1.711326 time 2019-01-31 10:56:32.868654
Model ind 579 epoch 338 head A head_i_epoch 0 batch 0: avg loss -3.172568 avg loss no lamb -3.172568 time 2019-01-31 10:59:30.364217
Model ind 579 epoch 338 head A head_i_epoch 0 batch 100: avg loss -3.246985 avg loss no lamb -3.246985 time 2019-01-31 11:02:27.729675
Model ind 579 epoch 338 head A head_i_epoch 0 batch 200: avg loss -3.310185 avg loss no lamb -3.310185 time 2019-01-31 11:05:23.893637
Pre: time 2019-01-31 11:08:45.908463: 
 	std: 0.0036323906
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.22771667, 0.22966667, 0.21961667, 0.22895, 0.22765]
	train_accs: [0.22771667, 0.22966667, 0.21961667, 0.22895, 0.22765]
	best_train_sub_head: 1
	worst: 0.21961667
	avg: 0.22672
	best: 0.22966667

Starting e_i: 339
Model ind 579 epoch 339 head B head_i_epoch 0 batch 0: avg loss -1.608632 avg loss no lamb -1.608632 time 2019-01-31 11:08:48.955193
Model ind 579 epoch 339 head B head_i_epoch 0 batch 100: avg loss -1.729148 avg loss no lamb -1.729148 time 2019-01-31 11:11:45.281650
Model ind 579 epoch 339 head B head_i_epoch 0 batch 200: avg loss -1.665366 avg loss no lamb -1.665366 time 2019-01-31 11:14:41.208249
Model ind 579 epoch 339 head A head_i_epoch 0 batch 0: avg loss -3.226760 avg loss no lamb -3.226760 time 2019-01-31 11:17:36.934966
Model ind 579 epoch 339 head A head_i_epoch 0 batch 100: avg loss -3.238281 avg loss no lamb -3.238281 time 2019-01-31 11:20:34.425336
Model ind 579 epoch 339 head A head_i_epoch 0 batch 200: avg loss -3.255877 avg loss no lamb -3.255877 time 2019-01-31 11:23:32.068405
Pre: time 2019-01-31 11:26:55.862138: 
 	std: 0.004290205
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 13), (3, 9), (4, 12), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 5), (12, 1), (13, 18), (14, 16), (15, 15), (16, 6), (17, 3), (18, 19), (19, 8)]
	test_accs: [0.23241666, 0.23305, 0.22261667, 0.23253334, 0.23463333]
	train_accs: [0.23241666, 0.23305, 0.22261667, 0.23253334, 0.23463333]
	best_train_sub_head: 4
	worst: 0.22261667
	avg: 0.23105001
	best: 0.23463333

Starting e_i: 340
Model ind 579 epoch 340 head B head_i_epoch 0 batch 0: avg loss -1.668361 avg loss no lamb -1.668361 time 2019-01-31 11:26:59.022772
Model ind 579 epoch 340 head B head_i_epoch 0 batch 100: avg loss -1.709962 avg loss no lamb -1.709962 time 2019-01-31 11:29:55.802882
Model ind 579 epoch 340 head B head_i_epoch 0 batch 200: avg loss -1.731405 avg loss no lamb -1.731405 time 2019-01-31 11:32:51.683217
Model ind 579 epoch 340 head A head_i_epoch 0 batch 0: avg loss -3.189072 avg loss no lamb -3.189072 time 2019-01-31 11:35:47.010588
Model ind 579 epoch 340 head A head_i_epoch 0 batch 100: avg loss -3.277901 avg loss no lamb -3.277901 time 2019-01-31 11:38:44.537461
Model ind 579 epoch 340 head A head_i_epoch 0 batch 200: avg loss -3.284636 avg loss no lamb -3.284636 time 2019-01-31 11:41:41.309498
Pre: time 2019-01-31 11:45:05.971836: 
 	std: 0.003769328
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.23278333, 0.23306666, 0.22296667, 0.23141667, 0.2318]
	train_accs: [0.23278333, 0.23306666, 0.22296667, 0.23141667, 0.2318]
	best_train_sub_head: 1
	worst: 0.22296667
	avg: 0.23040667
	best: 0.23306666

Starting e_i: 341
Model ind 579 epoch 341 head B head_i_epoch 0 batch 0: avg loss -1.637069 avg loss no lamb -1.637069 time 2019-01-31 11:45:12.703358
Model ind 579 epoch 341 head B head_i_epoch 0 batch 100: avg loss -1.687343 avg loss no lamb -1.687343 time 2019-01-31 11:48:09.617612
Model ind 579 epoch 341 head B head_i_epoch 0 batch 200: avg loss -1.686127 avg loss no lamb -1.686127 time 2019-01-31 11:51:07.527637
Model ind 579 epoch 341 head A head_i_epoch 0 batch 0: avg loss -3.218948 avg loss no lamb -3.218948 time 2019-01-31 11:54:03.923693
Model ind 579 epoch 341 head A head_i_epoch 0 batch 100: avg loss -3.201310 avg loss no lamb -3.201310 time 2019-01-31 11:57:01.605141
Model ind 579 epoch 341 head A head_i_epoch 0 batch 200: avg loss -3.273775 avg loss no lamb -3.273775 time 2019-01-31 12:00:00.816848
Pre: time 2019-01-31 12:03:23.801935: 
 	std: 0.0043470887
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23461667, 0.23345, 0.22263333, 0.23275, 0.2326]
	train_accs: [0.23461667, 0.23345, 0.22263333, 0.23275, 0.2326]
	best_train_sub_head: 0
	worst: 0.22263333
	avg: 0.23121
	best: 0.23461667

Starting e_i: 342
Model ind 579 epoch 342 head B head_i_epoch 0 batch 0: avg loss -1.710916 avg loss no lamb -1.710916 time 2019-01-31 12:03:27.764950
Model ind 579 epoch 342 head B head_i_epoch 0 batch 100: avg loss -1.714251 avg loss no lamb -1.714251 time 2019-01-31 12:06:24.432550
Model ind 579 epoch 342 head B head_i_epoch 0 batch 200: avg loss -1.718593 avg loss no lamb -1.718593 time 2019-01-31 12:09:20.990048
Model ind 579 epoch 342 head A head_i_epoch 0 batch 0: avg loss -3.146182 avg loss no lamb -3.146182 time 2019-01-31 12:12:17.868986
Model ind 579 epoch 342 head A head_i_epoch 0 batch 100: avg loss -3.323447 avg loss no lamb -3.323447 time 2019-01-31 12:15:16.224340
Model ind 579 epoch 342 head A head_i_epoch 0 batch 200: avg loss -3.316776 avg loss no lamb -3.316776 time 2019-01-31 12:18:14.978398
Pre: time 2019-01-31 12:21:37.070169: 
 	std: 0.0033549054
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23561667, 0.23373333, 0.22611667, 0.23268333, 0.23456667]
	train_accs: [0.23561667, 0.23373333, 0.22611667, 0.23268333, 0.23456667]
	best_train_sub_head: 0
	worst: 0.22611667
	avg: 0.23254332
	best: 0.23561667

Starting e_i: 343
Model ind 579 epoch 343 head B head_i_epoch 0 batch 0: avg loss -1.649535 avg loss no lamb -1.649535 time 2019-01-31 12:21:40.066661
Model ind 579 epoch 343 head B head_i_epoch 0 batch 100: avg loss -1.679805 avg loss no lamb -1.679805 time 2019-01-31 12:24:36.344970
Model ind 579 epoch 343 head B head_i_epoch 0 batch 200: avg loss -1.646821 avg loss no lamb -1.646821 time 2019-01-31 12:27:32.323487
Model ind 579 epoch 343 head A head_i_epoch 0 batch 0: avg loss -3.170478 avg loss no lamb -3.170478 time 2019-01-31 12:30:28.464363
Model ind 579 epoch 343 head A head_i_epoch 0 batch 100: avg loss -3.268945 avg loss no lamb -3.268945 time 2019-01-31 12:33:26.485583
Model ind 579 epoch 343 head A head_i_epoch 0 batch 200: avg loss -3.284667 avg loss no lamb -3.284667 time 2019-01-31 12:36:23.535148
Pre: time 2019-01-31 12:39:46.333335: 
 	std: 0.004085602
	best_train_sub_head_match: [(0, 18), (1, 5), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23605, 0.23518333, 0.22501667, 0.23506667, 0.2342]
	train_accs: [0.23605, 0.23518333, 0.22501667, 0.23506667, 0.2342]
	best_train_sub_head: 0
	worst: 0.22501667
	avg: 0.23310332
	best: 0.23605

Starting e_i: 344
Model ind 579 epoch 344 head B head_i_epoch 0 batch 0: avg loss -1.616589 avg loss no lamb -1.616589 time 2019-01-31 12:39:49.719269
Model ind 579 epoch 344 head B head_i_epoch 0 batch 100: avg loss -1.737239 avg loss no lamb -1.737239 time 2019-01-31 12:42:45.058977
Model ind 579 epoch 344 head B head_i_epoch 0 batch 200: avg loss -1.711270 avg loss no lamb -1.711270 time 2019-01-31 12:45:40.788947
Model ind 579 epoch 344 head A head_i_epoch 0 batch 0: avg loss -3.248906 avg loss no lamb -3.248906 time 2019-01-31 12:48:37.381322
Model ind 579 epoch 344 head A head_i_epoch 0 batch 100: avg loss -3.244749 avg loss no lamb -3.244749 time 2019-01-31 12:51:36.282154
Model ind 579 epoch 344 head A head_i_epoch 0 batch 200: avg loss -3.270460 avg loss no lamb -3.270460 time 2019-01-31 12:54:34.478337
Pre: time 2019-01-31 12:57:57.143279: 
 	std: 0.004077341
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2288, 0.23173334, 0.22058333, 0.23153333, 0.22936666]
	train_accs: [0.2288, 0.23173334, 0.22058333, 0.23153333, 0.22936666]
	best_train_sub_head: 1
	worst: 0.22058333
	avg: 0.22840333
	best: 0.23173334

Starting e_i: 345
Model ind 579 epoch 345 head B head_i_epoch 0 batch 0: avg loss -1.642772 avg loss no lamb -1.642772 time 2019-01-31 12:58:00.397785
Model ind 579 epoch 345 head B head_i_epoch 0 batch 100: avg loss -1.655216 avg loss no lamb -1.655216 time 2019-01-31 13:00:57.729818
Model ind 579 epoch 345 head B head_i_epoch 0 batch 200: avg loss -1.711609 avg loss no lamb -1.711609 time 2019-01-31 13:03:54.764223
Model ind 579 epoch 345 head A head_i_epoch 0 batch 0: avg loss -3.209891 avg loss no lamb -3.209891 time 2019-01-31 13:06:51.396508
Model ind 579 epoch 345 head A head_i_epoch 0 batch 100: avg loss -3.282254 avg loss no lamb -3.282254 time 2019-01-31 13:09:49.578822
Model ind 579 epoch 345 head A head_i_epoch 0 batch 200: avg loss -3.325848 avg loss no lamb -3.325848 time 2019-01-31 13:12:48.807286
Pre: time 2019-01-31 13:16:12.822890: 
 	std: 0.0029790823
	best_train_sub_head_match: [(0, 18), (1, 16), (2, 14), (3, 0), (4, 12), (5, 4), (6, 8), (7, 6), (8, 5), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23113333, 0.22961667, 0.22303334, 0.22991666, 0.23075]
	train_accs: [0.23113333, 0.22961667, 0.22303334, 0.22991666, 0.23075]
	best_train_sub_head: 0
	worst: 0.22303334
	avg: 0.22888999
	best: 0.23113333

Starting e_i: 346
Model ind 579 epoch 346 head B head_i_epoch 0 batch 0: avg loss -1.610410 avg loss no lamb -1.610410 time 2019-01-31 13:16:16.182167
Model ind 579 epoch 346 head B head_i_epoch 0 batch 100: avg loss -1.660149 avg loss no lamb -1.660149 time 2019-01-31 13:19:12.439018
Model ind 579 epoch 346 head B head_i_epoch 0 batch 200: avg loss -1.779881 avg loss no lamb -1.779881 time 2019-01-31 13:22:08.193666
Model ind 579 epoch 346 head A head_i_epoch 0 batch 0: avg loss -3.197337 avg loss no lamb -3.197337 time 2019-01-31 13:25:04.066290
Model ind 579 epoch 346 head A head_i_epoch 0 batch 100: avg loss -3.234488 avg loss no lamb -3.234488 time 2019-01-31 13:28:01.689149
Model ind 579 epoch 346 head A head_i_epoch 0 batch 200: avg loss -3.274103 avg loss no lamb -3.274103 time 2019-01-31 13:30:59.354587
Pre: time 2019-01-31 13:34:19.833150: 
 	std: 0.004125818
	best_train_sub_head_match: [(0, 18), (1, 16), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 13), (9, 10), (10, 7), (11, 8), (12, 19), (13, 9), (14, 15), (15, 5), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23935, 0.23816666, 0.228, 0.23775, 0.2375]
	train_accs: [0.23935, 0.23816666, 0.228, 0.23775, 0.2375]
	best_train_sub_head: 0
	worst: 0.228
	avg: 0.23615332
	best: 0.23935

Starting e_i: 347
Model ind 579 epoch 347 head B head_i_epoch 0 batch 0: avg loss -1.632074 avg loss no lamb -1.632074 time 2019-01-31 13:34:27.017191
Model ind 579 epoch 347 head B head_i_epoch 0 batch 100: avg loss -1.738829 avg loss no lamb -1.738829 time 2019-01-31 13:37:23.115037
Model ind 579 epoch 347 head B head_i_epoch 0 batch 200: avg loss -1.699697 avg loss no lamb -1.699697 time 2019-01-31 13:40:19.952269
Model ind 579 epoch 347 head A head_i_epoch 0 batch 0: avg loss -3.238549 avg loss no lamb -3.238549 time 2019-01-31 13:43:15.628824
Model ind 579 epoch 347 head A head_i_epoch 0 batch 100: avg loss -3.225392 avg loss no lamb -3.225392 time 2019-01-31 13:46:13.101043
Model ind 579 epoch 347 head A head_i_epoch 0 batch 200: avg loss -3.310655 avg loss no lamb -3.310655 time 2019-01-31 13:49:10.436054
Pre: time 2019-01-31 13:52:32.340539: 
 	std: 0.0050154454
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23503333, 0.23418333, 0.22171667, 0.23373333, 0.23386666]
	train_accs: [0.23503333, 0.23418333, 0.22171667, 0.23373333, 0.23386666]
	best_train_sub_head: 0
	worst: 0.22171667
	avg: 0.23170666
	best: 0.23503333

Starting e_i: 348
Model ind 579 epoch 348 head B head_i_epoch 0 batch 0: avg loss -1.671715 avg loss no lamb -1.671715 time 2019-01-31 13:52:35.419661
Model ind 579 epoch 348 head B head_i_epoch 0 batch 100: avg loss -1.606018 avg loss no lamb -1.606018 time 2019-01-31 13:55:31.238956
Model ind 579 epoch 348 head B head_i_epoch 0 batch 200: avg loss -1.792933 avg loss no lamb -1.792933 time 2019-01-31 13:58:28.887934
Model ind 579 epoch 348 head A head_i_epoch 0 batch 0: avg loss -3.238209 avg loss no lamb -3.238209 time 2019-01-31 14:01:23.519506
Model ind 579 epoch 348 head A head_i_epoch 0 batch 100: avg loss -3.262235 avg loss no lamb -3.262235 time 2019-01-31 14:04:21.910960
Model ind 579 epoch 348 head A head_i_epoch 0 batch 200: avg loss -3.280709 avg loss no lamb -3.280709 time 2019-01-31 14:07:20.065182
Pre: time 2019-01-31 14:10:42.463324: 
 	std: 0.004916251
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 7), (9, 10), (10, 19), (11, 8), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24011667, 0.23823333, 0.22693333, 0.2382, 0.23973334]
	train_accs: [0.24011667, 0.23823333, 0.22693333, 0.2382, 0.23973334]
	best_train_sub_head: 0
	worst: 0.22693333
	avg: 0.23664331
	best: 0.24011667

Starting e_i: 349
Model ind 579 epoch 349 head B head_i_epoch 0 batch 0: avg loss -1.596178 avg loss no lamb -1.596178 time 2019-01-31 14:10:49.595074
Model ind 579 epoch 349 head B head_i_epoch 0 batch 100: avg loss -1.692166 avg loss no lamb -1.692166 time 2019-01-31 14:13:45.896023
Model ind 579 epoch 349 head B head_i_epoch 0 batch 200: avg loss -1.644444 avg loss no lamb -1.644444 time 2019-01-31 14:16:42.150790
Model ind 579 epoch 349 head A head_i_epoch 0 batch 0: avg loss -3.234783 avg loss no lamb -3.234783 time 2019-01-31 14:19:38.953054
Model ind 579 epoch 349 head A head_i_epoch 0 batch 100: avg loss -3.261050 avg loss no lamb -3.261050 time 2019-01-31 14:22:36.859698
Model ind 579 epoch 349 head A head_i_epoch 0 batch 200: avg loss -3.319122 avg loss no lamb -3.319122 time 2019-01-31 14:25:34.193415
Pre: time 2019-01-31 14:28:56.550261: 
 	std: 0.0037875012
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 15), (3, 9), (4, 12), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 5), (12, 16), (13, 18), (14, 1), (15, 13), (16, 6), (17, 3), (18, 19), (19, 8)]
	test_accs: [0.23095, 0.23063333, 0.22115, 0.22908333, 0.23111667]
	train_accs: [0.23095, 0.23063333, 0.22115, 0.22908333, 0.23111667]
	best_train_sub_head: 4
	worst: 0.22115
	avg: 0.22858664
	best: 0.23111667

Starting e_i: 350
Model ind 579 epoch 350 head B head_i_epoch 0 batch 0: avg loss -1.587018 avg loss no lamb -1.587018 time 2019-01-31 14:28:59.822511
Model ind 579 epoch 350 head B head_i_epoch 0 batch 100: avg loss -1.722271 avg loss no lamb -1.722271 time 2019-01-31 14:31:56.470585
Model ind 579 epoch 350 head B head_i_epoch 0 batch 200: avg loss -1.627637 avg loss no lamb -1.627637 time 2019-01-31 14:34:52.568876
Model ind 579 epoch 350 head A head_i_epoch 0 batch 0: avg loss -3.227882 avg loss no lamb -3.227882 time 2019-01-31 14:37:49.634912
Model ind 579 epoch 350 head A head_i_epoch 0 batch 100: avg loss -3.265655 avg loss no lamb -3.265655 time 2019-01-31 14:40:46.616505
Model ind 579 epoch 350 head A head_i_epoch 0 batch 200: avg loss -3.301043 avg loss no lamb -3.301043 time 2019-01-31 14:43:43.611950
Pre: time 2019-01-31 14:47:05.133055: 
 	std: 0.004389399
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 19), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 7), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.23371667, 0.2345, 0.2227, 0.23271666, 0.23338333]
	train_accs: [0.23371667, 0.2345, 0.2227, 0.23271666, 0.23338333]
	best_train_sub_head: 1
	worst: 0.2227
	avg: 0.23140332
	best: 0.2345

Starting e_i: 351
Model ind 579 epoch 351 head B head_i_epoch 0 batch 0: avg loss -1.608262 avg loss no lamb -1.608262 time 2019-01-31 14:47:13.870318
Model ind 579 epoch 351 head B head_i_epoch 0 batch 100: avg loss -1.728027 avg loss no lamb -1.728027 time 2019-01-31 14:50:09.549195
Model ind 579 epoch 351 head B head_i_epoch 0 batch 200: avg loss -1.621211 avg loss no lamb -1.621211 time 2019-01-31 14:53:06.653553
Model ind 579 epoch 351 head A head_i_epoch 0 batch 0: avg loss -3.211852 avg loss no lamb -3.211852 time 2019-01-31 14:56:02.513487
Model ind 579 epoch 351 head A head_i_epoch 0 batch 100: avg loss -3.297247 avg loss no lamb -3.297247 time 2019-01-31 14:58:59.756621
Model ind 579 epoch 351 head A head_i_epoch 0 batch 200: avg loss -3.277282 avg loss no lamb -3.277282 time 2019-01-31 15:01:58.128574
Pre: time 2019-01-31 15:05:22.064365: 
 	std: 0.0039751907
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.2399, 0.24148333, 0.23041667, 0.24031667, 0.23873334]
	train_accs: [0.2399, 0.24148333, 0.23041667, 0.24031667, 0.23873334]
	best_train_sub_head: 1
	worst: 0.23041667
	avg: 0.23817
	best: 0.24148333

Starting e_i: 352
Model ind 579 epoch 352 head B head_i_epoch 0 batch 0: avg loss -1.650486 avg loss no lamb -1.650486 time 2019-01-31 15:05:32.820898
Model ind 579 epoch 352 head B head_i_epoch 0 batch 100: avg loss -1.723537 avg loss no lamb -1.723537 time 2019-01-31 15:08:29.155521
Model ind 579 epoch 352 head B head_i_epoch 0 batch 200: avg loss -1.670239 avg loss no lamb -1.670239 time 2019-01-31 15:11:25.162211
Model ind 579 epoch 352 head A head_i_epoch 0 batch 0: avg loss -3.234122 avg loss no lamb -3.234122 time 2019-01-31 15:14:21.715205
Model ind 579 epoch 352 head A head_i_epoch 0 batch 100: avg loss -3.279479 avg loss no lamb -3.279479 time 2019-01-31 15:17:18.841501
Model ind 579 epoch 352 head A head_i_epoch 0 batch 200: avg loss -3.286485 avg loss no lamb -3.286485 time 2019-01-31 15:20:18.338086
Pre: time 2019-01-31 15:23:41.412856: 
 	std: 0.004176541
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.23071666, 0.23193334, 0.2205, 0.23066667, 0.22996667]
	train_accs: [0.23071666, 0.23193334, 0.2205, 0.23066667, 0.22996667]
	best_train_sub_head: 1
	worst: 0.2205
	avg: 0.22875667
	best: 0.23193334

Starting e_i: 353
Model ind 579 epoch 353 head B head_i_epoch 0 batch 0: avg loss -1.610264 avg loss no lamb -1.610264 time 2019-01-31 15:23:44.911388
Model ind 579 epoch 353 head B head_i_epoch 0 batch 100: avg loss -1.657578 avg loss no lamb -1.657578 time 2019-01-31 15:26:40.848658
Model ind 579 epoch 353 head B head_i_epoch 0 batch 200: avg loss -1.710775 avg loss no lamb -1.710775 time 2019-01-31 15:29:38.802364
Model ind 579 epoch 353 head A head_i_epoch 0 batch 0: avg loss -3.182964 avg loss no lamb -3.182964 time 2019-01-31 15:32:36.448253
Model ind 579 epoch 353 head A head_i_epoch 0 batch 100: avg loss -3.253088 avg loss no lamb -3.253088 time 2019-01-31 15:35:33.972017
Model ind 579 epoch 353 head A head_i_epoch 0 batch 200: avg loss -3.317017 avg loss no lamb -3.317017 time 2019-01-31 15:38:33.578553
Pre: time 2019-01-31 15:41:55.280545: 
 	std: 0.0029476073
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 5), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.23175, 0.23235, 0.22436666, 0.23173334, 0.23045]
	train_accs: [0.23175, 0.23235, 0.22436666, 0.23173334, 0.23045]
	best_train_sub_head: 1
	worst: 0.22436666
	avg: 0.23013
	best: 0.23235

Starting e_i: 354
Model ind 579 epoch 354 head B head_i_epoch 0 batch 0: avg loss -1.577210 avg loss no lamb -1.577210 time 2019-01-31 15:41:58.999056
Model ind 579 epoch 354 head B head_i_epoch 0 batch 100: avg loss -1.728072 avg loss no lamb -1.728072 time 2019-01-31 15:44:55.862568
Model ind 579 epoch 354 head B head_i_epoch 0 batch 200: avg loss -1.686280 avg loss no lamb -1.686280 time 2019-01-31 15:47:53.429236
Model ind 579 epoch 354 head A head_i_epoch 0 batch 0: avg loss -3.192981 avg loss no lamb -3.192981 time 2019-01-31 15:50:49.738323
Model ind 579 epoch 354 head A head_i_epoch 0 batch 100: avg loss -3.269841 avg loss no lamb -3.269841 time 2019-01-31 15:53:49.854365
Model ind 579 epoch 354 head A head_i_epoch 0 batch 200: avg loss -3.324841 avg loss no lamb -3.324841 time 2019-01-31 15:56:50.090180
Pre: time 2019-01-31 16:00:13.235968: 
 	std: 0.0042438726
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.2352, 0.23643333, 0.22483334, 0.2355, 0.23376666]
	train_accs: [0.2352, 0.23643333, 0.22483334, 0.2355, 0.23376666]
	best_train_sub_head: 1
	worst: 0.22483334
	avg: 0.23314667
	best: 0.23643333

Starting e_i: 355
Model ind 579 epoch 355 head B head_i_epoch 0 batch 0: avg loss -1.641518 avg loss no lamb -1.641518 time 2019-01-31 16:00:16.708759
Model ind 579 epoch 355 head B head_i_epoch 0 batch 100: avg loss -1.759680 avg loss no lamb -1.759680 time 2019-01-31 16:03:14.988492
Model ind 579 epoch 355 head B head_i_epoch 0 batch 200: avg loss -1.688569 avg loss no lamb -1.688569 time 2019-01-31 16:06:11.658139
Model ind 579 epoch 355 head A head_i_epoch 0 batch 0: avg loss -3.200373 avg loss no lamb -3.200373 time 2019-01-31 16:09:08.728656
Model ind 579 epoch 355 head A head_i_epoch 0 batch 100: avg loss -3.194157 avg loss no lamb -3.194157 time 2019-01-31 16:12:08.529215
Model ind 579 epoch 355 head A head_i_epoch 0 batch 200: avg loss -3.288555 avg loss no lamb -3.288555 time 2019-01-31 16:15:06.131299
Pre: time 2019-01-31 16:18:32.048950: 
 	std: 0.0039888835
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23581667, 0.23456667, 0.22491667, 0.2345, 0.23431666]
	train_accs: [0.23581667, 0.23456667, 0.22491667, 0.2345, 0.23431666]
	best_train_sub_head: 0
	worst: 0.22491667
	avg: 0.23282333
	best: 0.23581667

Starting e_i: 356
Model ind 579 epoch 356 head B head_i_epoch 0 batch 0: avg loss -1.659560 avg loss no lamb -1.659560 time 2019-01-31 16:18:35.201971
Model ind 579 epoch 356 head B head_i_epoch 0 batch 100: avg loss -1.794599 avg loss no lamb -1.794599 time 2019-01-31 16:21:32.704344
Model ind 579 epoch 356 head B head_i_epoch 0 batch 200: avg loss -1.800275 avg loss no lamb -1.800275 time 2019-01-31 16:24:29.923838
Model ind 579 epoch 356 head A head_i_epoch 0 batch 0: avg loss -3.230620 avg loss no lamb -3.230620 time 2019-01-31 16:27:26.212187
Model ind 579 epoch 356 head A head_i_epoch 0 batch 100: avg loss -3.283360 avg loss no lamb -3.283360 time 2019-01-31 16:30:23.450733
Model ind 579 epoch 356 head A head_i_epoch 0 batch 200: avg loss -3.322527 avg loss no lamb -3.322527 time 2019-01-31 16:33:22.708564
Pre: time 2019-01-31 16:36:44.486684: 
 	std: 0.004268261
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23298334, 0.23296666, 0.22161667, 0.23163334, 0.23066667]
	train_accs: [0.23298334, 0.23296666, 0.22161667, 0.23163334, 0.23066667]
	best_train_sub_head: 0
	worst: 0.22161667
	avg: 0.22997335
	best: 0.23298334

Starting e_i: 357
Model ind 579 epoch 357 head B head_i_epoch 0 batch 0: avg loss -1.670723 avg loss no lamb -1.670723 time 2019-01-31 16:36:47.813467
Model ind 579 epoch 357 head B head_i_epoch 0 batch 100: avg loss -1.725371 avg loss no lamb -1.725371 time 2019-01-31 16:39:45.065970
Model ind 579 epoch 357 head B head_i_epoch 0 batch 200: avg loss -1.793401 avg loss no lamb -1.793401 time 2019-01-31 16:42:41.779592
Model ind 579 epoch 357 head A head_i_epoch 0 batch 0: avg loss -3.197454 avg loss no lamb -3.197454 time 2019-01-31 16:45:39.413658
Model ind 579 epoch 357 head A head_i_epoch 0 batch 100: avg loss -3.283426 avg loss no lamb -3.283426 time 2019-01-31 16:48:39.047914
Model ind 579 epoch 357 head A head_i_epoch 0 batch 200: avg loss -3.318726 avg loss no lamb -3.318726 time 2019-01-31 16:51:37.343779
Pre: time 2019-01-31 16:54:58.425593: 
 	std: 0.004081291
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23321667, 0.2331, 0.22226667, 0.2315, 0.23128334]
	train_accs: [0.23321667, 0.2331, 0.22226667, 0.2315, 0.23128334]
	best_train_sub_head: 0
	worst: 0.22226667
	avg: 0.23027334
	best: 0.23321667

Starting e_i: 358
Model ind 579 epoch 358 head B head_i_epoch 0 batch 0: avg loss -1.632837 avg loss no lamb -1.632837 time 2019-01-31 16:55:01.448934
Model ind 579 epoch 358 head B head_i_epoch 0 batch 100: avg loss -1.738347 avg loss no lamb -1.738347 time 2019-01-31 16:57:57.666598
Model ind 579 epoch 358 head B head_i_epoch 0 batch 200: avg loss -1.634014 avg loss no lamb -1.634014 time 2019-01-31 17:00:54.732029
Model ind 579 epoch 358 head A head_i_epoch 0 batch 0: avg loss -3.177300 avg loss no lamb -3.177300 time 2019-01-31 17:03:52.723962
Model ind 579 epoch 358 head A head_i_epoch 0 batch 100: avg loss -3.260757 avg loss no lamb -3.260757 time 2019-01-31 17:06:50.747445
Model ind 579 epoch 358 head A head_i_epoch 0 batch 200: avg loss -3.292814 avg loss no lamb -3.292814 time 2019-01-31 17:09:49.877683
Pre: time 2019-01-31 17:13:10.460052: 
 	std: 0.004027796
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.23496667, 0.23595, 0.22486667, 0.23428333, 0.23396666]
	train_accs: [0.23496667, 0.23595, 0.22486667, 0.23428333, 0.23396666]
	best_train_sub_head: 1
	worst: 0.22486667
	avg: 0.23280665
	best: 0.23595

Starting e_i: 359
Model ind 579 epoch 359 head B head_i_epoch 0 batch 0: avg loss -1.593861 avg loss no lamb -1.593861 time 2019-01-31 17:13:13.768365
Model ind 579 epoch 359 head B head_i_epoch 0 batch 100: avg loss -1.724612 avg loss no lamb -1.724612 time 2019-01-31 17:16:09.253217
Model ind 579 epoch 359 head B head_i_epoch 0 batch 200: avg loss -1.729443 avg loss no lamb -1.729443 time 2019-01-31 17:19:05.155611
Model ind 579 epoch 359 head A head_i_epoch 0 batch 0: avg loss -3.178016 avg loss no lamb -3.178016 time 2019-01-31 17:22:01.352178
Model ind 579 epoch 359 head A head_i_epoch 0 batch 100: avg loss -3.278076 avg loss no lamb -3.278076 time 2019-01-31 17:24:58.242501
Model ind 579 epoch 359 head A head_i_epoch 0 batch 200: avg loss -3.241800 avg loss no lamb -3.241800 time 2019-01-31 17:27:55.285805
Pre: time 2019-01-31 17:31:16.895226: 
 	std: 0.0035722493
	best_train_sub_head_match: [(0, 5), (1, 16), (2, 14), (3, 0), (4, 12), (5, 4), (6, 8), (7, 6), (8, 15), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 13), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23488334, 0.23405, 0.225, 0.23298334, 0.23315]
	train_accs: [0.23488334, 0.23405, 0.225, 0.23298334, 0.23315]
	best_train_sub_head: 0
	worst: 0.225
	avg: 0.23201334
	best: 0.23488334

Starting e_i: 360
Model ind 579 epoch 360 head B head_i_epoch 0 batch 0: avg loss -1.663794 avg loss no lamb -1.663794 time 2019-01-31 17:31:20.065385
Model ind 579 epoch 360 head B head_i_epoch 0 batch 100: avg loss -1.711484 avg loss no lamb -1.711484 time 2019-01-31 17:34:18.049967
Model ind 579 epoch 360 head B head_i_epoch 0 batch 200: avg loss -1.662428 avg loss no lamb -1.662428 time 2019-01-31 17:37:14.812886
Model ind 579 epoch 360 head A head_i_epoch 0 batch 0: avg loss -3.235492 avg loss no lamb -3.235492 time 2019-01-31 17:40:11.029551
Model ind 579 epoch 360 head A head_i_epoch 0 batch 100: avg loss -3.253321 avg loss no lamb -3.253321 time 2019-01-31 17:43:09.723140
Model ind 579 epoch 360 head A head_i_epoch 0 batch 200: avg loss -3.275630 avg loss no lamb -3.275630 time 2019-01-31 17:46:08.921871
Pre: time 2019-01-31 17:49:31.720816: 
 	std: 0.003924731
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.23325, 0.23536667, 0.22448333, 0.23473333, 0.2324]
	train_accs: [0.23325, 0.23536667, 0.22448333, 0.23473333, 0.2324]
	best_train_sub_head: 1
	worst: 0.22448333
	avg: 0.23204665
	best: 0.23536667

Starting e_i: 361
Model ind 579 epoch 361 head B head_i_epoch 0 batch 0: avg loss -1.666978 avg loss no lamb -1.666978 time 2019-01-31 17:49:38.993431
Model ind 579 epoch 361 head B head_i_epoch 0 batch 100: avg loss -1.690405 avg loss no lamb -1.690405 time 2019-01-31 17:52:35.371490
Model ind 579 epoch 361 head B head_i_epoch 0 batch 200: avg loss -1.617449 avg loss no lamb -1.617449 time 2019-01-31 17:55:32.276548
Model ind 579 epoch 361 head A head_i_epoch 0 batch 0: avg loss -3.218042 avg loss no lamb -3.218042 time 2019-01-31 17:58:30.788165
Model ind 579 epoch 361 head A head_i_epoch 0 batch 100: avg loss -3.273581 avg loss no lamb -3.273581 time 2019-01-31 18:01:29.104680
Model ind 579 epoch 361 head A head_i_epoch 0 batch 200: avg loss -3.313642 avg loss no lamb -3.313642 time 2019-01-31 18:04:27.036764
Pre: time 2019-01-31 18:07:50.085096: 
 	std: 0.004236886
	best_train_sub_head_match: [(0, 5), (1, 16), (2, 14), (3, 0), (4, 12), (5, 4), (6, 8), (7, 6), (8, 13), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23651667, 0.23641667, 0.22545, 0.23566666, 0.23533334]
	train_accs: [0.23651667, 0.23641667, 0.22545, 0.23566666, 0.23533334]
	best_train_sub_head: 0
	worst: 0.22545
	avg: 0.23387666
	best: 0.23651667

Starting e_i: 362
Model ind 579 epoch 362 head B head_i_epoch 0 batch 0: avg loss -1.692317 avg loss no lamb -1.692317 time 2019-01-31 18:07:53.403734
Model ind 579 epoch 362 head B head_i_epoch 0 batch 100: avg loss -1.722691 avg loss no lamb -1.722691 time 2019-01-31 18:10:51.661552
Model ind 579 epoch 362 head B head_i_epoch 0 batch 200: avg loss -1.722560 avg loss no lamb -1.722560 time 2019-01-31 18:13:48.051466
Model ind 579 epoch 362 head A head_i_epoch 0 batch 0: avg loss -3.263047 avg loss no lamb -3.263047 time 2019-01-31 18:16:43.781402
Model ind 579 epoch 362 head A head_i_epoch 0 batch 100: avg loss -3.264911 avg loss no lamb -3.264911 time 2019-01-31 18:19:40.961033
Model ind 579 epoch 362 head A head_i_epoch 0 batch 200: avg loss -3.265964 avg loss no lamb -3.265964 time 2019-01-31 18:22:37.909099
Pre: time 2019-01-31 18:25:58.985666: 
 	std: 0.0035588923
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 7), (9, 10), (10, 19), (11, 8), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23463333, 0.23246667, 0.22421667, 0.23213333, 0.23183334]
	train_accs: [0.23463333, 0.23246667, 0.22421667, 0.23213333, 0.23183334]
	best_train_sub_head: 0
	worst: 0.22421667
	avg: 0.23105666
	best: 0.23463333

Starting e_i: 363
Model ind 579 epoch 363 head B head_i_epoch 0 batch 0: avg loss -1.576193 avg loss no lamb -1.576193 time 2019-01-31 18:26:02.142652
Model ind 579 epoch 363 head B head_i_epoch 0 batch 100: avg loss -1.743627 avg loss no lamb -1.743627 time 2019-01-31 18:28:57.846584
Model ind 579 epoch 363 head B head_i_epoch 0 batch 200: avg loss -1.581036 avg loss no lamb -1.581036 time 2019-01-31 18:31:55.384534
Model ind 579 epoch 363 head A head_i_epoch 0 batch 0: avg loss -3.204560 avg loss no lamb -3.204560 time 2019-01-31 18:34:52.886495
Model ind 579 epoch 363 head A head_i_epoch 0 batch 100: avg loss -3.254654 avg loss no lamb -3.254654 time 2019-01-31 18:37:52.491974
Model ind 579 epoch 363 head A head_i_epoch 0 batch 200: avg loss -3.277216 avg loss no lamb -3.277216 time 2019-01-31 18:40:49.796377
Pre: time 2019-01-31 18:44:15.010887: 
 	std: 0.0036312926
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23361667, 0.23243333, 0.22376667, 0.2327, 0.23235]
	train_accs: [0.23361667, 0.23243333, 0.22376667, 0.2327, 0.23235]
	best_train_sub_head: 0
	worst: 0.22376667
	avg: 0.23097333
	best: 0.23361667

Starting e_i: 364
Model ind 579 epoch 364 head B head_i_epoch 0 batch 0: avg loss -1.642941 avg loss no lamb -1.642941 time 2019-01-31 18:44:18.413787
Model ind 579 epoch 364 head B head_i_epoch 0 batch 100: avg loss -1.713551 avg loss no lamb -1.713551 time 2019-01-31 18:47:16.829787
Model ind 579 epoch 364 head B head_i_epoch 0 batch 200: avg loss -1.767745 avg loss no lamb -1.767745 time 2019-01-31 18:50:15.000417
Model ind 579 epoch 364 head A head_i_epoch 0 batch 0: avg loss -3.284409 avg loss no lamb -3.284409 time 2019-01-31 18:53:10.513535
Model ind 579 epoch 364 head A head_i_epoch 0 batch 100: avg loss -3.326082 avg loss no lamb -3.326082 time 2019-01-31 18:56:08.502260
Model ind 579 epoch 364 head A head_i_epoch 0 batch 200: avg loss -3.291327 avg loss no lamb -3.291327 time 2019-01-31 18:59:05.784483
Pre: time 2019-01-31 19:02:26.580956: 
 	std: 0.0045269476
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23838334, 0.23703334, 0.2257, 0.2357, 0.23595]
	train_accs: [0.23838334, 0.23703334, 0.2257, 0.2357, 0.23595]
	best_train_sub_head: 0
	worst: 0.2257
	avg: 0.23455334
	best: 0.23838334

Starting e_i: 365
Model ind 579 epoch 365 head B head_i_epoch 0 batch 0: avg loss -1.603749 avg loss no lamb -1.603749 time 2019-01-31 19:02:32.005334
Model ind 579 epoch 365 head B head_i_epoch 0 batch 100: avg loss -1.794066 avg loss no lamb -1.794066 time 2019-01-31 19:05:27.548256
Model ind 579 epoch 365 head B head_i_epoch 0 batch 200: avg loss -1.649038 avg loss no lamb -1.649038 time 2019-01-31 19:08:23.403870
Model ind 579 epoch 365 head A head_i_epoch 0 batch 0: avg loss -3.271988 avg loss no lamb -3.271988 time 2019-01-31 19:11:20.141610
Model ind 579 epoch 365 head A head_i_epoch 0 batch 100: avg loss -3.279390 avg loss no lamb -3.279390 time 2019-01-31 19:14:17.682278
Model ind 579 epoch 365 head A head_i_epoch 0 batch 200: avg loss -3.275448 avg loss no lamb -3.275448 time 2019-01-31 19:17:16.260372
Pre: time 2019-01-31 19:20:37.940458: 
 	std: 0.003681202
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23645, 0.23376666, 0.22576667, 0.2334, 0.23471667]
	train_accs: [0.23645, 0.23376666, 0.22576667, 0.2334, 0.23471667]
	best_train_sub_head: 0
	worst: 0.22576667
	avg: 0.23282
	best: 0.23645

Starting e_i: 366
Model ind 579 epoch 366 head B head_i_epoch 0 batch 0: avg loss -1.612745 avg loss no lamb -1.612745 time 2019-01-31 19:20:41.325239
Model ind 579 epoch 366 head B head_i_epoch 0 batch 100: avg loss -1.730995 avg loss no lamb -1.730995 time 2019-01-31 19:23:37.424297
Model ind 579 epoch 366 head B head_i_epoch 0 batch 200: avg loss -1.705561 avg loss no lamb -1.705561 time 2019-01-31 19:26:33.303043
Model ind 579 epoch 366 head A head_i_epoch 0 batch 0: avg loss -3.356796 avg loss no lamb -3.356796 time 2019-01-31 19:29:31.438219
Model ind 579 epoch 366 head A head_i_epoch 0 batch 100: avg loss -3.264014 avg loss no lamb -3.264014 time 2019-01-31 19:32:28.842428
Model ind 579 epoch 366 head A head_i_epoch 0 batch 200: avg loss -3.276031 avg loss no lamb -3.276031 time 2019-01-31 19:35:27.152294
Pre: time 2019-01-31 19:38:47.817167: 
 	std: 0.0033984748
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 7), (9, 10), (10, 19), (11, 8), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.238, 0.23741667, 0.22883333, 0.23715, 0.23631667]
	train_accs: [0.238, 0.23741667, 0.22883333, 0.23715, 0.23631667]
	best_train_sub_head: 0
	worst: 0.22883333
	avg: 0.23554333
	best: 0.238

Starting e_i: 367
Model ind 579 epoch 367 head B head_i_epoch 0 batch 0: avg loss -1.642959 avg loss no lamb -1.642959 time 2019-01-31 19:38:50.838720
Model ind 579 epoch 367 head B head_i_epoch 0 batch 100: avg loss -1.750306 avg loss no lamb -1.750306 time 2019-01-31 19:41:47.090544
Model ind 579 epoch 367 head B head_i_epoch 0 batch 200: avg loss -1.729266 avg loss no lamb -1.729266 time 2019-01-31 19:44:43.499767
Model ind 579 epoch 367 head A head_i_epoch 0 batch 0: avg loss -3.226396 avg loss no lamb -3.226396 time 2019-01-31 19:47:39.538895
Model ind 579 epoch 367 head A head_i_epoch 0 batch 100: avg loss -3.282523 avg loss no lamb -3.282523 time 2019-01-31 19:50:37.365324
Model ind 579 epoch 367 head A head_i_epoch 0 batch 200: avg loss -3.249130 avg loss no lamb -3.249130 time 2019-01-31 19:53:34.972219
Pre: time 2019-01-31 19:56:58.092807: 
 	std: 0.004632187
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24006666, 0.23845, 0.2272, 0.23793334, 0.23803334]
	train_accs: [0.24006666, 0.23845, 0.2272, 0.23793334, 0.23803334]
	best_train_sub_head: 0
	worst: 0.2272
	avg: 0.23633666
	best: 0.24006666

Starting e_i: 368
Model ind 579 epoch 368 head B head_i_epoch 0 batch 0: avg loss -1.696031 avg loss no lamb -1.696031 time 2019-01-31 19:57:01.754637
Model ind 579 epoch 368 head B head_i_epoch 0 batch 100: avg loss -1.717260 avg loss no lamb -1.717260 time 2019-01-31 19:59:57.814770
Model ind 579 epoch 368 head B head_i_epoch 0 batch 200: avg loss -1.696320 avg loss no lamb -1.696320 time 2019-01-31 20:02:54.108901
Model ind 579 epoch 368 head A head_i_epoch 0 batch 0: avg loss -3.212286 avg loss no lamb -3.212286 time 2019-01-31 20:05:50.579041
Model ind 579 epoch 368 head A head_i_epoch 0 batch 100: avg loss -3.200058 avg loss no lamb -3.200058 time 2019-01-31 20:08:49.427140
Model ind 579 epoch 368 head A head_i_epoch 0 batch 200: avg loss -3.329791 avg loss no lamb -3.329791 time 2019-01-31 20:11:49.802262
Pre: time 2019-01-31 20:15:13.224224: 
 	std: 0.004109279
	best_train_sub_head_match: [(0, 5), (1, 16), (2, 14), (3, 0), (4, 12), (5, 4), (6, 8), (7, 6), (8, 13), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23838334, 0.2374, 0.22693333, 0.23626667, 0.23575]
	train_accs: [0.23838334, 0.2374, 0.22693333, 0.23626667, 0.23575]
	best_train_sub_head: 0
	worst: 0.22693333
	avg: 0.23494668
	best: 0.23838334

Starting e_i: 369
Model ind 579 epoch 369 head B head_i_epoch 0 batch 0: avg loss -1.666881 avg loss no lamb -1.666881 time 2019-01-31 20:15:16.645926
Model ind 579 epoch 369 head B head_i_epoch 0 batch 100: avg loss -1.661777 avg loss no lamb -1.661777 time 2019-01-31 20:18:13.526161
Model ind 579 epoch 369 head B head_i_epoch 0 batch 200: avg loss -1.647462 avg loss no lamb -1.647462 time 2019-01-31 20:21:09.366516
Model ind 579 epoch 369 head A head_i_epoch 0 batch 0: avg loss -3.202934 avg loss no lamb -3.202934 time 2019-01-31 20:24:05.379931
Model ind 579 epoch 369 head A head_i_epoch 0 batch 100: avg loss -3.313005 avg loss no lamb -3.313005 time 2019-01-31 20:27:02.824845
Model ind 579 epoch 369 head A head_i_epoch 0 batch 200: avg loss -3.290001 avg loss no lamb -3.290001 time 2019-01-31 20:30:01.244691
Pre: time 2019-01-31 20:33:23.538521: 
 	std: 0.004108385
	best_train_sub_head_match: [(0, 18), (1, 5), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 13), (9, 10), (10, 7), (11, 8), (12, 19), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23785, 0.2351, 0.22596666, 0.23528333, 0.23548333]
	train_accs: [0.23785, 0.2351, 0.22596666, 0.23528333, 0.23548333]
	best_train_sub_head: 0
	worst: 0.22596666
	avg: 0.23393667
	best: 0.23785

Starting e_i: 370
Model ind 579 epoch 370 head B head_i_epoch 0 batch 0: avg loss -1.632719 avg loss no lamb -1.632719 time 2019-01-31 20:33:26.829314
Model ind 579 epoch 370 head B head_i_epoch 0 batch 100: avg loss -1.653461 avg loss no lamb -1.653461 time 2019-01-31 20:36:24.123869
Model ind 579 epoch 370 head B head_i_epoch 0 batch 200: avg loss -1.625514 avg loss no lamb -1.625514 time 2019-01-31 20:39:22.453063
Model ind 579 epoch 370 head A head_i_epoch 0 batch 0: avg loss -3.235287 avg loss no lamb -3.235287 time 2019-01-31 20:42:19.742304
Model ind 579 epoch 370 head A head_i_epoch 0 batch 100: avg loss -3.308743 avg loss no lamb -3.308743 time 2019-01-31 20:45:18.580226
Model ind 579 epoch 370 head A head_i_epoch 0 batch 200: avg loss -3.190622 avg loss no lamb -3.190622 time 2019-01-31 20:48:15.566013
Pre: time 2019-01-31 20:51:36.848191: 
 	std: 0.0042792223
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23581667, 0.2335, 0.22365, 0.2341, 0.23278333]
	train_accs: [0.23581667, 0.2335, 0.22365, 0.2341, 0.23278333]
	best_train_sub_head: 0
	worst: 0.22365
	avg: 0.23197
	best: 0.23581667

Starting e_i: 371
Model ind 579 epoch 371 head B head_i_epoch 0 batch 0: avg loss -1.726434 avg loss no lamb -1.726434 time 2019-01-31 20:51:45.021994
Model ind 579 epoch 371 head B head_i_epoch 0 batch 100: avg loss -1.710017 avg loss no lamb -1.710017 time 2019-01-31 20:54:41.376072
Model ind 579 epoch 371 head B head_i_epoch 0 batch 200: avg loss -1.653348 avg loss no lamb -1.653348 time 2019-01-31 20:57:37.745451
Model ind 579 epoch 371 head A head_i_epoch 0 batch 0: avg loss -3.300256 avg loss no lamb -3.300256 time 2019-01-31 21:00:34.420022
Model ind 579 epoch 371 head A head_i_epoch 0 batch 100: avg loss -3.278660 avg loss no lamb -3.278660 time 2019-01-31 21:03:31.681478
Model ind 579 epoch 371 head A head_i_epoch 0 batch 200: avg loss -3.341122 avg loss no lamb -3.341122 time 2019-01-31 21:06:28.956206
Pre: time 2019-01-31 21:09:52.265083: 
 	std: 0.0041225227
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2402, 0.24235, 0.23103334, 0.24183333, 0.23991667]
	train_accs: [0.2402, 0.24235, 0.23103334, 0.24183333, 0.23991667]
	best_train_sub_head: 1
	worst: 0.23103334
	avg: 0.23906668
	best: 0.24235

Starting e_i: 372
Model ind 579 epoch 372 head B head_i_epoch 0 batch 0: avg loss -1.619913 avg loss no lamb -1.619913 time 2019-01-31 21:09:58.990919
Model ind 579 epoch 372 head B head_i_epoch 0 batch 100: avg loss -1.681658 avg loss no lamb -1.681658 time 2019-01-31 21:12:55.175057
Model ind 579 epoch 372 head B head_i_epoch 0 batch 200: avg loss -1.707424 avg loss no lamb -1.707424 time 2019-01-31 21:15:53.259468
Model ind 579 epoch 372 head A head_i_epoch 0 batch 0: avg loss -3.180804 avg loss no lamb -3.180804 time 2019-01-31 21:18:51.409203
Model ind 579 epoch 372 head A head_i_epoch 0 batch 100: avg loss -3.335842 avg loss no lamb -3.335842 time 2019-01-31 21:21:50.048856
Model ind 579 epoch 372 head A head_i_epoch 0 batch 200: avg loss -3.350635 avg loss no lamb -3.350635 time 2019-01-31 21:24:48.438094
Pre: time 2019-01-31 21:28:10.718101: 
 	std: 0.0032090435
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 16), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 2), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 5), (19, 19)]
	test_accs: [0.23521666, 0.2353, 0.22738333, 0.23618333, 0.23445]
	train_accs: [0.23521666, 0.2353, 0.22738333, 0.23618333, 0.23445]
	best_train_sub_head: 3
	worst: 0.22738333
	avg: 0.23370667
	best: 0.23618333

Starting e_i: 373
Model ind 579 epoch 373 head B head_i_epoch 0 batch 0: avg loss -1.701499 avg loss no lamb -1.701499 time 2019-01-31 21:28:14.168273
Model ind 579 epoch 373 head B head_i_epoch 0 batch 100: avg loss -1.616122 avg loss no lamb -1.616122 time 2019-01-31 21:31:12.604979
Model ind 579 epoch 373 head B head_i_epoch 0 batch 200: avg loss -1.728224 avg loss no lamb -1.728224 time 2019-01-31 21:34:10.449576
Model ind 579 epoch 373 head A head_i_epoch 0 batch 0: avg loss -3.243065 avg loss no lamb -3.243065 time 2019-01-31 21:37:08.304151
Model ind 579 epoch 373 head A head_i_epoch 0 batch 100: avg loss -3.331601 avg loss no lamb -3.331601 time 2019-01-31 21:40:06.074977
Model ind 579 epoch 373 head A head_i_epoch 0 batch 200: avg loss -3.346365 avg loss no lamb -3.346365 time 2019-01-31 21:43:03.172547
Pre: time 2019-01-31 21:46:24.827204: 
 	std: 0.0040481607
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 2), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.23505, 0.2361, 0.22531667, 0.23578334, 0.23436667]
	train_accs: [0.23505, 0.2361, 0.22531667, 0.23578334, 0.23436667]
	best_train_sub_head: 1
	worst: 0.22531667
	avg: 0.23332334
	best: 0.2361

Starting e_i: 374
Model ind 579 epoch 374 head B head_i_epoch 0 batch 0: avg loss -1.674528 avg loss no lamb -1.674528 time 2019-01-31 21:46:28.034831
Model ind 579 epoch 374 head B head_i_epoch 0 batch 100: avg loss -1.731315 avg loss no lamb -1.731315 time 2019-01-31 21:49:24.732992
Model ind 579 epoch 374 head B head_i_epoch 0 batch 200: avg loss -1.707637 avg loss no lamb -1.707637 time 2019-01-31 21:52:21.217071
Model ind 579 epoch 374 head A head_i_epoch 0 batch 0: avg loss -3.261522 avg loss no lamb -3.261522 time 2019-01-31 21:55:19.232112
Model ind 579 epoch 374 head A head_i_epoch 0 batch 100: avg loss -3.281177 avg loss no lamb -3.281177 time 2019-01-31 21:58:17.113192
Model ind 579 epoch 374 head A head_i_epoch 0 batch 200: avg loss -3.313697 avg loss no lamb -3.313697 time 2019-01-31 22:01:13.878234
Pre: time 2019-01-31 22:04:35.626551: 
 	std: 0.0043762424
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.23895, 0.2398, 0.22826667, 0.2392, 0.23873334]
	train_accs: [0.23895, 0.2398, 0.22826667, 0.2392, 0.23873334]
	best_train_sub_head: 1
	worst: 0.22826667
	avg: 0.23699
	best: 0.2398

Starting e_i: 375
Model ind 579 epoch 375 head B head_i_epoch 0 batch 0: avg loss -1.725818 avg loss no lamb -1.725818 time 2019-01-31 22:04:39.104548
Model ind 579 epoch 375 head B head_i_epoch 0 batch 100: avg loss -1.680612 avg loss no lamb -1.680612 time 2019-01-31 22:07:35.324132
Model ind 579 epoch 375 head B head_i_epoch 0 batch 200: avg loss -1.654774 avg loss no lamb -1.654774 time 2019-01-31 22:10:30.354758
Model ind 579 epoch 375 head A head_i_epoch 0 batch 0: avg loss -3.216514 avg loss no lamb -3.216514 time 2019-01-31 22:13:25.375373
Model ind 579 epoch 375 head A head_i_epoch 0 batch 100: avg loss -3.243330 avg loss no lamb -3.243330 time 2019-01-31 22:16:23.279096
Model ind 579 epoch 375 head A head_i_epoch 0 batch 200: avg loss -3.275321 avg loss no lamb -3.275321 time 2019-01-31 22:19:20.206815
Pre: time 2019-01-31 22:22:41.394617: 
 	std: 0.003895224
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 12), (10, 15), (11, 17), (12, 5), (13, 16), (14, 1), (15, 8), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.23095, 0.23268333, 0.22196667, 0.23073334, 0.23183334]
	train_accs: [0.23095, 0.23268333, 0.22196667, 0.23073334, 0.23183334]
	best_train_sub_head: 1
	worst: 0.22196667
	avg: 0.22963333
	best: 0.23268333

Starting e_i: 376
Model ind 579 epoch 376 head B head_i_epoch 0 batch 0: avg loss -1.625862 avg loss no lamb -1.625862 time 2019-01-31 22:22:44.450854
Model ind 579 epoch 376 head B head_i_epoch 0 batch 100: avg loss -1.766487 avg loss no lamb -1.766487 time 2019-01-31 22:25:40.609557
Model ind 579 epoch 376 head B head_i_epoch 0 batch 200: avg loss -1.626810 avg loss no lamb -1.626810 time 2019-01-31 22:28:36.658390
Model ind 579 epoch 376 head A head_i_epoch 0 batch 0: avg loss -3.230014 avg loss no lamb -3.230014 time 2019-01-31 22:31:34.644886
Model ind 579 epoch 376 head A head_i_epoch 0 batch 100: avg loss -3.231075 avg loss no lamb -3.231075 time 2019-01-31 22:34:31.691790
Model ind 579 epoch 376 head A head_i_epoch 0 batch 200: avg loss -3.299119 avg loss no lamb -3.299119 time 2019-01-31 22:37:28.916928
Pre: time 2019-01-31 22:40:52.621563: 
 	std: 0.0039549335
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23878333, 0.23845, 0.22826667, 0.23811667, 0.23641667]
	train_accs: [0.23878333, 0.23845, 0.22826667, 0.23811667, 0.23641667]
	best_train_sub_head: 0
	worst: 0.22826667
	avg: 0.23600666
	best: 0.23878333

Starting e_i: 377
Model ind 579 epoch 377 head B head_i_epoch 0 batch 0: avg loss -1.591565 avg loss no lamb -1.591565 time 2019-01-31 22:40:56.177581
Model ind 579 epoch 377 head B head_i_epoch 0 batch 100: avg loss -1.654813 avg loss no lamb -1.654813 time 2019-01-31 22:43:52.024221
Model ind 579 epoch 377 head B head_i_epoch 0 batch 200: avg loss -1.663696 avg loss no lamb -1.663696 time 2019-01-31 22:46:49.147028
Model ind 579 epoch 377 head A head_i_epoch 0 batch 0: avg loss -3.319214 avg loss no lamb -3.319214 time 2019-01-31 22:49:46.375636
Model ind 579 epoch 377 head A head_i_epoch 0 batch 100: avg loss -3.288269 avg loss no lamb -3.288269 time 2019-01-31 22:52:44.797080
Model ind 579 epoch 377 head A head_i_epoch 0 batch 200: avg loss -3.243850 avg loss no lamb -3.243850 time 2019-01-31 22:55:43.014625
Pre: time 2019-01-31 22:59:04.660406: 
 	std: 0.0034804558
	best_train_sub_head_match: [(0, 5), (1, 12), (2, 14), (3, 0), (4, 2), (5, 4), (6, 8), (7, 6), (8, 15), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 13), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23985, 0.23761667, 0.22988333, 0.23805, 0.23793334]
	train_accs: [0.23985, 0.23761667, 0.22988333, 0.23805, 0.23793334]
	best_train_sub_head: 0
	worst: 0.22988333
	avg: 0.23666668
	best: 0.23985

Starting e_i: 378
Model ind 579 epoch 378 head B head_i_epoch 0 batch 0: avg loss -1.659678 avg loss no lamb -1.659678 time 2019-01-31 22:59:07.776751
Model ind 579 epoch 378 head B head_i_epoch 0 batch 100: avg loss -1.690147 avg loss no lamb -1.690147 time 2019-01-31 23:02:03.913918
Model ind 579 epoch 378 head B head_i_epoch 0 batch 200: avg loss -1.724106 avg loss no lamb -1.724106 time 2019-01-31 23:04:59.844397
Model ind 579 epoch 378 head A head_i_epoch 0 batch 0: avg loss -3.184355 avg loss no lamb -3.184355 time 2019-01-31 23:07:55.288018
Model ind 579 epoch 378 head A head_i_epoch 0 batch 100: avg loss -3.242357 avg loss no lamb -3.242357 time 2019-01-31 23:10:54.627225
Model ind 579 epoch 378 head A head_i_epoch 0 batch 200: avg loss -3.338900 avg loss no lamb -3.338900 time 2019-01-31 23:13:52.947410
Pre: time 2019-01-31 23:17:16.431184: 
 	std: 0.003810813
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 16), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 2), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2346, 0.23488334, 0.22516666, 0.23528333, 0.2336]
	train_accs: [0.2346, 0.23488334, 0.22516666, 0.23528333, 0.2336]
	best_train_sub_head: 3
	worst: 0.22516666
	avg: 0.23270667
	best: 0.23528333

Starting e_i: 379
Model ind 579 epoch 379 head B head_i_epoch 0 batch 0: avg loss -1.562121 avg loss no lamb -1.562121 time 2019-01-31 23:17:19.909394
Model ind 579 epoch 379 head B head_i_epoch 0 batch 100: avg loss -1.734096 avg loss no lamb -1.734096 time 2019-01-31 23:20:16.170078
Model ind 579 epoch 379 head B head_i_epoch 0 batch 200: avg loss -1.737672 avg loss no lamb -1.737672 time 2019-01-31 23:23:12.188034
Model ind 579 epoch 379 head A head_i_epoch 0 batch 0: avg loss -3.239271 avg loss no lamb -3.239271 time 2019-01-31 23:26:09.176985
Model ind 579 epoch 379 head A head_i_epoch 0 batch 100: avg loss -3.281943 avg loss no lamb -3.281943 time 2019-01-31 23:29:07.245631
Model ind 579 epoch 379 head A head_i_epoch 0 batch 200: avg loss -3.325576 avg loss no lamb -3.325576 time 2019-01-31 23:32:04.512239
Pre: time 2019-01-31 23:35:28.633125: 
 	std: 0.0032683741
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 16), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 2), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.23438333, 0.23301667, 0.22571667, 0.23468333, 0.23176667]
	train_accs: [0.23438333, 0.23301667, 0.22571667, 0.23468333, 0.23176667]
	best_train_sub_head: 3
	worst: 0.22571667
	avg: 0.23191333
	best: 0.23468333

Starting e_i: 380
Model ind 579 epoch 380 head B head_i_epoch 0 batch 0: avg loss -1.653213 avg loss no lamb -1.653213 time 2019-01-31 23:35:31.829333
Model ind 579 epoch 380 head B head_i_epoch 0 batch 100: avg loss -1.769484 avg loss no lamb -1.769484 time 2019-01-31 23:38:28.853097
Model ind 579 epoch 380 head B head_i_epoch 0 batch 200: avg loss -1.643675 avg loss no lamb -1.643675 time 2019-01-31 23:41:26.840762
Model ind 579 epoch 380 head A head_i_epoch 0 batch 0: avg loss -3.263208 avg loss no lamb -3.263208 time 2019-01-31 23:44:22.855700
Model ind 579 epoch 380 head A head_i_epoch 0 batch 100: avg loss -3.295334 avg loss no lamb -3.295334 time 2019-01-31 23:47:20.796019
Model ind 579 epoch 380 head A head_i_epoch 0 batch 200: avg loss -3.292288 avg loss no lamb -3.292288 time 2019-01-31 23:50:17.646453
Pre: time 2019-01-31 23:53:38.462900: 
 	std: 0.0032423865
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.23361667, 0.23478334, 0.22641666, 0.23508333, 0.23421666]
	train_accs: [0.23361667, 0.23478334, 0.22641666, 0.23508333, 0.23421666]
	best_train_sub_head: 3
	worst: 0.22641666
	avg: 0.23282333
	best: 0.23508333

Starting e_i: 381
Model ind 579 epoch 381 head B head_i_epoch 0 batch 0: avg loss -1.600398 avg loss no lamb -1.600398 time 2019-01-31 23:53:45.809651
Model ind 579 epoch 381 head B head_i_epoch 0 batch 100: avg loss -1.725596 avg loss no lamb -1.725596 time 2019-01-31 23:56:42.214678
Model ind 579 epoch 381 head B head_i_epoch 0 batch 200: avg loss -1.677055 avg loss no lamb -1.677055 time 2019-01-31 23:59:38.258164
Model ind 579 epoch 381 head A head_i_epoch 0 batch 0: avg loss -3.256025 avg loss no lamb -3.256025 time 2019-02-01 00:02:33.778346
Model ind 579 epoch 381 head A head_i_epoch 0 batch 100: avg loss -3.333970 avg loss no lamb -3.333970 time 2019-02-01 00:05:33.506802
Model ind 579 epoch 381 head A head_i_epoch 0 batch 200: avg loss -3.321047 avg loss no lamb -3.321047 time 2019-02-01 00:08:32.406092
Pre: time 2019-02-01 00:11:54.816751: 
 	std: 0.004543817
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.23845, 0.239, 0.22693333, 0.23783334, 0.23763333]
	train_accs: [0.23845, 0.239, 0.22693333, 0.23783334, 0.23763333]
	best_train_sub_head: 1
	worst: 0.22693333
	avg: 0.23596999
	best: 0.239

Starting e_i: 382
Model ind 579 epoch 382 head B head_i_epoch 0 batch 0: avg loss -1.673161 avg loss no lamb -1.673161 time 2019-02-01 00:11:57.951843
Model ind 579 epoch 382 head B head_i_epoch 0 batch 100: avg loss -1.717839 avg loss no lamb -1.717839 time 2019-02-01 00:14:54.368801
Model ind 579 epoch 382 head B head_i_epoch 0 batch 200: avg loss -1.761676 avg loss no lamb -1.761676 time 2019-02-01 00:17:50.003679
Model ind 579 epoch 382 head A head_i_epoch 0 batch 0: avg loss -3.275062 avg loss no lamb -3.275062 time 2019-02-01 00:20:47.390500
Model ind 579 epoch 382 head A head_i_epoch 0 batch 100: avg loss -3.278399 avg loss no lamb -3.278399 time 2019-02-01 00:23:45.052891
Model ind 579 epoch 382 head A head_i_epoch 0 batch 200: avg loss -3.349910 avg loss no lamb -3.349910 time 2019-02-01 00:26:43.243188
Pre: time 2019-02-01 00:30:06.887739: 
 	std: 0.00411489
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.23793334, 0.23858333, 0.22733334, 0.23706667, 0.23591666]
	train_accs: [0.23793334, 0.23858333, 0.22733334, 0.23706667, 0.23591666]
	best_train_sub_head: 1
	worst: 0.22733334
	avg: 0.23536667
	best: 0.23858333

Starting e_i: 383
Model ind 579 epoch 383 head B head_i_epoch 0 batch 0: avg loss -1.622802 avg loss no lamb -1.622802 time 2019-02-01 00:30:10.583873
Model ind 579 epoch 383 head B head_i_epoch 0 batch 100: avg loss -1.673007 avg loss no lamb -1.673007 time 2019-02-01 00:33:09.504989
Model ind 579 epoch 383 head B head_i_epoch 0 batch 200: avg loss -1.717770 avg loss no lamb -1.717770 time 2019-02-01 00:36:06.435117
Model ind 579 epoch 383 head A head_i_epoch 0 batch 0: avg loss -3.211103 avg loss no lamb -3.211103 time 2019-02-01 00:39:02.141681
Model ind 579 epoch 383 head A head_i_epoch 0 batch 100: avg loss -3.215307 avg loss no lamb -3.215307 time 2019-02-01 00:41:58.928805
Model ind 579 epoch 383 head A head_i_epoch 0 batch 200: avg loss -3.325765 avg loss no lamb -3.325765 time 2019-02-01 00:44:56.858801
Pre: time 2019-02-01 00:48:32.785105: 
 	std: 0.004259076
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 15), (3, 13), (4, 4), (5, 5), (6, 7), (7, 11), (8, 3), (9, 2), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.23776667, 0.24066667, 0.22841667, 0.23896667, 0.23708333]
	train_accs: [0.23776667, 0.24066667, 0.22841667, 0.23896667, 0.23708333]
	best_train_sub_head: 1
	worst: 0.22841667
	avg: 0.23657998
	best: 0.24066667

Starting e_i: 384
Model ind 579 epoch 384 head B head_i_epoch 0 batch 0: avg loss -1.607166 avg loss no lamb -1.607166 time 2019-02-01 00:48:36.374480
Model ind 579 epoch 384 head B head_i_epoch 0 batch 100: avg loss -1.734229 avg loss no lamb -1.734229 time 2019-02-01 00:51:37.415301
Model ind 579 epoch 384 head B head_i_epoch 0 batch 200: avg loss -1.710879 avg loss no lamb -1.710879 time 2019-02-01 00:54:34.826507
Model ind 579 epoch 384 head A head_i_epoch 0 batch 0: avg loss -3.279107 avg loss no lamb -3.279107 time 2019-02-01 00:57:31.704521
Model ind 579 epoch 384 head A head_i_epoch 0 batch 100: avg loss -3.245517 avg loss no lamb -3.245517 time 2019-02-01 01:00:28.819255
Model ind 579 epoch 384 head A head_i_epoch 0 batch 200: avg loss -3.263530 avg loss no lamb -3.263530 time 2019-02-01 01:03:25.140507
Pre: time 2019-02-01 01:06:46.450589: 
 	std: 0.0038730917
	best_train_sub_head_match: [(0, 13), (1, 15), (2, 16), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 2), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 18)]
	test_accs: [0.2405, 0.24226667, 0.23188333, 0.24236667, 0.23858333]
	train_accs: [0.2405, 0.24226667, 0.23188333, 0.24236667, 0.23858333]
	best_train_sub_head: 3
	worst: 0.23188333
	avg: 0.23912
	best: 0.24236667

Starting e_i: 385
Model ind 579 epoch 385 head B head_i_epoch 0 batch 0: avg loss -1.675094 avg loss no lamb -1.675094 time 2019-02-01 01:06:55.382989
Model ind 579 epoch 385 head B head_i_epoch 0 batch 100: avg loss -1.797854 avg loss no lamb -1.797854 time 2019-02-01 01:09:50.785092
Model ind 579 epoch 385 head B head_i_epoch 0 batch 200: avg loss -1.751094 avg loss no lamb -1.751094 time 2019-02-01 01:12:47.827698
Model ind 579 epoch 385 head A head_i_epoch 0 batch 0: avg loss -3.254540 avg loss no lamb -3.254540 time 2019-02-01 01:15:44.592573
Model ind 579 epoch 385 head A head_i_epoch 0 batch 100: avg loss -3.306206 avg loss no lamb -3.306206 time 2019-02-01 01:18:42.731867
Model ind 579 epoch 385 head A head_i_epoch 0 batch 200: avg loss -3.284487 avg loss no lamb -3.284487 time 2019-02-01 01:21:39.939258
Pre: time 2019-02-01 01:25:00.880054: 
 	std: 0.004262307
	best_train_sub_head_match: [(0, 13), (1, 15), (2, 16), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 12), (13, 11), (14, 10), (15, 1), (16, 2), (17, 17), (18, 0), (19, 18)]
	test_accs: [0.23701666, 0.23716667, 0.22636667, 0.23735, 0.23645]
	train_accs: [0.23701666, 0.23716667, 0.22636667, 0.23735, 0.23645]
	best_train_sub_head: 3
	worst: 0.22636667
	avg: 0.23486999
	best: 0.23735

Starting e_i: 386
Model ind 579 epoch 386 head B head_i_epoch 0 batch 0: avg loss -1.588468 avg loss no lamb -1.588468 time 2019-02-01 01:25:04.015518
Model ind 579 epoch 386 head B head_i_epoch 0 batch 100: avg loss -1.672751 avg loss no lamb -1.672751 time 2019-02-01 01:28:00.502976
Model ind 579 epoch 386 head B head_i_epoch 0 batch 200: avg loss -1.713151 avg loss no lamb -1.713151 time 2019-02-01 01:30:55.981183
Model ind 579 epoch 386 head A head_i_epoch 0 batch 0: avg loss -3.227414 avg loss no lamb -3.227414 time 2019-02-01 01:33:51.601538
Model ind 579 epoch 386 head A head_i_epoch 0 batch 100: avg loss -3.270689 avg loss no lamb -3.270689 time 2019-02-01 01:36:47.293449
Model ind 579 epoch 386 head A head_i_epoch 0 batch 200: avg loss -3.339225 avg loss no lamb -3.339225 time 2019-02-01 01:39:44.705558
Pre: time 2019-02-01 01:43:05.558523: 
 	std: 0.005460632
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.23835, 0.2394, 0.22481667, 0.23848334, 0.23718333]
	train_accs: [0.23835, 0.2394, 0.22481667, 0.23848334, 0.23718333]
	best_train_sub_head: 1
	worst: 0.22481667
	avg: 0.23564668
	best: 0.2394

Starting e_i: 387
Model ind 579 epoch 387 head B head_i_epoch 0 batch 0: avg loss -1.652094 avg loss no lamb -1.652094 time 2019-02-01 01:43:08.643247
Model ind 579 epoch 387 head B head_i_epoch 0 batch 100: avg loss -1.712425 avg loss no lamb -1.712425 time 2019-02-01 01:46:04.049092
Model ind 579 epoch 387 head B head_i_epoch 0 batch 200: avg loss -1.690230 avg loss no lamb -1.690230 time 2019-02-01 01:49:00.440739
Model ind 579 epoch 387 head A head_i_epoch 0 batch 0: avg loss -3.253251 avg loss no lamb -3.253251 time 2019-02-01 01:51:59.214964
Model ind 579 epoch 387 head A head_i_epoch 0 batch 100: avg loss -3.338502 avg loss no lamb -3.338502 time 2019-02-01 01:54:56.422540
Model ind 579 epoch 387 head A head_i_epoch 0 batch 200: avg loss -3.326092 avg loss no lamb -3.326092 time 2019-02-01 01:57:53.818232
Pre: time 2019-02-01 02:01:15.314617: 
 	std: 0.0037277495
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 13), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.22961667, 0.2321, 0.22121666, 0.23006667, 0.22841667]
	train_accs: [0.22961667, 0.2321, 0.22121666, 0.23006667, 0.22841667]
	best_train_sub_head: 1
	worst: 0.22121666
	avg: 0.22828333
	best: 0.2321

Starting e_i: 388
Model ind 579 epoch 388 head B head_i_epoch 0 batch 0: avg loss -1.640697 avg loss no lamb -1.640697 time 2019-02-01 02:01:18.380997
Model ind 579 epoch 388 head B head_i_epoch 0 batch 100: avg loss -1.831488 avg loss no lamb -1.831488 time 2019-02-01 02:04:14.605772
Model ind 579 epoch 388 head B head_i_epoch 0 batch 200: avg loss -1.694378 avg loss no lamb -1.694378 time 2019-02-01 02:07:10.841688
Model ind 579 epoch 388 head A head_i_epoch 0 batch 0: avg loss -3.265018 avg loss no lamb -3.265018 time 2019-02-01 02:10:07.146704
Model ind 579 epoch 388 head A head_i_epoch 0 batch 100: avg loss -3.304165 avg loss no lamb -3.304165 time 2019-02-01 02:13:06.537312
Model ind 579 epoch 388 head A head_i_epoch 0 batch 200: avg loss -3.361741 avg loss no lamb -3.361741 time 2019-02-01 02:16:03.217570
Pre: time 2019-02-01 02:19:26.368782: 
 	std: 0.004084642
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23656666, 0.23611666, 0.22593333, 0.23533334, 0.23635]
	train_accs: [0.23656666, 0.23611666, 0.22593333, 0.23533334, 0.23635]
	best_train_sub_head: 0
	worst: 0.22593333
	avg: 0.23406
	best: 0.23656666

Starting e_i: 389
Model ind 579 epoch 389 head B head_i_epoch 0 batch 0: avg loss -1.594729 avg loss no lamb -1.594729 time 2019-02-01 02:19:29.690931
Model ind 579 epoch 389 head B head_i_epoch 0 batch 100: avg loss -1.694698 avg loss no lamb -1.694698 time 2019-02-01 02:22:27.377743
Model ind 579 epoch 389 head B head_i_epoch 0 batch 200: avg loss -1.667442 avg loss no lamb -1.667442 time 2019-02-01 02:25:22.714977
Model ind 579 epoch 389 head A head_i_epoch 0 batch 0: avg loss -3.244091 avg loss no lamb -3.244091 time 2019-02-01 02:28:19.111081
Model ind 579 epoch 389 head A head_i_epoch 0 batch 100: avg loss -3.284351 avg loss no lamb -3.284351 time 2019-02-01 02:31:15.834180
Model ind 579 epoch 389 head A head_i_epoch 0 batch 200: avg loss -3.307248 avg loss no lamb -3.307248 time 2019-02-01 02:34:14.211648
Pre: time 2019-02-01 02:37:37.131486: 
 	std: 0.003935255
	best_train_sub_head_match: [(0, 5), (1, 16), (2, 14), (3, 0), (4, 12), (5, 4), (6, 8), (7, 6), (8, 15), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 13), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23566666, 0.23493333, 0.225, 0.2339, 0.23441666]
	train_accs: [0.23566666, 0.23493333, 0.225, 0.2339, 0.23441666]
	best_train_sub_head: 0
	worst: 0.225
	avg: 0.23278335
	best: 0.23566666

Starting e_i: 390
Model ind 579 epoch 390 head B head_i_epoch 0 batch 0: avg loss -1.651289 avg loss no lamb -1.651289 time 2019-02-01 02:37:40.570716
Model ind 579 epoch 390 head B head_i_epoch 0 batch 100: avg loss -1.730651 avg loss no lamb -1.730651 time 2019-02-01 02:40:37.055446
Model ind 579 epoch 390 head B head_i_epoch 0 batch 200: avg loss -1.685205 avg loss no lamb -1.685205 time 2019-02-01 02:43:33.775203
Model ind 579 epoch 390 head A head_i_epoch 0 batch 0: avg loss -3.216901 avg loss no lamb -3.216901 time 2019-02-01 02:46:29.214141
Model ind 579 epoch 390 head A head_i_epoch 0 batch 100: avg loss -3.273371 avg loss no lamb -3.273371 time 2019-02-01 02:49:26.075284
Model ind 579 epoch 390 head A head_i_epoch 0 batch 200: avg loss -3.353921 avg loss no lamb -3.353921 time 2019-02-01 02:52:22.147573
Pre: time 2019-02-01 02:55:43.600775: 
 	std: 0.004018284
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 5), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 12), (10, 8), (11, 17), (12, 13), (13, 1), (14, 0), (15, 2), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.23575, 0.23636666, 0.22545, 0.23466666, 0.23466666]
	train_accs: [0.23575, 0.23636666, 0.22545, 0.23466666, 0.23466666]
	best_train_sub_head: 1
	worst: 0.22545
	avg: 0.23337999
	best: 0.23636666

Starting e_i: 391
Model ind 579 epoch 391 head B head_i_epoch 0 batch 0: avg loss -1.819660 avg loss no lamb -1.819660 time 2019-02-01 02:55:50.203341
Model ind 579 epoch 391 head B head_i_epoch 0 batch 100: avg loss -1.676865 avg loss no lamb -1.676865 time 2019-02-01 02:58:47.391377
Model ind 579 epoch 391 head B head_i_epoch 0 batch 200: avg loss -1.710978 avg loss no lamb -1.710978 time 2019-02-01 03:01:45.132255
Model ind 579 epoch 391 head A head_i_epoch 0 batch 0: avg loss -3.290909 avg loss no lamb -3.290909 time 2019-02-01 03:04:43.992535
Model ind 579 epoch 391 head A head_i_epoch 0 batch 100: avg loss -3.317040 avg loss no lamb -3.317040 time 2019-02-01 03:07:40.620872
Model ind 579 epoch 391 head A head_i_epoch 0 batch 200: avg loss -3.386373 avg loss no lamb -3.386373 time 2019-02-01 03:10:39.079772
Pre: time 2019-02-01 03:14:00.383511: 
 	std: 0.0036167284
	best_train_sub_head_match: [(0, 5), (1, 12), (2, 14), (3, 0), (4, 2), (5, 4), (6, 8), (7, 6), (8, 13), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24101667, 0.23951666, 0.23088333, 0.23895, 0.23956667]
	train_accs: [0.24101667, 0.23951666, 0.23088333, 0.23895, 0.23956667]
	best_train_sub_head: 0
	worst: 0.23088333
	avg: 0.23798665
	best: 0.24101667

Starting e_i: 392
Model ind 579 epoch 392 head B head_i_epoch 0 batch 0: avg loss -1.758212 avg loss no lamb -1.758212 time 2019-02-01 03:14:03.792646
Model ind 579 epoch 392 head B head_i_epoch 0 batch 100: avg loss -1.718738 avg loss no lamb -1.718738 time 2019-02-01 03:16:59.407647
Model ind 579 epoch 392 head B head_i_epoch 0 batch 200: avg loss -1.656800 avg loss no lamb -1.656800 time 2019-02-01 03:19:56.963632
Model ind 579 epoch 392 head A head_i_epoch 0 batch 0: avg loss -3.279542 avg loss no lamb -3.279542 time 2019-02-01 03:22:54.155937
Model ind 579 epoch 392 head A head_i_epoch 0 batch 100: avg loss -3.310735 avg loss no lamb -3.310735 time 2019-02-01 03:25:51.298213
Model ind 579 epoch 392 head A head_i_epoch 0 batch 200: avg loss -3.326329 avg loss no lamb -3.326329 time 2019-02-01 03:28:47.750667
Pre: time 2019-02-01 03:32:09.844374: 
 	std: 0.0034138397
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.23578334, 0.23585, 0.22696666, 0.23566666, 0.23403333]
	train_accs: [0.23578334, 0.23585, 0.22696666, 0.23566666, 0.23403333]
	best_train_sub_head: 1
	worst: 0.22696666
	avg: 0.23366001
	best: 0.23585

Starting e_i: 393
Model ind 579 epoch 393 head B head_i_epoch 0 batch 0: avg loss -1.620767 avg loss no lamb -1.620767 time 2019-02-01 03:32:13.173806
Model ind 579 epoch 393 head B head_i_epoch 0 batch 100: avg loss -1.644953 avg loss no lamb -1.644953 time 2019-02-01 03:35:09.412472
Model ind 579 epoch 393 head B head_i_epoch 0 batch 200: avg loss -1.662977 avg loss no lamb -1.662977 time 2019-02-01 03:38:07.164343
Model ind 579 epoch 393 head A head_i_epoch 0 batch 0: avg loss -3.233067 avg loss no lamb -3.233067 time 2019-02-01 03:41:02.832001
Model ind 579 epoch 393 head A head_i_epoch 0 batch 100: avg loss -3.342738 avg loss no lamb -3.342738 time 2019-02-01 03:44:00.190038
Model ind 579 epoch 393 head A head_i_epoch 0 batch 200: avg loss -3.288096 avg loss no lamb -3.288096 time 2019-02-01 03:46:58.360921
Pre: time 2019-02-01 03:50:19.409098: 
 	std: 0.0037240891
	best_train_sub_head_match: [(0, 5), (1, 12), (2, 14), (3, 0), (4, 2), (5, 4), (6, 8), (7, 6), (8, 13), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23946667, 0.23853333, 0.2296, 0.23758334, 0.23941667]
	train_accs: [0.23946667, 0.23853333, 0.2296, 0.23758334, 0.23941667]
	best_train_sub_head: 0
	worst: 0.2296
	avg: 0.23692
	best: 0.23946667

Starting e_i: 394
Model ind 579 epoch 394 head B head_i_epoch 0 batch 0: avg loss -1.680663 avg loss no lamb -1.680663 time 2019-02-01 03:50:22.894403
Model ind 579 epoch 394 head B head_i_epoch 0 batch 100: avg loss -1.654495 avg loss no lamb -1.654495 time 2019-02-01 03:53:20.186189
Model ind 579 epoch 394 head B head_i_epoch 0 batch 200: avg loss -1.771684 avg loss no lamb -1.771684 time 2019-02-01 03:56:16.704007
Model ind 579 epoch 394 head A head_i_epoch 0 batch 0: avg loss -3.232158 avg loss no lamb -3.232158 time 2019-02-01 03:59:13.483559
Model ind 579 epoch 394 head A head_i_epoch 0 batch 100: avg loss -3.316116 avg loss no lamb -3.316116 time 2019-02-01 04:02:10.924414
Model ind 579 epoch 394 head A head_i_epoch 0 batch 200: avg loss -3.317953 avg loss no lamb -3.317953 time 2019-02-01 04:05:08.296004
Pre: time 2019-02-01 04:08:33.388723: 
 	std: 0.0037325823
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 2), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2345, 0.23496667, 0.22478333, 0.23305, 0.23321667]
	train_accs: [0.2345, 0.23496667, 0.22478333, 0.23305, 0.23321667]
	best_train_sub_head: 1
	worst: 0.22478333
	avg: 0.23210332
	best: 0.23496667

Starting e_i: 395
Model ind 579 epoch 395 head B head_i_epoch 0 batch 0: avg loss -1.704104 avg loss no lamb -1.704104 time 2019-02-01 04:08:36.540786
Model ind 579 epoch 395 head B head_i_epoch 0 batch 100: avg loss -1.715071 avg loss no lamb -1.715071 time 2019-02-01 04:11:32.627888
Model ind 579 epoch 395 head B head_i_epoch 0 batch 200: avg loss -1.683144 avg loss no lamb -1.683144 time 2019-02-01 04:14:28.474380
Model ind 579 epoch 395 head A head_i_epoch 0 batch 0: avg loss -3.287871 avg loss no lamb -3.287871 time 2019-02-01 04:17:24.259683
Model ind 579 epoch 395 head A head_i_epoch 0 batch 100: avg loss -3.264077 avg loss no lamb -3.264077 time 2019-02-01 04:20:21.926690
Model ind 579 epoch 395 head A head_i_epoch 0 batch 200: avg loss -3.278301 avg loss no lamb -3.278301 time 2019-02-01 04:23:19.647169
Pre: time 2019-02-01 04:26:41.055932: 
 	std: 0.0037348592
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.23858333, 0.23968333, 0.2296, 0.23861666, 0.23863333]
	train_accs: [0.23858333, 0.23968333, 0.2296, 0.23861666, 0.23863333]
	best_train_sub_head: 1
	worst: 0.2296
	avg: 0.23702332
	best: 0.23968333

Starting e_i: 396
Model ind 579 epoch 396 head B head_i_epoch 0 batch 0: avg loss -1.731301 avg loss no lamb -1.731301 time 2019-02-01 04:26:44.511584
Model ind 579 epoch 396 head B head_i_epoch 0 batch 100: avg loss -1.665465 avg loss no lamb -1.665465 time 2019-02-01 04:29:41.464648
Model ind 579 epoch 396 head B head_i_epoch 0 batch 200: avg loss -1.727442 avg loss no lamb -1.727442 time 2019-02-01 04:32:37.513749
Model ind 579 epoch 396 head A head_i_epoch 0 batch 0: avg loss -3.222226 avg loss no lamb -3.222226 time 2019-02-01 04:35:34.619532
Model ind 579 epoch 396 head A head_i_epoch 0 batch 100: avg loss -3.316287 avg loss no lamb -3.316287 time 2019-02-01 04:38:30.831224
Model ind 579 epoch 396 head A head_i_epoch 0 batch 200: avg loss -3.311718 avg loss no lamb -3.311718 time 2019-02-01 04:41:27.876537
Pre: time 2019-02-01 04:44:48.752569: 
 	std: 0.0035852417
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24028334, 0.24045, 0.23098333, 0.23911667, 0.23961666]
	train_accs: [0.24028334, 0.24045, 0.23098333, 0.23911667, 0.23961666]
	best_train_sub_head: 1
	worst: 0.23098333
	avg: 0.23809
	best: 0.24045

Starting e_i: 397
Model ind 579 epoch 397 head B head_i_epoch 0 batch 0: avg loss -1.641214 avg loss no lamb -1.641214 time 2019-02-01 04:44:52.018876
Model ind 579 epoch 397 head B head_i_epoch 0 batch 100: avg loss -1.706931 avg loss no lamb -1.706931 time 2019-02-01 04:47:48.581410
Model ind 579 epoch 397 head B head_i_epoch 0 batch 200: avg loss -1.650472 avg loss no lamb -1.650472 time 2019-02-01 04:50:44.478622
Model ind 579 epoch 397 head A head_i_epoch 0 batch 0: avg loss -3.202925 avg loss no lamb -3.202925 time 2019-02-01 04:53:41.203526
Model ind 579 epoch 397 head A head_i_epoch 0 batch 100: avg loss -3.355318 avg loss no lamb -3.355318 time 2019-02-01 04:56:41.702589
Model ind 579 epoch 397 head A head_i_epoch 0 batch 200: avg loss -3.320633 avg loss no lamb -3.320633 time 2019-02-01 04:59:40.877644
Pre: time 2019-02-01 05:03:01.848170: 
 	std: 0.0037926077
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 15), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.2414, 0.2428, 0.23241666, 0.24205, 0.2407]
	train_accs: [0.2414, 0.2428, 0.23241666, 0.24205, 0.2407]
	best_train_sub_head: 1
	worst: 0.23241666
	avg: 0.23987332
	best: 0.2428

Starting e_i: 398
Model ind 579 epoch 398 head B head_i_epoch 0 batch 0: avg loss -1.686142 avg loss no lamb -1.686142 time 2019-02-01 05:03:14.678311
Model ind 579 epoch 398 head B head_i_epoch 0 batch 100: avg loss -1.725003 avg loss no lamb -1.725003 time 2019-02-01 05:06:10.631735
Model ind 579 epoch 398 head B head_i_epoch 0 batch 200: avg loss -1.703639 avg loss no lamb -1.703639 time 2019-02-01 05:09:07.362171
Model ind 579 epoch 398 head A head_i_epoch 0 batch 0: avg loss -3.322826 avg loss no lamb -3.322826 time 2019-02-01 05:12:04.972883
Model ind 579 epoch 398 head A head_i_epoch 0 batch 100: avg loss -3.220030 avg loss no lamb -3.220030 time 2019-02-01 05:15:03.221662
Model ind 579 epoch 398 head A head_i_epoch 0 batch 200: avg loss -3.322322 avg loss no lamb -3.322322 time 2019-02-01 05:18:01.702508
Pre: time 2019-02-01 05:21:27.522843: 
 	std: 0.004375525
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.23885, 0.23975, 0.22803333, 0.23891667, 0.23803334]
	train_accs: [0.23885, 0.23975, 0.22803333, 0.23891667, 0.23803334]
	best_train_sub_head: 1
	worst: 0.22803333
	avg: 0.23671666
	best: 0.23975

Starting e_i: 399
Model ind 579 epoch 399 head B head_i_epoch 0 batch 0: avg loss -1.737371 avg loss no lamb -1.737371 time 2019-02-01 05:21:30.694003
Model ind 579 epoch 399 head B head_i_epoch 0 batch 100: avg loss -1.677124 avg loss no lamb -1.677124 time 2019-02-01 05:24:27.926520
Model ind 579 epoch 399 head B head_i_epoch 0 batch 200: avg loss -1.708255 avg loss no lamb -1.708255 time 2019-02-01 05:27:23.800685
Model ind 579 epoch 399 head A head_i_epoch 0 batch 0: avg loss -3.297869 avg loss no lamb -3.297869 time 2019-02-01 05:30:20.389677
Model ind 579 epoch 399 head A head_i_epoch 0 batch 100: avg loss -3.324296 avg loss no lamb -3.324296 time 2019-02-01 05:33:19.050223
Model ind 579 epoch 399 head A head_i_epoch 0 batch 200: avg loss -3.306326 avg loss no lamb -3.306326 time 2019-02-01 05:36:16.444247
Pre: time 2019-02-01 05:39:41.163595: 
 	std: 0.004437945
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 15), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.24078333, 0.24121666, 0.22968334, 0.24105, 0.23978333]
	train_accs: [0.24078333, 0.24121666, 0.22968334, 0.24105, 0.23978333]
	best_train_sub_head: 1
	worst: 0.22968334
	avg: 0.23850334
	best: 0.24121666

Starting e_i: 400
Model ind 579 epoch 400 head B head_i_epoch 0 batch 0: avg loss -1.651292 avg loss no lamb -1.651292 time 2019-02-01 05:39:44.520549
Model ind 579 epoch 400 head B head_i_epoch 0 batch 100: avg loss -1.698776 avg loss no lamb -1.698776 time 2019-02-01 05:42:41.483467
Model ind 579 epoch 400 head B head_i_epoch 0 batch 200: avg loss -1.596546 avg loss no lamb -1.596546 time 2019-02-01 05:45:37.500300
Model ind 579 epoch 400 head A head_i_epoch 0 batch 0: avg loss -3.263822 avg loss no lamb -3.263822 time 2019-02-01 05:48:33.642316
Model ind 579 epoch 400 head A head_i_epoch 0 batch 100: avg loss -3.298517 avg loss no lamb -3.298517 time 2019-02-01 05:51:30.639813
Model ind 579 epoch 400 head A head_i_epoch 0 batch 200: avg loss -3.307570 avg loss no lamb -3.307570 time 2019-02-01 05:54:28.154082
Pre: time 2019-02-01 05:57:49.670910: 
 	std: 0.0045338282
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.23923333, 0.2413, 0.22871667, 0.23996666, 0.23898333]
	train_accs: [0.23923333, 0.2413, 0.22871667, 0.23996666, 0.23898333]
	best_train_sub_head: 1
	worst: 0.22871667
	avg: 0.23764
	best: 0.2413

Starting e_i: 401
Model ind 579 epoch 401 head B head_i_epoch 0 batch 0: avg loss -1.725904 avg loss no lamb -1.725904 time 2019-02-01 05:57:56.187807
Model ind 579 epoch 401 head B head_i_epoch 0 batch 100: avg loss -1.698803 avg loss no lamb -1.698803 time 2019-02-01 06:00:53.778413
Model ind 579 epoch 401 head B head_i_epoch 0 batch 200: avg loss -1.706280 avg loss no lamb -1.706280 time 2019-02-01 06:03:49.397529
Model ind 579 epoch 401 head A head_i_epoch 0 batch 0: avg loss -3.305878 avg loss no lamb -3.305878 time 2019-02-01 06:06:45.983513
Model ind 579 epoch 401 head A head_i_epoch 0 batch 100: avg loss -3.305420 avg loss no lamb -3.305420 time 2019-02-01 06:09:43.708187
Model ind 579 epoch 401 head A head_i_epoch 0 batch 200: avg loss -3.298800 avg loss no lamb -3.298800 time 2019-02-01 06:12:42.963559
Pre: time 2019-02-01 06:16:06.304278: 
 	std: 0.004949744
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 5), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24593334, 0.24725, 0.23381667, 0.24571666, 0.24548334]
	train_accs: [0.24593334, 0.24725, 0.23381667, 0.24571666, 0.24548334]
	best_train_sub_head: 1
	worst: 0.23381667
	avg: 0.24363999
	best: 0.24725

Starting e_i: 402
Model ind 579 epoch 402 head B head_i_epoch 0 batch 0: avg loss -1.661713 avg loss no lamb -1.661713 time 2019-02-01 06:16:13.101210
Model ind 579 epoch 402 head B head_i_epoch 0 batch 100: avg loss -1.694004 avg loss no lamb -1.694004 time 2019-02-01 06:19:11.401668
Model ind 579 epoch 402 head B head_i_epoch 0 batch 200: avg loss -1.688769 avg loss no lamb -1.688769 time 2019-02-01 06:22:09.387653
Model ind 579 epoch 402 head A head_i_epoch 0 batch 0: avg loss -3.220031 avg loss no lamb -3.220031 time 2019-02-01 06:25:05.675895
Model ind 579 epoch 402 head A head_i_epoch 0 batch 100: avg loss -3.267609 avg loss no lamb -3.267609 time 2019-02-01 06:28:01.633771
Model ind 579 epoch 402 head A head_i_epoch 0 batch 200: avg loss -3.317976 avg loss no lamb -3.317976 time 2019-02-01 06:30:59.116977
Pre: time 2019-02-01 06:34:21.054311: 
 	std: 0.0045857043
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23763333, 0.23701666, 0.22535, 0.23658334, 0.23548333]
	train_accs: [0.23763333, 0.23701666, 0.22535, 0.23658334, 0.23548333]
	best_train_sub_head: 0
	worst: 0.22535
	avg: 0.23441334
	best: 0.23763333

Starting e_i: 403
Model ind 579 epoch 403 head B head_i_epoch 0 batch 0: avg loss -1.757438 avg loss no lamb -1.757438 time 2019-02-01 06:34:24.772463
Model ind 579 epoch 403 head B head_i_epoch 0 batch 100: avg loss -1.646911 avg loss no lamb -1.646911 time 2019-02-01 06:37:20.678760
Model ind 579 epoch 403 head B head_i_epoch 0 batch 200: avg loss -1.733542 avg loss no lamb -1.733542 time 2019-02-01 06:40:16.698552
Model ind 579 epoch 403 head A head_i_epoch 0 batch 0: avg loss -3.267473 avg loss no lamb -3.267473 time 2019-02-01 06:43:11.094546
Model ind 579 epoch 403 head A head_i_epoch 0 batch 100: avg loss -3.287828 avg loss no lamb -3.287828 time 2019-02-01 06:46:07.334735
Model ind 579 epoch 403 head A head_i_epoch 0 batch 200: avg loss -3.347732 avg loss no lamb -3.347732 time 2019-02-01 06:49:03.228632
Pre: time 2019-02-01 06:52:24.646730: 
 	std: 0.0039743856
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24125, 0.24088334, 0.23075, 0.24068333, 0.23948333]
	train_accs: [0.24125, 0.24088334, 0.23075, 0.24068333, 0.23948333]
	best_train_sub_head: 0
	worst: 0.23075
	avg: 0.23861
	best: 0.24125

Starting e_i: 404
Model ind 579 epoch 404 head B head_i_epoch 0 batch 0: avg loss -1.719212 avg loss no lamb -1.719212 time 2019-02-01 06:52:28.049840
Model ind 579 epoch 404 head B head_i_epoch 0 batch 100: avg loss -1.625205 avg loss no lamb -1.625205 time 2019-02-01 06:55:26.472818
Model ind 579 epoch 404 head B head_i_epoch 0 batch 200: avg loss -1.677777 avg loss no lamb -1.677777 time 2019-02-01 06:58:22.415325
Model ind 579 epoch 404 head A head_i_epoch 0 batch 0: avg loss -3.241912 avg loss no lamb -3.241912 time 2019-02-01 07:01:18.752913
Model ind 579 epoch 404 head A head_i_epoch 0 batch 100: avg loss -3.296569 avg loss no lamb -3.296569 time 2019-02-01 07:04:17.162958
Model ind 579 epoch 404 head A head_i_epoch 0 batch 200: avg loss -3.361823 avg loss no lamb -3.361823 time 2019-02-01 07:07:15.376209
Pre: time 2019-02-01 07:10:36.449266: 
 	std: 0.0045751096
	best_train_sub_head_match: [(0, 5), (1, 12), (2, 14), (3, 0), (4, 2), (5, 4), (6, 8), (7, 6), (8, 13), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2393, 0.23801666, 0.2269, 0.23748334, 0.23816666]
	train_accs: [0.2393, 0.23801666, 0.2269, 0.23748334, 0.23816666]
	best_train_sub_head: 0
	worst: 0.2269
	avg: 0.23597333
	best: 0.2393

Starting e_i: 405
Model ind 579 epoch 405 head B head_i_epoch 0 batch 0: avg loss -1.746591 avg loss no lamb -1.746591 time 2019-02-01 07:10:39.948733
Model ind 579 epoch 405 head B head_i_epoch 0 batch 100: avg loss -1.636450 avg loss no lamb -1.636450 time 2019-02-01 07:13:36.039047
Model ind 579 epoch 405 head B head_i_epoch 0 batch 200: avg loss -1.760091 avg loss no lamb -1.760091 time 2019-02-01 07:16:34.272014
Model ind 579 epoch 405 head A head_i_epoch 0 batch 0: avg loss -3.323823 avg loss no lamb -3.323823 time 2019-02-01 07:19:29.813582
Model ind 579 epoch 405 head A head_i_epoch 0 batch 100: avg loss -3.297680 avg loss no lamb -3.297680 time 2019-02-01 07:22:28.440671
Model ind 579 epoch 405 head A head_i_epoch 0 batch 200: avg loss -3.337059 avg loss no lamb -3.337059 time 2019-02-01 07:25:25.319969
Pre: time 2019-02-01 07:28:47.622411: 
 	std: 0.0034760812
	best_train_sub_head_match: [(0, 5), (1, 12), (2, 14), (3, 0), (4, 2), (5, 4), (6, 8), (7, 6), (8, 13), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23848334, 0.23768333, 0.2292, 0.23751667, 0.23771666]
	train_accs: [0.23848334, 0.23768333, 0.2292, 0.23751667, 0.23771666]
	best_train_sub_head: 0
	worst: 0.2292
	avg: 0.23612002
	best: 0.23848334

Starting e_i: 406
Model ind 579 epoch 406 head B head_i_epoch 0 batch 0: avg loss -1.762403 avg loss no lamb -1.762403 time 2019-02-01 07:28:50.728657
Model ind 579 epoch 406 head B head_i_epoch 0 batch 100: avg loss -1.761638 avg loss no lamb -1.761638 time 2019-02-01 07:31:46.706163
Model ind 579 epoch 406 head B head_i_epoch 0 batch 200: avg loss -1.745152 avg loss no lamb -1.745152 time 2019-02-01 07:34:42.372180
Model ind 579 epoch 406 head A head_i_epoch 0 batch 0: avg loss -3.252683 avg loss no lamb -3.252683 time 2019-02-01 07:37:38.233907
Model ind 579 epoch 406 head A head_i_epoch 0 batch 100: avg loss -3.323473 avg loss no lamb -3.323473 time 2019-02-01 07:40:35.307158
Model ind 579 epoch 406 head A head_i_epoch 0 batch 200: avg loss -3.319024 avg loss no lamb -3.319024 time 2019-02-01 07:43:34.005736
Pre: time 2019-02-01 07:46:57.120369: 
 	std: 0.0041975775
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 16), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 12), (13, 11), (14, 10), (15, 1), (16, 2), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.23613334, 0.23728333, 0.22646667, 0.23776667, 0.23618333]
	train_accs: [0.23613334, 0.23728333, 0.22646667, 0.23776667, 0.23618333]
	best_train_sub_head: 3
	worst: 0.22646667
	avg: 0.23476668
	best: 0.23776667

Starting e_i: 407
Model ind 579 epoch 407 head B head_i_epoch 0 batch 0: avg loss -1.724227 avg loss no lamb -1.724227 time 2019-02-01 07:47:00.749542
Model ind 579 epoch 407 head B head_i_epoch 0 batch 100: avg loss -1.750948 avg loss no lamb -1.750948 time 2019-02-01 07:49:56.289960
Model ind 579 epoch 407 head B head_i_epoch 0 batch 200: avg loss -1.725133 avg loss no lamb -1.725133 time 2019-02-01 07:52:52.210431
Model ind 579 epoch 407 head A head_i_epoch 0 batch 0: avg loss -3.250625 avg loss no lamb -3.250625 time 2019-02-01 07:55:47.781496
Model ind 579 epoch 407 head A head_i_epoch 0 batch 100: avg loss -3.310214 avg loss no lamb -3.310214 time 2019-02-01 07:58:46.554212
Model ind 579 epoch 407 head A head_i_epoch 0 batch 200: avg loss -3.329173 avg loss no lamb -3.329173 time 2019-02-01 08:01:45.591849
Pre: time 2019-02-01 08:05:07.604575: 
 	std: 0.0034870857
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 16), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 12), (13, 11), (14, 10), (15, 1), (16, 2), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.23431666, 0.23471667, 0.22598334, 0.23551667, 0.2338]
	train_accs: [0.23431666, 0.23471667, 0.22598334, 0.23551667, 0.2338]
	best_train_sub_head: 3
	worst: 0.22598334
	avg: 0.23286667
	best: 0.23551667

Starting e_i: 408
Model ind 579 epoch 408 head B head_i_epoch 0 batch 0: avg loss -1.687481 avg loss no lamb -1.687481 time 2019-02-01 08:05:10.943387
Model ind 579 epoch 408 head B head_i_epoch 0 batch 100: avg loss -1.673186 avg loss no lamb -1.673186 time 2019-02-01 08:08:07.655131
Model ind 579 epoch 408 head B head_i_epoch 0 batch 200: avg loss -1.713799 avg loss no lamb -1.713799 time 2019-02-01 08:11:05.340668
Model ind 579 epoch 408 head A head_i_epoch 0 batch 0: avg loss -3.233202 avg loss no lamb -3.233202 time 2019-02-01 08:14:03.451310
Model ind 579 epoch 408 head A head_i_epoch 0 batch 100: avg loss -3.327372 avg loss no lamb -3.327372 time 2019-02-01 08:17:01.064170
Model ind 579 epoch 408 head A head_i_epoch 0 batch 200: avg loss -3.290633 avg loss no lamb -3.290633 time 2019-02-01 08:19:58.741283
Pre: time 2019-02-01 08:23:19.498574: 
 	std: 0.004240942
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 16), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 12), (13, 11), (14, 10), (15, 1), (16, 2), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2374, 0.23745, 0.22701667, 0.23851667, 0.23671667]
	train_accs: [0.2374, 0.23745, 0.22701667, 0.23851667, 0.23671667]
	best_train_sub_head: 3
	worst: 0.22701667
	avg: 0.23542002
	best: 0.23851667

Starting e_i: 409
Model ind 579 epoch 409 head B head_i_epoch 0 batch 0: avg loss -1.682790 avg loss no lamb -1.682790 time 2019-02-01 08:23:23.017777
Model ind 579 epoch 409 head B head_i_epoch 0 batch 100: avg loss -1.696463 avg loss no lamb -1.696463 time 2019-02-01 08:26:18.040956
Model ind 579 epoch 409 head B head_i_epoch 0 batch 200: avg loss -1.755935 avg loss no lamb -1.755935 time 2019-02-01 08:29:15.330285
Model ind 579 epoch 409 head A head_i_epoch 0 batch 0: avg loss -3.302563 avg loss no lamb -3.302563 time 2019-02-01 08:32:11.072643
Model ind 579 epoch 409 head A head_i_epoch 0 batch 100: avg loss -3.274618 avg loss no lamb -3.274618 time 2019-02-01 08:35:08.097939
Model ind 579 epoch 409 head A head_i_epoch 0 batch 200: avg loss -3.309779 avg loss no lamb -3.309779 time 2019-02-01 08:38:05.868186
Pre: time 2019-02-01 08:41:26.564271: 
 	std: 0.0038629216
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 15), (3, 13), (4, 4), (5, 5), (6, 7), (7, 11), (8, 3), (9, 2), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.23608333, 0.2367, 0.22641666, 0.23635, 0.23393333]
	train_accs: [0.23608333, 0.2367, 0.22641666, 0.23635, 0.23393333]
	best_train_sub_head: 1
	worst: 0.22641666
	avg: 0.23389666
	best: 0.2367

Starting e_i: 410
Model ind 579 epoch 410 head B head_i_epoch 0 batch 0: avg loss -1.673312 avg loss no lamb -1.673312 time 2019-02-01 08:41:29.756211
Model ind 579 epoch 410 head B head_i_epoch 0 batch 100: avg loss -1.777501 avg loss no lamb -1.777501 time 2019-02-01 08:44:25.387063
Model ind 579 epoch 410 head B head_i_epoch 0 batch 200: avg loss -1.719608 avg loss no lamb -1.719608 time 2019-02-01 08:47:22.544573
Model ind 579 epoch 410 head A head_i_epoch 0 batch 0: avg loss -3.288626 avg loss no lamb -3.288626 time 2019-02-01 08:50:19.917028
Model ind 579 epoch 410 head A head_i_epoch 0 batch 100: avg loss -3.297532 avg loss no lamb -3.297532 time 2019-02-01 08:53:17.620194
Model ind 579 epoch 410 head A head_i_epoch 0 batch 200: avg loss -3.263984 avg loss no lamb -3.263984 time 2019-02-01 08:56:14.968039
Pre: time 2019-02-01 08:59:36.222414: 
 	std: 0.0035286944
	best_train_sub_head_match: [(0, 18), (1, 12), (2, 14), (3, 0), (4, 2), (5, 4), (6, 8), (7, 6), (8, 5), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24128333, 0.24055, 0.23186667, 0.241, 0.23915]
	train_accs: [0.24128333, 0.24055, 0.23186667, 0.241, 0.23915]
	best_train_sub_head: 0
	worst: 0.23186667
	avg: 0.23877001
	best: 0.24128333

Starting e_i: 411
Model ind 579 epoch 411 head B head_i_epoch 0 batch 0: avg loss -1.701999 avg loss no lamb -1.701999 time 2019-02-01 08:59:44.915649
Model ind 579 epoch 411 head B head_i_epoch 0 batch 100: avg loss -1.721225 avg loss no lamb -1.721225 time 2019-02-01 09:02:40.648609
Model ind 579 epoch 411 head B head_i_epoch 0 batch 200: avg loss -1.703772 avg loss no lamb -1.703772 time 2019-02-01 09:05:35.946564
Model ind 579 epoch 411 head A head_i_epoch 0 batch 0: avg loss -3.295092 avg loss no lamb -3.295092 time 2019-02-01 09:08:31.803047
Model ind 579 epoch 411 head A head_i_epoch 0 batch 100: avg loss -3.305190 avg loss no lamb -3.305190 time 2019-02-01 09:11:31.174936
Model ind 579 epoch 411 head A head_i_epoch 0 batch 200: avg loss -3.401138 avg loss no lamb -3.401138 time 2019-02-01 09:14:28.868545
Pre: time 2019-02-01 09:17:52.759700: 
 	std: 0.0036457079
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24215, 0.24363333, 0.23345, 0.2423, 0.24151666]
	train_accs: [0.24215, 0.24363333, 0.23345, 0.2423, 0.24151666]
	best_train_sub_head: 1
	worst: 0.23345
	avg: 0.24061
	best: 0.24363333

Starting e_i: 412
Model ind 579 epoch 412 head B head_i_epoch 0 batch 0: avg loss -1.714641 avg loss no lamb -1.714641 time 2019-02-01 09:17:55.972828
Model ind 579 epoch 412 head B head_i_epoch 0 batch 100: avg loss -1.750464 avg loss no lamb -1.750464 time 2019-02-01 09:20:54.490388
Model ind 579 epoch 412 head B head_i_epoch 0 batch 200: avg loss -1.584977 avg loss no lamb -1.584977 time 2019-02-01 09:23:50.071848
Model ind 579 epoch 412 head A head_i_epoch 0 batch 0: avg loss -3.315660 avg loss no lamb -3.315660 time 2019-02-01 09:26:46.697408
Model ind 579 epoch 412 head A head_i_epoch 0 batch 100: avg loss -3.350969 avg loss no lamb -3.350969 time 2019-02-01 09:29:44.997315
Model ind 579 epoch 412 head A head_i_epoch 0 batch 200: avg loss -3.315523 avg loss no lamb -3.315523 time 2019-02-01 09:32:41.993991
Pre: time 2019-02-01 09:36:05.008032: 
 	std: 0.0040432177
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 2), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23695, 0.23686667, 0.22636667, 0.23653333, 0.23475]
	train_accs: [0.23695, 0.23686667, 0.22636667, 0.23653333, 0.23475]
	best_train_sub_head: 0
	worst: 0.22636667
	avg: 0.23429334
	best: 0.23695

Starting e_i: 413
Model ind 579 epoch 413 head B head_i_epoch 0 batch 0: avg loss -1.660605 avg loss no lamb -1.660605 time 2019-02-01 09:36:08.279004
Model ind 579 epoch 413 head B head_i_epoch 0 batch 100: avg loss -1.653609 avg loss no lamb -1.653609 time 2019-02-01 09:39:04.928006
Model ind 579 epoch 413 head B head_i_epoch 0 batch 200: avg loss -1.712008 avg loss no lamb -1.712008 time 2019-02-01 09:42:01.657927
Model ind 579 epoch 413 head A head_i_epoch 0 batch 0: avg loss -3.269458 avg loss no lamb -3.269458 time 2019-02-01 09:44:57.121614
Model ind 579 epoch 413 head A head_i_epoch 0 batch 100: avg loss -3.277587 avg loss no lamb -3.277587 time 2019-02-01 09:47:54.063467
Model ind 579 epoch 413 head A head_i_epoch 0 batch 200: avg loss -3.335539 avg loss no lamb -3.335539 time 2019-02-01 09:50:51.153214
Pre: time 2019-02-01 09:54:12.104682: 
 	std: 0.003859724
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2384, 0.23708333, 0.22771667, 0.23698333, 0.23646666]
	train_accs: [0.2384, 0.23708333, 0.22771667, 0.23698333, 0.23646666]
	best_train_sub_head: 0
	worst: 0.22771667
	avg: 0.23532999
	best: 0.2384

Starting e_i: 414
Model ind 579 epoch 414 head B head_i_epoch 0 batch 0: avg loss -1.675677 avg loss no lamb -1.675677 time 2019-02-01 09:54:16.481347
Model ind 579 epoch 414 head B head_i_epoch 0 batch 100: avg loss -1.721588 avg loss no lamb -1.721588 time 2019-02-01 09:57:12.094755
Model ind 579 epoch 414 head B head_i_epoch 0 batch 200: avg loss -1.735112 avg loss no lamb -1.735112 time 2019-02-01 10:00:10.812179
Model ind 579 epoch 414 head A head_i_epoch 0 batch 0: avg loss -3.196387 avg loss no lamb -3.196387 time 2019-02-01 10:03:07.666637
Model ind 579 epoch 414 head A head_i_epoch 0 batch 100: avg loss -3.326113 avg loss no lamb -3.326113 time 2019-02-01 10:06:04.976464
Model ind 579 epoch 414 head A head_i_epoch 0 batch 200: avg loss -3.338120 avg loss no lamb -3.338120 time 2019-02-01 10:09:03.868786
Pre: time 2019-02-01 10:12:27.266413: 
 	std: 0.0044014594
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 13), (19, 18)]
	test_accs: [0.24, 0.24131666, 0.22995, 0.24145, 0.24075]
	train_accs: [0.24, 0.24131666, 0.22995, 0.24145, 0.24075]
	best_train_sub_head: 3
	worst: 0.22995
	avg: 0.23869333
	best: 0.24145

Starting e_i: 415
Model ind 579 epoch 415 head B head_i_epoch 0 batch 0: avg loss -1.681578 avg loss no lamb -1.681578 time 2019-02-01 10:12:30.519083
Model ind 579 epoch 415 head B head_i_epoch 0 batch 100: avg loss -1.729970 avg loss no lamb -1.729970 time 2019-02-01 10:15:27.906586
Model ind 579 epoch 415 head B head_i_epoch 0 batch 200: avg loss -1.693804 avg loss no lamb -1.693804 time 2019-02-01 10:18:23.685444
Model ind 579 epoch 415 head A head_i_epoch 0 batch 0: avg loss -3.262111 avg loss no lamb -3.262111 time 2019-02-01 10:21:19.696381
Model ind 579 epoch 415 head A head_i_epoch 0 batch 100: avg loss -3.301749 avg loss no lamb -3.301749 time 2019-02-01 10:24:17.684588
Model ind 579 epoch 415 head A head_i_epoch 0 batch 200: avg loss -3.344492 avg loss no lamb -3.344492 time 2019-02-01 10:27:14.693105
Pre: time 2019-02-01 10:30:35.104610: 
 	std: 0.0043397783
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 2), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2349, 0.23425, 0.2234, 0.23453334, 0.23258333]
	train_accs: [0.2349, 0.23425, 0.2234, 0.23453334, 0.23258333]
	best_train_sub_head: 0
	worst: 0.2234
	avg: 0.23193333
	best: 0.2349

Starting e_i: 416
Model ind 579 epoch 416 head B head_i_epoch 0 batch 0: avg loss -1.711499 avg loss no lamb -1.711499 time 2019-02-01 10:30:38.712635
Model ind 579 epoch 416 head B head_i_epoch 0 batch 100: avg loss -1.682358 avg loss no lamb -1.682358 time 2019-02-01 10:33:34.378837
Model ind 579 epoch 416 head B head_i_epoch 0 batch 200: avg loss -1.722623 avg loss no lamb -1.722623 time 2019-02-01 10:36:31.113251
Model ind 579 epoch 416 head A head_i_epoch 0 batch 0: avg loss -3.253385 avg loss no lamb -3.253385 time 2019-02-01 10:39:28.947014
Model ind 579 epoch 416 head A head_i_epoch 0 batch 100: avg loss -3.316915 avg loss no lamb -3.316915 time 2019-02-01 10:42:26.767759
Model ind 579 epoch 416 head A head_i_epoch 0 batch 200: avg loss -3.354617 avg loss no lamb -3.354617 time 2019-02-01 10:45:24.229463
Pre: time 2019-02-01 10:48:46.962590: 
 	std: 0.00470489
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.23725, 0.23846667, 0.22605, 0.23835, 0.23671667]
	train_accs: [0.23725, 0.23846667, 0.22605, 0.23835, 0.23671667]
	best_train_sub_head: 1
	worst: 0.22605
	avg: 0.23536666
	best: 0.23846667

Starting e_i: 417
Model ind 579 epoch 417 head B head_i_epoch 0 batch 0: avg loss -1.679912 avg loss no lamb -1.679912 time 2019-02-01 10:48:50.029777
Model ind 579 epoch 417 head B head_i_epoch 0 batch 100: avg loss -1.686311 avg loss no lamb -1.686311 time 2019-02-01 10:51:46.829428
Model ind 579 epoch 417 head B head_i_epoch 0 batch 200: avg loss -1.720228 avg loss no lamb -1.720228 time 2019-02-01 10:54:42.929386
Model ind 579 epoch 417 head A head_i_epoch 0 batch 0: avg loss -3.241348 avg loss no lamb -3.241348 time 2019-02-01 10:57:39.454163
Model ind 579 epoch 417 head A head_i_epoch 0 batch 100: avg loss -3.304425 avg loss no lamb -3.304425 time 2019-02-01 11:00:36.745154
Model ind 579 epoch 417 head A head_i_epoch 0 batch 200: avg loss -3.365876 avg loss no lamb -3.365876 time 2019-02-01 11:03:34.137674
Pre: time 2019-02-01 11:06:56.568145: 
 	std: 0.0035594548
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 13), (19, 18)]
	test_accs: [0.23955, 0.23955, 0.23086667, 0.24031667, 0.23951666]
	train_accs: [0.23955, 0.23955, 0.23086667, 0.24031667, 0.23951666]
	best_train_sub_head: 3
	worst: 0.23086667
	avg: 0.23796001
	best: 0.24031667

Starting e_i: 418
Model ind 579 epoch 418 head B head_i_epoch 0 batch 0: avg loss -1.606551 avg loss no lamb -1.606551 time 2019-02-01 11:06:59.939322
Model ind 579 epoch 418 head B head_i_epoch 0 batch 100: avg loss -1.693047 avg loss no lamb -1.693047 time 2019-02-01 11:09:55.780715
Model ind 579 epoch 418 head B head_i_epoch 0 batch 200: avg loss -1.661160 avg loss no lamb -1.661160 time 2019-02-01 11:12:52.924003
Model ind 579 epoch 418 head A head_i_epoch 0 batch 0: avg loss -3.240147 avg loss no lamb -3.240147 time 2019-02-01 11:15:50.167959
Model ind 579 epoch 418 head A head_i_epoch 0 batch 100: avg loss -3.316723 avg loss no lamb -3.316723 time 2019-02-01 11:18:47.641340
Model ind 579 epoch 418 head A head_i_epoch 0 batch 200: avg loss -3.342559 avg loss no lamb -3.342559 time 2019-02-01 11:21:45.939651
Pre: time 2019-02-01 11:25:07.158526: 
 	std: 0.0036722985
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 13), (19, 18)]
	test_accs: [0.2409, 0.24023333, 0.23146667, 0.24103333, 0.24028334]
	train_accs: [0.2409, 0.24023333, 0.23146667, 0.24103333, 0.24028334]
	best_train_sub_head: 3
	worst: 0.23146667
	avg: 0.23878333
	best: 0.24103333

Starting e_i: 419
Model ind 579 epoch 419 head B head_i_epoch 0 batch 0: avg loss -1.700305 avg loss no lamb -1.700305 time 2019-02-01 11:25:10.270765
Model ind 579 epoch 419 head B head_i_epoch 0 batch 100: avg loss -1.709728 avg loss no lamb -1.709728 time 2019-02-01 11:28:07.375681
Model ind 579 epoch 419 head B head_i_epoch 0 batch 200: avg loss -1.685365 avg loss no lamb -1.685365 time 2019-02-01 11:31:05.204036
Model ind 579 epoch 419 head A head_i_epoch 0 batch 0: avg loss -3.273824 avg loss no lamb -3.273824 time 2019-02-01 11:34:02.254933
Model ind 579 epoch 419 head A head_i_epoch 0 batch 100: avg loss -3.260979 avg loss no lamb -3.260979 time 2019-02-01 11:36:59.737667
Model ind 579 epoch 419 head A head_i_epoch 0 batch 200: avg loss -3.387077 avg loss no lamb -3.387077 time 2019-02-01 11:39:58.133924
Pre: time 2019-02-01 11:43:20.313628: 
 	std: 0.0049745208
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24215, 0.24521667, 0.23178333, 0.2447, 0.2437]
	train_accs: [0.24215, 0.24521667, 0.23178333, 0.2447, 0.2437]
	best_train_sub_head: 1
	worst: 0.23178333
	avg: 0.24151
	best: 0.24521667

Starting e_i: 420
Model ind 579 epoch 420 head B head_i_epoch 0 batch 0: avg loss -1.726466 avg loss no lamb -1.726466 time 2019-02-01 11:43:23.399878
Model ind 579 epoch 420 head B head_i_epoch 0 batch 100: avg loss -1.633082 avg loss no lamb -1.633082 time 2019-02-01 11:46:19.192290
Model ind 579 epoch 420 head B head_i_epoch 0 batch 200: avg loss -1.605054 avg loss no lamb -1.605054 time 2019-02-01 11:49:16.356340
Model ind 579 epoch 420 head A head_i_epoch 0 batch 0: avg loss -3.267930 avg loss no lamb -3.267930 time 2019-02-01 11:52:11.569550
Model ind 579 epoch 420 head A head_i_epoch 0 batch 100: avg loss -3.270865 avg loss no lamb -3.270865 time 2019-02-01 11:55:09.608892
Model ind 579 epoch 420 head A head_i_epoch 0 batch 200: avg loss -3.326225 avg loss no lamb -3.326225 time 2019-02-01 11:58:07.660199
Pre: time 2019-02-01 12:01:29.223057: 
 	std: 0.004473493
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.23438333, 0.2362, 0.22486667, 0.23745, 0.23486666]
	train_accs: [0.23438333, 0.2362, 0.22486667, 0.23745, 0.23486666]
	best_train_sub_head: 3
	worst: 0.22486667
	avg: 0.23355334
	best: 0.23745

Starting e_i: 421
Model ind 579 epoch 421 head B head_i_epoch 0 batch 0: avg loss -1.794767 avg loss no lamb -1.794767 time 2019-02-01 12:01:38.847355
Model ind 579 epoch 421 head B head_i_epoch 0 batch 100: avg loss -1.704577 avg loss no lamb -1.704577 time 2019-02-01 12:04:35.093366
Model ind 579 epoch 421 head B head_i_epoch 0 batch 200: avg loss -1.726678 avg loss no lamb -1.726678 time 2019-02-01 12:07:30.751323
Model ind 579 epoch 421 head A head_i_epoch 0 batch 0: avg loss -3.289086 avg loss no lamb -3.289086 time 2019-02-01 12:10:26.794947
Model ind 579 epoch 421 head A head_i_epoch 0 batch 100: avg loss -3.315133 avg loss no lamb -3.315133 time 2019-02-01 12:13:24.170804
Model ind 579 epoch 421 head A head_i_epoch 0 batch 200: avg loss -3.300913 avg loss no lamb -3.300913 time 2019-02-01 12:16:22.568996
Pre: time 2019-02-01 12:19:45.101974: 
 	std: 0.005060867
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 16), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 12), (13, 11), (14, 10), (15, 1), (16, 2), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24196666, 0.24301666, 0.23031667, 0.24411666, 0.24221666]
	train_accs: [0.24196666, 0.24301666, 0.23031667, 0.24411666, 0.24221666]
	best_train_sub_head: 3
	worst: 0.23031667
	avg: 0.24032667
	best: 0.24411666

Starting e_i: 422
Model ind 579 epoch 422 head B head_i_epoch 0 batch 0: avg loss -1.721939 avg loss no lamb -1.721939 time 2019-02-01 12:19:48.695046
Model ind 579 epoch 422 head B head_i_epoch 0 batch 100: avg loss -1.732246 avg loss no lamb -1.732246 time 2019-02-01 12:22:45.146291
Model ind 579 epoch 422 head B head_i_epoch 0 batch 200: avg loss -1.757187 avg loss no lamb -1.757187 time 2019-02-01 12:25:42.381330
Model ind 579 epoch 422 head A head_i_epoch 0 batch 0: avg loss -3.254348 avg loss no lamb -3.254348 time 2019-02-01 12:28:38.636764
Model ind 579 epoch 422 head A head_i_epoch 0 batch 100: avg loss -3.340067 avg loss no lamb -3.340067 time 2019-02-01 12:31:35.597340
Model ind 579 epoch 422 head A head_i_epoch 0 batch 200: avg loss -3.327427 avg loss no lamb -3.327427 time 2019-02-01 12:34:34.144264
Pre: time 2019-02-01 12:37:56.019086: 
 	std: 0.0040026167
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 15), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.24156667, 0.24243334, 0.2319, 0.24228333, 0.24101667]
	train_accs: [0.24156667, 0.24243334, 0.2319, 0.24228333, 0.24101667]
	best_train_sub_head: 1
	worst: 0.2319
	avg: 0.23984
	best: 0.24243334

Starting e_i: 423
Model ind 579 epoch 423 head B head_i_epoch 0 batch 0: avg loss -1.692830 avg loss no lamb -1.692830 time 2019-02-01 12:37:59.245063
Model ind 579 epoch 423 head B head_i_epoch 0 batch 100: avg loss -1.604983 avg loss no lamb -1.604983 time 2019-02-01 12:40:58.018680
Model ind 579 epoch 423 head B head_i_epoch 0 batch 200: avg loss -1.743443 avg loss no lamb -1.743443 time 2019-02-01 12:43:55.209990
Model ind 579 epoch 423 head A head_i_epoch 0 batch 0: avg loss -3.310207 avg loss no lamb -3.310207 time 2019-02-01 12:46:51.863987
Model ind 579 epoch 423 head A head_i_epoch 0 batch 100: avg loss -3.355806 avg loss no lamb -3.355806 time 2019-02-01 12:49:49.659159
Model ind 579 epoch 423 head A head_i_epoch 0 batch 200: avg loss -3.331313 avg loss no lamb -3.331313 time 2019-02-01 12:52:47.631750
Pre: time 2019-02-01 12:56:09.168269: 
 	std: 0.004466474
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.23905, 0.2419, 0.22993334, 0.24223334, 0.23925]
	train_accs: [0.23905, 0.2419, 0.22993334, 0.24223334, 0.23925]
	best_train_sub_head: 3
	worst: 0.22993334
	avg: 0.23847333
	best: 0.24223334

Starting e_i: 424
Model ind 579 epoch 424 head B head_i_epoch 0 batch 0: avg loss -1.701339 avg loss no lamb -1.701339 time 2019-02-01 12:56:12.248028
Model ind 579 epoch 424 head B head_i_epoch 0 batch 100: avg loss -1.630242 avg loss no lamb -1.630242 time 2019-02-01 12:59:09.710993
Model ind 579 epoch 424 head B head_i_epoch 0 batch 200: avg loss -1.691951 avg loss no lamb -1.691951 time 2019-02-01 13:02:06.641957
Model ind 579 epoch 424 head A head_i_epoch 0 batch 0: avg loss -3.289950 avg loss no lamb -3.289950 time 2019-02-01 13:05:03.961100
Model ind 579 epoch 424 head A head_i_epoch 0 batch 100: avg loss -3.258595 avg loss no lamb -3.258595 time 2019-02-01 13:08:01.001644
Model ind 579 epoch 424 head A head_i_epoch 0 batch 200: avg loss -3.363602 avg loss no lamb -3.363602 time 2019-02-01 13:10:58.906344
Pre: time 2019-02-01 13:14:20.326115: 
 	std: 0.0045593376
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 16), (3, 5), (4, 4), (5, 3), (6, 18), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 2), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 13), (19, 19)]
	test_accs: [0.24125, 0.24138333, 0.23001666, 0.24151666, 0.2415]
	train_accs: [0.24125, 0.24138333, 0.23001666, 0.24151666, 0.2415]
	best_train_sub_head: 3
	worst: 0.23001666
	avg: 0.23913333
	best: 0.24151666

Starting e_i: 425
Model ind 579 epoch 425 head B head_i_epoch 0 batch 0: avg loss -1.737059 avg loss no lamb -1.737059 time 2019-02-01 13:14:23.420382
Model ind 579 epoch 425 head B head_i_epoch 0 batch 100: avg loss -1.746864 avg loss no lamb -1.746864 time 2019-02-01 13:17:21.898970
Model ind 579 epoch 425 head B head_i_epoch 0 batch 200: avg loss -1.723570 avg loss no lamb -1.723570 time 2019-02-01 13:20:19.123850
Model ind 579 epoch 425 head A head_i_epoch 0 batch 0: avg loss -3.305039 avg loss no lamb -3.305039 time 2019-02-01 13:23:16.936794
Model ind 579 epoch 425 head A head_i_epoch 0 batch 100: avg loss -3.322983 avg loss no lamb -3.322983 time 2019-02-01 13:26:18.169345
Model ind 579 epoch 425 head A head_i_epoch 0 batch 200: avg loss -3.371867 avg loss no lamb -3.371867 time 2019-02-01 13:29:17.158033
Pre: time 2019-02-01 13:32:43.464837: 
 	std: 0.004188031
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.23801666, 0.23955, 0.22833334, 0.23915, 0.23806667]
	train_accs: [0.23801666, 0.23955, 0.22833334, 0.23915, 0.23806667]
	best_train_sub_head: 1
	worst: 0.22833334
	avg: 0.23662333
	best: 0.23955

Starting e_i: 426
Model ind 579 epoch 426 head B head_i_epoch 0 batch 0: avg loss -1.748222 avg loss no lamb -1.748222 time 2019-02-01 13:32:46.672850
Model ind 579 epoch 426 head B head_i_epoch 0 batch 100: avg loss -1.694807 avg loss no lamb -1.694807 time 2019-02-01 13:35:43.992401
Model ind 579 epoch 426 head B head_i_epoch 0 batch 200: avg loss -1.782021 avg loss no lamb -1.782021 time 2019-02-01 13:38:40.431247
Model ind 579 epoch 426 head A head_i_epoch 0 batch 0: avg loss -3.298640 avg loss no lamb -3.298640 time 2019-02-01 13:41:38.025867
Model ind 579 epoch 426 head A head_i_epoch 0 batch 100: avg loss -3.270222 avg loss no lamb -3.270222 time 2019-02-01 13:44:37.689972
Model ind 579 epoch 426 head A head_i_epoch 0 batch 200: avg loss -3.375067 avg loss no lamb -3.375067 time 2019-02-01 13:47:37.167478
Pre: time 2019-02-01 13:51:00.073557: 
 	std: 0.0042075757
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 15), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.24048333, 0.24246667, 0.23103334, 0.24148333, 0.2413]
	train_accs: [0.24048333, 0.24246667, 0.23103334, 0.24148333, 0.2413]
	best_train_sub_head: 1
	worst: 0.23103334
	avg: 0.23935334
	best: 0.24246667

Starting e_i: 427
Model ind 579 epoch 427 head B head_i_epoch 0 batch 0: avg loss -1.742468 avg loss no lamb -1.742468 time 2019-02-01 13:51:03.176765
Model ind 579 epoch 427 head B head_i_epoch 0 batch 100: avg loss -1.672794 avg loss no lamb -1.672794 time 2019-02-01 13:54:00.037268
Model ind 579 epoch 427 head B head_i_epoch 0 batch 200: avg loss -1.733609 avg loss no lamb -1.733609 time 2019-02-01 13:56:56.635199
Model ind 579 epoch 427 head A head_i_epoch 0 batch 0: avg loss -3.281421 avg loss no lamb -3.281421 time 2019-02-01 13:59:53.269108
Model ind 579 epoch 427 head A head_i_epoch 0 batch 100: avg loss -3.241779 avg loss no lamb -3.241779 time 2019-02-01 14:02:52.314328
Model ind 579 epoch 427 head A head_i_epoch 0 batch 200: avg loss -3.323985 avg loss no lamb -3.323985 time 2019-02-01 14:05:50.841616
Pre: time 2019-02-01 14:09:13.907900: 
 	std: 0.0040140343
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 5), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.23886667, 0.23926666, 0.22885, 0.2385, 0.23883334]
	train_accs: [0.23886667, 0.23926666, 0.22885, 0.2385, 0.23883334]
	best_train_sub_head: 1
	worst: 0.22885
	avg: 0.23686333
	best: 0.23926666

Starting e_i: 428
Model ind 579 epoch 428 head B head_i_epoch 0 batch 0: avg loss -1.648359 avg loss no lamb -1.648359 time 2019-02-01 14:09:17.519756
Model ind 579 epoch 428 head B head_i_epoch 0 batch 100: avg loss -1.704176 avg loss no lamb -1.704176 time 2019-02-01 14:12:13.514795
Model ind 579 epoch 428 head B head_i_epoch 0 batch 200: avg loss -1.681639 avg loss no lamb -1.681639 time 2019-02-01 14:15:10.351789
Model ind 579 epoch 428 head A head_i_epoch 0 batch 0: avg loss -3.266788 avg loss no lamb -3.266788 time 2019-02-01 14:18:08.695353
Model ind 579 epoch 428 head A head_i_epoch 0 batch 100: avg loss -3.279373 avg loss no lamb -3.279373 time 2019-02-01 14:21:06.276014
Model ind 579 epoch 428 head A head_i_epoch 0 batch 200: avg loss -3.306855 avg loss no lamb -3.306855 time 2019-02-01 14:24:03.718275
Pre: time 2019-02-01 14:27:27.759863: 
 	std: 0.004324772
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.23935, 0.23873334, 0.2278, 0.23838334, 0.23761667]
	train_accs: [0.23935, 0.23873334, 0.2278, 0.23838334, 0.23761667]
	best_train_sub_head: 0
	worst: 0.2278
	avg: 0.23637667
	best: 0.23935

Starting e_i: 429
Model ind 579 epoch 429 head B head_i_epoch 0 batch 0: avg loss -1.714693 avg loss no lamb -1.714693 time 2019-02-01 14:27:30.931347
Model ind 579 epoch 429 head B head_i_epoch 0 batch 100: avg loss -1.684134 avg loss no lamb -1.684134 time 2019-02-01 14:30:28.627819
Model ind 579 epoch 429 head B head_i_epoch 0 batch 200: avg loss -1.781869 avg loss no lamb -1.781869 time 2019-02-01 14:33:25.228785
Model ind 579 epoch 429 head A head_i_epoch 0 batch 0: avg loss -3.290612 avg loss no lamb -3.290612 time 2019-02-01 14:36:21.764856
Model ind 579 epoch 429 head A head_i_epoch 0 batch 100: avg loss -3.375314 avg loss no lamb -3.375314 time 2019-02-01 14:39:19.136760
Model ind 579 epoch 429 head A head_i_epoch 0 batch 200: avg loss -3.406790 avg loss no lamb -3.406790 time 2019-02-01 14:42:16.101172
Pre: time 2019-02-01 14:45:37.460035: 
 	std: 0.004721071
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.23913333, 0.24051666, 0.2278, 0.23958333, 0.23883334]
	train_accs: [0.23913333, 0.24051666, 0.2278, 0.23958333, 0.23883334]
	best_train_sub_head: 1
	worst: 0.2278
	avg: 0.23717332
	best: 0.24051666

Starting e_i: 430
Model ind 579 epoch 430 head B head_i_epoch 0 batch 0: avg loss -1.644440 avg loss no lamb -1.644440 time 2019-02-01 14:45:40.699160
Model ind 579 epoch 430 head B head_i_epoch 0 batch 100: avg loss -1.653694 avg loss no lamb -1.653694 time 2019-02-01 14:48:36.628727
Model ind 579 epoch 430 head B head_i_epoch 0 batch 200: avg loss -1.719364 avg loss no lamb -1.719364 time 2019-02-01 14:51:32.798872
Model ind 579 epoch 430 head A head_i_epoch 0 batch 0: avg loss -3.346772 avg loss no lamb -3.346772 time 2019-02-01 14:54:28.719853
Model ind 579 epoch 430 head A head_i_epoch 0 batch 100: avg loss -3.341478 avg loss no lamb -3.341478 time 2019-02-01 14:57:27.470508
Model ind 579 epoch 430 head A head_i_epoch 0 batch 200: avg loss -3.406230 avg loss no lamb -3.406230 time 2019-02-01 15:00:25.984461
Pre: time 2019-02-01 15:03:48.443303: 
 	std: 0.005063787
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.24281667, 0.24405, 0.2306, 0.24341667, 0.24246667]
	train_accs: [0.24281667, 0.24405, 0.2306, 0.24341667, 0.24246667]
	best_train_sub_head: 1
	worst: 0.2306
	avg: 0.24067
	best: 0.24405

Starting e_i: 431
Model ind 579 epoch 431 head B head_i_epoch 0 batch 0: avg loss -1.724688 avg loss no lamb -1.724688 time 2019-02-01 15:03:59.434816
Model ind 579 epoch 431 head B head_i_epoch 0 batch 100: avg loss -1.714899 avg loss no lamb -1.714899 time 2019-02-01 15:06:57.045418
Model ind 579 epoch 431 head B head_i_epoch 0 batch 200: avg loss -1.705859 avg loss no lamb -1.705859 time 2019-02-01 15:09:54.844912
Model ind 579 epoch 431 head A head_i_epoch 0 batch 0: avg loss -3.250271 avg loss no lamb -3.250271 time 2019-02-01 15:12:51.925359
Model ind 579 epoch 431 head A head_i_epoch 0 batch 100: avg loss -3.386117 avg loss no lamb -3.386117 time 2019-02-01 15:15:49.931857
Model ind 579 epoch 431 head A head_i_epoch 0 batch 200: avg loss -3.340727 avg loss no lamb -3.340727 time 2019-02-01 15:18:48.066045
Pre: time 2019-02-01 15:22:10.438023: 
 	std: 0.0046017906
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24113333, 0.24153334, 0.2292, 0.23995, 0.23966667]
	train_accs: [0.24113333, 0.24153334, 0.2292, 0.23995, 0.23966667]
	best_train_sub_head: 1
	worst: 0.2292
	avg: 0.23829667
	best: 0.24153334

Starting e_i: 432
Model ind 579 epoch 432 head B head_i_epoch 0 batch 0: avg loss -1.686564 avg loss no lamb -1.686564 time 2019-02-01 15:22:14.172134
Model ind 579 epoch 432 head B head_i_epoch 0 batch 100: avg loss -1.686806 avg loss no lamb -1.686806 time 2019-02-01 15:25:10.687650
Model ind 579 epoch 432 head B head_i_epoch 0 batch 200: avg loss -1.773086 avg loss no lamb -1.773086 time 2019-02-01 15:28:07.438261
Model ind 579 epoch 432 head A head_i_epoch 0 batch 0: avg loss -3.338451 avg loss no lamb -3.338451 time 2019-02-01 15:31:03.929936
Model ind 579 epoch 432 head A head_i_epoch 0 batch 100: avg loss -3.319251 avg loss no lamb -3.319251 time 2019-02-01 15:34:03.380044
Model ind 579 epoch 432 head A head_i_epoch 0 batch 200: avg loss -3.372941 avg loss no lamb -3.372941 time 2019-02-01 15:37:00.250744
Pre: time 2019-02-01 15:40:22.024941: 
 	std: 0.0041071037
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.23965, 0.24081667, 0.22963333, 0.23986667, 0.23873334]
	train_accs: [0.23965, 0.24081667, 0.22963333, 0.23986667, 0.23873334]
	best_train_sub_head: 1
	worst: 0.22963333
	avg: 0.23774
	best: 0.24081667

Starting e_i: 433
Model ind 579 epoch 433 head B head_i_epoch 0 batch 0: avg loss -1.656152 avg loss no lamb -1.656152 time 2019-02-01 15:40:25.103365
Model ind 579 epoch 433 head B head_i_epoch 0 batch 100: avg loss -1.728484 avg loss no lamb -1.728484 time 2019-02-01 15:43:21.908256
Model ind 579 epoch 433 head B head_i_epoch 0 batch 200: avg loss -1.719586 avg loss no lamb -1.719586 time 2019-02-01 15:46:19.547793
Model ind 579 epoch 433 head A head_i_epoch 0 batch 0: avg loss -3.322638 avg loss no lamb -3.322638 time 2019-02-01 15:49:16.301298
Model ind 579 epoch 433 head A head_i_epoch 0 batch 100: avg loss -3.343262 avg loss no lamb -3.343262 time 2019-02-01 15:52:13.593040
Model ind 579 epoch 433 head A head_i_epoch 0 batch 200: avg loss -3.382385 avg loss no lamb -3.382385 time 2019-02-01 15:55:12.628823
Pre: time 2019-02-01 15:58:36.516121: 
 	std: 0.0038343202
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.24001667, 0.24225, 0.23175, 0.2416, 0.24071667]
	train_accs: [0.24001667, 0.24225, 0.23175, 0.2416, 0.24071667]
	best_train_sub_head: 1
	worst: 0.23175
	avg: 0.23926668
	best: 0.24225

Starting e_i: 434
Model ind 579 epoch 434 head B head_i_epoch 0 batch 0: avg loss -1.711453 avg loss no lamb -1.711453 time 2019-02-01 15:58:40.183969
Model ind 579 epoch 434 head B head_i_epoch 0 batch 100: avg loss -1.710099 avg loss no lamb -1.710099 time 2019-02-01 16:01:36.888145
Model ind 579 epoch 434 head B head_i_epoch 0 batch 200: avg loss -1.671428 avg loss no lamb -1.671428 time 2019-02-01 16:04:33.098064
Model ind 579 epoch 434 head A head_i_epoch 0 batch 0: avg loss -3.263731 avg loss no lamb -3.263731 time 2019-02-01 16:07:29.517276
Model ind 579 epoch 434 head A head_i_epoch 0 batch 100: avg loss -3.360844 avg loss no lamb -3.360844 time 2019-02-01 16:10:28.088181
Model ind 579 epoch 434 head A head_i_epoch 0 batch 200: avg loss -3.352494 avg loss no lamb -3.352494 time 2019-02-01 16:13:26.189697
Pre: time 2019-02-01 16:16:48.468450: 
 	std: 0.0047955853
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.24005, 0.24058333, 0.22815, 0.24016666, 0.23966667]
	train_accs: [0.24005, 0.24058333, 0.22815, 0.24016666, 0.23966667]
	best_train_sub_head: 1
	worst: 0.22815
	avg: 0.23772332
	best: 0.24058333

Starting e_i: 435
Model ind 579 epoch 435 head B head_i_epoch 0 batch 0: avg loss -1.665697 avg loss no lamb -1.665697 time 2019-02-01 16:16:51.579909
Model ind 579 epoch 435 head B head_i_epoch 0 batch 100: avg loss -1.706337 avg loss no lamb -1.706337 time 2019-02-01 16:19:48.632869
Model ind 579 epoch 435 head B head_i_epoch 0 batch 200: avg loss -1.750105 avg loss no lamb -1.750105 time 2019-02-01 16:22:46.404352
Model ind 579 epoch 435 head A head_i_epoch 0 batch 0: avg loss -3.270955 avg loss no lamb -3.270955 time 2019-02-01 16:25:43.085647
Model ind 579 epoch 435 head A head_i_epoch 0 batch 100: avg loss -3.307081 avg loss no lamb -3.307081 time 2019-02-01 16:28:40.863000
Model ind 579 epoch 435 head A head_i_epoch 0 batch 200: avg loss -3.316963 avg loss no lamb -3.316963 time 2019-02-01 16:31:39.394388
Pre: time 2019-02-01 16:35:00.614471: 
 	std: 0.004755573
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.24308333, 0.24466667, 0.23221667, 0.24428333, 0.2441]
	train_accs: [0.24308333, 0.24466667, 0.23221667, 0.24428333, 0.2441]
	best_train_sub_head: 1
	worst: 0.23221667
	avg: 0.24166998
	best: 0.24466667

Starting e_i: 436
Model ind 579 epoch 436 head B head_i_epoch 0 batch 0: avg loss -1.745268 avg loss no lamb -1.745268 time 2019-02-01 16:35:04.395522
Model ind 579 epoch 436 head B head_i_epoch 0 batch 100: avg loss -1.623802 avg loss no lamb -1.623802 time 2019-02-01 16:38:01.860978
Model ind 579 epoch 436 head B head_i_epoch 0 batch 200: avg loss -1.739201 avg loss no lamb -1.739201 time 2019-02-01 16:40:59.136302
Model ind 579 epoch 436 head A head_i_epoch 0 batch 0: avg loss -3.304039 avg loss no lamb -3.304039 time 2019-02-01 16:43:55.135183
Model ind 579 epoch 436 head A head_i_epoch 0 batch 100: avg loss -3.360287 avg loss no lamb -3.360287 time 2019-02-01 16:46:55.336211
Model ind 579 epoch 436 head A head_i_epoch 0 batch 200: avg loss -3.376911 avg loss no lamb -3.376911 time 2019-02-01 16:49:53.281352
Pre: time 2019-02-01 16:53:15.372112: 
 	std: 0.003804141
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 16), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 2), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.23965, 0.24071667, 0.23096667, 0.24148333, 0.23921667]
	train_accs: [0.23965, 0.24071667, 0.23096667, 0.24148333, 0.23921667]
	best_train_sub_head: 3
	worst: 0.23096667
	avg: 0.23840666
	best: 0.24148333

Starting e_i: 437
Model ind 579 epoch 437 head B head_i_epoch 0 batch 0: avg loss -1.673895 avg loss no lamb -1.673895 time 2019-02-01 16:53:18.814090
Model ind 579 epoch 437 head B head_i_epoch 0 batch 100: avg loss -1.874610 avg loss no lamb -1.874610 time 2019-02-01 16:56:16.246475
Model ind 579 epoch 437 head B head_i_epoch 0 batch 200: avg loss -1.760900 avg loss no lamb -1.760900 time 2019-02-01 16:59:13.057550
Model ind 579 epoch 437 head A head_i_epoch 0 batch 0: avg loss -3.301140 avg loss no lamb -3.301140 time 2019-02-01 17:02:09.471680
Model ind 579 epoch 437 head A head_i_epoch 0 batch 100: avg loss -3.313721 avg loss no lamb -3.313721 time 2019-02-01 17:05:07.452536
Model ind 579 epoch 437 head A head_i_epoch 0 batch 200: avg loss -3.375942 avg loss no lamb -3.375942 time 2019-02-01 17:08:05.679179
Pre: time 2019-02-01 17:11:27.786297: 
 	std: 0.0045241765
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 16), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 12), (13, 11), (14, 10), (15, 1), (16, 2), (17, 17), (18, 15), (19, 18)]
	test_accs: [0.24143334, 0.24338333, 0.2315, 0.24373333, 0.24183333]
	train_accs: [0.24143334, 0.24338333, 0.2315, 0.24373333, 0.24183333]
	best_train_sub_head: 3
	worst: 0.2315
	avg: 0.24037667
	best: 0.24373333

Starting e_i: 438
Model ind 579 epoch 438 head B head_i_epoch 0 batch 0: avg loss -1.720226 avg loss no lamb -1.720226 time 2019-02-01 17:11:30.838085
Model ind 579 epoch 438 head B head_i_epoch 0 batch 100: avg loss -1.664589 avg loss no lamb -1.664589 time 2019-02-01 17:14:28.200243
Model ind 579 epoch 438 head B head_i_epoch 0 batch 200: avg loss -1.765525 avg loss no lamb -1.765525 time 2019-02-01 17:17:25.025352
Model ind 579 epoch 438 head A head_i_epoch 0 batch 0: avg loss -3.348998 avg loss no lamb -3.348998 time 2019-02-01 17:20:23.376883
Model ind 579 epoch 438 head A head_i_epoch 0 batch 100: avg loss -3.356459 avg loss no lamb -3.356459 time 2019-02-01 17:23:21.220382
Model ind 579 epoch 438 head A head_i_epoch 0 batch 200: avg loss -3.393830 avg loss no lamb -3.393830 time 2019-02-01 17:26:19.407837
Pre: time 2019-02-01 17:29:41.655593: 
 	std: 0.0038177383
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24026667, 0.23986667, 0.23036666, 0.24013333, 0.2392]
	train_accs: [0.24026667, 0.23986667, 0.23036666, 0.24013333, 0.2392]
	best_train_sub_head: 0
	worst: 0.23036666
	avg: 0.23796669
	best: 0.24026667

Starting e_i: 439
Model ind 579 epoch 439 head B head_i_epoch 0 batch 0: avg loss -1.659062 avg loss no lamb -1.659062 time 2019-02-01 17:29:44.901320
Model ind 579 epoch 439 head B head_i_epoch 0 batch 100: avg loss -1.735461 avg loss no lamb -1.735461 time 2019-02-01 17:32:43.092992
Model ind 579 epoch 439 head B head_i_epoch 0 batch 200: avg loss -1.677540 avg loss no lamb -1.677540 time 2019-02-01 17:35:39.580718
Model ind 579 epoch 439 head A head_i_epoch 0 batch 0: avg loss -3.325221 avg loss no lamb -3.325221 time 2019-02-01 17:38:35.329198
Model ind 579 epoch 439 head A head_i_epoch 0 batch 100: avg loss -3.310882 avg loss no lamb -3.310882 time 2019-02-01 17:41:34.672814
Model ind 579 epoch 439 head A head_i_epoch 0 batch 200: avg loss -3.432735 avg loss no lamb -3.432735 time 2019-02-01 17:44:32.319657
Pre: time 2019-02-01 17:47:54.594698: 
 	std: 0.003979721
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 19), (4, 4), (5, 3), (6, 13), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 18)]
	test_accs: [0.24125, 0.2427, 0.2323, 0.243, 0.24146667]
	train_accs: [0.24125, 0.2427, 0.2323, 0.243, 0.24146667]
	best_train_sub_head: 3
	worst: 0.2323
	avg: 0.24014333
	best: 0.243

Starting e_i: 440
Model ind 579 epoch 440 head B head_i_epoch 0 batch 0: avg loss -1.643553 avg loss no lamb -1.643553 time 2019-02-01 17:47:57.761626
Model ind 579 epoch 440 head B head_i_epoch 0 batch 100: avg loss -1.684361 avg loss no lamb -1.684361 time 2019-02-01 17:50:54.044757
Model ind 579 epoch 440 head B head_i_epoch 0 batch 200: avg loss -1.775326 avg loss no lamb -1.775326 time 2019-02-01 17:53:51.762804
Model ind 579 epoch 440 head A head_i_epoch 0 batch 0: avg loss -3.298759 avg loss no lamb -3.298759 time 2019-02-01 17:56:47.794407
Model ind 579 epoch 440 head A head_i_epoch 0 batch 100: avg loss -3.348753 avg loss no lamb -3.348753 time 2019-02-01 17:59:46.333593
Model ind 579 epoch 440 head A head_i_epoch 0 batch 200: avg loss -3.371069 avg loss no lamb -3.371069 time 2019-02-01 18:02:43.532007
Pre: time 2019-02-01 18:06:08.176482: 
 	std: 0.0029506807
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 15), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.23788333, 0.23933333, 0.23143333, 0.23931667, 0.23808333]
	train_accs: [0.23788333, 0.23933333, 0.23143333, 0.23931667, 0.23808333]
	best_train_sub_head: 1
	worst: 0.23143333
	avg: 0.23721
	best: 0.23933333

Starting e_i: 441
Model ind 579 epoch 441 head B head_i_epoch 0 batch 0: avg loss -1.748989 avg loss no lamb -1.748989 time 2019-02-01 18:06:16.304793
Model ind 579 epoch 441 head B head_i_epoch 0 batch 100: avg loss -1.830169 avg loss no lamb -1.830169 time 2019-02-01 18:09:13.486672
Model ind 579 epoch 441 head B head_i_epoch 0 batch 200: avg loss -1.761753 avg loss no lamb -1.761753 time 2019-02-01 18:12:10.528889
Model ind 579 epoch 441 head A head_i_epoch 0 batch 0: avg loss -3.308130 avg loss no lamb -3.308130 time 2019-02-01 18:15:08.533155
Model ind 579 epoch 441 head A head_i_epoch 0 batch 100: avg loss -3.388078 avg loss no lamb -3.388078 time 2019-02-01 18:18:07.542360
Model ind 579 epoch 441 head A head_i_epoch 0 batch 200: avg loss -3.383079 avg loss no lamb -3.383079 time 2019-02-01 18:21:04.415911
Pre: time 2019-02-01 18:24:28.896779: 
 	std: 0.0036167635
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 16), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 2), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 13), (19, 18)]
	test_accs: [0.24205, 0.2425, 0.23316666, 0.24271667, 0.24118334]
	train_accs: [0.24205, 0.2425, 0.23316666, 0.24271667, 0.24118334]
	best_train_sub_head: 3
	worst: 0.23316666
	avg: 0.24032335
	best: 0.24271667

Starting e_i: 442
Model ind 579 epoch 442 head B head_i_epoch 0 batch 0: avg loss -1.739439 avg loss no lamb -1.739439 time 2019-02-01 18:24:32.535191
Model ind 579 epoch 442 head B head_i_epoch 0 batch 100: avg loss -1.744818 avg loss no lamb -1.744818 time 2019-02-01 18:27:29.964139
Model ind 579 epoch 442 head B head_i_epoch 0 batch 200: avg loss -1.698323 avg loss no lamb -1.698323 time 2019-02-01 18:30:25.415177
Model ind 579 epoch 442 head A head_i_epoch 0 batch 0: avg loss -3.343719 avg loss no lamb -3.343719 time 2019-02-01 18:33:21.814870
Model ind 579 epoch 442 head A head_i_epoch 0 batch 100: avg loss -3.329888 avg loss no lamb -3.329888 time 2019-02-01 18:36:18.141388
Model ind 579 epoch 442 head A head_i_epoch 0 batch 200: avg loss -3.373591 avg loss no lamb -3.373591 time 2019-02-01 18:39:16.199779
Pre: time 2019-02-01 18:42:37.471913: 
 	std: 0.0046430724
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.23843333, 0.23998334, 0.2277, 0.23968333, 0.23878333]
	train_accs: [0.23843333, 0.23998334, 0.2277, 0.23968333, 0.23878333]
	best_train_sub_head: 1
	worst: 0.2277
	avg: 0.23691666
	best: 0.23998334

Starting e_i: 443
Model ind 579 epoch 443 head B head_i_epoch 0 batch 0: avg loss -1.694605 avg loss no lamb -1.694605 time 2019-02-01 18:42:40.728726
Model ind 579 epoch 443 head B head_i_epoch 0 batch 100: avg loss -1.789288 avg loss no lamb -1.789288 time 2019-02-01 18:45:38.235679
Model ind 579 epoch 443 head B head_i_epoch 0 batch 200: avg loss -1.719932 avg loss no lamb -1.719932 time 2019-02-01 18:48:34.655788
Model ind 579 epoch 443 head A head_i_epoch 0 batch 0: avg loss -3.322402 avg loss no lamb -3.322402 time 2019-02-01 18:51:30.367935
Model ind 579 epoch 443 head A head_i_epoch 0 batch 100: avg loss -3.280501 avg loss no lamb -3.280501 time 2019-02-01 18:54:28.842626
Model ind 579 epoch 443 head A head_i_epoch 0 batch 200: avg loss -3.362301 avg loss no lamb -3.362301 time 2019-02-01 18:57:25.896864
Pre: time 2019-02-01 19:00:49.983216: 
 	std: 0.003796906
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.24253333, 0.24296667, 0.233, 0.24241666, 0.2419]
	train_accs: [0.24253333, 0.24296667, 0.233, 0.24241666, 0.2419]
	best_train_sub_head: 1
	worst: 0.233
	avg: 0.24056332
	best: 0.24296667

Starting e_i: 444
Model ind 579 epoch 444 head B head_i_epoch 0 batch 0: avg loss -1.642635 avg loss no lamb -1.642635 time 2019-02-01 19:00:53.673550
Model ind 579 epoch 444 head B head_i_epoch 0 batch 100: avg loss -1.762677 avg loss no lamb -1.762677 time 2019-02-01 19:03:51.521616
Model ind 579 epoch 444 head B head_i_epoch 0 batch 200: avg loss -1.707717 avg loss no lamb -1.707717 time 2019-02-01 19:06:48.122337
Model ind 579 epoch 444 head A head_i_epoch 0 batch 0: avg loss -3.315266 avg loss no lamb -3.315266 time 2019-02-01 19:09:46.767792
Model ind 579 epoch 444 head A head_i_epoch 0 batch 100: avg loss -3.334003 avg loss no lamb -3.334003 time 2019-02-01 19:12:45.319355
Model ind 579 epoch 444 head A head_i_epoch 0 batch 200: avg loss -3.357189 avg loss no lamb -3.357189 time 2019-02-01 19:15:43.666973
Pre: time 2019-02-01 19:19:05.099895: 
 	std: 0.0040076943
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 16), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 12), (13, 11), (14, 10), (15, 1), (16, 2), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24208333, 0.24225, 0.23243333, 0.24296667, 0.2424]
	train_accs: [0.24208333, 0.24225, 0.23243333, 0.24296667, 0.2424]
	best_train_sub_head: 3
	worst: 0.23243333
	avg: 0.24042666
	best: 0.24296667

Starting e_i: 445
Model ind 579 epoch 445 head B head_i_epoch 0 batch 0: avg loss -1.727961 avg loss no lamb -1.727961 time 2019-02-01 19:19:08.297852
Model ind 579 epoch 445 head B head_i_epoch 0 batch 100: avg loss -1.717695 avg loss no lamb -1.717695 time 2019-02-01 19:22:04.140192
Model ind 579 epoch 445 head B head_i_epoch 0 batch 200: avg loss -1.686542 avg loss no lamb -1.686542 time 2019-02-01 19:25:02.369439
Model ind 579 epoch 445 head A head_i_epoch 0 batch 0: avg loss -3.276541 avg loss no lamb -3.276541 time 2019-02-01 19:27:59.105885
Model ind 579 epoch 445 head A head_i_epoch 0 batch 100: avg loss -3.328647 avg loss no lamb -3.328647 time 2019-02-01 19:30:56.590141
Model ind 579 epoch 445 head A head_i_epoch 0 batch 200: avg loss -3.385792 avg loss no lamb -3.385792 time 2019-02-01 19:33:56.411328
Pre: time 2019-02-01 19:37:18.502261: 
 	std: 0.0038731077
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 16), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 2), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2419, 0.24185, 0.23236667, 0.24271667, 0.24153334]
	train_accs: [0.2419, 0.24185, 0.23236667, 0.24271667, 0.24153334]
	best_train_sub_head: 3
	worst: 0.23236667
	avg: 0.24007335
	best: 0.24271667

Starting e_i: 446
Model ind 579 epoch 446 head B head_i_epoch 0 batch 0: avg loss -1.784703 avg loss no lamb -1.784703 time 2019-02-01 19:37:22.137531
Model ind 579 epoch 446 head B head_i_epoch 0 batch 100: avg loss -1.792466 avg loss no lamb -1.792466 time 2019-02-01 19:40:21.276938
Model ind 579 epoch 446 head B head_i_epoch 0 batch 200: avg loss -1.662145 avg loss no lamb -1.662145 time 2019-02-01 19:43:18.149825
Model ind 579 epoch 446 head A head_i_epoch 0 batch 0: avg loss -3.284290 avg loss no lamb -3.284290 time 2019-02-01 19:46:15.038849
Model ind 579 epoch 446 head A head_i_epoch 0 batch 100: avg loss -3.389944 avg loss no lamb -3.389944 time 2019-02-01 19:49:12.886812
Model ind 579 epoch 446 head A head_i_epoch 0 batch 200: avg loss -3.358702 avg loss no lamb -3.358702 time 2019-02-01 19:52:10.323233
Pre: time 2019-02-01 19:55:32.373232: 
 	std: 0.0044787247
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 12), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 2), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24223334, 0.24385, 0.232, 0.24341667, 0.24296667]
	train_accs: [0.24223334, 0.24385, 0.232, 0.24341667, 0.24296667]
	best_train_sub_head: 1
	worst: 0.232
	avg: 0.24089333
	best: 0.24385

Starting e_i: 447
Model ind 579 epoch 447 head B head_i_epoch 0 batch 0: avg loss -1.700649 avg loss no lamb -1.700649 time 2019-02-01 19:55:35.502423
Model ind 579 epoch 447 head B head_i_epoch 0 batch 100: avg loss -1.735687 avg loss no lamb -1.735687 time 2019-02-01 19:58:33.688151
Model ind 579 epoch 447 head B head_i_epoch 0 batch 200: avg loss -1.751333 avg loss no lamb -1.751333 time 2019-02-01 20:01:30.265838
Model ind 579 epoch 447 head A head_i_epoch 0 batch 0: avg loss -3.353203 avg loss no lamb -3.353203 time 2019-02-01 20:04:28.032610
Model ind 579 epoch 447 head A head_i_epoch 0 batch 100: avg loss -3.316338 avg loss no lamb -3.316338 time 2019-02-01 20:07:27.969618
Model ind 579 epoch 447 head A head_i_epoch 0 batch 200: avg loss -3.345819 avg loss no lamb -3.345819 time 2019-02-01 20:10:26.620326
Pre: time 2019-02-01 20:13:48.108779: 
 	std: 0.003976787
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 0), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 2), (10, 8), (11, 17), (12, 18), (13, 1), (14, 5), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2403, 0.24088334, 0.23036666, 0.24013333, 0.23975]
	train_accs: [0.2403, 0.24088334, 0.23036666, 0.24013333, 0.23975]
	best_train_sub_head: 1
	worst: 0.23036666
	avg: 0.23828666
	best: 0.24088334

Starting e_i: 448
Model ind 579 epoch 448 head B head_i_epoch 0 batch 0: avg loss -1.673231 avg loss no lamb -1.673231 time 2019-02-01 20:13:51.751866
Model ind 579 epoch 448 head B head_i_epoch 0 batch 100: avg loss -1.744439 avg loss no lamb -1.744439 time 2019-02-01 20:16:48.918132
Model ind 579 epoch 448 head B head_i_epoch 0 batch 200: avg loss -1.779288 avg loss no lamb -1.779288 time 2019-02-01 20:19:46.217227
Model ind 579 epoch 448 head A head_i_epoch 0 batch 0: avg loss -3.250773 avg loss no lamb -3.250773 time 2019-02-01 20:22:43.495013
Model ind 579 epoch 448 head A head_i_epoch 0 batch 100: avg loss -3.342594 avg loss no lamb -3.342594 time 2019-02-01 20:25:41.698350
Model ind 579 epoch 448 head A head_i_epoch 0 batch 200: avg loss -3.363468 avg loss no lamb -3.363468 time 2019-02-01 20:28:39.883137
Pre: time 2019-02-01 20:32:02.000820: 
 	std: 0.0042959293
	best_train_sub_head_match: [(0, 5), (1, 2), (2, 14), (3, 0), (4, 12), (5, 4), (6, 8), (7, 6), (8, 15), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 13), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24051666, 0.24016666, 0.22926667, 0.23958333, 0.23961666]
	train_accs: [0.24051666, 0.24016666, 0.22926667, 0.23958333, 0.23961666]
	best_train_sub_head: 0
	worst: 0.22926667
	avg: 0.23783
	best: 0.24051666

Starting e_i: 449
Model ind 579 epoch 449 head B head_i_epoch 0 batch 0: avg loss -1.755431 avg loss no lamb -1.755431 time 2019-02-01 20:32:05.236415
Model ind 579 epoch 449 head B head_i_epoch 0 batch 100: avg loss -1.707044 avg loss no lamb -1.707044 time 2019-02-01 20:35:04.249544
Model ind 579 epoch 449 head B head_i_epoch 0 batch 200: avg loss -1.709692 avg loss no lamb -1.709692 time 2019-02-01 20:38:01.994081
Model ind 579 epoch 449 head A head_i_epoch 0 batch 0: avg loss -3.388243 avg loss no lamb -3.388243 time 2019-02-01 20:41:00.141005
Model ind 579 epoch 449 head A head_i_epoch 0 batch 100: avg loss -3.353860 avg loss no lamb -3.353860 time 2019-02-01 20:43:58.507393
Model ind 579 epoch 449 head A head_i_epoch 0 batch 200: avg loss -3.364093 avg loss no lamb -3.364093 time 2019-02-01 20:46:56.573693
Pre: time 2019-02-01 20:50:21.682373: 
 	std: 0.0045919623
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24178334, 0.24438334, 0.23233333, 0.2444, 0.24368334]
	train_accs: [0.24178334, 0.24438334, 0.23233333, 0.2444, 0.24368334]
	best_train_sub_head: 3
	worst: 0.23233333
	avg: 0.24131668
	best: 0.2444

Starting e_i: 450
Model ind 579 epoch 450 head B head_i_epoch 0 batch 0: avg loss -1.818396 avg loss no lamb -1.818396 time 2019-02-01 20:50:25.458709
Model ind 579 epoch 450 head B head_i_epoch 0 batch 100: avg loss -1.766783 avg loss no lamb -1.766783 time 2019-02-01 20:53:23.008487
Model ind 579 epoch 450 head B head_i_epoch 0 batch 200: avg loss -1.783294 avg loss no lamb -1.783294 time 2019-02-01 20:56:20.099780
Model ind 579 epoch 450 head A head_i_epoch 0 batch 0: avg loss -3.308924 avg loss no lamb -3.308924 time 2019-02-01 20:59:17.082416
Model ind 579 epoch 450 head A head_i_epoch 0 batch 100: avg loss -3.367148 avg loss no lamb -3.367148 time 2019-02-01 21:02:16.311801
Model ind 579 epoch 450 head A head_i_epoch 0 batch 200: avg loss -3.341322 avg loss no lamb -3.341322 time 2019-02-01 21:05:14.109264
Pre: time 2019-02-01 21:08:35.395414: 
 	std: 0.0033607632
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.23735, 0.23935, 0.23016667, 0.23896667, 0.2378]
	train_accs: [0.23735, 0.23935, 0.23016667, 0.23896667, 0.2378]
	best_train_sub_head: 1
	worst: 0.23016667
	avg: 0.23672667
	best: 0.23935

Starting e_i: 451
Model ind 579 epoch 451 head B head_i_epoch 0 batch 0: avg loss -1.665591 avg loss no lamb -1.665591 time 2019-02-01 21:08:45.404343
Model ind 579 epoch 451 head B head_i_epoch 0 batch 100: avg loss -1.655442 avg loss no lamb -1.655442 time 2019-02-01 21:11:43.228573
Model ind 579 epoch 451 head B head_i_epoch 0 batch 200: avg loss -1.753157 avg loss no lamb -1.753157 time 2019-02-01 21:14:38.766512
Model ind 579 epoch 451 head A head_i_epoch 0 batch 0: avg loss -3.256425 avg loss no lamb -3.256425 time 2019-02-01 21:17:36.924405
Model ind 579 epoch 451 head A head_i_epoch 0 batch 100: avg loss -3.305499 avg loss no lamb -3.305499 time 2019-02-01 21:20:34.635709
Model ind 579 epoch 451 head A head_i_epoch 0 batch 200: avg loss -3.385258 avg loss no lamb -3.385258 time 2019-02-01 21:23:33.475591
Pre: time 2019-02-01 21:26:58.089211: 
 	std: 0.0032647834
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.24068333, 0.2418, 0.23315, 0.24108334, 0.24146667]
	train_accs: [0.24068333, 0.2418, 0.23315, 0.24108334, 0.24146667]
	best_train_sub_head: 1
	worst: 0.23315
	avg: 0.23963666
	best: 0.2418

Starting e_i: 452
Model ind 579 epoch 452 head B head_i_epoch 0 batch 0: avg loss -1.708063 avg loss no lamb -1.708063 time 2019-02-01 21:27:01.899659
Model ind 579 epoch 452 head B head_i_epoch 0 batch 100: avg loss -1.692690 avg loss no lamb -1.692690 time 2019-02-01 21:29:57.855644
Model ind 579 epoch 452 head B head_i_epoch 0 batch 200: avg loss -1.761785 avg loss no lamb -1.761785 time 2019-02-01 21:32:54.318612
Model ind 579 epoch 452 head A head_i_epoch 0 batch 0: avg loss -3.318455 avg loss no lamb -3.318455 time 2019-02-01 21:35:51.273381
Model ind 579 epoch 452 head A head_i_epoch 0 batch 100: avg loss -3.350764 avg loss no lamb -3.350764 time 2019-02-01 21:38:49.146657
Model ind 579 epoch 452 head A head_i_epoch 0 batch 200: avg loss -3.360752 avg loss no lamb -3.360752 time 2019-02-01 21:41:46.382538
Pre: time 2019-02-01 21:45:08.456723: 
 	std: 0.003435005
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 12), (10, 15), (11, 17), (12, 5), (13, 1), (14, 2), (15, 8), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.24166666, 0.24186666, 0.23285, 0.24105, 0.241]
	train_accs: [0.24166666, 0.24186666, 0.23285, 0.24105, 0.241]
	best_train_sub_head: 1
	worst: 0.23285
	avg: 0.23968668
	best: 0.24186666

Starting e_i: 453
Model ind 579 epoch 453 head B head_i_epoch 0 batch 0: avg loss -1.715938 avg loss no lamb -1.715938 time 2019-02-01 21:45:11.858759
Model ind 579 epoch 453 head B head_i_epoch 0 batch 100: avg loss -1.784449 avg loss no lamb -1.784449 time 2019-02-01 21:48:08.843321
Model ind 579 epoch 453 head B head_i_epoch 0 batch 200: avg loss -1.728309 avg loss no lamb -1.728309 time 2019-02-01 21:51:04.266839
Model ind 579 epoch 453 head A head_i_epoch 0 batch 0: avg loss -3.297862 avg loss no lamb -3.297862 time 2019-02-01 21:54:01.088946
Model ind 579 epoch 453 head A head_i_epoch 0 batch 100: avg loss -3.384148 avg loss no lamb -3.384148 time 2019-02-01 21:56:58.851544
Model ind 579 epoch 453 head A head_i_epoch 0 batch 200: avg loss -3.375649 avg loss no lamb -3.375649 time 2019-02-01 21:59:56.397620
Pre: time 2019-02-01 22:03:18.706140: 
 	std: 0.0037657463
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.24386667, 0.24498333, 0.23493333, 0.24453333, 0.24373333]
	train_accs: [0.24386667, 0.24498333, 0.23493333, 0.24453333, 0.24373333]
	best_train_sub_head: 1
	worst: 0.23493333
	avg: 0.24240999
	best: 0.24498333

Starting e_i: 454
Model ind 579 epoch 454 head B head_i_epoch 0 batch 0: avg loss -1.628366 avg loss no lamb -1.628366 time 2019-02-01 22:03:25.538183
Model ind 579 epoch 454 head B head_i_epoch 0 batch 100: avg loss -1.739766 avg loss no lamb -1.739766 time 2019-02-01 22:06:21.677240
Model ind 579 epoch 454 head B head_i_epoch 0 batch 200: avg loss -1.751922 avg loss no lamb -1.751922 time 2019-02-01 22:09:17.656077
Model ind 579 epoch 454 head A head_i_epoch 0 batch 0: avg loss -3.325400 avg loss no lamb -3.325400 time 2019-02-01 22:12:14.007560
Model ind 579 epoch 454 head A head_i_epoch 0 batch 100: avg loss -3.352796 avg loss no lamb -3.352796 time 2019-02-01 22:15:11.452585
Model ind 579 epoch 454 head A head_i_epoch 0 batch 200: avg loss -3.351515 avg loss no lamb -3.351515 time 2019-02-01 22:18:07.912520
Pre: time 2019-02-01 22:21:30.687955: 
 	std: 0.004881012
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2434, 0.2434, 0.2311, 0.24366666, 0.24261667]
	train_accs: [0.2434, 0.2434, 0.2311, 0.24366666, 0.24261667]
	best_train_sub_head: 3
	worst: 0.2311
	avg: 0.24083667
	best: 0.24366666

Starting e_i: 455
Model ind 579 epoch 455 head B head_i_epoch 0 batch 0: avg loss -1.703171 avg loss no lamb -1.703171 time 2019-02-01 22:21:34.432114
Model ind 579 epoch 455 head B head_i_epoch 0 batch 100: avg loss -1.725113 avg loss no lamb -1.725113 time 2019-02-01 22:24:30.881170
Model ind 579 epoch 455 head B head_i_epoch 0 batch 200: avg loss -1.708742 avg loss no lamb -1.708742 time 2019-02-01 22:27:28.471887
Model ind 579 epoch 455 head A head_i_epoch 0 batch 0: avg loss -3.304112 avg loss no lamb -3.304112 time 2019-02-01 22:30:24.863521
Model ind 579 epoch 455 head A head_i_epoch 0 batch 100: avg loss -3.328733 avg loss no lamb -3.328733 time 2019-02-01 22:33:21.863354
Model ind 579 epoch 455 head A head_i_epoch 0 batch 200: avg loss -3.319563 avg loss no lamb -3.319563 time 2019-02-01 22:36:18.828027
Pre: time 2019-02-01 22:39:41.645322: 
 	std: 0.0038141913
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 16), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 2), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2373, 0.23716667, 0.2277, 0.23785, 0.2363]
	train_accs: [0.2373, 0.23716667, 0.2277, 0.23785, 0.2363]
	best_train_sub_head: 3
	worst: 0.2277
	avg: 0.23526335
	best: 0.23785

Starting e_i: 456
Model ind 579 epoch 456 head B head_i_epoch 0 batch 0: avg loss -1.685152 avg loss no lamb -1.685152 time 2019-02-01 22:39:44.939065
Model ind 579 epoch 456 head B head_i_epoch 0 batch 100: avg loss -1.719734 avg loss no lamb -1.719734 time 2019-02-01 22:42:43.714214
Model ind 579 epoch 456 head B head_i_epoch 0 batch 200: avg loss -1.776742 avg loss no lamb -1.776742 time 2019-02-01 22:45:41.164290
Model ind 579 epoch 456 head A head_i_epoch 0 batch 0: avg loss -3.328273 avg loss no lamb -3.328273 time 2019-02-01 22:48:38.735855
Model ind 579 epoch 456 head A head_i_epoch 0 batch 100: avg loss -3.316943 avg loss no lamb -3.316943 time 2019-02-01 22:51:37.647919
Model ind 579 epoch 456 head A head_i_epoch 0 batch 200: avg loss -3.330034 avg loss no lamb -3.330034 time 2019-02-01 22:54:35.630760
Pre: time 2019-02-01 22:57:59.850296: 
 	std: 0.0037594123
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 1), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 14), (16, 12), (17, 17), (18, 15), (19, 18)]
	test_accs: [0.23685, 0.23661667, 0.22751667, 0.23766667, 0.23623334]
	train_accs: [0.23685, 0.23661667, 0.22751667, 0.23766667, 0.23623334]
	best_train_sub_head: 3
	worst: 0.22751667
	avg: 0.23497668
	best: 0.23766667

Starting e_i: 457
Model ind 579 epoch 457 head B head_i_epoch 0 batch 0: avg loss -1.679981 avg loss no lamb -1.679981 time 2019-02-01 22:58:03.603026
Model ind 579 epoch 457 head B head_i_epoch 0 batch 100: avg loss -1.769331 avg loss no lamb -1.769331 time 2019-02-01 23:01:01.464362
Model ind 579 epoch 457 head B head_i_epoch 0 batch 200: avg loss -1.744751 avg loss no lamb -1.744751 time 2019-02-01 23:04:00.497404
Model ind 579 epoch 457 head A head_i_epoch 0 batch 0: avg loss -3.306490 avg loss no lamb -3.306490 time 2019-02-01 23:06:57.280965
Model ind 579 epoch 457 head A head_i_epoch 0 batch 100: avg loss -3.345491 avg loss no lamb -3.345491 time 2019-02-01 23:09:56.424231
Model ind 579 epoch 457 head A head_i_epoch 0 batch 200: avg loss -3.313040 avg loss no lamb -3.313040 time 2019-02-01 23:12:54.498303
Pre: time 2019-02-01 23:16:17.818654: 
 	std: 0.0037549739
	best_train_sub_head_match: [(0, 5), (1, 1), (2, 14), (3, 0), (4, 12), (5, 4), (6, 8), (7, 6), (8, 13), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 16), (19, 11)]
	test_accs: [0.24226667, 0.24116667, 0.2322, 0.2417, 0.24093333]
	train_accs: [0.24226667, 0.24116667, 0.2322, 0.2417, 0.24093333]
	best_train_sub_head: 0
	worst: 0.2322
	avg: 0.23965332
	best: 0.24226667

Starting e_i: 458
Model ind 579 epoch 458 head B head_i_epoch 0 batch 0: avg loss -1.666501 avg loss no lamb -1.666501 time 2019-02-01 23:16:21.168258
Model ind 579 epoch 458 head B head_i_epoch 0 batch 100: avg loss -1.708824 avg loss no lamb -1.708824 time 2019-02-01 23:19:16.689811
Model ind 579 epoch 458 head B head_i_epoch 0 batch 200: avg loss -1.747633 avg loss no lamb -1.747633 time 2019-02-01 23:22:15.096291
Model ind 579 epoch 458 head A head_i_epoch 0 batch 0: avg loss -3.317469 avg loss no lamb -3.317469 time 2019-02-01 23:25:12.714614
Model ind 579 epoch 458 head A head_i_epoch 0 batch 100: avg loss -3.372398 avg loss no lamb -3.372398 time 2019-02-01 23:28:11.143331
Model ind 579 epoch 458 head A head_i_epoch 0 batch 200: avg loss -3.397705 avg loss no lamb -3.397705 time 2019-02-01 23:31:07.698663
Pre: time 2019-02-01 23:34:30.907615: 
 	std: 0.003220532
	best_train_sub_head_match: [(0, 9), (1, 16), (2, 5), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 2), (10, 8), (11, 17), (12, 13), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.24271667, 0.24343333, 0.23496667, 0.2433, 0.2424]
	train_accs: [0.24271667, 0.24343333, 0.23496667, 0.2433, 0.2424]
	best_train_sub_head: 1
	worst: 0.23496667
	avg: 0.24136333
	best: 0.24343333

Starting e_i: 459
Model ind 579 epoch 459 head B head_i_epoch 0 batch 0: avg loss -1.760669 avg loss no lamb -1.760669 time 2019-02-01 23:34:34.232272
Model ind 579 epoch 459 head B head_i_epoch 0 batch 100: avg loss -1.755253 avg loss no lamb -1.755253 time 2019-02-01 23:37:32.089522
Model ind 579 epoch 459 head B head_i_epoch 0 batch 200: avg loss -1.665856 avg loss no lamb -1.665856 time 2019-02-01 23:40:29.068972
Model ind 579 epoch 459 head A head_i_epoch 0 batch 0: avg loss -3.373801 avg loss no lamb -3.373801 time 2019-02-01 23:43:24.765744
Model ind 579 epoch 459 head A head_i_epoch 0 batch 100: avg loss -3.389566 avg loss no lamb -3.389566 time 2019-02-01 23:46:21.309553
Model ind 579 epoch 459 head A head_i_epoch 0 batch 200: avg loss -3.386951 avg loss no lamb -3.386951 time 2019-02-01 23:49:17.329170
Pre: time 2019-02-01 23:52:40.778224: 
 	std: 0.004452398
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 16), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 12), (13, 11), (14, 10), (15, 1), (16, 2), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2439, 0.24403334, 0.23306666, 0.2449, 0.24378334]
	train_accs: [0.2439, 0.24403334, 0.23306666, 0.2449, 0.24378334]
	best_train_sub_head: 3
	worst: 0.23306666
	avg: 0.24193665
	best: 0.2449

Starting e_i: 460
Model ind 579 epoch 460 head B head_i_epoch 0 batch 0: avg loss -1.772444 avg loss no lamb -1.772444 time 2019-02-01 23:52:44.146230
Model ind 579 epoch 460 head B head_i_epoch 0 batch 100: avg loss -1.651603 avg loss no lamb -1.651603 time 2019-02-01 23:55:39.510019
Model ind 579 epoch 460 head B head_i_epoch 0 batch 200: avg loss -1.792033 avg loss no lamb -1.792033 time 2019-02-01 23:58:37.150330
Model ind 579 epoch 460 head A head_i_epoch 0 batch 0: avg loss -3.344864 avg loss no lamb -3.344864 time 2019-02-02 00:01:33.946916
Model ind 579 epoch 460 head A head_i_epoch 0 batch 100: avg loss -3.370235 avg loss no lamb -3.370235 time 2019-02-02 00:04:33.018980
Model ind 579 epoch 460 head A head_i_epoch 0 batch 200: avg loss -3.312263 avg loss no lamb -3.312263 time 2019-02-02 00:07:32.774281
Pre: time 2019-02-02 00:10:56.698496: 
 	std: 0.0049105855
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24108334, 0.24361667, 0.2304, 0.24291667, 0.24238333]
	train_accs: [0.24108334, 0.24361667, 0.2304, 0.24291667, 0.24238333]
	best_train_sub_head: 1
	worst: 0.2304
	avg: 0.24008003
	best: 0.24361667

Starting e_i: 461
Model ind 579 epoch 461 head B head_i_epoch 0 batch 0: avg loss -1.705483 avg loss no lamb -1.705483 time 2019-02-02 00:11:04.691822
Model ind 579 epoch 461 head B head_i_epoch 0 batch 100: avg loss -1.684808 avg loss no lamb -1.684808 time 2019-02-02 00:14:01.223819
Model ind 579 epoch 461 head B head_i_epoch 0 batch 200: avg loss -1.703032 avg loss no lamb -1.703032 time 2019-02-02 00:16:59.108068
Model ind 579 epoch 461 head A head_i_epoch 0 batch 0: avg loss -3.293459 avg loss no lamb -3.293459 time 2019-02-02 00:19:55.669911
Model ind 579 epoch 461 head A head_i_epoch 0 batch 100: avg loss -3.346533 avg loss no lamb -3.346533 time 2019-02-02 00:22:53.320182
Model ind 579 epoch 461 head A head_i_epoch 0 batch 200: avg loss -3.301986 avg loss no lamb -3.301986 time 2019-02-02 00:25:52.040896
Pre: time 2019-02-02 00:29:16.209118: 
 	std: 0.003932847
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 16), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 2), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24223334, 0.24216667, 0.23251666, 0.24293333, 0.24191667]
	train_accs: [0.24223334, 0.24216667, 0.23251666, 0.24293333, 0.24191667]
	best_train_sub_head: 3
	worst: 0.23251666
	avg: 0.24035335
	best: 0.24293333

Starting e_i: 462
Model ind 579 epoch 462 head B head_i_epoch 0 batch 0: avg loss -1.746816 avg loss no lamb -1.746816 time 2019-02-02 00:29:19.763254
Model ind 579 epoch 462 head B head_i_epoch 0 batch 100: avg loss -1.780975 avg loss no lamb -1.780975 time 2019-02-02 00:32:18.620696
Model ind 579 epoch 462 head B head_i_epoch 0 batch 200: avg loss -1.726871 avg loss no lamb -1.726871 time 2019-02-02 00:35:17.506679
Model ind 579 epoch 462 head A head_i_epoch 0 batch 0: avg loss -3.347203 avg loss no lamb -3.347203 time 2019-02-02 00:38:15.138409
Model ind 579 epoch 462 head A head_i_epoch 0 batch 100: avg loss -3.322995 avg loss no lamb -3.322995 time 2019-02-02 00:41:12.342991
Model ind 579 epoch 462 head A head_i_epoch 0 batch 200: avg loss -3.355055 avg loss no lamb -3.355055 time 2019-02-02 00:44:11.437746
Pre: time 2019-02-02 00:47:33.362508: 
 	std: 0.0044594067
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.23885, 0.24005, 0.22843333, 0.23996666, 0.23923333]
	train_accs: [0.23885, 0.24005, 0.22843333, 0.23996666, 0.23923333]
	best_train_sub_head: 1
	worst: 0.22843333
	avg: 0.23730667
	best: 0.24005

Starting e_i: 463
Model ind 579 epoch 463 head B head_i_epoch 0 batch 0: avg loss -1.694804 avg loss no lamb -1.694804 time 2019-02-02 00:47:37.187256
Model ind 579 epoch 463 head B head_i_epoch 0 batch 100: avg loss -1.783335 avg loss no lamb -1.783335 time 2019-02-02 00:50:33.073036
Model ind 579 epoch 463 head B head_i_epoch 0 batch 200: avg loss -1.716088 avg loss no lamb -1.716088 time 2019-02-02 00:53:29.077026
Model ind 579 epoch 463 head A head_i_epoch 0 batch 0: avg loss -3.286769 avg loss no lamb -3.286769 time 2019-02-02 00:56:26.893772
Model ind 579 epoch 463 head A head_i_epoch 0 batch 100: avg loss -3.354693 avg loss no lamb -3.354693 time 2019-02-02 00:59:25.154387
Model ind 579 epoch 463 head A head_i_epoch 0 batch 200: avg loss -3.329856 avg loss no lamb -3.329856 time 2019-02-02 01:02:23.485758
Pre: time 2019-02-02 01:05:45.483512: 
 	std: 0.0046212696
	best_train_sub_head_match: [(0, 13), (1, 15), (2, 16), (3, 5), (4, 4), (5, 3), (6, 18), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 2), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24386667, 0.24353333, 0.23225, 0.24455, 0.24298333]
	train_accs: [0.24386667, 0.24353333, 0.23225, 0.24455, 0.24298333]
	best_train_sub_head: 3
	worst: 0.23225
	avg: 0.24143668
	best: 0.24455

Starting e_i: 464
Model ind 579 epoch 464 head B head_i_epoch 0 batch 0: avg loss -1.694039 avg loss no lamb -1.694039 time 2019-02-02 01:05:48.853803
Model ind 579 epoch 464 head B head_i_epoch 0 batch 100: avg loss -1.820246 avg loss no lamb -1.820246 time 2019-02-02 01:08:44.690377
Model ind 579 epoch 464 head B head_i_epoch 0 batch 200: avg loss -1.776289 avg loss no lamb -1.776289 time 2019-02-02 01:11:40.738240
Model ind 579 epoch 464 head A head_i_epoch 0 batch 0: avg loss -3.334356 avg loss no lamb -3.334356 time 2019-02-02 01:14:37.677807
Model ind 579 epoch 464 head A head_i_epoch 0 batch 100: avg loss -3.371443 avg loss no lamb -3.371443 time 2019-02-02 01:17:34.538161
Model ind 579 epoch 464 head A head_i_epoch 0 batch 200: avg loss -3.349704 avg loss no lamb -3.349704 time 2019-02-02 01:20:33.238759
Pre: time 2019-02-02 01:23:55.402066: 
 	std: 0.0044470136
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24031667, 0.2414, 0.2302, 0.24191667, 0.24133334]
	train_accs: [0.24031667, 0.2414, 0.2302, 0.24191667, 0.24133334]
	best_train_sub_head: 3
	worst: 0.2302
	avg: 0.23903334
	best: 0.24191667

Starting e_i: 465
Model ind 579 epoch 465 head B head_i_epoch 0 batch 0: avg loss -1.766040 avg loss no lamb -1.766040 time 2019-02-02 01:23:58.706558
Model ind 579 epoch 465 head B head_i_epoch 0 batch 100: avg loss -1.775046 avg loss no lamb -1.775046 time 2019-02-02 01:26:55.244402
Model ind 579 epoch 465 head B head_i_epoch 0 batch 200: avg loss -1.697200 avg loss no lamb -1.697200 time 2019-02-02 01:29:51.353357
Model ind 579 epoch 465 head A head_i_epoch 0 batch 0: avg loss -3.334927 avg loss no lamb -3.334927 time 2019-02-02 01:32:47.828130
Model ind 579 epoch 465 head A head_i_epoch 0 batch 100: avg loss -3.363347 avg loss no lamb -3.363347 time 2019-02-02 01:35:46.085645
Model ind 579 epoch 465 head A head_i_epoch 0 batch 200: avg loss -3.383166 avg loss no lamb -3.383166 time 2019-02-02 01:38:42.772937
Pre: time 2019-02-02 01:42:05.052662: 
 	std: 0.004409263
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.23895, 0.24058333, 0.22918333, 0.24038333, 0.2405]
	train_accs: [0.23895, 0.24058333, 0.22918333, 0.24038333, 0.2405]
	best_train_sub_head: 1
	worst: 0.22918333
	avg: 0.23792
	best: 0.24058333

Starting e_i: 466
Model ind 579 epoch 466 head B head_i_epoch 0 batch 0: avg loss -1.687454 avg loss no lamb -1.687454 time 2019-02-02 01:42:08.183842
Model ind 579 epoch 466 head B head_i_epoch 0 batch 100: avg loss -1.802662 avg loss no lamb -1.802662 time 2019-02-02 01:45:04.222273
Model ind 579 epoch 466 head B head_i_epoch 0 batch 200: avg loss -1.697827 avg loss no lamb -1.697827 time 2019-02-02 01:48:01.013219
Model ind 579 epoch 466 head A head_i_epoch 0 batch 0: avg loss -3.294370 avg loss no lamb -3.294370 time 2019-02-02 01:50:57.183160
Model ind 579 epoch 466 head A head_i_epoch 0 batch 100: avg loss -3.355579 avg loss no lamb -3.355579 time 2019-02-02 01:53:54.508698
Model ind 579 epoch 466 head A head_i_epoch 0 batch 200: avg loss -3.248152 avg loss no lamb -3.248152 time 2019-02-02 01:56:52.023738
Pre: time 2019-02-02 02:00:17.275063: 
 	std: 0.004578519
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24288334, 0.24401666, 0.23208334, 0.24368334, 0.24338333]
	train_accs: [0.24288334, 0.24401666, 0.23208334, 0.24368334, 0.24338333]
	best_train_sub_head: 1
	worst: 0.23208334
	avg: 0.24121001
	best: 0.24401666

Starting e_i: 467
Model ind 579 epoch 467 head B head_i_epoch 0 batch 0: avg loss -1.713196 avg loss no lamb -1.713196 time 2019-02-02 02:00:20.987949
Model ind 579 epoch 467 head B head_i_epoch 0 batch 100: avg loss -1.725890 avg loss no lamb -1.725890 time 2019-02-02 02:03:18.618753
Model ind 579 epoch 467 head B head_i_epoch 0 batch 200: avg loss -1.753116 avg loss no lamb -1.753116 time 2019-02-02 02:06:15.834353
Model ind 579 epoch 467 head A head_i_epoch 0 batch 0: avg loss -3.298330 avg loss no lamb -3.298330 time 2019-02-02 02:09:12.918456
Model ind 579 epoch 467 head A head_i_epoch 0 batch 100: avg loss -3.361402 avg loss no lamb -3.361402 time 2019-02-02 02:12:12.383275
Model ind 579 epoch 467 head A head_i_epoch 0 batch 200: avg loss -3.376656 avg loss no lamb -3.376656 time 2019-02-02 02:15:09.203745
Pre: time 2019-02-02 02:18:31.829425: 
 	std: 0.0044608978
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.23673333, 0.23881666, 0.22733334, 0.2389, 0.23875]
	train_accs: [0.23673333, 0.23881666, 0.22733334, 0.2389, 0.23875]
	best_train_sub_head: 3
	worst: 0.22733334
	avg: 0.23610668
	best: 0.2389

Starting e_i: 468
Model ind 579 epoch 468 head B head_i_epoch 0 batch 0: avg loss -1.662529 avg loss no lamb -1.662529 time 2019-02-02 02:18:34.999884
Model ind 579 epoch 468 head B head_i_epoch 0 batch 100: avg loss -1.708954 avg loss no lamb -1.708954 time 2019-02-02 02:21:32.668135
Model ind 579 epoch 468 head B head_i_epoch 0 batch 200: avg loss -1.713591 avg loss no lamb -1.713591 time 2019-02-02 02:24:30.440044
Model ind 579 epoch 468 head A head_i_epoch 0 batch 0: avg loss -3.287222 avg loss no lamb -3.287222 time 2019-02-02 02:27:27.022206
Model ind 579 epoch 468 head A head_i_epoch 0 batch 100: avg loss -3.316678 avg loss no lamb -3.316678 time 2019-02-02 02:30:24.556892
Model ind 579 epoch 468 head A head_i_epoch 0 batch 200: avg loss -3.374152 avg loss no lamb -3.374152 time 2019-02-02 02:33:21.736424
Pre: time 2019-02-02 02:36:42.718283: 
 	std: 0.0051022824
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24611667, 0.24728334, 0.2342, 0.24748333, 0.24671666]
	train_accs: [0.24611667, 0.24728334, 0.2342, 0.24748333, 0.24671666]
	best_train_sub_head: 3
	worst: 0.2342
	avg: 0.24436
	best: 0.24748333

Starting e_i: 469
Model ind 579 epoch 469 head B head_i_epoch 0 batch 0: avg loss -1.602558 avg loss no lamb -1.602558 time 2019-02-02 02:36:51.191927
Model ind 579 epoch 469 head B head_i_epoch 0 batch 100: avg loss -1.709512 avg loss no lamb -1.709512 time 2019-02-02 02:39:47.817570
Model ind 579 epoch 469 head B head_i_epoch 0 batch 200: avg loss -1.789304 avg loss no lamb -1.789304 time 2019-02-02 02:42:45.593653
Model ind 579 epoch 469 head A head_i_epoch 0 batch 0: avg loss -3.346633 avg loss no lamb -3.346633 time 2019-02-02 02:45:41.945890
Model ind 579 epoch 469 head A head_i_epoch 0 batch 100: avg loss -3.364452 avg loss no lamb -3.364452 time 2019-02-02 02:48:39.338593
Model ind 579 epoch 469 head A head_i_epoch 0 batch 200: avg loss -3.382678 avg loss no lamb -3.382678 time 2019-02-02 02:51:36.479638
Pre: time 2019-02-02 02:54:57.575049: 
 	std: 0.0040644067
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.23668334, 0.23986667, 0.22913334, 0.23976667, 0.23918334]
	train_accs: [0.23668334, 0.23986667, 0.22913334, 0.23976667, 0.23918334]
	best_train_sub_head: 1
	worst: 0.22913334
	avg: 0.23692667
	best: 0.23986667

Starting e_i: 470
Model ind 579 epoch 470 head B head_i_epoch 0 batch 0: avg loss -1.657133 avg loss no lamb -1.657133 time 2019-02-02 02:55:00.972582
Model ind 579 epoch 470 head B head_i_epoch 0 batch 100: avg loss -1.703981 avg loss no lamb -1.703981 time 2019-02-02 02:57:58.358870
Model ind 579 epoch 470 head B head_i_epoch 0 batch 200: avg loss -1.788249 avg loss no lamb -1.788249 time 2019-02-02 03:00:56.037358
Model ind 579 epoch 470 head A head_i_epoch 0 batch 0: avg loss -3.280630 avg loss no lamb -3.280630 time 2019-02-02 03:03:52.761595
Model ind 579 epoch 470 head A head_i_epoch 0 batch 100: avg loss -3.336551 avg loss no lamb -3.336551 time 2019-02-02 03:06:50.053333
Model ind 579 epoch 470 head A head_i_epoch 0 batch 200: avg loss -3.381803 avg loss no lamb -3.381803 time 2019-02-02 03:09:49.071108
Pre: time 2019-02-02 03:13:11.690765: 
 	std: 0.0043832557
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 13), (19, 18)]
	test_accs: [0.2468, 0.24648333, 0.23558334, 0.24708334, 0.24545]
	train_accs: [0.2468, 0.24648333, 0.23558334, 0.24708334, 0.24545]
	best_train_sub_head: 3
	worst: 0.23558334
	avg: 0.24428001
	best: 0.24708334

Starting e_i: 471
Model ind 579 epoch 471 head B head_i_epoch 0 batch 0: avg loss -1.713629 avg loss no lamb -1.713629 time 2019-02-02 03:13:20.575136
Model ind 579 epoch 471 head B head_i_epoch 0 batch 100: avg loss -1.733804 avg loss no lamb -1.733804 time 2019-02-02 03:16:16.456094
Model ind 579 epoch 471 head B head_i_epoch 0 batch 200: avg loss -1.752904 avg loss no lamb -1.752904 time 2019-02-02 03:19:12.613284
Model ind 579 epoch 471 head A head_i_epoch 0 batch 0: avg loss -3.313449 avg loss no lamb -3.313449 time 2019-02-02 03:22:08.300622
Model ind 579 epoch 471 head A head_i_epoch 0 batch 100: avg loss -3.354456 avg loss no lamb -3.354456 time 2019-02-02 03:25:05.741285
Model ind 579 epoch 471 head A head_i_epoch 0 batch 200: avg loss -3.377748 avg loss no lamb -3.377748 time 2019-02-02 03:28:02.866964
Pre: time 2019-02-02 03:31:25.579814: 
 	std: 0.0038713017
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 5), (4, 4), (5, 3), (6, 18), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 19)]
	test_accs: [0.24125, 0.24125, 0.23176667, 0.24176666, 0.24146667]
	train_accs: [0.24125, 0.24125, 0.23176667, 0.24176666, 0.24146667]
	best_train_sub_head: 3
	worst: 0.23176667
	avg: 0.2395
	best: 0.24176666

Starting e_i: 472
Model ind 579 epoch 472 head B head_i_epoch 0 batch 0: avg loss -1.699055 avg loss no lamb -1.699055 time 2019-02-02 03:31:28.774813
Model ind 579 epoch 472 head B head_i_epoch 0 batch 100: avg loss -1.729238 avg loss no lamb -1.729238 time 2019-02-02 03:34:26.831487
Model ind 579 epoch 472 head B head_i_epoch 0 batch 200: avg loss -1.796992 avg loss no lamb -1.796992 time 2019-02-02 03:37:23.199897
Model ind 579 epoch 472 head A head_i_epoch 0 batch 0: avg loss -3.425814 avg loss no lamb -3.425814 time 2019-02-02 03:40:21.105175
Model ind 579 epoch 472 head A head_i_epoch 0 batch 100: avg loss -3.384865 avg loss no lamb -3.384865 time 2019-02-02 03:43:19.798018
Model ind 579 epoch 472 head A head_i_epoch 0 batch 200: avg loss -3.474915 avg loss no lamb -3.474915 time 2019-02-02 03:46:18.310326
Pre: time 2019-02-02 03:49:40.708395: 
 	std: 0.003528765
	best_train_sub_head_match: [(0, 5), (1, 16), (2, 14), (3, 0), (4, 12), (5, 4), (6, 8), (7, 6), (8, 15), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 13), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2431, 0.24188334, 0.23375, 0.24275, 0.24231666]
	train_accs: [0.2431, 0.24188334, 0.23375, 0.24275, 0.24231666]
	best_train_sub_head: 0
	worst: 0.23375
	avg: 0.24076
	best: 0.2431

Starting e_i: 473
Model ind 579 epoch 473 head B head_i_epoch 0 batch 0: avg loss -1.749846 avg loss no lamb -1.749846 time 2019-02-02 03:49:44.272441
Model ind 579 epoch 473 head B head_i_epoch 0 batch 100: avg loss -1.737690 avg loss no lamb -1.737690 time 2019-02-02 03:52:40.852160
Model ind 579 epoch 473 head B head_i_epoch 0 batch 200: avg loss -1.785587 avg loss no lamb -1.785587 time 2019-02-02 03:55:36.779234
Model ind 579 epoch 473 head A head_i_epoch 0 batch 0: avg loss -3.310662 avg loss no lamb -3.310662 time 2019-02-02 03:58:34.240609
Model ind 579 epoch 473 head A head_i_epoch 0 batch 100: avg loss -3.443577 avg loss no lamb -3.443577 time 2019-02-02 04:01:31.257455
Model ind 579 epoch 473 head A head_i_epoch 0 batch 200: avg loss -3.435922 avg loss no lamb -3.435922 time 2019-02-02 04:04:27.604229
Pre: time 2019-02-02 04:07:50.847069: 
 	std: 0.0039600544
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 5), (4, 4), (5, 3), (6, 18), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 13), (19, 19)]
	test_accs: [0.24273333, 0.24266666, 0.23285, 0.24303333, 0.24253333]
	train_accs: [0.24273333, 0.24266666, 0.23285, 0.24303333, 0.24253333]
	best_train_sub_head: 3
	worst: 0.23285
	avg: 0.24076334
	best: 0.24303333

Starting e_i: 474
Model ind 579 epoch 474 head B head_i_epoch 0 batch 0: avg loss -1.702027 avg loss no lamb -1.702027 time 2019-02-02 04:07:54.112350
Model ind 579 epoch 474 head B head_i_epoch 0 batch 100: avg loss -1.735612 avg loss no lamb -1.735612 time 2019-02-02 04:10:51.428050
Model ind 579 epoch 474 head B head_i_epoch 0 batch 200: avg loss -1.716470 avg loss no lamb -1.716470 time 2019-02-02 04:13:48.597046
Model ind 579 epoch 474 head A head_i_epoch 0 batch 0: avg loss -3.356228 avg loss no lamb -3.356228 time 2019-02-02 04:16:46.291187
Model ind 579 epoch 474 head A head_i_epoch 0 batch 100: avg loss -3.319196 avg loss no lamb -3.319196 time 2019-02-02 04:19:43.809278
Model ind 579 epoch 474 head A head_i_epoch 0 batch 200: avg loss -3.336588 avg loss no lamb -3.336588 time 2019-02-02 04:22:43.017173
Pre: time 2019-02-02 04:26:05.277656: 
 	std: 0.00411095
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 5), (12, 13), (13, 18), (14, 1), (15, 15), (16, 6), (17, 3), (18, 19), (19, 12)]
	test_accs: [0.2465, 0.24578333, 0.23636666, 0.24645, 0.24748333]
	train_accs: [0.2465, 0.24578333, 0.23636666, 0.24645, 0.24748333]
	best_train_sub_head: 4
	worst: 0.23636666
	avg: 0.24451666
	best: 0.24748333

Starting e_i: 475
Model ind 579 epoch 475 head B head_i_epoch 0 batch 0: avg loss -1.715756 avg loss no lamb -1.715756 time 2019-02-02 04:26:08.424580
Model ind 579 epoch 475 head B head_i_epoch 0 batch 100: avg loss -1.698922 avg loss no lamb -1.698922 time 2019-02-02 04:29:04.612677
Model ind 579 epoch 475 head B head_i_epoch 0 batch 200: avg loss -1.775984 avg loss no lamb -1.775984 time 2019-02-02 04:32:00.248771
Model ind 579 epoch 475 head A head_i_epoch 0 batch 0: avg loss -3.309147 avg loss no lamb -3.309147 time 2019-02-02 04:34:58.114087
Model ind 579 epoch 475 head A head_i_epoch 0 batch 100: avg loss -3.341055 avg loss no lamb -3.341055 time 2019-02-02 04:37:55.963170
Model ind 579 epoch 475 head A head_i_epoch 0 batch 200: avg loss -3.378726 avg loss no lamb -3.378726 time 2019-02-02 04:40:53.928418
Pre: time 2019-02-02 04:44:16.620278: 
 	std: 0.0032937468
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 15), (3, 9), (4, 16), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 18), (12, 12), (13, 19), (14, 1), (15, 13), (16, 6), (17, 3), (18, 5), (19, 8)]
	test_accs: [0.2424, 0.24181667, 0.23415, 0.24168333, 0.2432]
	train_accs: [0.2424, 0.24181667, 0.23415, 0.24168333, 0.2432]
	best_train_sub_head: 4
	worst: 0.23415
	avg: 0.24064998
	best: 0.2432

Starting e_i: 476
Model ind 579 epoch 476 head B head_i_epoch 0 batch 0: avg loss -1.661623 avg loss no lamb -1.661623 time 2019-02-02 04:44:19.912699
Model ind 579 epoch 476 head B head_i_epoch 0 batch 100: avg loss -1.766065 avg loss no lamb -1.766065 time 2019-02-02 04:47:17.221265
Model ind 579 epoch 476 head B head_i_epoch 0 batch 200: avg loss -1.751150 avg loss no lamb -1.751150 time 2019-02-02 04:50:13.660313
Model ind 579 epoch 476 head A head_i_epoch 0 batch 0: avg loss -3.297621 avg loss no lamb -3.297621 time 2019-02-02 04:53:09.852982
Model ind 579 epoch 476 head A head_i_epoch 0 batch 100: avg loss -3.398337 avg loss no lamb -3.398337 time 2019-02-02 04:56:07.969412
Model ind 579 epoch 476 head A head_i_epoch 0 batch 200: avg loss -3.388384 avg loss no lamb -3.388384 time 2019-02-02 04:59:05.685354
Pre: time 2019-02-02 05:02:28.063402: 
 	std: 0.0038708504
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 15), (3, 9), (4, 12), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 18), (12, 1), (13, 19), (14, 16), (15, 13), (16, 6), (17, 3), (18, 5), (19, 8)]
	test_accs: [0.24376667, 0.2443, 0.23481667, 0.24465, 0.24503334]
	train_accs: [0.24376667, 0.2443, 0.23481667, 0.24465, 0.24503334]
	best_train_sub_head: 4
	worst: 0.23481667
	avg: 0.24251334
	best: 0.24503334

Starting e_i: 477
Model ind 579 epoch 477 head B head_i_epoch 0 batch 0: avg loss -1.747249 avg loss no lamb -1.747249 time 2019-02-02 05:02:31.410050
Model ind 579 epoch 477 head B head_i_epoch 0 batch 100: avg loss -1.739198 avg loss no lamb -1.739198 time 2019-02-02 05:05:28.637683
Model ind 579 epoch 477 head B head_i_epoch 0 batch 200: avg loss -1.793216 avg loss no lamb -1.793216 time 2019-02-02 05:08:26.701087
Model ind 579 epoch 477 head A head_i_epoch 0 batch 0: avg loss -3.355251 avg loss no lamb -3.355251 time 2019-02-02 05:11:23.763720
Model ind 579 epoch 477 head A head_i_epoch 0 batch 100: avg loss -3.391762 avg loss no lamb -3.391762 time 2019-02-02 05:14:22.884156
Model ind 579 epoch 477 head A head_i_epoch 0 batch 200: avg loss -3.377959 avg loss no lamb -3.377959 time 2019-02-02 05:17:20.287409
Pre: time 2019-02-02 05:20:43.617155: 
 	std: 0.003889445
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24411666, 0.2434, 0.23415, 0.24401666, 0.24388333]
	train_accs: [0.24411666, 0.2434, 0.23415, 0.24401666, 0.24388333]
	best_train_sub_head: 0
	worst: 0.23415
	avg: 0.24191332
	best: 0.24411666

Starting e_i: 478
Model ind 579 epoch 478 head B head_i_epoch 0 batch 0: avg loss -1.783538 avg loss no lamb -1.783538 time 2019-02-02 05:20:47.150085
Model ind 579 epoch 478 head B head_i_epoch 0 batch 100: avg loss -1.790023 avg loss no lamb -1.790023 time 2019-02-02 05:23:44.939427
Model ind 579 epoch 478 head B head_i_epoch 0 batch 200: avg loss -1.710024 avg loss no lamb -1.710024 time 2019-02-02 05:26:42.535785
Model ind 579 epoch 478 head A head_i_epoch 0 batch 0: avg loss -3.308574 avg loss no lamb -3.308574 time 2019-02-02 05:29:40.482664
Model ind 579 epoch 478 head A head_i_epoch 0 batch 100: avg loss -3.386729 avg loss no lamb -3.386729 time 2019-02-02 05:32:38.629165
Model ind 579 epoch 478 head A head_i_epoch 0 batch 200: avg loss -3.382571 avg loss no lamb -3.382571 time 2019-02-02 05:35:38.047838
Pre: time 2019-02-02 05:39:00.857349: 
 	std: 0.004091803
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24183333, 0.24085, 0.23101667, 0.24108334, 0.24108334]
	train_accs: [0.24183333, 0.24085, 0.23101667, 0.24108334, 0.24108334]
	best_train_sub_head: 0
	worst: 0.23101667
	avg: 0.23917334
	best: 0.24183333

Starting e_i: 479
Model ind 579 epoch 479 head B head_i_epoch 0 batch 0: avg loss -1.638167 avg loss no lamb -1.638167 time 2019-02-02 05:39:04.081145
Model ind 579 epoch 479 head B head_i_epoch 0 batch 100: avg loss -1.709935 avg loss no lamb -1.709935 time 2019-02-02 05:42:01.342998
Model ind 579 epoch 479 head B head_i_epoch 0 batch 200: avg loss -1.825304 avg loss no lamb -1.825304 time 2019-02-02 05:44:57.496493
Model ind 579 epoch 479 head A head_i_epoch 0 batch 0: avg loss -3.355073 avg loss no lamb -3.355073 time 2019-02-02 05:47:53.987320
Model ind 579 epoch 479 head A head_i_epoch 0 batch 100: avg loss -3.358989 avg loss no lamb -3.358989 time 2019-02-02 05:50:52.084365
Model ind 579 epoch 479 head A head_i_epoch 0 batch 200: avg loss -3.398937 avg loss no lamb -3.398937 time 2019-02-02 05:53:50.275159
Pre: time 2019-02-02 05:57:11.003836: 
 	std: 0.003777316
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.24173333, 0.24275, 0.23265, 0.2417, 0.242]
	train_accs: [0.24173333, 0.24275, 0.23265, 0.2417, 0.242]
	best_train_sub_head: 1
	worst: 0.23265
	avg: 0.24016666
	best: 0.24275

Starting e_i: 480
Model ind 579 epoch 480 head B head_i_epoch 0 batch 0: avg loss -1.720031 avg loss no lamb -1.720031 time 2019-02-02 05:57:14.334499
Model ind 579 epoch 480 head B head_i_epoch 0 batch 100: avg loss -1.812990 avg loss no lamb -1.812990 time 2019-02-02 06:00:10.955695
Model ind 579 epoch 480 head B head_i_epoch 0 batch 200: avg loss -1.699091 avg loss no lamb -1.699091 time 2019-02-02 06:03:06.998362
Model ind 579 epoch 480 head A head_i_epoch 0 batch 0: avg loss -3.358810 avg loss no lamb -3.358810 time 2019-02-02 06:06:04.116276
Model ind 579 epoch 480 head A head_i_epoch 0 batch 100: avg loss -3.357424 avg loss no lamb -3.357424 time 2019-02-02 06:09:04.310454
Model ind 579 epoch 480 head A head_i_epoch 0 batch 200: avg loss -3.376911 avg loss no lamb -3.376911 time 2019-02-02 06:12:01.542640
Pre: time 2019-02-02 06:15:24.781593: 
 	std: 0.004638146
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.23705, 0.2381, 0.226, 0.23808333, 0.23686667]
	train_accs: [0.23705, 0.2381, 0.226, 0.23808333, 0.23686667]
	best_train_sub_head: 1
	worst: 0.226
	avg: 0.23522
	best: 0.2381

Starting e_i: 481
Model ind 579 epoch 481 head B head_i_epoch 0 batch 0: avg loss -1.760733 avg loss no lamb -1.760733 time 2019-02-02 06:15:36.929455
Model ind 579 epoch 481 head B head_i_epoch 0 batch 100: avg loss -1.720842 avg loss no lamb -1.720842 time 2019-02-02 06:18:33.403136
Model ind 579 epoch 481 head B head_i_epoch 0 batch 200: avg loss -1.738518 avg loss no lamb -1.738518 time 2019-02-02 06:21:30.637317
Model ind 579 epoch 481 head A head_i_epoch 0 batch 0: avg loss -3.348926 avg loss no lamb -3.348926 time 2019-02-02 06:24:29.077577
Model ind 579 epoch 481 head A head_i_epoch 0 batch 100: avg loss -3.357614 avg loss no lamb -3.357614 time 2019-02-02 06:27:27.605011
Model ind 579 epoch 481 head A head_i_epoch 0 batch 200: avg loss -3.366400 avg loss no lamb -3.366400 time 2019-02-02 06:30:26.617050
Pre: time 2019-02-02 06:33:50.549860: 
 	std: 0.0042190123
	best_train_sub_head_match: [(0, 13), (1, 15), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 18)]
	test_accs: [0.24533333, 0.246, 0.23513333, 0.24608333, 0.24515]
	train_accs: [0.24533333, 0.246, 0.23513333, 0.24608333, 0.24515]
	best_train_sub_head: 3
	worst: 0.23513333
	avg: 0.24354
	best: 0.24608333

Starting e_i: 482
Model ind 579 epoch 482 head B head_i_epoch 0 batch 0: avg loss -1.752077 avg loss no lamb -1.752077 time 2019-02-02 06:33:53.808429
Model ind 579 epoch 482 head B head_i_epoch 0 batch 100: avg loss -1.707293 avg loss no lamb -1.707293 time 2019-02-02 06:36:51.566879
Model ind 579 epoch 482 head B head_i_epoch 0 batch 200: avg loss -1.763220 avg loss no lamb -1.763220 time 2019-02-02 06:39:47.748339
Model ind 579 epoch 482 head A head_i_epoch 0 batch 0: avg loss -3.365675 avg loss no lamb -3.365675 time 2019-02-02 06:42:44.247157
Model ind 579 epoch 482 head A head_i_epoch 0 batch 100: avg loss -3.336427 avg loss no lamb -3.336427 time 2019-02-02 06:45:41.384388
Model ind 579 epoch 482 head A head_i_epoch 0 batch 200: avg loss -3.374151 avg loss no lamb -3.374151 time 2019-02-02 06:48:38.935548
Pre: time 2019-02-02 06:52:03.397622: 
 	std: 0.0036076338
	best_train_sub_head_match: [(0, 5), (1, 12), (2, 14), (3, 0), (4, 2), (5, 4), (6, 8), (7, 6), (8, 15), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 13), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24106666, 0.24086666, 0.2319, 0.24091667, 0.24081667]
	train_accs: [0.24106666, 0.24086666, 0.2319, 0.24091667, 0.24081667]
	best_train_sub_head: 0
	worst: 0.2319
	avg: 0.23911333
	best: 0.24106666

Starting e_i: 483
Model ind 579 epoch 483 head B head_i_epoch 0 batch 0: avg loss -1.793823 avg loss no lamb -1.793823 time 2019-02-02 06:52:06.951199
Model ind 579 epoch 483 head B head_i_epoch 0 batch 100: avg loss -1.709510 avg loss no lamb -1.709510 time 2019-02-02 06:55:06.508579
Model ind 579 epoch 483 head B head_i_epoch 0 batch 200: avg loss -1.719212 avg loss no lamb -1.719212 time 2019-02-02 06:58:04.218031
Model ind 579 epoch 483 head A head_i_epoch 0 batch 0: avg loss -3.287139 avg loss no lamb -3.287139 time 2019-02-02 07:01:02.556816
Model ind 579 epoch 483 head A head_i_epoch 0 batch 100: avg loss -3.347807 avg loss no lamb -3.347807 time 2019-02-02 07:03:59.881388
Model ind 579 epoch 483 head A head_i_epoch 0 batch 200: avg loss -3.386678 avg loss no lamb -3.386678 time 2019-02-02 07:06:57.551723
Pre: time 2019-02-02 07:10:20.291824: 
 	std: 0.0033774176
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 13), (19, 18)]
	test_accs: [0.24563333, 0.24595, 0.23735, 0.24618334, 0.24526666]
	train_accs: [0.24563333, 0.24595, 0.23735, 0.24618334, 0.24526666]
	best_train_sub_head: 3
	worst: 0.23735
	avg: 0.24407665
	best: 0.24618334

Starting e_i: 484
Model ind 579 epoch 484 head B head_i_epoch 0 batch 0: avg loss -1.668420 avg loss no lamb -1.668420 time 2019-02-02 07:10:25.746267
Model ind 579 epoch 484 head B head_i_epoch 0 batch 100: avg loss -1.638873 avg loss no lamb -1.638873 time 2019-02-02 07:13:24.401644
Model ind 579 epoch 484 head B head_i_epoch 0 batch 200: avg loss -1.666398 avg loss no lamb -1.666398 time 2019-02-02 07:16:21.356073
Model ind 579 epoch 484 head A head_i_epoch 0 batch 0: avg loss -3.364364 avg loss no lamb -3.364364 time 2019-02-02 07:19:18.183381
Model ind 579 epoch 484 head A head_i_epoch 0 batch 100: avg loss -3.336859 avg loss no lamb -3.336859 time 2019-02-02 07:22:16.721383
Model ind 579 epoch 484 head A head_i_epoch 0 batch 200: avg loss -3.384128 avg loss no lamb -3.384128 time 2019-02-02 07:25:13.977999
Pre: time 2019-02-02 07:28:35.645199: 
 	std: 0.004821496
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.24436666, 0.2449, 0.23261666, 0.24475, 0.24463333]
	train_accs: [0.24436666, 0.2449, 0.23261666, 0.24475, 0.24463333]
	best_train_sub_head: 1
	worst: 0.23261666
	avg: 0.24225333
	best: 0.2449

Starting e_i: 485
Model ind 579 epoch 485 head B head_i_epoch 0 batch 0: avg loss -1.802618 avg loss no lamb -1.802618 time 2019-02-02 07:28:38.855565
Model ind 579 epoch 485 head B head_i_epoch 0 batch 100: avg loss -1.674276 avg loss no lamb -1.674276 time 2019-02-02 07:31:37.162480
Model ind 579 epoch 485 head B head_i_epoch 0 batch 200: avg loss -1.807438 avg loss no lamb -1.807438 time 2019-02-02 07:34:34.047216
Model ind 579 epoch 485 head A head_i_epoch 0 batch 0: avg loss -3.344074 avg loss no lamb -3.344074 time 2019-02-02 07:37:31.486106
Model ind 579 epoch 485 head A head_i_epoch 0 batch 100: avg loss -3.367615 avg loss no lamb -3.367615 time 2019-02-02 07:40:29.117829
Model ind 579 epoch 485 head A head_i_epoch 0 batch 200: avg loss -3.407778 avg loss no lamb -3.407778 time 2019-02-02 07:43:28.634777
Pre: time 2019-02-02 07:46:50.107058: 
 	std: 0.0038909218
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 15), (3, 9), (4, 12), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 18), (12, 1), (13, 19), (14, 16), (15, 13), (16, 6), (17, 3), (18, 5), (19, 8)]
	test_accs: [0.24558334, 0.24558334, 0.23613334, 0.24586667, 0.24631667]
	train_accs: [0.24558334, 0.24558334, 0.23613334, 0.24586667, 0.24631667]
	best_train_sub_head: 4
	worst: 0.23613334
	avg: 0.24389668
	best: 0.24631667

Starting e_i: 486
Model ind 579 epoch 486 head B head_i_epoch 0 batch 0: avg loss -1.689609 avg loss no lamb -1.689609 time 2019-02-02 07:46:53.693571
Model ind 579 epoch 486 head B head_i_epoch 0 batch 100: avg loss -1.683370 avg loss no lamb -1.683370 time 2019-02-02 07:49:51.898038
Model ind 579 epoch 486 head B head_i_epoch 0 batch 200: avg loss -1.774880 avg loss no lamb -1.774880 time 2019-02-02 07:52:47.724054
Model ind 579 epoch 486 head A head_i_epoch 0 batch 0: avg loss -3.352654 avg loss no lamb -3.352654 time 2019-02-02 07:55:44.404728
Model ind 579 epoch 486 head A head_i_epoch 0 batch 100: avg loss -3.331639 avg loss no lamb -3.331639 time 2019-02-02 07:58:41.755789
Model ind 579 epoch 486 head A head_i_epoch 0 batch 200: avg loss -3.408305 avg loss no lamb -3.408305 time 2019-02-02 08:01:40.338677
Pre: time 2019-02-02 08:05:01.497634: 
 	std: 0.0043155723
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24121666, 0.2427, 0.23208334, 0.24365, 0.24315]
	train_accs: [0.24121666, 0.2427, 0.23208334, 0.24365, 0.24315]
	best_train_sub_head: 3
	worst: 0.23208334
	avg: 0.24056001
	best: 0.24365

Starting e_i: 487
Model ind 579 epoch 487 head B head_i_epoch 0 batch 0: avg loss -1.830515 avg loss no lamb -1.830515 time 2019-02-02 08:05:04.714730
Model ind 579 epoch 487 head B head_i_epoch 0 batch 100: avg loss -1.699236 avg loss no lamb -1.699236 time 2019-02-02 08:08:01.299347
Model ind 579 epoch 487 head B head_i_epoch 0 batch 200: avg loss -1.737625 avg loss no lamb -1.737625 time 2019-02-02 08:10:58.749341
Model ind 579 epoch 487 head A head_i_epoch 0 batch 0: avg loss -3.357714 avg loss no lamb -3.357714 time 2019-02-02 08:13:54.943693
Model ind 579 epoch 487 head A head_i_epoch 0 batch 100: avg loss -3.393262 avg loss no lamb -3.393262 time 2019-02-02 08:16:52.335162
Model ind 579 epoch 487 head A head_i_epoch 0 batch 200: avg loss -3.377719 avg loss no lamb -3.377719 time 2019-02-02 08:19:49.297621
Pre: time 2019-02-02 08:23:10.818479: 
 	std: 0.0042660884
	best_train_sub_head_match: [(0, 13), (1, 15), (2, 2), (3, 5), (4, 4), (5, 3), (6, 18), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2419, 0.2423, 0.23156667, 0.2425, 0.24218333]
	train_accs: [0.2419, 0.2423, 0.23156667, 0.2425, 0.24218333]
	best_train_sub_head: 3
	worst: 0.23156667
	avg: 0.24008998
	best: 0.2425

Starting e_i: 488
Model ind 579 epoch 488 head B head_i_epoch 0 batch 0: avg loss -1.687225 avg loss no lamb -1.687225 time 2019-02-02 08:23:14.738082
Model ind 579 epoch 488 head B head_i_epoch 0 batch 100: avg loss -1.731664 avg loss no lamb -1.731664 time 2019-02-02 08:26:10.482260
Model ind 579 epoch 488 head B head_i_epoch 0 batch 200: avg loss -1.803074 avg loss no lamb -1.803074 time 2019-02-02 08:29:07.281907
Model ind 579 epoch 488 head A head_i_epoch 0 batch 0: avg loss -3.348314 avg loss no lamb -3.348314 time 2019-02-02 08:32:03.072658
Model ind 579 epoch 488 head A head_i_epoch 0 batch 100: avg loss -3.396887 avg loss no lamb -3.396887 time 2019-02-02 08:35:02.114038
Model ind 579 epoch 488 head A head_i_epoch 0 batch 200: avg loss -3.355235 avg loss no lamb -3.355235 time 2019-02-02 08:38:00.512153
Pre: time 2019-02-02 08:41:21.185819: 
 	std: 0.0036576935
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 5), (12, 13), (13, 18), (14, 1), (15, 15), (16, 6), (17, 3), (18, 19), (19, 12)]
	test_accs: [0.23996666, 0.24046667, 0.2313, 0.24046667, 0.24078333]
	train_accs: [0.23996666, 0.24046667, 0.2313, 0.24046667, 0.24078333]
	best_train_sub_head: 4
	worst: 0.2313
	avg: 0.23859668
	best: 0.24078333

Starting e_i: 489
Model ind 579 epoch 489 head B head_i_epoch 0 batch 0: avg loss -1.749003 avg loss no lamb -1.749003 time 2019-02-02 08:41:24.425379
Model ind 579 epoch 489 head B head_i_epoch 0 batch 100: avg loss -1.757079 avg loss no lamb -1.757079 time 2019-02-02 08:44:21.704362
Model ind 579 epoch 489 head B head_i_epoch 0 batch 200: avg loss -1.763032 avg loss no lamb -1.763032 time 2019-02-02 08:47:18.774235
Model ind 579 epoch 489 head A head_i_epoch 0 batch 0: avg loss -3.419223 avg loss no lamb -3.419223 time 2019-02-02 08:50:15.315849
Model ind 579 epoch 489 head A head_i_epoch 0 batch 100: avg loss -3.339693 avg loss no lamb -3.339693 time 2019-02-02 08:53:12.413617
Model ind 579 epoch 489 head A head_i_epoch 0 batch 200: avg loss -3.359124 avg loss no lamb -3.359124 time 2019-02-02 08:56:09.950071
Pre: time 2019-02-02 08:59:32.073548: 
 	std: 0.004196353
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.24141666, 0.24151666, 0.23103334, 0.24143334, 0.24171667]
	train_accs: [0.24141666, 0.24151666, 0.23103334, 0.24143334, 0.24171667]
	best_train_sub_head: 4
	worst: 0.23103334
	avg: 0.23942332
	best: 0.24171667

Starting e_i: 490
Model ind 579 epoch 490 head B head_i_epoch 0 batch 0: avg loss -1.706681 avg loss no lamb -1.706681 time 2019-02-02 08:59:35.535275
Model ind 579 epoch 490 head B head_i_epoch 0 batch 100: avg loss -1.753579 avg loss no lamb -1.753579 time 2019-02-02 09:02:32.212825
Model ind 579 epoch 490 head B head_i_epoch 0 batch 200: avg loss -1.747669 avg loss no lamb -1.747669 time 2019-02-02 09:05:27.997537
Model ind 579 epoch 490 head A head_i_epoch 0 batch 0: avg loss -3.325529 avg loss no lamb -3.325529 time 2019-02-02 09:08:24.858725
Model ind 579 epoch 490 head A head_i_epoch 0 batch 100: avg loss -3.367995 avg loss no lamb -3.367995 time 2019-02-02 09:11:23.259198
Model ind 579 epoch 490 head A head_i_epoch 0 batch 200: avg loss -3.441886 avg loss no lamb -3.441886 time 2019-02-02 09:14:23.385278
Pre: time 2019-02-02 09:17:50.416752: 
 	std: 0.0037193103
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24338333, 0.24386667, 0.23458333, 0.24416667, 0.24401666]
	train_accs: [0.24338333, 0.24386667, 0.23458333, 0.24416667, 0.24401666]
	best_train_sub_head: 3
	worst: 0.23458333
	avg: 0.24200335
	best: 0.24416667

Starting e_i: 491
Model ind 579 epoch 491 head B head_i_epoch 0 batch 0: avg loss -1.698277 avg loss no lamb -1.698277 time 2019-02-02 09:17:57.548247
Model ind 579 epoch 491 head B head_i_epoch 0 batch 100: avg loss -1.722795 avg loss no lamb -1.722795 time 2019-02-02 09:20:54.248921
Model ind 579 epoch 491 head B head_i_epoch 0 batch 200: avg loss -1.792521 avg loss no lamb -1.792521 time 2019-02-02 09:23:53.292091
Model ind 579 epoch 491 head A head_i_epoch 0 batch 0: avg loss -3.332392 avg loss no lamb -3.332392 time 2019-02-02 09:26:53.272155
Model ind 579 epoch 491 head A head_i_epoch 0 batch 100: avg loss -3.360938 avg loss no lamb -3.360938 time 2019-02-02 09:29:51.787433
Model ind 579 epoch 491 head A head_i_epoch 0 batch 200: avg loss -3.387500 avg loss no lamb -3.387500 time 2019-02-02 09:32:49.438113
Pre: time 2019-02-02 09:36:11.523823: 
 	std: 0.0037379295
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 5), (12, 13), (13, 18), (14, 1), (15, 15), (16, 6), (17, 3), (18, 19), (19, 12)]
	test_accs: [0.24503334, 0.24508333, 0.23573333, 0.24478333, 0.24536666]
	train_accs: [0.24503334, 0.24508333, 0.23573333, 0.24478333, 0.24536666]
	best_train_sub_head: 4
	worst: 0.23573333
	avg: 0.24319999
	best: 0.24536666

Starting e_i: 492
Model ind 579 epoch 492 head B head_i_epoch 0 batch 0: avg loss -1.673602 avg loss no lamb -1.673602 time 2019-02-02 09:36:15.168589
Model ind 579 epoch 492 head B head_i_epoch 0 batch 100: avg loss -1.696451 avg loss no lamb -1.696451 time 2019-02-02 09:39:10.979024
Model ind 579 epoch 492 head B head_i_epoch 0 batch 200: avg loss -1.670275 avg loss no lamb -1.670275 time 2019-02-02 09:42:06.867360
Model ind 579 epoch 492 head A head_i_epoch 0 batch 0: avg loss -3.308605 avg loss no lamb -3.308605 time 2019-02-02 09:45:03.091826
Model ind 579 epoch 492 head A head_i_epoch 0 batch 100: avg loss -3.390857 avg loss no lamb -3.390857 time 2019-02-02 09:47:59.890537
Model ind 579 epoch 492 head A head_i_epoch 0 batch 200: avg loss -3.409900 avg loss no lamb -3.409900 time 2019-02-02 09:50:57.346535
Pre: time 2019-02-02 09:54:22.023181: 
 	std: 0.0041141063
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.24271667, 0.24318333, 0.23293333, 0.24333334, 0.24355]
	train_accs: [0.24271667, 0.24318333, 0.23293333, 0.24333334, 0.24355]
	best_train_sub_head: 4
	worst: 0.23293333
	avg: 0.24114332
	best: 0.24355

Starting e_i: 493
Model ind 579 epoch 493 head B head_i_epoch 0 batch 0: avg loss -1.756583 avg loss no lamb -1.756583 time 2019-02-02 09:54:25.336534
Model ind 579 epoch 493 head B head_i_epoch 0 batch 100: avg loss -1.751000 avg loss no lamb -1.751000 time 2019-02-02 09:57:24.037008
Model ind 579 epoch 493 head B head_i_epoch 0 batch 200: avg loss -1.775969 avg loss no lamb -1.775969 time 2019-02-02 10:00:20.354982
Model ind 579 epoch 493 head A head_i_epoch 0 batch 0: avg loss -3.306288 avg loss no lamb -3.306288 time 2019-02-02 10:03:17.484396
Model ind 579 epoch 493 head A head_i_epoch 0 batch 100: avg loss -3.402133 avg loss no lamb -3.402133 time 2019-02-02 10:06:16.136853
Model ind 579 epoch 493 head A head_i_epoch 0 batch 200: avg loss -3.370542 avg loss no lamb -3.370542 time 2019-02-02 10:09:13.509212
Pre: time 2019-02-02 10:12:35.198013: 
 	std: 0.004286038
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24221666, 0.2443, 0.2336, 0.24486667, 0.24478333]
	train_accs: [0.24221666, 0.2443, 0.2336, 0.24486667, 0.24478333]
	best_train_sub_head: 3
	worst: 0.2336
	avg: 0.24195333
	best: 0.24486667

Starting e_i: 494
Model ind 579 epoch 494 head B head_i_epoch 0 batch 0: avg loss -1.636199 avg loss no lamb -1.636199 time 2019-02-02 10:12:38.837716
Model ind 579 epoch 494 head B head_i_epoch 0 batch 100: avg loss -1.771695 avg loss no lamb -1.771695 time 2019-02-02 10:15:35.552864
Model ind 579 epoch 494 head B head_i_epoch 0 batch 200: avg loss -1.724545 avg loss no lamb -1.724545 time 2019-02-02 10:18:32.477343
Model ind 579 epoch 494 head A head_i_epoch 0 batch 0: avg loss -3.332660 avg loss no lamb -3.332660 time 2019-02-02 10:21:29.238093
Model ind 579 epoch 494 head A head_i_epoch 0 batch 100: avg loss -3.379293 avg loss no lamb -3.379293 time 2019-02-02 10:24:27.493222
Model ind 579 epoch 494 head A head_i_epoch 0 batch 200: avg loss -3.347992 avg loss no lamb -3.347992 time 2019-02-02 10:27:25.064498
Pre: time 2019-02-02 10:30:47.155050: 
 	std: 0.0035955305
	best_train_sub_head_match: [(0, 5), (1, 12), (2, 14), (3, 0), (4, 16), (5, 4), (6, 8), (7, 6), (8, 15), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 13), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24753334, 0.24681666, 0.23811667, 0.24745, 0.24636666]
	train_accs: [0.24753334, 0.24681666, 0.23811667, 0.24745, 0.24636666]
	best_train_sub_head: 0
	worst: 0.23811667
	avg: 0.24525666
	best: 0.24753334

Starting e_i: 495
Model ind 579 epoch 495 head B head_i_epoch 0 batch 0: avg loss -1.769494 avg loss no lamb -1.769494 time 2019-02-02 10:30:54.586249
Model ind 579 epoch 495 head B head_i_epoch 0 batch 100: avg loss -1.764402 avg loss no lamb -1.764402 time 2019-02-02 10:33:50.633565
Model ind 579 epoch 495 head B head_i_epoch 0 batch 200: avg loss -1.698382 avg loss no lamb -1.698382 time 2019-02-02 10:36:48.873228
Model ind 579 epoch 495 head A head_i_epoch 0 batch 0: avg loss -3.350726 avg loss no lamb -3.350726 time 2019-02-02 10:39:47.825657
Model ind 579 epoch 495 head A head_i_epoch 0 batch 100: avg loss -3.362978 avg loss no lamb -3.362978 time 2019-02-02 10:42:45.522537
Model ind 579 epoch 495 head A head_i_epoch 0 batch 200: avg loss -3.384009 avg loss no lamb -3.384009 time 2019-02-02 10:45:43.221872
Pre: time 2019-02-02 10:49:06.304144: 
 	std: 0.00443576
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.24431667, 0.24458334, 0.23365, 0.24498333, 0.245]
	train_accs: [0.24431667, 0.24458334, 0.23365, 0.24498333, 0.245]
	best_train_sub_head: 4
	worst: 0.23365
	avg: 0.24250667
	best: 0.245

Starting e_i: 496
Model ind 579 epoch 496 head B head_i_epoch 0 batch 0: avg loss -1.802176 avg loss no lamb -1.802176 time 2019-02-02 10:49:10.056254
Model ind 579 epoch 496 head B head_i_epoch 0 batch 100: avg loss -1.766709 avg loss no lamb -1.766709 time 2019-02-02 10:52:06.839157
Model ind 579 epoch 496 head B head_i_epoch 0 batch 200: avg loss -1.704610 avg loss no lamb -1.704610 time 2019-02-02 10:55:02.916091
Model ind 579 epoch 496 head A head_i_epoch 0 batch 0: avg loss -3.341152 avg loss no lamb -3.341152 time 2019-02-02 10:57:59.816365
Model ind 579 epoch 496 head A head_i_epoch 0 batch 100: avg loss -3.389258 avg loss no lamb -3.389258 time 2019-02-02 11:00:56.581279
Model ind 579 epoch 496 head A head_i_epoch 0 batch 200: avg loss -3.365819 avg loss no lamb -3.365819 time 2019-02-02 11:03:53.556460
Pre: time 2019-02-02 11:07:16.474636: 
 	std: 0.003726503
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 13), (19, 18)]
	test_accs: [0.23873334, 0.23901667, 0.2296, 0.23913333, 0.23875]
	train_accs: [0.23873334, 0.23901667, 0.2296, 0.23913333, 0.23875]
	best_train_sub_head: 3
	worst: 0.2296
	avg: 0.23704667
	best: 0.23913333

Starting e_i: 497
Model ind 579 epoch 497 head B head_i_epoch 0 batch 0: avg loss -1.764952 avg loss no lamb -1.764952 time 2019-02-02 11:07:19.711114
Model ind 579 epoch 497 head B head_i_epoch 0 batch 100: avg loss -1.721753 avg loss no lamb -1.721753 time 2019-02-02 11:10:18.382792
Model ind 579 epoch 497 head B head_i_epoch 0 batch 200: avg loss -1.763900 avg loss no lamb -1.763900 time 2019-02-02 11:13:15.343120
Model ind 579 epoch 497 head A head_i_epoch 0 batch 0: avg loss -3.333701 avg loss no lamb -3.333701 time 2019-02-02 11:16:11.990568
Model ind 579 epoch 497 head A head_i_epoch 0 batch 100: avg loss -3.349286 avg loss no lamb -3.349286 time 2019-02-02 11:19:10.995708
Model ind 579 epoch 497 head A head_i_epoch 0 batch 200: avg loss -3.389521 avg loss no lamb -3.389521 time 2019-02-02 11:22:08.174430
Pre: time 2019-02-02 11:25:29.928311: 
 	std: 0.0038333565
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 5), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24121666, 0.24158333, 0.23168333, 0.24125, 0.24096666]
	train_accs: [0.24121666, 0.24158333, 0.23168333, 0.24125, 0.24096666]
	best_train_sub_head: 1
	worst: 0.23168333
	avg: 0.23933999
	best: 0.24158333

Starting e_i: 498
Model ind 579 epoch 498 head B head_i_epoch 0 batch 0: avg loss -1.765086 avg loss no lamb -1.765086 time 2019-02-02 11:25:33.443797
Model ind 579 epoch 498 head B head_i_epoch 0 batch 100: avg loss -1.767106 avg loss no lamb -1.767106 time 2019-02-02 11:28:31.050154
Model ind 579 epoch 498 head B head_i_epoch 0 batch 200: avg loss -1.674945 avg loss no lamb -1.674945 time 2019-02-02 11:31:28.811841
Model ind 579 epoch 498 head A head_i_epoch 0 batch 0: avg loss -3.375745 avg loss no lamb -3.375745 time 2019-02-02 11:34:24.995168
Model ind 579 epoch 498 head A head_i_epoch 0 batch 100: avg loss -3.382437 avg loss no lamb -3.382437 time 2019-02-02 11:37:23.159319
Model ind 579 epoch 498 head A head_i_epoch 0 batch 200: avg loss -3.367270 avg loss no lamb -3.367270 time 2019-02-02 11:40:21.958469
Pre: time 2019-02-02 11:43:46.760668: 
 	std: 0.0038568922
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.241, 0.24161667, 0.23221667, 0.24278334, 0.2416]
	train_accs: [0.241, 0.24161667, 0.23221667, 0.24278334, 0.2416]
	best_train_sub_head: 3
	worst: 0.23221667
	avg: 0.23984334
	best: 0.24278334

Starting e_i: 499
Model ind 579 epoch 499 head B head_i_epoch 0 batch 0: avg loss -1.751498 avg loss no lamb -1.751498 time 2019-02-02 11:43:50.126464
Model ind 579 epoch 499 head B head_i_epoch 0 batch 100: avg loss -1.781103 avg loss no lamb -1.781103 time 2019-02-02 11:46:48.139576
Model ind 579 epoch 499 head B head_i_epoch 0 batch 200: avg loss -1.721732 avg loss no lamb -1.721732 time 2019-02-02 11:49:44.957363
Model ind 579 epoch 499 head A head_i_epoch 0 batch 0: avg loss -3.297630 avg loss no lamb -3.297630 time 2019-02-02 11:52:40.950492
Model ind 579 epoch 499 head A head_i_epoch 0 batch 100: avg loss -3.342169 avg loss no lamb -3.342169 time 2019-02-02 11:55:39.115363
Model ind 579 epoch 499 head A head_i_epoch 0 batch 200: avg loss -3.437164 avg loss no lamb -3.437164 time 2019-02-02 11:58:36.803868
Pre: time 2019-02-02 12:02:00.305497: 
 	std: 0.0037276174
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24331667, 0.24373333, 0.23425, 0.24355, 0.24365]
	train_accs: [0.24331667, 0.24373333, 0.23425, 0.24355, 0.24365]
	best_train_sub_head: 1
	worst: 0.23425
	avg: 0.24170001
	best: 0.24373333

Starting e_i: 500
Model ind 579 epoch 500 head B head_i_epoch 0 batch 0: avg loss -1.700133 avg loss no lamb -1.700133 time 2019-02-02 12:02:03.643134
Model ind 579 epoch 500 head B head_i_epoch 0 batch 100: avg loss -1.781109 avg loss no lamb -1.781109 time 2019-02-02 12:05:01.216103
Model ind 579 epoch 500 head B head_i_epoch 0 batch 200: avg loss -1.770684 avg loss no lamb -1.770684 time 2019-02-02 12:07:59.759850
Model ind 579 epoch 500 head A head_i_epoch 0 batch 0: avg loss -3.358382 avg loss no lamb -3.358382 time 2019-02-02 12:10:56.454559
Model ind 579 epoch 500 head A head_i_epoch 0 batch 100: avg loss -3.345156 avg loss no lamb -3.345156 time 2019-02-02 12:13:55.352610
Model ind 579 epoch 500 head A head_i_epoch 0 batch 200: avg loss -3.359217 avg loss no lamb -3.359217 time 2019-02-02 12:16:52.535724
Pre: time 2019-02-02 12:20:15.884444: 
 	std: 0.00453836
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24606666, 0.24585, 0.23455, 0.24605, 0.24558334]
	train_accs: [0.24606666, 0.24585, 0.23455, 0.24605, 0.24558334]
	best_train_sub_head: 0
	worst: 0.23455
	avg: 0.24362
	best: 0.24606666

Starting e_i: 501
Model ind 579 epoch 501 head B head_i_epoch 0 batch 0: avg loss -1.659230 avg loss no lamb -1.659230 time 2019-02-02 12:20:22.394747
Model ind 579 epoch 501 head B head_i_epoch 0 batch 100: avg loss -1.810956 avg loss no lamb -1.810956 time 2019-02-02 12:23:20.226569
Model ind 579 epoch 501 head B head_i_epoch 0 batch 200: avg loss -1.763016 avg loss no lamb -1.763016 time 2019-02-02 12:26:19.182899
Model ind 579 epoch 501 head A head_i_epoch 0 batch 0: avg loss -3.307196 avg loss no lamb -3.307196 time 2019-02-02 12:29:17.264593
Model ind 579 epoch 501 head A head_i_epoch 0 batch 100: avg loss -3.350573 avg loss no lamb -3.350573 time 2019-02-02 12:32:16.396673
Model ind 579 epoch 501 head A head_i_epoch 0 batch 200: avg loss -3.378265 avg loss no lamb -3.378265 time 2019-02-02 12:35:13.751612
Pre: time 2019-02-02 12:38:36.285025: 
 	std: 0.004351538
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24223334, 0.24378334, 0.23241666, 0.24378334, 0.243]
	train_accs: [0.24223334, 0.24378334, 0.23241666, 0.24378334, 0.243]
	best_train_sub_head: 1
	worst: 0.23241666
	avg: 0.24104336
	best: 0.24378334

Starting e_i: 502
Model ind 579 epoch 502 head B head_i_epoch 0 batch 0: avg loss -1.750709 avg loss no lamb -1.750709 time 2019-02-02 12:38:39.550942
Model ind 579 epoch 502 head B head_i_epoch 0 batch 100: avg loss -1.738441 avg loss no lamb -1.738441 time 2019-02-02 12:41:36.593949
Model ind 579 epoch 502 head B head_i_epoch 0 batch 200: avg loss -1.734475 avg loss no lamb -1.734475 time 2019-02-02 12:44:33.201655
Model ind 579 epoch 502 head A head_i_epoch 0 batch 0: avg loss -3.351681 avg loss no lamb -3.351681 time 2019-02-02 12:47:30.942137
Model ind 579 epoch 502 head A head_i_epoch 0 batch 100: avg loss -3.398199 avg loss no lamb -3.398199 time 2019-02-02 12:50:28.743988
Model ind 579 epoch 502 head A head_i_epoch 0 batch 200: avg loss -3.398403 avg loss no lamb -3.398403 time 2019-02-02 12:53:26.226260
Pre: time 2019-02-02 12:56:49.928667: 
 	std: 0.004657958
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 5), (4, 4), (5, 3), (6, 18), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 19)]
	test_accs: [0.24646667, 0.24738333, 0.23558334, 0.24786666, 0.24696666]
	train_accs: [0.24646667, 0.24738333, 0.23558334, 0.24786666, 0.24696666]
	best_train_sub_head: 3
	worst: 0.23558334
	avg: 0.2448533
	best: 0.24786666

Starting e_i: 503
Model ind 579 epoch 503 head B head_i_epoch 0 batch 0: avg loss -1.797970 avg loss no lamb -1.797970 time 2019-02-02 12:57:03.302896
Model ind 579 epoch 503 head B head_i_epoch 0 batch 100: avg loss -1.782463 avg loss no lamb -1.782463 time 2019-02-02 13:00:00.603288
Model ind 579 epoch 503 head B head_i_epoch 0 batch 200: avg loss -1.774875 avg loss no lamb -1.774875 time 2019-02-02 13:02:57.822216
Model ind 579 epoch 503 head A head_i_epoch 0 batch 0: avg loss -3.303249 avg loss no lamb -3.303249 time 2019-02-02 13:05:53.789257
Model ind 579 epoch 503 head A head_i_epoch 0 batch 100: avg loss -3.353423 avg loss no lamb -3.353423 time 2019-02-02 13:08:51.136169
Model ind 579 epoch 503 head A head_i_epoch 0 batch 200: avg loss -3.362956 avg loss no lamb -3.362956 time 2019-02-02 13:11:48.862334
Pre: time 2019-02-02 13:15:11.581156: 
 	std: 0.0038962588
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 13), (19, 18)]
	test_accs: [0.245, 0.24503334, 0.23531666, 0.24561666, 0.24438334]
	train_accs: [0.245, 0.24503334, 0.23531666, 0.24561666, 0.24438334]
	best_train_sub_head: 3
	worst: 0.23531666
	avg: 0.24307
	best: 0.24561666

Starting e_i: 504
Model ind 579 epoch 504 head B head_i_epoch 0 batch 0: avg loss -1.781610 avg loss no lamb -1.781610 time 2019-02-02 13:15:14.841355
Model ind 579 epoch 504 head B head_i_epoch 0 batch 100: avg loss -1.800103 avg loss no lamb -1.800103 time 2019-02-02 13:18:11.860765
Model ind 579 epoch 504 head B head_i_epoch 0 batch 200: avg loss -1.755345 avg loss no lamb -1.755345 time 2019-02-02 13:21:09.228005
Model ind 579 epoch 504 head A head_i_epoch 0 batch 0: avg loss -3.304464 avg loss no lamb -3.304464 time 2019-02-02 13:24:07.258646
Model ind 579 epoch 504 head A head_i_epoch 0 batch 100: avg loss -3.395513 avg loss no lamb -3.395513 time 2019-02-02 13:27:05.260647
Model ind 579 epoch 504 head A head_i_epoch 0 batch 200: avg loss -3.410269 avg loss no lamb -3.410269 time 2019-02-02 13:30:02.910168
Pre: time 2019-02-02 13:33:24.949243: 
 	std: 0.0038530573
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.2475, 0.24858333, 0.23835, 0.2478, 0.24788333]
	train_accs: [0.2475, 0.24858333, 0.23835, 0.2478, 0.24788333]
	best_train_sub_head: 1
	worst: 0.23835
	avg: 0.24602333
	best: 0.24858333

Starting e_i: 505
Model ind 579 epoch 505 head B head_i_epoch 0 batch 0: avg loss -1.731036 avg loss no lamb -1.731036 time 2019-02-02 13:33:32.147819
Model ind 579 epoch 505 head B head_i_epoch 0 batch 100: avg loss -1.780634 avg loss no lamb -1.780634 time 2019-02-02 13:36:30.542580
Model ind 579 epoch 505 head B head_i_epoch 0 batch 200: avg loss -1.717209 avg loss no lamb -1.717209 time 2019-02-02 13:39:28.998149
Model ind 579 epoch 505 head A head_i_epoch 0 batch 0: avg loss -3.363762 avg loss no lamb -3.363762 time 2019-02-02 13:42:26.212265
Model ind 579 epoch 505 head A head_i_epoch 0 batch 100: avg loss -3.370470 avg loss no lamb -3.370470 time 2019-02-02 13:45:25.474512
Model ind 579 epoch 505 head A head_i_epoch 0 batch 200: avg loss -3.358004 avg loss no lamb -3.358004 time 2019-02-02 13:48:25.189020
Pre: time 2019-02-02 13:51:48.009932: 
 	std: 0.0041771135
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 12), (5, 4), (6, 2), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2429, 0.2428, 0.23213333, 0.24218333, 0.24233334]
	train_accs: [0.2429, 0.2428, 0.23213333, 0.24218333, 0.24233334]
	best_train_sub_head: 0
	worst: 0.23213333
	avg: 0.24047
	best: 0.2429

Starting e_i: 506
Model ind 579 epoch 506 head B head_i_epoch 0 batch 0: avg loss -1.715130 avg loss no lamb -1.715130 time 2019-02-02 13:51:51.559213
Model ind 579 epoch 506 head B head_i_epoch 0 batch 100: avg loss -1.725999 avg loss no lamb -1.725999 time 2019-02-02 13:54:49.144896
Model ind 579 epoch 506 head B head_i_epoch 0 batch 200: avg loss -1.814815 avg loss no lamb -1.814815 time 2019-02-02 13:57:46.683766
Model ind 579 epoch 506 head A head_i_epoch 0 batch 0: avg loss -3.340455 avg loss no lamb -3.340455 time 2019-02-02 14:00:43.267822
Model ind 579 epoch 506 head A head_i_epoch 0 batch 100: avg loss -3.452640 avg loss no lamb -3.452640 time 2019-02-02 14:03:41.287381
Model ind 579 epoch 506 head A head_i_epoch 0 batch 200: avg loss -3.363578 avg loss no lamb -3.363578 time 2019-02-02 14:06:37.872223
Pre: time 2019-02-02 14:10:01.633502: 
 	std: 0.0036608211
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 5), (11, 17), (12, 18), (13, 1), (14, 12), (15, 8), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24351667, 0.24405, 0.23445, 0.2431, 0.24361667]
	train_accs: [0.24351667, 0.24405, 0.23445, 0.2431, 0.24361667]
	best_train_sub_head: 1
	worst: 0.23445
	avg: 0.24174666
	best: 0.24405

Starting e_i: 507
Model ind 579 epoch 507 head B head_i_epoch 0 batch 0: avg loss -1.721722 avg loss no lamb -1.721722 time 2019-02-02 14:10:04.891753
Model ind 579 epoch 507 head B head_i_epoch 0 batch 100: avg loss -1.720219 avg loss no lamb -1.720219 time 2019-02-02 14:13:01.350608
Model ind 579 epoch 507 head B head_i_epoch 0 batch 200: avg loss -1.685210 avg loss no lamb -1.685210 time 2019-02-02 14:15:58.355075
Model ind 579 epoch 507 head A head_i_epoch 0 batch 0: avg loss -3.308263 avg loss no lamb -3.308263 time 2019-02-02 14:18:55.723077
Model ind 579 epoch 507 head A head_i_epoch 0 batch 100: avg loss -3.483031 avg loss no lamb -3.483031 time 2019-02-02 14:21:53.662322
Model ind 579 epoch 507 head A head_i_epoch 0 batch 200: avg loss -3.427121 avg loss no lamb -3.427121 time 2019-02-02 14:24:51.756770
Pre: time 2019-02-02 14:28:15.481428: 
 	std: 0.0038026096
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2432, 0.2435, 0.23376666, 0.24296667, 0.24338333]
	train_accs: [0.2432, 0.2435, 0.23376666, 0.24296667, 0.24338333]
	best_train_sub_head: 1
	worst: 0.23376666
	avg: 0.24136333
	best: 0.2435

Starting e_i: 508
Model ind 579 epoch 508 head B head_i_epoch 0 batch 0: avg loss -1.766432 avg loss no lamb -1.766432 time 2019-02-02 14:28:18.834839
Model ind 579 epoch 508 head B head_i_epoch 0 batch 100: avg loss -1.720970 avg loss no lamb -1.720970 time 2019-02-02 14:31:15.458345
Model ind 579 epoch 508 head B head_i_epoch 0 batch 200: avg loss -1.755541 avg loss no lamb -1.755541 time 2019-02-02 14:34:12.639417
Model ind 579 epoch 508 head A head_i_epoch 0 batch 0: avg loss -3.337021 avg loss no lamb -3.337021 time 2019-02-02 14:37:10.491856
Model ind 579 epoch 508 head A head_i_epoch 0 batch 100: avg loss -3.408645 avg loss no lamb -3.408645 time 2019-02-02 14:40:09.748007
Model ind 579 epoch 508 head A head_i_epoch 0 batch 200: avg loss -3.360921 avg loss no lamb -3.360921 time 2019-02-02 14:43:09.427875
Pre: time 2019-02-02 14:46:33.233347: 
 	std: 0.004328909
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 15), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.2428, 0.24391666, 0.23223333, 0.24243334, 0.24278334]
	train_accs: [0.2428, 0.24391666, 0.23223333, 0.24243334, 0.24278334]
	best_train_sub_head: 1
	worst: 0.23223333
	avg: 0.24083333
	best: 0.24391666

Starting e_i: 509
Model ind 579 epoch 509 head B head_i_epoch 0 batch 0: avg loss -1.712887 avg loss no lamb -1.712887 time 2019-02-02 14:46:36.692560
Model ind 579 epoch 509 head B head_i_epoch 0 batch 100: avg loss -1.705494 avg loss no lamb -1.705494 time 2019-02-02 14:49:34.854585
Model ind 579 epoch 509 head B head_i_epoch 0 batch 200: avg loss -1.770392 avg loss no lamb -1.770392 time 2019-02-02 14:52:32.108042
Model ind 579 epoch 509 head A head_i_epoch 0 batch 0: avg loss -3.321493 avg loss no lamb -3.321493 time 2019-02-02 14:55:30.092304
Model ind 579 epoch 509 head A head_i_epoch 0 batch 100: avg loss -3.339394 avg loss no lamb -3.339394 time 2019-02-02 14:58:29.360481
Model ind 579 epoch 509 head A head_i_epoch 0 batch 200: avg loss -3.427556 avg loss no lamb -3.427556 time 2019-02-02 15:01:26.735721
Pre: time 2019-02-02 15:04:49.686565: 
 	std: 0.003891682
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24778333, 0.24613333, 0.23701666, 0.2457, 0.24673334]
	train_accs: [0.24778333, 0.24613333, 0.23701666, 0.2457, 0.24673334]
	best_train_sub_head: 0
	worst: 0.23701666
	avg: 0.24467333
	best: 0.24778333

Starting e_i: 510
Model ind 579 epoch 510 head B head_i_epoch 0 batch 0: avg loss -1.725388 avg loss no lamb -1.725388 time 2019-02-02 15:04:53.630501
Model ind 579 epoch 510 head B head_i_epoch 0 batch 100: avg loss -1.707640 avg loss no lamb -1.707640 time 2019-02-02 15:07:49.814365
Model ind 579 epoch 510 head B head_i_epoch 0 batch 200: avg loss -1.730550 avg loss no lamb -1.730550 time 2019-02-02 15:10:47.964952
Model ind 579 epoch 510 head A head_i_epoch 0 batch 0: avg loss -3.354022 avg loss no lamb -3.354022 time 2019-02-02 15:13:43.986118
Model ind 579 epoch 510 head A head_i_epoch 0 batch 100: avg loss -3.451135 avg loss no lamb -3.451135 time 2019-02-02 15:16:42.799972
Model ind 579 epoch 510 head A head_i_epoch 0 batch 200: avg loss -3.399279 avg loss no lamb -3.399279 time 2019-02-02 15:19:40.587143
Pre: time 2019-02-02 15:23:03.150788: 
 	std: 0.003974681
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.2474, 0.2478, 0.23771666, 0.24756667, 0.24781667]
	train_accs: [0.2474, 0.2478, 0.23771666, 0.24756667, 0.24781667]
	best_train_sub_head: 4
	worst: 0.23771666
	avg: 0.24565999
	best: 0.24781667

Starting e_i: 511
Model ind 579 epoch 511 head B head_i_epoch 0 batch 0: avg loss -1.741748 avg loss no lamb -1.741748 time 2019-02-02 15:23:11.351046
Model ind 579 epoch 511 head B head_i_epoch 0 batch 100: avg loss -1.747244 avg loss no lamb -1.747244 time 2019-02-02 15:26:07.598079
Model ind 579 epoch 511 head B head_i_epoch 0 batch 200: avg loss -1.717793 avg loss no lamb -1.717793 time 2019-02-02 15:29:04.498315
Model ind 579 epoch 511 head A head_i_epoch 0 batch 0: avg loss -3.421237 avg loss no lamb -3.421237 time 2019-02-02 15:32:00.478037
Model ind 579 epoch 511 head A head_i_epoch 0 batch 100: avg loss -3.403313 avg loss no lamb -3.403313 time 2019-02-02 15:34:58.839544
Model ind 579 epoch 511 head A head_i_epoch 0 batch 200: avg loss -3.353819 avg loss no lamb -3.353819 time 2019-02-02 15:37:56.444870
Pre: time 2019-02-02 15:41:19.431201: 
 	std: 0.0047767456
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.246, 0.2469, 0.23428333, 0.24615, 0.24568333]
	train_accs: [0.246, 0.2469, 0.23428333, 0.24615, 0.24568333]
	best_train_sub_head: 1
	worst: 0.23428333
	avg: 0.24380334
	best: 0.2469

Starting e_i: 512
Model ind 579 epoch 512 head B head_i_epoch 0 batch 0: avg loss -1.821269 avg loss no lamb -1.821269 time 2019-02-02 15:41:23.176726
Model ind 579 epoch 512 head B head_i_epoch 0 batch 100: avg loss -1.788213 avg loss no lamb -1.788213 time 2019-02-02 15:44:20.123519
Model ind 579 epoch 512 head B head_i_epoch 0 batch 200: avg loss -1.740319 avg loss no lamb -1.740319 time 2019-02-02 15:47:18.379427
Model ind 579 epoch 512 head A head_i_epoch 0 batch 0: avg loss -3.344327 avg loss no lamb -3.344327 time 2019-02-02 15:50:16.578177
Model ind 579 epoch 512 head A head_i_epoch 0 batch 100: avg loss -3.373131 avg loss no lamb -3.373131 time 2019-02-02 15:53:15.129343
Model ind 579 epoch 512 head A head_i_epoch 0 batch 200: avg loss -3.351179 avg loss no lamb -3.351179 time 2019-02-02 15:56:14.335715
Pre: time 2019-02-02 15:59:38.900018: 
 	std: 0.004535034
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24826667, 0.24791667, 0.23656666, 0.24763334, 0.24775]
	train_accs: [0.24826667, 0.24791667, 0.23656666, 0.24763334, 0.24775]
	best_train_sub_head: 0
	worst: 0.23656666
	avg: 0.24562666
	best: 0.24826667

Starting e_i: 513
Model ind 579 epoch 513 head B head_i_epoch 0 batch 0: avg loss -1.733217 avg loss no lamb -1.733217 time 2019-02-02 15:59:42.267238
Model ind 579 epoch 513 head B head_i_epoch 0 batch 100: avg loss -1.728606 avg loss no lamb -1.728606 time 2019-02-02 16:02:40.388838
Model ind 579 epoch 513 head B head_i_epoch 0 batch 200: avg loss -1.713507 avg loss no lamb -1.713507 time 2019-02-02 16:05:39.228907
Model ind 579 epoch 513 head A head_i_epoch 0 batch 0: avg loss -3.372905 avg loss no lamb -3.372905 time 2019-02-02 16:08:35.681597
Model ind 579 epoch 513 head A head_i_epoch 0 batch 100: avg loss -3.471690 avg loss no lamb -3.471690 time 2019-02-02 16:11:34.046921
Model ind 579 epoch 513 head A head_i_epoch 0 batch 200: avg loss -3.424110 avg loss no lamb -3.424110 time 2019-02-02 16:14:33.698993
Pre: time 2019-02-02 16:17:56.499544: 
 	std: 0.004707785
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 5), (12, 13), (13, 18), (14, 1), (15, 15), (16, 6), (17, 3), (18, 19), (19, 12)]
	test_accs: [0.24543333, 0.24601667, 0.23408334, 0.24576667, 0.24613333]
	train_accs: [0.24543333, 0.24601667, 0.23408334, 0.24576667, 0.24613333]
	best_train_sub_head: 4
	worst: 0.23408334
	avg: 0.24348667
	best: 0.24613333

Starting e_i: 514
Model ind 579 epoch 514 head B head_i_epoch 0 batch 0: avg loss -1.745580 avg loss no lamb -1.745580 time 2019-02-02 16:17:59.961509
Model ind 579 epoch 514 head B head_i_epoch 0 batch 100: avg loss -1.836051 avg loss no lamb -1.836051 time 2019-02-02 16:20:55.807663
Model ind 579 epoch 514 head B head_i_epoch 0 batch 200: avg loss -1.721579 avg loss no lamb -1.721579 time 2019-02-02 16:23:52.088940
Model ind 579 epoch 514 head A head_i_epoch 0 batch 0: avg loss -3.336730 avg loss no lamb -3.336730 time 2019-02-02 16:26:49.828491
Model ind 579 epoch 514 head A head_i_epoch 0 batch 100: avg loss -3.443391 avg loss no lamb -3.443391 time 2019-02-02 16:29:48.671370
Model ind 579 epoch 514 head A head_i_epoch 0 batch 200: avg loss -3.401897 avg loss no lamb -3.401897 time 2019-02-02 16:32:46.985771
Pre: time 2019-02-02 16:36:11.880020: 
 	std: 0.004577879
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2438, 0.24553333, 0.23403333, 0.24631667, 0.24551667]
	train_accs: [0.2438, 0.24553333, 0.23403333, 0.24631667, 0.24551667]
	best_train_sub_head: 3
	worst: 0.23403333
	avg: 0.24304001
	best: 0.24631667

Starting e_i: 515
Model ind 579 epoch 515 head B head_i_epoch 0 batch 0: avg loss -1.703253 avg loss no lamb -1.703253 time 2019-02-02 16:36:15.447295
Model ind 579 epoch 515 head B head_i_epoch 0 batch 100: avg loss -1.749609 avg loss no lamb -1.749609 time 2019-02-02 16:39:12.379370
Model ind 579 epoch 515 head B head_i_epoch 0 batch 200: avg loss -1.671222 avg loss no lamb -1.671222 time 2019-02-02 16:42:09.904480
Model ind 579 epoch 515 head A head_i_epoch 0 batch 0: avg loss -3.371241 avg loss no lamb -3.371241 time 2019-02-02 16:45:08.295853
Model ind 579 epoch 515 head A head_i_epoch 0 batch 100: avg loss -3.361703 avg loss no lamb -3.361703 time 2019-02-02 16:48:06.373261
Model ind 579 epoch 515 head A head_i_epoch 0 batch 200: avg loss -3.438550 avg loss no lamb -3.438550 time 2019-02-02 16:51:05.828144
Pre: time 2019-02-02 16:54:28.830870: 
 	std: 0.004759116
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24401666, 0.24536666, 0.23415, 0.24703333, 0.2466]
	train_accs: [0.24401666, 0.24536666, 0.23415, 0.24703333, 0.2466]
	best_train_sub_head: 3
	worst: 0.23415
	avg: 0.24343333
	best: 0.24703333

Starting e_i: 516
Model ind 579 epoch 516 head B head_i_epoch 0 batch 0: avg loss -1.770308 avg loss no lamb -1.770308 time 2019-02-02 16:54:32.649809
Model ind 579 epoch 516 head B head_i_epoch 0 batch 100: avg loss -1.693056 avg loss no lamb -1.693056 time 2019-02-02 16:57:30.884161
Model ind 579 epoch 516 head B head_i_epoch 0 batch 200: avg loss -1.790173 avg loss no lamb -1.790173 time 2019-02-02 17:00:27.085170
Model ind 579 epoch 516 head A head_i_epoch 0 batch 0: avg loss -3.386057 avg loss no lamb -3.386057 time 2019-02-02 17:03:24.854842
Model ind 579 epoch 516 head A head_i_epoch 0 batch 100: avg loss -3.356001 avg loss no lamb -3.356001 time 2019-02-02 17:06:22.237544
Model ind 579 epoch 516 head A head_i_epoch 0 batch 200: avg loss -3.393492 avg loss no lamb -3.393492 time 2019-02-02 17:09:20.008149
Pre: time 2019-02-02 17:12:43.012778: 
 	std: 0.0039730375
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2453, 0.24516666, 0.23548333, 0.24575, 0.2454]
	train_accs: [0.2453, 0.24516666, 0.23548333, 0.24575, 0.2454]
	best_train_sub_head: 3
	worst: 0.23548333
	avg: 0.24342
	best: 0.24575

Starting e_i: 517
Model ind 579 epoch 517 head B head_i_epoch 0 batch 0: avg loss -1.788095 avg loss no lamb -1.788095 time 2019-02-02 17:12:46.602895
Model ind 579 epoch 517 head B head_i_epoch 0 batch 100: avg loss -1.802869 avg loss no lamb -1.802869 time 2019-02-02 17:15:43.635055
Model ind 579 epoch 517 head B head_i_epoch 0 batch 200: avg loss -1.785694 avg loss no lamb -1.785694 time 2019-02-02 17:18:39.562385
Model ind 579 epoch 517 head A head_i_epoch 0 batch 0: avg loss -3.372720 avg loss no lamb -3.372720 time 2019-02-02 17:21:36.552562
Model ind 579 epoch 517 head A head_i_epoch 0 batch 100: avg loss -3.400698 avg loss no lamb -3.400698 time 2019-02-02 17:24:35.088077
Model ind 579 epoch 517 head A head_i_epoch 0 batch 200: avg loss -3.398860 avg loss no lamb -3.398860 time 2019-02-02 17:27:32.615560
Pre: time 2019-02-02 17:30:55.042574: 
 	std: 0.0044517065
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24303333, 0.24238333, 0.2318, 0.24313334, 0.24308333]
	train_accs: [0.24303333, 0.24238333, 0.2318, 0.24313334, 0.24308333]
	best_train_sub_head: 3
	worst: 0.2318
	avg: 0.24068668
	best: 0.24313334

Starting e_i: 518
Model ind 579 epoch 518 head B head_i_epoch 0 batch 0: avg loss -1.794995 avg loss no lamb -1.794995 time 2019-02-02 17:30:58.313848
Model ind 579 epoch 518 head B head_i_epoch 0 batch 100: avg loss -1.739325 avg loss no lamb -1.739325 time 2019-02-02 17:33:55.156666
Model ind 579 epoch 518 head B head_i_epoch 0 batch 200: avg loss -1.802356 avg loss no lamb -1.802356 time 2019-02-02 17:36:53.504010
Model ind 579 epoch 518 head A head_i_epoch 0 batch 0: avg loss -3.424677 avg loss no lamb -3.424677 time 2019-02-02 17:39:51.995697
Model ind 579 epoch 518 head A head_i_epoch 0 batch 100: avg loss -3.340960 avg loss no lamb -3.340960 time 2019-02-02 17:42:49.330106
Model ind 579 epoch 518 head A head_i_epoch 0 batch 200: avg loss -3.382391 avg loss no lamb -3.382391 time 2019-02-02 17:45:50.298002
Pre: time 2019-02-02 17:49:13.049547: 
 	std: 0.0040088026
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24481666, 0.24491666, 0.23595, 0.24675, 0.24658333]
	train_accs: [0.24481666, 0.24491666, 0.23595, 0.24675, 0.24658333]
	best_train_sub_head: 3
	worst: 0.23595
	avg: 0.24380334
	best: 0.24675

Starting e_i: 519
Model ind 579 epoch 519 head B head_i_epoch 0 batch 0: avg loss -1.788898 avg loss no lamb -1.788898 time 2019-02-02 17:49:16.576575
Model ind 579 epoch 519 head B head_i_epoch 0 batch 100: avg loss -1.765269 avg loss no lamb -1.765269 time 2019-02-02 17:52:12.972793
Model ind 579 epoch 519 head B head_i_epoch 0 batch 200: avg loss -1.705614 avg loss no lamb -1.705614 time 2019-02-02 17:55:10.444152
Model ind 579 epoch 519 head A head_i_epoch 0 batch 0: avg loss -3.362814 avg loss no lamb -3.362814 time 2019-02-02 17:58:08.337239
Model ind 579 epoch 519 head A head_i_epoch 0 batch 100: avg loss -3.375995 avg loss no lamb -3.375995 time 2019-02-02 18:01:07.597798
Model ind 579 epoch 519 head A head_i_epoch 0 batch 200: avg loss -3.404947 avg loss no lamb -3.404947 time 2019-02-02 18:04:06.039807
Pre: time 2019-02-02 18:07:32.116926: 
 	std: 0.0037196074
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.24223334, 0.24135, 0.23326667, 0.24305, 0.24308333]
	train_accs: [0.24223334, 0.24135, 0.23326667, 0.24305, 0.24308333]
	best_train_sub_head: 4
	worst: 0.23326667
	avg: 0.24059665
	best: 0.24308333

Starting e_i: 520
Model ind 579 epoch 520 head B head_i_epoch 0 batch 0: avg loss -1.643354 avg loss no lamb -1.643354 time 2019-02-02 18:07:35.858343
Model ind 579 epoch 520 head B head_i_epoch 0 batch 100: avg loss -1.679415 avg loss no lamb -1.679415 time 2019-02-02 18:10:33.357862
Model ind 579 epoch 520 head B head_i_epoch 0 batch 200: avg loss -1.766306 avg loss no lamb -1.766306 time 2019-02-02 18:13:30.552364
Model ind 579 epoch 520 head A head_i_epoch 0 batch 0: avg loss -3.412866 avg loss no lamb -3.412866 time 2019-02-02 18:16:27.065833
Model ind 579 epoch 520 head A head_i_epoch 0 batch 100: avg loss -3.376592 avg loss no lamb -3.376592 time 2019-02-02 18:19:25.322138
Model ind 579 epoch 520 head A head_i_epoch 0 batch 200: avg loss -3.441431 avg loss no lamb -3.441431 time 2019-02-02 18:22:25.081098
Pre: time 2019-02-02 18:25:50.670018: 
 	std: 0.0038886834
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.249, 0.2488, 0.24041666, 0.25098333, 0.25075]
	train_accs: [0.249, 0.2488, 0.24041666, 0.25098333, 0.25075]
	best_train_sub_head: 3
	worst: 0.24041666
	avg: 0.24798998
	best: 0.25098333

Starting e_i: 521
Model ind 579 epoch 521 head B head_i_epoch 0 batch 0: avg loss -1.714765 avg loss no lamb -1.714765 time 2019-02-02 18:26:07.308329
Model ind 579 epoch 521 head B head_i_epoch 0 batch 100: avg loss -1.789039 avg loss no lamb -1.789039 time 2019-02-02 18:29:06.453355
Model ind 579 epoch 521 head B head_i_epoch 0 batch 200: avg loss -1.734683 avg loss no lamb -1.734683 time 2019-02-02 18:32:05.319396
Model ind 579 epoch 521 head A head_i_epoch 0 batch 0: avg loss -3.405467 avg loss no lamb -3.405467 time 2019-02-02 18:35:04.706975
Model ind 579 epoch 521 head A head_i_epoch 0 batch 100: avg loss -3.414062 avg loss no lamb -3.414062 time 2019-02-02 18:38:03.641374
Model ind 579 epoch 521 head A head_i_epoch 0 batch 200: avg loss -3.406279 avg loss no lamb -3.406279 time 2019-02-02 18:41:01.877014
Pre: time 2019-02-02 18:44:24.397056: 
 	std: 0.0041640075
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24583334, 0.2449, 0.23541667, 0.2462, 0.24611667]
	train_accs: [0.24583334, 0.2449, 0.23541667, 0.2462, 0.24611667]
	best_train_sub_head: 3
	worst: 0.23541667
	avg: 0.24369332
	best: 0.2462

Starting e_i: 522
Model ind 579 epoch 522 head B head_i_epoch 0 batch 0: avg loss -1.746642 avg loss no lamb -1.746642 time 2019-02-02 18:44:27.707094
Model ind 579 epoch 522 head B head_i_epoch 0 batch 100: avg loss -1.764902 avg loss no lamb -1.764902 time 2019-02-02 18:47:25.374875
Model ind 579 epoch 522 head B head_i_epoch 0 batch 200: avg loss -1.774952 avg loss no lamb -1.774952 time 2019-02-02 18:50:21.975230
Model ind 579 epoch 522 head A head_i_epoch 0 batch 0: avg loss -3.359873 avg loss no lamb -3.359873 time 2019-02-02 18:53:19.380005
Model ind 579 epoch 522 head A head_i_epoch 0 batch 100: avg loss -3.317493 avg loss no lamb -3.317493 time 2019-02-02 18:56:16.892216
Model ind 579 epoch 522 head A head_i_epoch 0 batch 200: avg loss -3.387934 avg loss no lamb -3.387934 time 2019-02-02 18:59:14.563422
Pre: time 2019-02-02 19:02:37.526914: 
 	std: 0.0044954233
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24813333, 0.24728334, 0.23666666, 0.24845, 0.24756667]
	train_accs: [0.24813333, 0.24728334, 0.23666666, 0.24845, 0.24756667]
	best_train_sub_head: 3
	worst: 0.23666666
	avg: 0.24561998
	best: 0.24845

Starting e_i: 523
Model ind 579 epoch 523 head B head_i_epoch 0 batch 0: avg loss -1.798567 avg loss no lamb -1.798567 time 2019-02-02 19:02:41.109130
Model ind 579 epoch 523 head B head_i_epoch 0 batch 100: avg loss -1.745371 avg loss no lamb -1.745371 time 2019-02-02 19:05:37.734219
Model ind 579 epoch 523 head B head_i_epoch 0 batch 200: avg loss -1.696320 avg loss no lamb -1.696320 time 2019-02-02 19:08:34.185544
Model ind 579 epoch 523 head A head_i_epoch 0 batch 0: avg loss -3.326599 avg loss no lamb -3.326599 time 2019-02-02 19:11:32.701290
Model ind 579 epoch 523 head A head_i_epoch 0 batch 100: avg loss -3.425640 avg loss no lamb -3.425640 time 2019-02-02 19:14:31.208068
Model ind 579 epoch 523 head A head_i_epoch 0 batch 200: avg loss -3.359547 avg loss no lamb -3.359547 time 2019-02-02 19:17:30.287138
Pre: time 2019-02-02 19:20:53.595811: 
 	std: 0.0037819245
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24553333, 0.24611667, 0.23708333, 0.2471, 0.24696666]
	train_accs: [0.24553333, 0.24611667, 0.23708333, 0.2471, 0.24696666]
	best_train_sub_head: 3
	worst: 0.23708333
	avg: 0.24456
	best: 0.2471

Starting e_i: 524
Model ind 579 epoch 524 head B head_i_epoch 0 batch 0: avg loss -1.790111 avg loss no lamb -1.790111 time 2019-02-02 19:20:56.868959
Model ind 579 epoch 524 head B head_i_epoch 0 batch 100: avg loss -1.781540 avg loss no lamb -1.781540 time 2019-02-02 19:23:53.575624
Model ind 579 epoch 524 head B head_i_epoch 0 batch 200: avg loss -1.729751 avg loss no lamb -1.729751 time 2019-02-02 19:26:53.006201
Model ind 579 epoch 524 head A head_i_epoch 0 batch 0: avg loss -3.373606 avg loss no lamb -3.373606 time 2019-02-02 19:29:49.796627
Model ind 579 epoch 524 head A head_i_epoch 0 batch 100: avg loss -3.353003 avg loss no lamb -3.353003 time 2019-02-02 19:32:48.277275
Model ind 579 epoch 524 head A head_i_epoch 0 batch 200: avg loss -3.367973 avg loss no lamb -3.367973 time 2019-02-02 19:35:46.773520
Pre: time 2019-02-02 19:39:11.022232: 
 	std: 0.004312532
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 5), (12, 13), (13, 18), (14, 1), (15, 15), (16, 6), (17, 3), (18, 19), (19, 12)]
	test_accs: [0.2424, 0.24156667, 0.23158333, 0.2424, 0.24288334]
	train_accs: [0.2424, 0.24156667, 0.23158333, 0.2424, 0.24288334]
	best_train_sub_head: 4
	worst: 0.23158333
	avg: 0.24016666
	best: 0.24288334

Starting e_i: 525
Model ind 579 epoch 525 head B head_i_epoch 0 batch 0: avg loss -1.738482 avg loss no lamb -1.738482 time 2019-02-02 19:39:14.401982
Model ind 579 epoch 525 head B head_i_epoch 0 batch 100: avg loss -1.700864 avg loss no lamb -1.700864 time 2019-02-02 19:42:12.901401
Model ind 579 epoch 525 head B head_i_epoch 0 batch 200: avg loss -1.761773 avg loss no lamb -1.761773 time 2019-02-02 19:45:11.000326
Model ind 579 epoch 525 head A head_i_epoch 0 batch 0: avg loss -3.334245 avg loss no lamb -3.334245 time 2019-02-02 19:48:08.942788
Model ind 579 epoch 525 head A head_i_epoch 0 batch 100: avg loss -3.396770 avg loss no lamb -3.396770 time 2019-02-02 19:51:07.382537
Model ind 579 epoch 525 head A head_i_epoch 0 batch 200: avg loss -3.418810 avg loss no lamb -3.418810 time 2019-02-02 19:54:05.641748
Pre: time 2019-02-02 19:57:27.982836: 
 	std: 0.003709828
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24901667, 0.24795, 0.23918334, 0.2486, 0.24806666]
	train_accs: [0.24901667, 0.24795, 0.23918334, 0.2486, 0.24806666]
	best_train_sub_head: 0
	worst: 0.23918334
	avg: 0.24656335
	best: 0.24901667

Starting e_i: 526
Model ind 579 epoch 526 head B head_i_epoch 0 batch 0: avg loss -1.788936 avg loss no lamb -1.788936 time 2019-02-02 19:57:31.861269
Model ind 579 epoch 526 head B head_i_epoch 0 batch 100: avg loss -1.763934 avg loss no lamb -1.763934 time 2019-02-02 20:00:28.988080
Model ind 579 epoch 526 head B head_i_epoch 0 batch 200: avg loss -1.767986 avg loss no lamb -1.767986 time 2019-02-02 20:03:25.726155
Model ind 579 epoch 526 head A head_i_epoch 0 batch 0: avg loss -3.328936 avg loss no lamb -3.328936 time 2019-02-02 20:06:21.931875
Model ind 579 epoch 526 head A head_i_epoch 0 batch 100: avg loss -3.382237 avg loss no lamb -3.382237 time 2019-02-02 20:09:19.437586
Model ind 579 epoch 526 head A head_i_epoch 0 batch 200: avg loss -3.434487 avg loss no lamb -3.434487 time 2019-02-02 20:12:17.134993
Pre: time 2019-02-02 20:15:39.610360: 
 	std: 0.0034606562
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24433333, 0.24251667, 0.23513333, 0.2439, 0.24385]
	train_accs: [0.24433333, 0.24251667, 0.23513333, 0.2439, 0.24385]
	best_train_sub_head: 0
	worst: 0.23513333
	avg: 0.24194665
	best: 0.24433333

Starting e_i: 527
Model ind 579 epoch 527 head B head_i_epoch 0 batch 0: avg loss -1.703589 avg loss no lamb -1.703589 time 2019-02-02 20:15:42.926414
Model ind 579 epoch 527 head B head_i_epoch 0 batch 100: avg loss -1.845991 avg loss no lamb -1.845991 time 2019-02-02 20:18:40.347452
Model ind 579 epoch 527 head B head_i_epoch 0 batch 200: avg loss -1.718847 avg loss no lamb -1.718847 time 2019-02-02 20:21:36.362047
Model ind 579 epoch 527 head A head_i_epoch 0 batch 0: avg loss -3.391607 avg loss no lamb -3.391607 time 2019-02-02 20:24:34.312169
Model ind 579 epoch 527 head A head_i_epoch 0 batch 100: avg loss -3.454038 avg loss no lamb -3.454038 time 2019-02-02 20:27:32.025545
Model ind 579 epoch 527 head A head_i_epoch 0 batch 200: avg loss -3.394610 avg loss no lamb -3.394610 time 2019-02-02 20:30:30.081909
Pre: time 2019-02-02 20:33:52.176673: 
 	std: 0.004023055
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 2), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2438, 0.24191667, 0.23293333, 0.24298333, 0.24281667]
	train_accs: [0.2438, 0.24191667, 0.23293333, 0.24298333, 0.24281667]
	best_train_sub_head: 0
	worst: 0.23293333
	avg: 0.24089
	best: 0.2438

Starting e_i: 528
Model ind 579 epoch 528 head B head_i_epoch 0 batch 0: avg loss -1.815203 avg loss no lamb -1.815203 time 2019-02-02 20:33:55.998054
Model ind 579 epoch 528 head B head_i_epoch 0 batch 100: avg loss -1.750613 avg loss no lamb -1.750613 time 2019-02-02 20:36:52.933651
Model ind 579 epoch 528 head B head_i_epoch 0 batch 200: avg loss -1.748662 avg loss no lamb -1.748662 time 2019-02-02 20:39:49.542139
Model ind 579 epoch 528 head A head_i_epoch 0 batch 0: avg loss -3.328478 avg loss no lamb -3.328478 time 2019-02-02 20:42:47.278135
Model ind 579 epoch 528 head A head_i_epoch 0 batch 100: avg loss -3.325985 avg loss no lamb -3.325985 time 2019-02-02 20:45:45.216306
Model ind 579 epoch 528 head A head_i_epoch 0 batch 200: avg loss -3.344055 avg loss no lamb -3.344055 time 2019-02-02 20:48:44.046238
Pre: time 2019-02-02 20:52:05.976873: 
 	std: 0.0034900247
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 2), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 16), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24488333, 0.24328333, 0.23538333, 0.24406667, 0.24381667]
	train_accs: [0.24488333, 0.24328333, 0.23538333, 0.24406667, 0.24381667]
	best_train_sub_head: 0
	worst: 0.23538333
	avg: 0.24228665
	best: 0.24488333

Starting e_i: 529
Model ind 579 epoch 529 head B head_i_epoch 0 batch 0: avg loss -1.680641 avg loss no lamb -1.680641 time 2019-02-02 20:52:09.441612
Model ind 579 epoch 529 head B head_i_epoch 0 batch 100: avg loss -1.826168 avg loss no lamb -1.826168 time 2019-02-02 20:55:06.745461
Model ind 579 epoch 529 head B head_i_epoch 0 batch 200: avg loss -1.705600 avg loss no lamb -1.705600 time 2019-02-02 20:58:03.805043
Model ind 579 epoch 529 head A head_i_epoch 0 batch 0: avg loss -3.335887 avg loss no lamb -3.335887 time 2019-02-02 21:00:59.894127
Model ind 579 epoch 529 head A head_i_epoch 0 batch 100: avg loss -3.345312 avg loss no lamb -3.345312 time 2019-02-02 21:03:57.699998
Model ind 579 epoch 529 head A head_i_epoch 0 batch 200: avg loss -3.387763 avg loss no lamb -3.387763 time 2019-02-02 21:06:58.005032
Pre: time 2019-02-02 21:10:23.247073: 
 	std: 0.0030495075
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24323334, 0.24435, 0.23656666, 0.24478333, 0.24396667]
	train_accs: [0.24323334, 0.24435, 0.23656666, 0.24478333, 0.24396667]
	best_train_sub_head: 3
	worst: 0.23656666
	avg: 0.24258001
	best: 0.24478333

Starting e_i: 530
Model ind 579 epoch 530 head B head_i_epoch 0 batch 0: avg loss -1.812144 avg loss no lamb -1.812144 time 2019-02-02 21:10:27.461565
Model ind 579 epoch 530 head B head_i_epoch 0 batch 100: avg loss -1.785569 avg loss no lamb -1.785569 time 2019-02-02 21:13:24.465583
Model ind 579 epoch 530 head B head_i_epoch 0 batch 200: avg loss -1.723399 avg loss no lamb -1.723399 time 2019-02-02 21:16:21.315413
Model ind 579 epoch 530 head A head_i_epoch 0 batch 0: avg loss -3.320650 avg loss no lamb -3.320650 time 2019-02-02 21:19:19.380843
Model ind 579 epoch 530 head A head_i_epoch 0 batch 100: avg loss -3.399037 avg loss no lamb -3.399037 time 2019-02-02 21:22:16.146706
Model ind 579 epoch 530 head A head_i_epoch 0 batch 200: avg loss -3.394759 avg loss no lamb -3.394759 time 2019-02-02 21:25:13.721221
Pre: time 2019-02-02 21:28:37.212942: 
 	std: 0.003827442
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24616666, 0.24553333, 0.23636666, 0.24598333, 0.246]
	train_accs: [0.24616666, 0.24553333, 0.23636666, 0.24598333, 0.246]
	best_train_sub_head: 0
	worst: 0.23636666
	avg: 0.24401002
	best: 0.24616666

Starting e_i: 531
Model ind 579 epoch 531 head B head_i_epoch 0 batch 0: avg loss -1.762379 avg loss no lamb -1.762379 time 2019-02-02 21:28:46.827194
Model ind 579 epoch 531 head B head_i_epoch 0 batch 100: avg loss -1.711874 avg loss no lamb -1.711874 time 2019-02-02 21:31:44.131221
Model ind 579 epoch 531 head B head_i_epoch 0 batch 200: avg loss -1.766921 avg loss no lamb -1.766921 time 2019-02-02 21:34:42.146095
Model ind 579 epoch 531 head A head_i_epoch 0 batch 0: avg loss -3.358160 avg loss no lamb -3.358160 time 2019-02-02 21:37:39.566779
Model ind 579 epoch 531 head A head_i_epoch 0 batch 100: avg loss -3.404741 avg loss no lamb -3.404741 time 2019-02-02 21:40:37.562881
Model ind 579 epoch 531 head A head_i_epoch 0 batch 200: avg loss -3.371228 avg loss no lamb -3.371228 time 2019-02-02 21:43:35.170198
Pre: time 2019-02-02 21:46:57.284418: 
 	std: 0.0040940032
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 15), (3, 9), (4, 16), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 5), (12, 12), (13, 18), (14, 1), (15, 13), (16, 6), (17, 3), (18, 19), (19, 8)]
	test_accs: [0.24435, 0.24405, 0.23408334, 0.24441667, 0.24443333]
	train_accs: [0.24435, 0.24405, 0.23408334, 0.24441667, 0.24443333]
	best_train_sub_head: 4
	worst: 0.23408334
	avg: 0.24226665
	best: 0.24443333

Starting e_i: 532
Model ind 579 epoch 532 head B head_i_epoch 0 batch 0: avg loss -1.747144 avg loss no lamb -1.747144 time 2019-02-02 21:47:01.301264
Model ind 579 epoch 532 head B head_i_epoch 0 batch 100: avg loss -1.737709 avg loss no lamb -1.737709 time 2019-02-02 21:49:58.439702
Model ind 579 epoch 532 head B head_i_epoch 0 batch 200: avg loss -1.753617 avg loss no lamb -1.753617 time 2019-02-02 21:52:56.693352
Model ind 579 epoch 532 head A head_i_epoch 0 batch 0: avg loss -3.311978 avg loss no lamb -3.311978 time 2019-02-02 21:55:52.490770
Model ind 579 epoch 532 head A head_i_epoch 0 batch 100: avg loss -3.374898 avg loss no lamb -3.374898 time 2019-02-02 21:58:48.939914
Model ind 579 epoch 532 head A head_i_epoch 0 batch 200: avg loss -3.344098 avg loss no lamb -3.344098 time 2019-02-02 22:01:47.187215
Pre: time 2019-02-02 22:05:08.673951: 
 	std: 0.0039674332
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24463333, 0.24465, 0.23525, 0.2456, 0.24556667]
	train_accs: [0.24463333, 0.24465, 0.23525, 0.2456, 0.24556667]
	best_train_sub_head: 3
	worst: 0.23525
	avg: 0.24313998
	best: 0.2456

Starting e_i: 533
Model ind 579 epoch 533 head B head_i_epoch 0 batch 0: avg loss -1.734414 avg loss no lamb -1.734414 time 2019-02-02 22:05:12.131791
Model ind 579 epoch 533 head B head_i_epoch 0 batch 100: avg loss -1.774657 avg loss no lamb -1.774657 time 2019-02-02 22:08:08.921673
Model ind 579 epoch 533 head B head_i_epoch 0 batch 200: avg loss -1.752861 avg loss no lamb -1.752861 time 2019-02-02 22:11:05.362856
Model ind 579 epoch 533 head A head_i_epoch 0 batch 0: avg loss -3.369747 avg loss no lamb -3.369747 time 2019-02-02 22:14:00.965554
Model ind 579 epoch 533 head A head_i_epoch 0 batch 100: avg loss -3.392232 avg loss no lamb -3.392232 time 2019-02-02 22:16:58.922502
Model ind 579 epoch 533 head A head_i_epoch 0 batch 200: avg loss -3.433362 avg loss no lamb -3.433362 time 2019-02-02 22:19:58.750524
Pre: time 2019-02-02 22:23:23.065084: 
 	std: 0.00429878
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24393333, 0.2427, 0.23241666, 0.24281667, 0.24298333]
	train_accs: [0.24393333, 0.2427, 0.23241666, 0.24281667, 0.24298333]
	best_train_sub_head: 0
	worst: 0.23241666
	avg: 0.24096999
	best: 0.24393333

Starting e_i: 534
Model ind 579 epoch 534 head B head_i_epoch 0 batch 0: avg loss -1.718633 avg loss no lamb -1.718633 time 2019-02-02 22:23:27.039777
Model ind 579 epoch 534 head B head_i_epoch 0 batch 100: avg loss -1.680339 avg loss no lamb -1.680339 time 2019-02-02 22:26:25.024856
Model ind 579 epoch 534 head B head_i_epoch 0 batch 200: avg loss -1.731266 avg loss no lamb -1.731266 time 2019-02-02 22:29:21.132517
Model ind 579 epoch 534 head A head_i_epoch 0 batch 0: avg loss -3.344032 avg loss no lamb -3.344032 time 2019-02-02 22:32:16.791669
Model ind 579 epoch 534 head A head_i_epoch 0 batch 100: avg loss -3.368441 avg loss no lamb -3.368441 time 2019-02-02 22:35:16.371433
Model ind 579 epoch 534 head A head_i_epoch 0 batch 200: avg loss -3.421591 avg loss no lamb -3.421591 time 2019-02-02 22:38:13.610309
Pre: time 2019-02-02 22:41:37.556278: 
 	std: 0.0038036944
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24685, 0.24643333, 0.2372, 0.2469, 0.24661666]
	train_accs: [0.24685, 0.24643333, 0.2372, 0.2469, 0.24661666]
	best_train_sub_head: 3
	worst: 0.2372
	avg: 0.2448
	best: 0.2469

Starting e_i: 535
Model ind 579 epoch 535 head B head_i_epoch 0 batch 0: avg loss -1.775410 avg loss no lamb -1.775410 time 2019-02-02 22:41:41.013590
Model ind 579 epoch 535 head B head_i_epoch 0 batch 100: avg loss -1.687304 avg loss no lamb -1.687304 time 2019-02-02 22:44:38.129309
Model ind 579 epoch 535 head B head_i_epoch 0 batch 200: avg loss -1.711648 avg loss no lamb -1.711648 time 2019-02-02 22:47:35.562930
Model ind 579 epoch 535 head A head_i_epoch 0 batch 0: avg loss -3.325555 avg loss no lamb -3.325555 time 2019-02-02 22:50:34.531945
Model ind 579 epoch 535 head A head_i_epoch 0 batch 100: avg loss -3.402226 avg loss no lamb -3.402226 time 2019-02-02 22:53:32.914040
Model ind 579 epoch 535 head A head_i_epoch 0 batch 200: avg loss -3.345773 avg loss no lamb -3.345773 time 2019-02-02 22:56:31.854319
Pre: time 2019-02-02 22:59:55.371887: 
 	std: 0.0034424716
	best_train_sub_head_match: [(0, 18), (1, 1), (2, 14), (3, 0), (4, 12), (5, 4), (6, 8), (7, 6), (8, 13), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 16), (19, 11)]
	test_accs: [0.24335, 0.24181667, 0.23385, 0.24263333, 0.24131666]
	train_accs: [0.24335, 0.24181667, 0.23385, 0.24263333, 0.24131666]
	best_train_sub_head: 0
	worst: 0.23385
	avg: 0.24059334
	best: 0.24335

Starting e_i: 536
Model ind 579 epoch 536 head B head_i_epoch 0 batch 0: avg loss -1.866529 avg loss no lamb -1.866529 time 2019-02-02 22:59:59.430908
Model ind 579 epoch 536 head B head_i_epoch 0 batch 100: avg loss -1.693781 avg loss no lamb -1.693781 time 2019-02-02 23:02:56.429292
Model ind 579 epoch 536 head B head_i_epoch 0 batch 200: avg loss -1.782673 avg loss no lamb -1.782673 time 2019-02-02 23:05:51.976821
Model ind 579 epoch 536 head A head_i_epoch 0 batch 0: avg loss -3.386882 avg loss no lamb -3.386882 time 2019-02-02 23:08:49.185231
Model ind 579 epoch 536 head A head_i_epoch 0 batch 100: avg loss -3.440353 avg loss no lamb -3.440353 time 2019-02-02 23:11:47.281038
Model ind 579 epoch 536 head A head_i_epoch 0 batch 200: avg loss -3.387584 avg loss no lamb -3.387584 time 2019-02-02 23:14:45.356437
Pre: time 2019-02-02 23:18:07.864902: 
 	std: 0.004590321
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2463, 0.24485, 0.23381667, 0.24491666, 0.24475]
	train_accs: [0.2463, 0.24485, 0.23381667, 0.24491666, 0.24475]
	best_train_sub_head: 0
	worst: 0.23381667
	avg: 0.24292667
	best: 0.2463

Starting e_i: 537
Model ind 579 epoch 537 head B head_i_epoch 0 batch 0: avg loss -1.830562 avg loss no lamb -1.830562 time 2019-02-02 23:18:11.472224
Model ind 579 epoch 537 head B head_i_epoch 0 batch 100: avg loss -1.704565 avg loss no lamb -1.704565 time 2019-02-02 23:21:09.219982
Model ind 579 epoch 537 head B head_i_epoch 0 batch 200: avg loss -1.762177 avg loss no lamb -1.762177 time 2019-02-02 23:24:06.079965
Model ind 579 epoch 537 head A head_i_epoch 0 batch 0: avg loss -3.399345 avg loss no lamb -3.399345 time 2019-02-02 23:27:04.265936
Model ind 579 epoch 537 head A head_i_epoch 0 batch 100: avg loss -3.391771 avg loss no lamb -3.391771 time 2019-02-02 23:30:01.808135
Model ind 579 epoch 537 head A head_i_epoch 0 batch 200: avg loss -3.376094 avg loss no lamb -3.376094 time 2019-02-02 23:33:00.158870
Pre: time 2019-02-02 23:36:24.610335: 
 	std: 0.004243211
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 16), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 2), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24568333, 0.2455, 0.23535, 0.24655, 0.24595]
	train_accs: [0.24568333, 0.2455, 0.23535, 0.24655, 0.24595]
	best_train_sub_head: 3
	worst: 0.23535
	avg: 0.24380668
	best: 0.24655

Starting e_i: 538
Model ind 579 epoch 538 head B head_i_epoch 0 batch 0: avg loss -1.805726 avg loss no lamb -1.805726 time 2019-02-02 23:36:28.542318
Model ind 579 epoch 538 head B head_i_epoch 0 batch 100: avg loss -1.772853 avg loss no lamb -1.772853 time 2019-02-02 23:39:26.896557
Model ind 579 epoch 538 head B head_i_epoch 0 batch 200: avg loss -1.788660 avg loss no lamb -1.788660 time 2019-02-02 23:42:23.611711
Model ind 579 epoch 538 head A head_i_epoch 0 batch 0: avg loss -3.401096 avg loss no lamb -3.401096 time 2019-02-02 23:45:19.687375
Model ind 579 epoch 538 head A head_i_epoch 0 batch 100: avg loss -3.392957 avg loss no lamb -3.392957 time 2019-02-02 23:48:17.644249
Model ind 579 epoch 538 head A head_i_epoch 0 batch 200: avg loss -3.429173 avg loss no lamb -3.429173 time 2019-02-02 23:51:17.057174
Pre: time 2019-02-02 23:54:39.393055: 
 	std: 0.00315402
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 5), (12, 13), (13, 18), (14, 1), (15, 15), (16, 6), (17, 3), (18, 19), (19, 12)]
	test_accs: [0.24093333, 0.24138333, 0.23365, 0.24181667, 0.24183333]
	train_accs: [0.24093333, 0.24138333, 0.23365, 0.24181667, 0.24183333]
	best_train_sub_head: 4
	worst: 0.23365
	avg: 0.23992333
	best: 0.24183333

Starting e_i: 539
Model ind 579 epoch 539 head B head_i_epoch 0 batch 0: avg loss -1.734990 avg loss no lamb -1.734990 time 2019-02-02 23:54:42.811177
Model ind 579 epoch 539 head B head_i_epoch 0 batch 100: avg loss -1.683694 avg loss no lamb -1.683694 time 2019-02-02 23:57:41.558353
Model ind 579 epoch 539 head B head_i_epoch 0 batch 200: avg loss -1.775391 avg loss no lamb -1.775391 time 2019-02-03 00:00:41.486149
Model ind 579 epoch 539 head A head_i_epoch 0 batch 0: avg loss -3.442106 avg loss no lamb -3.442106 time 2019-02-03 00:03:38.961273
Model ind 579 epoch 539 head A head_i_epoch 0 batch 100: avg loss -3.391738 avg loss no lamb -3.391738 time 2019-02-03 00:06:36.358028
Model ind 579 epoch 539 head A head_i_epoch 0 batch 200: avg loss -3.402031 avg loss no lamb -3.402031 time 2019-02-03 00:09:35.072090
Pre: time 2019-02-03 00:12:58.323189: 
 	std: 0.0033095398
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2458, 0.246, 0.23795, 0.2465, 0.24648333]
	train_accs: [0.2458, 0.246, 0.23795, 0.2465, 0.24648333]
	best_train_sub_head: 3
	worst: 0.23795
	avg: 0.24454668
	best: 0.2465

Starting e_i: 540
Model ind 579 epoch 540 head B head_i_epoch 0 batch 0: avg loss -1.775380 avg loss no lamb -1.775380 time 2019-02-03 00:13:01.849502
Model ind 579 epoch 540 head B head_i_epoch 0 batch 100: avg loss -1.777761 avg loss no lamb -1.777761 time 2019-02-03 00:15:58.378557
Model ind 579 epoch 540 head B head_i_epoch 0 batch 200: avg loss -1.751888 avg loss no lamb -1.751888 time 2019-02-03 00:18:53.796943
Model ind 579 epoch 540 head A head_i_epoch 0 batch 0: avg loss -3.355787 avg loss no lamb -3.355787 time 2019-02-03 00:21:50.080364
Model ind 579 epoch 540 head A head_i_epoch 0 batch 100: avg loss -3.413453 avg loss no lamb -3.413453 time 2019-02-03 00:24:48.142744
Model ind 579 epoch 540 head A head_i_epoch 0 batch 200: avg loss -3.475566 avg loss no lamb -3.475566 time 2019-02-03 00:27:47.012800
Pre: time 2019-02-03 00:31:12.589243: 
 	std: 0.003593526
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24581666, 0.24556667, 0.23696667, 0.2464, 0.24591666]
	train_accs: [0.24581666, 0.24556667, 0.23696667, 0.2464, 0.24591666]
	best_train_sub_head: 3
	worst: 0.23696667
	avg: 0.24413332
	best: 0.2464

Starting e_i: 541
Model ind 579 epoch 541 head B head_i_epoch 0 batch 0: avg loss -1.762235 avg loss no lamb -1.762235 time 2019-02-03 00:31:19.772269
Model ind 579 epoch 541 head B head_i_epoch 0 batch 100: avg loss -1.735813 avg loss no lamb -1.735813 time 2019-02-03 00:34:16.697147
Model ind 579 epoch 541 head B head_i_epoch 0 batch 200: avg loss -1.851626 avg loss no lamb -1.851626 time 2019-02-03 00:37:13.514296
Model ind 579 epoch 541 head A head_i_epoch 0 batch 0: avg loss -3.377188 avg loss no lamb -3.377188 time 2019-02-03 00:40:13.069854
Model ind 579 epoch 541 head A head_i_epoch 0 batch 100: avg loss -3.445984 avg loss no lamb -3.445984 time 2019-02-03 00:43:11.138346
Model ind 579 epoch 541 head A head_i_epoch 0 batch 200: avg loss -3.398839 avg loss no lamb -3.398839 time 2019-02-03 00:46:10.250844
Pre: time 2019-02-03 00:49:32.382395: 
 	std: 0.0035970006
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24281667, 0.24305, 0.23435, 0.2439, 0.24341667]
	train_accs: [0.24281667, 0.24305, 0.23435, 0.2439, 0.24341667]
	best_train_sub_head: 3
	worst: 0.23435
	avg: 0.24150667
	best: 0.2439

Starting e_i: 542
Model ind 579 epoch 542 head B head_i_epoch 0 batch 0: avg loss -1.804659 avg loss no lamb -1.804659 time 2019-02-03 00:49:35.795993
Model ind 579 epoch 542 head B head_i_epoch 0 batch 100: avg loss -1.842300 avg loss no lamb -1.842300 time 2019-02-03 00:52:33.364320
Model ind 579 epoch 542 head B head_i_epoch 0 batch 200: avg loss -1.827665 avg loss no lamb -1.827665 time 2019-02-03 00:55:32.604293
Model ind 579 epoch 542 head A head_i_epoch 0 batch 0: avg loss -3.329540 avg loss no lamb -3.329540 time 2019-02-03 00:58:29.266479
Model ind 579 epoch 542 head A head_i_epoch 0 batch 100: avg loss -3.450401 avg loss no lamb -3.450401 time 2019-02-03 01:01:25.835645
Model ind 579 epoch 542 head A head_i_epoch 0 batch 200: avg loss -3.387673 avg loss no lamb -3.387673 time 2019-02-03 01:04:24.221185
Pre: time 2019-02-03 01:07:46.929905: 
 	std: 0.0041356804
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24436666, 0.24468334, 0.2346, 0.2459, 0.24443333]
	train_accs: [0.24436666, 0.24468334, 0.2346, 0.2459, 0.24443333]
	best_train_sub_head: 3
	worst: 0.2346
	avg: 0.24279666
	best: 0.2459

Starting e_i: 543
Model ind 579 epoch 543 head B head_i_epoch 0 batch 0: avg loss -1.711687 avg loss no lamb -1.711687 time 2019-02-03 01:07:50.898255
Model ind 579 epoch 543 head B head_i_epoch 0 batch 100: avg loss -1.793567 avg loss no lamb -1.793567 time 2019-02-03 01:10:46.093567
Model ind 579 epoch 543 head B head_i_epoch 0 batch 200: avg loss -1.675993 avg loss no lamb -1.675993 time 2019-02-03 01:13:41.940639
Model ind 579 epoch 543 head A head_i_epoch 0 batch 0: avg loss -3.429559 avg loss no lamb -3.429559 time 2019-02-03 01:16:37.646602
Model ind 579 epoch 543 head A head_i_epoch 0 batch 100: avg loss -3.406598 avg loss no lamb -3.406598 time 2019-02-03 01:19:36.937180
Model ind 579 epoch 543 head A head_i_epoch 0 batch 200: avg loss -3.486685 avg loss no lamb -3.486685 time 2019-02-03 01:22:36.921315
Pre: time 2019-02-03 01:25:58.958771: 
 	std: 0.0041525955
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24663334, 0.24485, 0.23543334, 0.24628334, 0.24485]
	train_accs: [0.24663334, 0.24485, 0.23543334, 0.24628334, 0.24485]
	best_train_sub_head: 0
	worst: 0.23543334
	avg: 0.24361
	best: 0.24663334

Starting e_i: 544
Model ind 579 epoch 544 head B head_i_epoch 0 batch 0: avg loss -1.804384 avg loss no lamb -1.804384 time 2019-02-03 01:26:02.249159
Model ind 579 epoch 544 head B head_i_epoch 0 batch 100: avg loss -1.766294 avg loss no lamb -1.766294 time 2019-02-03 01:28:59.332889
Model ind 579 epoch 544 head B head_i_epoch 0 batch 200: avg loss -1.836690 avg loss no lamb -1.836690 time 2019-02-03 01:31:57.666092
Model ind 579 epoch 544 head A head_i_epoch 0 batch 0: avg loss -3.315246 avg loss no lamb -3.315246 time 2019-02-03 01:34:56.247204
Model ind 579 epoch 544 head A head_i_epoch 0 batch 100: avg loss -3.438335 avg loss no lamb -3.438335 time 2019-02-03 01:37:53.164502
Model ind 579 epoch 544 head A head_i_epoch 0 batch 200: avg loss -3.438113 avg loss no lamb -3.438113 time 2019-02-03 01:40:50.656704
Pre: time 2019-02-03 01:44:14.563596: 
 	std: 0.003843425
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2414, 0.24183333, 0.23238334, 0.24285, 0.24155]
	train_accs: [0.2414, 0.24183333, 0.23238334, 0.24285, 0.24155]
	best_train_sub_head: 3
	worst: 0.23238334
	avg: 0.24000335
	best: 0.24285

Starting e_i: 545
Model ind 579 epoch 545 head B head_i_epoch 0 batch 0: avg loss -1.795879 avg loss no lamb -1.795879 time 2019-02-03 01:44:18.426740
Model ind 579 epoch 545 head B head_i_epoch 0 batch 100: avg loss -1.731009 avg loss no lamb -1.731009 time 2019-02-03 01:47:14.076097
Model ind 579 epoch 545 head B head_i_epoch 0 batch 200: avg loss -1.775660 avg loss no lamb -1.775660 time 2019-02-03 01:50:10.696768
Model ind 579 epoch 545 head A head_i_epoch 0 batch 0: avg loss -3.353437 avg loss no lamb -3.353437 time 2019-02-03 01:53:07.380714
Model ind 579 epoch 545 head A head_i_epoch 0 batch 100: avg loss -3.429094 avg loss no lamb -3.429094 time 2019-02-03 01:56:05.568089
Model ind 579 epoch 545 head A head_i_epoch 0 batch 200: avg loss -3.342204 avg loss no lamb -3.342204 time 2019-02-03 01:59:03.099031
Pre: time 2019-02-03 02:02:26.052455: 
 	std: 0.0040986054
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24415, 0.24326667, 0.23393333, 0.24515, 0.24366666]
	train_accs: [0.24415, 0.24326667, 0.23393333, 0.24515, 0.24366666]
	best_train_sub_head: 3
	worst: 0.23393333
	avg: 0.24203333
	best: 0.24515

Starting e_i: 546
Model ind 579 epoch 546 head B head_i_epoch 0 batch 0: avg loss -1.747457 avg loss no lamb -1.747457 time 2019-02-03 02:02:29.557397
Model ind 579 epoch 546 head B head_i_epoch 0 batch 100: avg loss -1.722061 avg loss no lamb -1.722061 time 2019-02-03 02:05:27.191116
Model ind 579 epoch 546 head B head_i_epoch 0 batch 200: avg loss -1.811819 avg loss no lamb -1.811819 time 2019-02-03 02:08:24.761846
Model ind 579 epoch 546 head A head_i_epoch 0 batch 0: avg loss -3.345275 avg loss no lamb -3.345275 time 2019-02-03 02:11:21.520233
Model ind 579 epoch 546 head A head_i_epoch 0 batch 100: avg loss -3.452444 avg loss no lamb -3.452444 time 2019-02-03 02:14:18.999273
Model ind 579 epoch 546 head A head_i_epoch 0 batch 200: avg loss -3.394043 avg loss no lamb -3.394043 time 2019-02-03 02:17:17.544514
Pre: time 2019-02-03 02:20:39.893001: 
 	std: 0.0035218806
	best_train_sub_head_match: [(0, 5), (1, 1), (2, 14), (3, 0), (4, 12), (5, 4), (6, 8), (7, 6), (8, 15), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 13), (15, 2), (16, 3), (17, 17), (18, 16), (19, 11)]
	test_accs: [0.2425, 0.24138333, 0.23328333, 0.24245, 0.24176666]
	train_accs: [0.2425, 0.24138333, 0.23328333, 0.24245, 0.24176666]
	best_train_sub_head: 0
	worst: 0.23328333
	avg: 0.24027666
	best: 0.2425

Starting e_i: 547
Model ind 579 epoch 547 head B head_i_epoch 0 batch 0: avg loss -1.802778 avg loss no lamb -1.802778 time 2019-02-03 02:20:43.705487
Model ind 579 epoch 547 head B head_i_epoch 0 batch 100: avg loss -1.706841 avg loss no lamb -1.706841 time 2019-02-03 02:23:39.600525
Model ind 579 epoch 547 head B head_i_epoch 0 batch 200: avg loss -1.813153 avg loss no lamb -1.813153 time 2019-02-03 02:26:34.556898
Model ind 579 epoch 547 head A head_i_epoch 0 batch 0: avg loss -3.428273 avg loss no lamb -3.428273 time 2019-02-03 02:29:32.850110
Model ind 579 epoch 547 head A head_i_epoch 0 batch 100: avg loss -3.388738 avg loss no lamb -3.388738 time 2019-02-03 02:32:30.451687
Model ind 579 epoch 547 head A head_i_epoch 0 batch 200: avg loss -3.377365 avg loss no lamb -3.377365 time 2019-02-03 02:35:28.522268
Pre: time 2019-02-03 02:38:51.532436: 
 	std: 0.0031506035
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24356666, 0.24443333, 0.23691666, 0.24535, 0.24518333]
	train_accs: [0.24356666, 0.24443333, 0.23691666, 0.24535, 0.24518333]
	best_train_sub_head: 3
	worst: 0.23691666
	avg: 0.24308999
	best: 0.24535

Starting e_i: 548
Model ind 579 epoch 548 head B head_i_epoch 0 batch 0: avg loss -1.773939 avg loss no lamb -1.773939 time 2019-02-03 02:38:54.873346
Model ind 579 epoch 548 head B head_i_epoch 0 batch 100: avg loss -1.687888 avg loss no lamb -1.687888 time 2019-02-03 02:41:50.877368
Model ind 579 epoch 548 head B head_i_epoch 0 batch 200: avg loss -1.787180 avg loss no lamb -1.787180 time 2019-02-03 02:44:48.312799
Model ind 579 epoch 548 head A head_i_epoch 0 batch 0: avg loss -3.415038 avg loss no lamb -3.415038 time 2019-02-03 02:47:45.978751
Model ind 579 epoch 548 head A head_i_epoch 0 batch 100: avg loss -3.471865 avg loss no lamb -3.471865 time 2019-02-03 02:50:44.834541
Model ind 579 epoch 548 head A head_i_epoch 0 batch 200: avg loss -3.410088 avg loss no lamb -3.410088 time 2019-02-03 02:53:43.970880
Pre: time 2019-02-03 02:57:08.284342: 
 	std: 0.0034167496
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 15), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.24375, 0.24458334, 0.23575, 0.24445, 0.24426667]
	train_accs: [0.24375, 0.24458334, 0.23575, 0.24445, 0.24426667]
	best_train_sub_head: 1
	worst: 0.23575
	avg: 0.24256
	best: 0.24458334

Starting e_i: 549
Model ind 579 epoch 549 head B head_i_epoch 0 batch 0: avg loss -1.688552 avg loss no lamb -1.688552 time 2019-02-03 02:57:12.224907
Model ind 579 epoch 549 head B head_i_epoch 0 batch 100: avg loss -1.755976 avg loss no lamb -1.755976 time 2019-02-03 03:00:10.594867
Model ind 579 epoch 549 head B head_i_epoch 0 batch 200: avg loss -1.842744 avg loss no lamb -1.842744 time 2019-02-03 03:03:08.132848
Model ind 579 epoch 549 head A head_i_epoch 0 batch 0: avg loss -3.383574 avg loss no lamb -3.383574 time 2019-02-03 03:06:04.459119
Model ind 579 epoch 549 head A head_i_epoch 0 batch 100: avg loss -3.425571 avg loss no lamb -3.425571 time 2019-02-03 03:09:01.366975
Model ind 579 epoch 549 head A head_i_epoch 0 batch 200: avg loss -3.412071 avg loss no lamb -3.412071 time 2019-02-03 03:11:59.078277
Pre: time 2019-02-03 03:15:21.511392: 
 	std: 0.003635671
	best_train_sub_head_match: [(0, 13), (1, 15), (2, 2), (3, 5), (4, 4), (5, 3), (6, 18), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24458334, 0.2444, 0.23545, 0.24475, 0.2444]
	train_accs: [0.24458334, 0.2444, 0.23545, 0.24475, 0.2444]
	best_train_sub_head: 3
	worst: 0.23545
	avg: 0.24271667
	best: 0.24475

Starting e_i: 550
Model ind 579 epoch 550 head B head_i_epoch 0 batch 0: avg loss -1.766329 avg loss no lamb -1.766329 time 2019-02-03 03:15:24.928286
Model ind 579 epoch 550 head B head_i_epoch 0 batch 100: avg loss -1.747221 avg loss no lamb -1.747221 time 2019-02-03 03:18:22.807176
Model ind 579 epoch 550 head B head_i_epoch 0 batch 200: avg loss -1.791300 avg loss no lamb -1.791300 time 2019-02-03 03:21:19.147802
Model ind 579 epoch 550 head A head_i_epoch 0 batch 0: avg loss -3.362335 avg loss no lamb -3.362335 time 2019-02-03 03:24:17.397242
Model ind 579 epoch 550 head A head_i_epoch 0 batch 100: avg loss -3.439755 avg loss no lamb -3.439755 time 2019-02-03 03:27:16.450793
Model ind 579 epoch 550 head A head_i_epoch 0 batch 200: avg loss -3.407022 avg loss no lamb -3.407022 time 2019-02-03 03:30:14.668552
Pre: time 2019-02-03 03:33:36.335577: 
 	std: 0.0033316903
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 7), (6, 8), (7, 11), (8, 3), (9, 16), (10, 15), (11, 17), (12, 18), (13, 1), (14, 5), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2456, 0.24568333, 0.23711666, 0.24541667, 0.245]
	train_accs: [0.2456, 0.24568333, 0.23711666, 0.24541667, 0.245]
	best_train_sub_head: 1
	worst: 0.23711666
	avg: 0.24376333
	best: 0.24568333

Starting e_i: 551
Model ind 579 epoch 551 head B head_i_epoch 0 batch 0: avg loss -1.826785 avg loss no lamb -1.826785 time 2019-02-03 03:33:44.149274
Model ind 579 epoch 551 head B head_i_epoch 0 batch 100: avg loss -1.743441 avg loss no lamb -1.743441 time 2019-02-03 03:36:40.608934
Model ind 579 epoch 551 head B head_i_epoch 0 batch 200: avg loss -1.809258 avg loss no lamb -1.809258 time 2019-02-03 03:39:38.434158
Model ind 579 epoch 551 head A head_i_epoch 0 batch 0: avg loss -3.337513 avg loss no lamb -3.337513 time 2019-02-03 03:42:35.863597
Model ind 579 epoch 551 head A head_i_epoch 0 batch 100: avg loss -3.437869 avg loss no lamb -3.437869 time 2019-02-03 03:45:35.270128
Model ind 579 epoch 551 head A head_i_epoch 0 batch 200: avg loss -3.440565 avg loss no lamb -3.440565 time 2019-02-03 03:48:33.472052
Pre: time 2019-02-03 03:51:55.806773: 
 	std: 0.0031372232
	best_train_sub_head_match: [(0, 13), (1, 15), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 18)]
	test_accs: [0.24513334, 0.24453333, 0.23706667, 0.24515, 0.24473333]
	train_accs: [0.24513334, 0.24453333, 0.23706667, 0.24515, 0.24473333]
	best_train_sub_head: 3
	worst: 0.23706667
	avg: 0.24332333
	best: 0.24515

Starting e_i: 552
Model ind 579 epoch 552 head B head_i_epoch 0 batch 0: avg loss -1.694731 avg loss no lamb -1.694731 time 2019-02-03 03:51:59.234914
Model ind 579 epoch 552 head B head_i_epoch 0 batch 100: avg loss -1.755615 avg loss no lamb -1.755615 time 2019-02-03 03:54:55.380923
Model ind 579 epoch 552 head B head_i_epoch 0 batch 200: avg loss -1.794572 avg loss no lamb -1.794572 time 2019-02-03 03:57:54.293746
Model ind 579 epoch 552 head A head_i_epoch 0 batch 0: avg loss -3.303604 avg loss no lamb -3.303604 time 2019-02-03 04:00:53.438002
Model ind 579 epoch 552 head A head_i_epoch 0 batch 100: avg loss -3.423658 avg loss no lamb -3.423658 time 2019-02-03 04:03:51.474769
Model ind 579 epoch 552 head A head_i_epoch 0 batch 200: avg loss -3.428759 avg loss no lamb -3.428759 time 2019-02-03 04:06:48.726094
Pre: time 2019-02-03 04:10:11.950226: 
 	std: 0.0038772062
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24563333, 0.24636666, 0.23643333, 0.24633333, 0.24608333]
	train_accs: [0.24563333, 0.24636666, 0.23643333, 0.24633333, 0.24608333]
	best_train_sub_head: 1
	worst: 0.23643333
	avg: 0.24417
	best: 0.24636666

Starting e_i: 553
Model ind 579 epoch 553 head B head_i_epoch 0 batch 0: avg loss -1.861609 avg loss no lamb -1.861609 time 2019-02-03 04:10:15.768465
Model ind 579 epoch 553 head B head_i_epoch 0 batch 100: avg loss -1.722307 avg loss no lamb -1.722307 time 2019-02-03 04:13:11.786069
Model ind 579 epoch 553 head B head_i_epoch 0 batch 200: avg loss -1.645702 avg loss no lamb -1.645702 time 2019-02-03 04:16:09.403308
Model ind 579 epoch 553 head A head_i_epoch 0 batch 0: avg loss -3.357685 avg loss no lamb -3.357685 time 2019-02-03 04:19:04.732814
Model ind 579 epoch 553 head A head_i_epoch 0 batch 100: avg loss -3.445591 avg loss no lamb -3.445591 time 2019-02-03 04:22:03.118643
Model ind 579 epoch 553 head A head_i_epoch 0 batch 200: avg loss -3.399314 avg loss no lamb -3.399314 time 2019-02-03 04:25:01.573954
Pre: time 2019-02-03 04:28:24.703475: 
 	std: 0.0039903843
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 7), (7, 10), (8, 14), (9, 15), (10, 11), (11, 5), (12, 0), (13, 18), (14, 1), (15, 13), (16, 6), (17, 3), (18, 19), (19, 12)]
	test_accs: [0.24325, 0.24323334, 0.23343334, 0.24311666, 0.24393333]
	train_accs: [0.24325, 0.24323334, 0.23343334, 0.24311666, 0.24393333]
	best_train_sub_head: 4
	worst: 0.23343334
	avg: 0.24139336
	best: 0.24393333

Starting e_i: 554
Model ind 579 epoch 554 head B head_i_epoch 0 batch 0: avg loss -1.710859 avg loss no lamb -1.710859 time 2019-02-03 04:28:28.159624
Model ind 579 epoch 554 head B head_i_epoch 0 batch 100: avg loss -1.680331 avg loss no lamb -1.680331 time 2019-02-03 04:31:27.073717
Model ind 579 epoch 554 head B head_i_epoch 0 batch 200: avg loss -1.783957 avg loss no lamb -1.783957 time 2019-02-03 04:34:25.445947
Model ind 579 epoch 554 head A head_i_epoch 0 batch 0: avg loss -3.298926 avg loss no lamb -3.298926 time 2019-02-03 04:37:21.665543
Model ind 579 epoch 554 head A head_i_epoch 0 batch 100: avg loss -3.429123 avg loss no lamb -3.429123 time 2019-02-03 04:40:20.145598
Model ind 579 epoch 554 head A head_i_epoch 0 batch 200: avg loss -3.444595 avg loss no lamb -3.444595 time 2019-02-03 04:43:18.121950
Pre: time 2019-02-03 04:46:40.875070: 
 	std: 0.0043646256
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.24675, 0.24751666, 0.23638333, 0.24725, 0.24756667]
	train_accs: [0.24675, 0.24751666, 0.23638333, 0.24725, 0.24756667]
	best_train_sub_head: 4
	worst: 0.23638333
	avg: 0.24509335
	best: 0.24756667

Starting e_i: 555
Model ind 579 epoch 555 head B head_i_epoch 0 batch 0: avg loss -1.711993 avg loss no lamb -1.711993 time 2019-02-03 04:46:44.847456
Model ind 579 epoch 555 head B head_i_epoch 0 batch 100: avg loss -1.668174 avg loss no lamb -1.668174 time 2019-02-03 04:49:42.811052
Model ind 579 epoch 555 head B head_i_epoch 0 batch 200: avg loss -1.779107 avg loss no lamb -1.779107 time 2019-02-03 04:52:40.079607
Model ind 579 epoch 555 head A head_i_epoch 0 batch 0: avg loss -3.410126 avg loss no lamb -3.410126 time 2019-02-03 04:55:36.325647
Model ind 579 epoch 555 head A head_i_epoch 0 batch 100: avg loss -3.448222 avg loss no lamb -3.448222 time 2019-02-03 04:58:33.260151
Model ind 579 epoch 555 head A head_i_epoch 0 batch 200: avg loss -3.422754 avg loss no lamb -3.422754 time 2019-02-03 05:01:32.554284
Pre: time 2019-02-03 05:04:53.831011: 
 	std: 0.004510348
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24458334, 0.24606666, 0.23433334, 0.24568333, 0.24581666]
	train_accs: [0.24458334, 0.24606666, 0.23433334, 0.24568333, 0.24581666]
	best_train_sub_head: 1
	worst: 0.23433334
	avg: 0.24329667
	best: 0.24606666

Starting e_i: 556
Model ind 579 epoch 556 head B head_i_epoch 0 batch 0: avg loss -1.816926 avg loss no lamb -1.816926 time 2019-02-03 05:04:57.380198
Model ind 579 epoch 556 head B head_i_epoch 0 batch 100: avg loss -1.840344 avg loss no lamb -1.840344 time 2019-02-03 05:07:55.762610
Model ind 579 epoch 556 head B head_i_epoch 0 batch 200: avg loss -1.813031 avg loss no lamb -1.813031 time 2019-02-03 05:10:52.843028
Model ind 579 epoch 556 head A head_i_epoch 0 batch 0: avg loss -3.406994 avg loss no lamb -3.406994 time 2019-02-03 05:13:49.163733
Model ind 579 epoch 556 head A head_i_epoch 0 batch 100: avg loss -3.412741 avg loss no lamb -3.412741 time 2019-02-03 05:16:47.105489
Model ind 579 epoch 556 head A head_i_epoch 0 batch 200: avg loss -3.397420 avg loss no lamb -3.397420 time 2019-02-03 05:19:44.797472
Pre: time 2019-02-03 05:23:08.662850: 
 	std: 0.0044552623
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 15), (3, 13), (4, 4), (5, 5), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24436666, 0.24593334, 0.2344, 0.24591666, 0.24556667]
	train_accs: [0.24436666, 0.24593334, 0.2344, 0.24591666, 0.24556667]
	best_train_sub_head: 1
	worst: 0.2344
	avg: 0.24323666
	best: 0.24593334

Starting e_i: 557
Model ind 579 epoch 557 head B head_i_epoch 0 batch 0: avg loss -1.753925 avg loss no lamb -1.753925 time 2019-02-03 05:23:12.021246
Model ind 579 epoch 557 head B head_i_epoch 0 batch 100: avg loss -1.731567 avg loss no lamb -1.731567 time 2019-02-03 05:26:08.159190
Model ind 579 epoch 557 head B head_i_epoch 0 batch 200: avg loss -1.819980 avg loss no lamb -1.819980 time 2019-02-03 05:29:05.236039
Model ind 579 epoch 557 head A head_i_epoch 0 batch 0: avg loss -3.358152 avg loss no lamb -3.358152 time 2019-02-03 05:32:02.983285
Model ind 579 epoch 557 head A head_i_epoch 0 batch 100: avg loss -3.456568 avg loss no lamb -3.456568 time 2019-02-03 05:35:00.832416
Model ind 579 epoch 557 head A head_i_epoch 0 batch 200: avg loss -3.401889 avg loss no lamb -3.401889 time 2019-02-03 05:37:59.957431
Pre: time 2019-02-03 05:41:25.198885: 
 	std: 0.0042692153
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24666667, 0.247, 0.23623334, 0.2471, 0.24683334]
	train_accs: [0.24666667, 0.247, 0.23623334, 0.2471, 0.24683334]
	best_train_sub_head: 3
	worst: 0.23623334
	avg: 0.24476667
	best: 0.2471

Starting e_i: 558
Model ind 579 epoch 558 head B head_i_epoch 0 batch 0: avg loss -1.826187 avg loss no lamb -1.826187 time 2019-02-03 05:41:28.738765
Model ind 579 epoch 558 head B head_i_epoch 0 batch 100: avg loss -1.800931 avg loss no lamb -1.800931 time 2019-02-03 05:44:25.459045
Model ind 579 epoch 558 head B head_i_epoch 0 batch 200: avg loss -1.800254 avg loss no lamb -1.800254 time 2019-02-03 05:47:23.361338
Model ind 579 epoch 558 head A head_i_epoch 0 batch 0: avg loss -3.370364 avg loss no lamb -3.370364 time 2019-02-03 05:50:22.999539
Model ind 579 epoch 558 head A head_i_epoch 0 batch 100: avg loss -3.436784 avg loss no lamb -3.436784 time 2019-02-03 05:53:22.762798
Model ind 579 epoch 558 head A head_i_epoch 0 batch 200: avg loss -3.371510 avg loss no lamb -3.371510 time 2019-02-03 05:56:20.312860
Pre: time 2019-02-03 05:59:42.531593: 
 	std: 0.00419201
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.2437, 0.24393333, 0.23323333, 0.24385, 0.24331667]
	train_accs: [0.2437, 0.24393333, 0.23323333, 0.24385, 0.24331667]
	best_train_sub_head: 1
	worst: 0.23323333
	avg: 0.24160667
	best: 0.24393333

Starting e_i: 559
Model ind 579 epoch 559 head B head_i_epoch 0 batch 0: avg loss -1.764974 avg loss no lamb -1.764974 time 2019-02-03 05:59:46.272057
Model ind 579 epoch 559 head B head_i_epoch 0 batch 100: avg loss -1.770801 avg loss no lamb -1.770801 time 2019-02-03 06:02:43.717992
Model ind 579 epoch 559 head B head_i_epoch 0 batch 200: avg loss -1.767546 avg loss no lamb -1.767546 time 2019-02-03 06:05:40.460953
Model ind 579 epoch 559 head A head_i_epoch 0 batch 0: avg loss -3.413615 avg loss no lamb -3.413615 time 2019-02-03 06:08:36.423706
Model ind 579 epoch 559 head A head_i_epoch 0 batch 100: avg loss -3.372039 avg loss no lamb -3.372039 time 2019-02-03 06:11:36.334537
Model ind 579 epoch 559 head A head_i_epoch 0 batch 200: avg loss -3.426037 avg loss no lamb -3.426037 time 2019-02-03 06:14:34.723552
Pre: time 2019-02-03 06:17:57.737944: 
 	std: 0.0044911345
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.24536666, 0.246, 0.23425, 0.2456, 0.24476667]
	train_accs: [0.24536666, 0.246, 0.23425, 0.2456, 0.24476667]
	best_train_sub_head: 1
	worst: 0.23425
	avg: 0.24319668
	best: 0.246

Starting e_i: 560
Model ind 579 epoch 560 head B head_i_epoch 0 batch 0: avg loss -1.852299 avg loss no lamb -1.852299 time 2019-02-03 06:18:01.821031
Model ind 579 epoch 560 head B head_i_epoch 0 batch 100: avg loss -1.860006 avg loss no lamb -1.860006 time 2019-02-03 06:20:58.465192
Model ind 579 epoch 560 head B head_i_epoch 0 batch 200: avg loss -1.774989 avg loss no lamb -1.774989 time 2019-02-03 06:23:56.449288
Model ind 579 epoch 560 head A head_i_epoch 0 batch 0: avg loss -3.414412 avg loss no lamb -3.414412 time 2019-02-03 06:26:54.352469
Model ind 579 epoch 560 head A head_i_epoch 0 batch 100: avg loss -3.397950 avg loss no lamb -3.397950 time 2019-02-03 06:29:51.685863
Model ind 579 epoch 560 head A head_i_epoch 0 batch 200: avg loss -3.404065 avg loss no lamb -3.404065 time 2019-02-03 06:32:49.582690
Pre: time 2019-02-03 06:36:13.881101: 
 	std: 0.004353563
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 13), (19, 18)]
	test_accs: [0.24596667, 0.24593334, 0.2351, 0.24651666, 0.24536666]
	train_accs: [0.24596667, 0.24593334, 0.2351, 0.24651666, 0.24536666]
	best_train_sub_head: 3
	worst: 0.2351
	avg: 0.24377665
	best: 0.24651666

Starting e_i: 561
Model ind 579 epoch 561 head B head_i_epoch 0 batch 0: avg loss -1.758868 avg loss no lamb -1.758868 time 2019-02-03 06:36:21.481941
Model ind 579 epoch 561 head B head_i_epoch 0 batch 100: avg loss -1.740822 avg loss no lamb -1.740822 time 2019-02-03 06:39:19.341268
Model ind 579 epoch 561 head B head_i_epoch 0 batch 200: avg loss -1.719005 avg loss no lamb -1.719005 time 2019-02-03 06:42:14.745840
Model ind 579 epoch 561 head A head_i_epoch 0 batch 0: avg loss -3.399352 avg loss no lamb -3.399352 time 2019-02-03 06:45:12.544837
Model ind 579 epoch 561 head A head_i_epoch 0 batch 100: avg loss -3.444226 avg loss no lamb -3.444226 time 2019-02-03 06:48:09.759170
Model ind 579 epoch 561 head A head_i_epoch 0 batch 200: avg loss -3.451732 avg loss no lamb -3.451732 time 2019-02-03 06:51:08.235121
Pre: time 2019-02-03 06:54:30.316777: 
 	std: 0.004575278
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.24638334, 0.24786666, 0.23596667, 0.24741666, 0.24766667]
	train_accs: [0.24638334, 0.24786666, 0.23596667, 0.24741666, 0.24766667]
	best_train_sub_head: 1
	worst: 0.23596667
	avg: 0.24506001
	best: 0.24786666

Starting e_i: 562
Model ind 579 epoch 562 head B head_i_epoch 0 batch 0: avg loss -1.831303 avg loss no lamb -1.831303 time 2019-02-03 06:54:33.824507
Model ind 579 epoch 562 head B head_i_epoch 0 batch 100: avg loss -1.730938 avg loss no lamb -1.730938 time 2019-02-03 06:57:30.365860
Model ind 579 epoch 562 head B head_i_epoch 0 batch 200: avg loss -1.715938 avg loss no lamb -1.715938 time 2019-02-03 07:00:26.874381
Model ind 579 epoch 562 head A head_i_epoch 0 batch 0: avg loss -3.324059 avg loss no lamb -3.324059 time 2019-02-03 07:03:23.230261
Model ind 579 epoch 562 head A head_i_epoch 0 batch 100: avg loss -3.392057 avg loss no lamb -3.392057 time 2019-02-03 07:06:21.325765
Model ind 579 epoch 562 head A head_i_epoch 0 batch 200: avg loss -3.422368 avg loss no lamb -3.422368 time 2019-02-03 07:09:19.785589
Pre: time 2019-02-03 07:12:43.014729: 
 	std: 0.0042274417
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24188334, 0.24231666, 0.23198333, 0.24316667, 0.24263333]
	train_accs: [0.24188334, 0.24231666, 0.23198333, 0.24316667, 0.24263333]
	best_train_sub_head: 3
	worst: 0.23198333
	avg: 0.24039666
	best: 0.24316667

Starting e_i: 563
Model ind 579 epoch 563 head B head_i_epoch 0 batch 0: avg loss -1.822445 avg loss no lamb -1.822445 time 2019-02-03 07:12:46.542807
Model ind 579 epoch 563 head B head_i_epoch 0 batch 100: avg loss -1.800168 avg loss no lamb -1.800168 time 2019-02-03 07:15:43.533199
Model ind 579 epoch 563 head B head_i_epoch 0 batch 200: avg loss -1.789610 avg loss no lamb -1.789610 time 2019-02-03 07:18:42.565139
Model ind 579 epoch 563 head A head_i_epoch 0 batch 0: avg loss -3.360119 avg loss no lamb -3.360119 time 2019-02-03 07:21:40.939085
Model ind 579 epoch 563 head A head_i_epoch 0 batch 100: avg loss -3.426640 avg loss no lamb -3.426640 time 2019-02-03 07:24:40.962612
Model ind 579 epoch 563 head A head_i_epoch 0 batch 200: avg loss -3.434008 avg loss no lamb -3.434008 time 2019-02-03 07:27:39.194086
Pre: time 2019-02-03 07:31:02.287951: 
 	std: 0.0045804433
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24725, 0.24795, 0.23628333, 0.24836667, 0.24715]
	train_accs: [0.24725, 0.24795, 0.23628333, 0.24836667, 0.24715]
	best_train_sub_head: 3
	worst: 0.23628333
	avg: 0.2454
	best: 0.24836667

Starting e_i: 564
Model ind 579 epoch 564 head B head_i_epoch 0 batch 0: avg loss -1.797206 avg loss no lamb -1.797206 time 2019-02-03 07:31:05.689698
Model ind 579 epoch 564 head B head_i_epoch 0 batch 100: avg loss -1.733976 avg loss no lamb -1.733976 time 2019-02-03 07:34:03.525208
Model ind 579 epoch 564 head B head_i_epoch 0 batch 200: avg loss -1.773729 avg loss no lamb -1.773729 time 2019-02-03 07:37:01.403199
Model ind 579 epoch 564 head A head_i_epoch 0 batch 0: avg loss -3.409031 avg loss no lamb -3.409031 time 2019-02-03 07:39:59.120410
Model ind 579 epoch 564 head A head_i_epoch 0 batch 100: avg loss -3.406584 avg loss no lamb -3.406584 time 2019-02-03 07:42:56.667999
Model ind 579 epoch 564 head A head_i_epoch 0 batch 200: avg loss -3.450984 avg loss no lamb -3.450984 time 2019-02-03 07:45:53.760641
Pre: time 2019-02-03 07:49:16.902038: 
 	std: 0.004514314
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24903333, 0.24875, 0.23793334, 0.24978334, 0.24918333]
	train_accs: [0.24903333, 0.24875, 0.23793334, 0.24978334, 0.24918333]
	best_train_sub_head: 3
	worst: 0.23793334
	avg: 0.24693668
	best: 0.24978334

Starting e_i: 565
Model ind 579 epoch 565 head B head_i_epoch 0 batch 0: avg loss -1.791165 avg loss no lamb -1.791165 time 2019-02-03 07:49:20.499246
Model ind 579 epoch 565 head B head_i_epoch 0 batch 100: avg loss -1.691059 avg loss no lamb -1.691059 time 2019-02-03 07:52:17.525401
Model ind 579 epoch 565 head B head_i_epoch 0 batch 200: avg loss -1.757086 avg loss no lamb -1.757086 time 2019-02-03 07:55:13.151485
Model ind 579 epoch 565 head A head_i_epoch 0 batch 0: avg loss -3.376639 avg loss no lamb -3.376639 time 2019-02-03 07:58:08.918831
Model ind 579 epoch 565 head A head_i_epoch 0 batch 100: avg loss -3.480549 avg loss no lamb -3.480549 time 2019-02-03 08:01:07.275326
Model ind 579 epoch 565 head A head_i_epoch 0 batch 200: avg loss -3.420093 avg loss no lamb -3.420093 time 2019-02-03 08:04:07.579546
Pre: time 2019-02-03 08:07:32.615100: 
 	std: 0.003963261
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 13), (4, 4), (5, 5), (6, 7), (7, 11), (8, 3), (9, 12), (10, 15), (11, 17), (12, 18), (13, 16), (14, 1), (15, 8), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24418333, 0.24461667, 0.2345, 0.24461667, 0.24416667]
	train_accs: [0.24418333, 0.24461667, 0.2345, 0.24461667, 0.24416667]
	best_train_sub_head: 1
	worst: 0.2345
	avg: 0.24241666
	best: 0.24461667

Starting e_i: 566
Model ind 579 epoch 566 head B head_i_epoch 0 batch 0: avg loss -1.793403 avg loss no lamb -1.793403 time 2019-02-03 08:07:36.012900
Model ind 579 epoch 566 head B head_i_epoch 0 batch 100: avg loss -1.755741 avg loss no lamb -1.755741 time 2019-02-03 08:10:34.389595
Model ind 579 epoch 566 head B head_i_epoch 0 batch 200: avg loss -1.709942 avg loss no lamb -1.709942 time 2019-02-03 08:13:31.324115
Model ind 579 epoch 566 head A head_i_epoch 0 batch 0: avg loss -3.387593 avg loss no lamb -3.387593 time 2019-02-03 08:16:27.580148
Model ind 579 epoch 566 head A head_i_epoch 0 batch 100: avg loss -3.414109 avg loss no lamb -3.414109 time 2019-02-03 08:19:26.505659
Model ind 579 epoch 566 head A head_i_epoch 0 batch 200: avg loss -3.407492 avg loss no lamb -3.407492 time 2019-02-03 08:22:25.268951
Pre: time 2019-02-03 08:25:47.896064: 
 	std: 0.004264471
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.24513334, 0.24556667, 0.23528333, 0.2462, 0.24658333]
	train_accs: [0.24513334, 0.24556667, 0.23528333, 0.2462, 0.24658333]
	best_train_sub_head: 4
	worst: 0.23528333
	avg: 0.24375334
	best: 0.24658333

Starting e_i: 567
Model ind 579 epoch 567 head B head_i_epoch 0 batch 0: avg loss -1.741820 avg loss no lamb -1.741820 time 2019-02-03 08:25:51.310520
Model ind 579 epoch 567 head B head_i_epoch 0 batch 100: avg loss -1.743010 avg loss no lamb -1.743010 time 2019-02-03 08:28:47.936957
Model ind 579 epoch 567 head B head_i_epoch 0 batch 200: avg loss -1.705977 avg loss no lamb -1.705977 time 2019-02-03 08:31:45.363589
Model ind 579 epoch 567 head A head_i_epoch 0 batch 0: avg loss -3.421498 avg loss no lamb -3.421498 time 2019-02-03 08:34:43.524268
Model ind 579 epoch 567 head A head_i_epoch 0 batch 100: avg loss -3.457951 avg loss no lamb -3.457951 time 2019-02-03 08:37:42.004935
Model ind 579 epoch 567 head A head_i_epoch 0 batch 200: avg loss -3.475055 avg loss no lamb -3.475055 time 2019-02-03 08:40:40.784260
Pre: time 2019-02-03 08:44:06.322457: 
 	std: 0.004158041
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.24566667, 0.24655, 0.23643333, 0.24713333, 0.2475]
	train_accs: [0.24566667, 0.24655, 0.23643333, 0.24713333, 0.2475]
	best_train_sub_head: 4
	worst: 0.23643333
	avg: 0.24465665
	best: 0.2475

Starting e_i: 568
Model ind 579 epoch 568 head B head_i_epoch 0 batch 0: avg loss -1.750357 avg loss no lamb -1.750357 time 2019-02-03 08:44:09.781706
Model ind 579 epoch 568 head B head_i_epoch 0 batch 100: avg loss -1.775205 avg loss no lamb -1.775205 time 2019-02-03 08:47:06.653342
Model ind 579 epoch 568 head B head_i_epoch 0 batch 200: avg loss -1.774222 avg loss no lamb -1.774222 time 2019-02-03 08:50:03.489491
Model ind 579 epoch 568 head A head_i_epoch 0 batch 0: avg loss -3.337580 avg loss no lamb -3.337580 time 2019-02-03 08:53:00.291039
Model ind 579 epoch 568 head A head_i_epoch 0 batch 100: avg loss -3.412528 avg loss no lamb -3.412528 time 2019-02-03 08:55:59.885795
Model ind 579 epoch 568 head A head_i_epoch 0 batch 200: avg loss -3.454867 avg loss no lamb -3.454867 time 2019-02-03 08:58:58.499246
Pre: time 2019-02-03 09:02:22.309022: 
 	std: 0.0041767415
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2493, 0.24966666, 0.23925, 0.25005, 0.24968334]
	train_accs: [0.2493, 0.24966666, 0.23925, 0.25005, 0.24968334]
	best_train_sub_head: 3
	worst: 0.23925
	avg: 0.24758999
	best: 0.25005

Starting e_i: 569
Model ind 579 epoch 569 head B head_i_epoch 0 batch 0: avg loss -1.776288 avg loss no lamb -1.776288 time 2019-02-03 09:02:25.775247
Model ind 579 epoch 569 head B head_i_epoch 0 batch 100: avg loss -1.791198 avg loss no lamb -1.791198 time 2019-02-03 09:05:24.016412
Model ind 579 epoch 569 head B head_i_epoch 0 batch 200: avg loss -1.793054 avg loss no lamb -1.793054 time 2019-02-03 09:08:19.641812
Model ind 579 epoch 569 head A head_i_epoch 0 batch 0: avg loss -3.409278 avg loss no lamb -3.409278 time 2019-02-03 09:11:15.396170
Model ind 579 epoch 569 head A head_i_epoch 0 batch 100: avg loss -3.447807 avg loss no lamb -3.447807 time 2019-02-03 09:14:13.526343
Model ind 579 epoch 569 head A head_i_epoch 0 batch 200: avg loss -3.422941 avg loss no lamb -3.422941 time 2019-02-03 09:17:11.808157
Pre: time 2019-02-03 09:20:33.350478: 
 	std: 0.0039937478
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24836667, 0.24938333, 0.23916666, 0.24943334, 0.24923334]
	train_accs: [0.24836667, 0.24938333, 0.23916666, 0.24943334, 0.24923334]
	best_train_sub_head: 3
	worst: 0.23916666
	avg: 0.24711666
	best: 0.24943334

Starting e_i: 570
Model ind 579 epoch 570 head B head_i_epoch 0 batch 0: avg loss -1.787164 avg loss no lamb -1.787164 time 2019-02-03 09:20:37.313895
Model ind 579 epoch 570 head B head_i_epoch 0 batch 100: avg loss -1.773669 avg loss no lamb -1.773669 time 2019-02-03 09:23:33.444422
Model ind 579 epoch 570 head B head_i_epoch 0 batch 200: avg loss -1.743254 avg loss no lamb -1.743254 time 2019-02-03 09:26:30.018533
Model ind 579 epoch 570 head A head_i_epoch 0 batch 0: avg loss -3.418193 avg loss no lamb -3.418193 time 2019-02-03 09:29:26.596462
Model ind 579 epoch 570 head A head_i_epoch 0 batch 100: avg loss -3.417856 avg loss no lamb -3.417856 time 2019-02-03 09:32:25.427625
Model ind 579 epoch 570 head A head_i_epoch 0 batch 200: avg loss -3.429856 avg loss no lamb -3.429856 time 2019-02-03 09:35:22.305591
Pre: time 2019-02-03 09:38:44.341414: 
 	std: 0.0043261084
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 5), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24905, 0.25001666, 0.23863333, 0.24961667, 0.24893333]
	train_accs: [0.24905, 0.25001666, 0.23863333, 0.24961667, 0.24893333]
	best_train_sub_head: 1
	worst: 0.23863333
	avg: 0.24725
	best: 0.25001666

Starting e_i: 571
Model ind 579 epoch 571 head B head_i_epoch 0 batch 0: avg loss -1.769893 avg loss no lamb -1.769893 time 2019-02-03 09:38:52.061512
Model ind 579 epoch 571 head B head_i_epoch 0 batch 100: avg loss -1.797625 avg loss no lamb -1.797625 time 2019-02-03 09:41:50.157675
Model ind 579 epoch 571 head B head_i_epoch 0 batch 200: avg loss -1.736795 avg loss no lamb -1.736795 time 2019-02-03 09:44:48.361190
Model ind 579 epoch 571 head A head_i_epoch 0 batch 0: avg loss -3.413350 avg loss no lamb -3.413350 time 2019-02-03 09:47:46.711499
Model ind 579 epoch 571 head A head_i_epoch 0 batch 100: avg loss -3.371050 avg loss no lamb -3.371050 time 2019-02-03 09:50:45.002234
Model ind 579 epoch 571 head A head_i_epoch 0 batch 200: avg loss -3.459319 avg loss no lamb -3.459319 time 2019-02-03 09:53:43.948382
Pre: time 2019-02-03 09:57:06.796658: 
 	std: 0.004278808
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24748333, 0.24858333, 0.23785, 0.24898334, 0.24881667]
	train_accs: [0.24748333, 0.24858333, 0.23785, 0.24898334, 0.24881667]
	best_train_sub_head: 3
	worst: 0.23785
	avg: 0.24634333
	best: 0.24898334

Starting e_i: 572
Model ind 579 epoch 572 head B head_i_epoch 0 batch 0: avg loss -1.783030 avg loss no lamb -1.783030 time 2019-02-03 09:57:10.273893
Model ind 579 epoch 572 head B head_i_epoch 0 batch 100: avg loss -1.732094 avg loss no lamb -1.732094 time 2019-02-03 10:00:06.740844
Model ind 579 epoch 572 head B head_i_epoch 0 batch 200: avg loss -1.803926 avg loss no lamb -1.803926 time 2019-02-03 10:03:02.302947
Model ind 579 epoch 572 head A head_i_epoch 0 batch 0: avg loss -3.377578 avg loss no lamb -3.377578 time 2019-02-03 10:05:58.707812
Model ind 579 epoch 572 head A head_i_epoch 0 batch 100: avg loss -3.472031 avg loss no lamb -3.472031 time 2019-02-03 10:08:58.399715
Model ind 579 epoch 572 head A head_i_epoch 0 batch 200: avg loss -3.428304 avg loss no lamb -3.428304 time 2019-02-03 10:11:56.089927
Pre: time 2019-02-03 10:15:17.771106: 
 	std: 0.0042392355
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24488333, 0.24551667, 0.23528333, 0.24658333, 0.24615]
	train_accs: [0.24488333, 0.24551667, 0.23528333, 0.24658333, 0.24615]
	best_train_sub_head: 3
	worst: 0.23528333
	avg: 0.24368334
	best: 0.24658333

Starting e_i: 573
Model ind 579 epoch 573 head B head_i_epoch 0 batch 0: avg loss -1.744652 avg loss no lamb -1.744652 time 2019-02-03 10:15:21.770275
Model ind 579 epoch 573 head B head_i_epoch 0 batch 100: avg loss -1.703206 avg loss no lamb -1.703206 time 2019-02-03 10:18:19.878550
Model ind 579 epoch 573 head B head_i_epoch 0 batch 200: avg loss -1.759575 avg loss no lamb -1.759575 time 2019-02-03 10:21:17.033985
Model ind 579 epoch 573 head A head_i_epoch 0 batch 0: avg loss -3.412902 avg loss no lamb -3.412902 time 2019-02-03 10:24:13.820173
Model ind 579 epoch 573 head A head_i_epoch 0 batch 100: avg loss -3.475372 avg loss no lamb -3.475372 time 2019-02-03 10:27:13.436596
Model ind 579 epoch 573 head A head_i_epoch 0 batch 200: avg loss -3.406307 avg loss no lamb -3.406307 time 2019-02-03 10:30:12.074789
Pre: time 2019-02-03 10:33:35.111237: 
 	std: 0.005068397
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24761666, 0.24895, 0.23608333, 0.24911667, 0.24903333]
	train_accs: [0.24761666, 0.24895, 0.23608333, 0.24911667, 0.24903333]
	best_train_sub_head: 3
	worst: 0.23608333
	avg: 0.24615999
	best: 0.24911667

Starting e_i: 574
Model ind 579 epoch 574 head B head_i_epoch 0 batch 0: avg loss -1.742325 avg loss no lamb -1.742325 time 2019-02-03 10:33:38.556957
Model ind 579 epoch 574 head B head_i_epoch 0 batch 100: avg loss -1.751168 avg loss no lamb -1.751168 time 2019-02-03 10:36:34.473175
Model ind 579 epoch 574 head B head_i_epoch 0 batch 200: avg loss -1.687649 avg loss no lamb -1.687649 time 2019-02-03 10:39:31.798828
Model ind 579 epoch 574 head A head_i_epoch 0 batch 0: avg loss -3.340379 avg loss no lamb -3.340379 time 2019-02-03 10:42:27.941216
Model ind 579 epoch 574 head A head_i_epoch 0 batch 100: avg loss -3.426392 avg loss no lamb -3.426392 time 2019-02-03 10:45:25.225312
Model ind 579 epoch 574 head A head_i_epoch 0 batch 200: avg loss -3.452364 avg loss no lamb -3.452364 time 2019-02-03 10:48:22.526218
Pre: time 2019-02-03 10:51:47.855961: 
 	std: 0.005007369
	best_train_sub_head_match: [(0, 13), (1, 15), (2, 2), (3, 5), (4, 4), (5, 3), (6, 18), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24516666, 0.24593334, 0.23361667, 0.24663334, 0.24653333]
	train_accs: [0.24516666, 0.24593334, 0.23361667, 0.24663334, 0.24653333]
	best_train_sub_head: 3
	worst: 0.23361667
	avg: 0.24357668
	best: 0.24663334

Starting e_i: 575
Model ind 579 epoch 575 head B head_i_epoch 0 batch 0: avg loss -1.797429 avg loss no lamb -1.797429 time 2019-02-03 10:51:51.851743
Model ind 579 epoch 575 head B head_i_epoch 0 batch 100: avg loss -1.766122 avg loss no lamb -1.766122 time 2019-02-03 10:54:49.551203
Model ind 579 epoch 575 head B head_i_epoch 0 batch 200: avg loss -1.804013 avg loss no lamb -1.804013 time 2019-02-03 10:57:46.060666
Model ind 579 epoch 575 head A head_i_epoch 0 batch 0: avg loss -3.393573 avg loss no lamb -3.393573 time 2019-02-03 11:00:40.724280
Model ind 579 epoch 575 head A head_i_epoch 0 batch 100: avg loss -3.418160 avg loss no lamb -3.418160 time 2019-02-03 11:03:37.510407
Model ind 579 epoch 575 head A head_i_epoch 0 batch 200: avg loss -3.433101 avg loss no lamb -3.433101 time 2019-02-03 11:06:35.579407
Pre: time 2019-02-03 11:09:57.207212: 
 	std: 0.0031830582
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.24371667, 0.24378334, 0.23628333, 0.24423334, 0.24493334]
	train_accs: [0.24371667, 0.24378334, 0.23628333, 0.24423334, 0.24493334]
	best_train_sub_head: 4
	worst: 0.23628333
	avg: 0.24259003
	best: 0.24493334

Starting e_i: 576
Model ind 579 epoch 576 head B head_i_epoch 0 batch 0: avg loss -1.708662 avg loss no lamb -1.708662 time 2019-02-03 11:10:00.863324
Model ind 579 epoch 576 head B head_i_epoch 0 batch 100: avg loss -1.721212 avg loss no lamb -1.721212 time 2019-02-03 11:12:58.508070
Model ind 579 epoch 576 head B head_i_epoch 0 batch 200: avg loss -1.795365 avg loss no lamb -1.795365 time 2019-02-03 11:15:55.611552
Model ind 579 epoch 576 head A head_i_epoch 0 batch 0: avg loss -3.371864 avg loss no lamb -3.371864 time 2019-02-03 11:18:51.445422
Model ind 579 epoch 576 head A head_i_epoch 0 batch 100: avg loss -3.413152 avg loss no lamb -3.413152 time 2019-02-03 11:21:50.103813
Model ind 579 epoch 576 head A head_i_epoch 0 batch 200: avg loss -3.447418 avg loss no lamb -3.447418 time 2019-02-03 11:24:48.263649
Pre: time 2019-02-03 11:28:13.306231: 
 	std: 0.0045559444
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.246, 0.24783333, 0.23611666, 0.24746667, 0.24813333]
	train_accs: [0.246, 0.24783333, 0.23611666, 0.24746667, 0.24813333]
	best_train_sub_head: 4
	worst: 0.23611666
	avg: 0.24511
	best: 0.24813333

Starting e_i: 577
Model ind 579 epoch 577 head B head_i_epoch 0 batch 0: avg loss -1.736734 avg loss no lamb -1.736734 time 2019-02-03 11:28:17.531895
Model ind 579 epoch 577 head B head_i_epoch 0 batch 100: avg loss -1.763209 avg loss no lamb -1.763209 time 2019-02-03 11:31:13.462031
Model ind 579 epoch 577 head B head_i_epoch 0 batch 200: avg loss -1.782133 avg loss no lamb -1.782133 time 2019-02-03 11:34:11.671706
Model ind 579 epoch 577 head A head_i_epoch 0 batch 0: avg loss -3.392283 avg loss no lamb -3.392283 time 2019-02-03 11:37:08.417256
Model ind 579 epoch 577 head A head_i_epoch 0 batch 100: avg loss -3.406124 avg loss no lamb -3.406124 time 2019-02-03 11:40:05.954066
Model ind 579 epoch 577 head A head_i_epoch 0 batch 200: avg loss -3.408040 avg loss no lamb -3.408040 time 2019-02-03 11:43:04.282383
Pre: time 2019-02-03 11:46:29.281077: 
 	std: 0.004266512
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.24488333, 0.24488333, 0.23418333, 0.24415, 0.24531667]
	train_accs: [0.24488333, 0.24488333, 0.23418333, 0.24415, 0.24531667]
	best_train_sub_head: 4
	worst: 0.23418333
	avg: 0.24268332
	best: 0.24531667

Starting e_i: 578
Model ind 579 epoch 578 head B head_i_epoch 0 batch 0: avg loss -1.706628 avg loss no lamb -1.706628 time 2019-02-03 11:46:33.202521
Model ind 579 epoch 578 head B head_i_epoch 0 batch 100: avg loss -1.736380 avg loss no lamb -1.736380 time 2019-02-03 11:49:29.235944
Model ind 579 epoch 578 head B head_i_epoch 0 batch 200: avg loss -1.825697 avg loss no lamb -1.825697 time 2019-02-03 11:52:26.661922
Model ind 579 epoch 578 head A head_i_epoch 0 batch 0: avg loss -3.446463 avg loss no lamb -3.446463 time 2019-02-03 11:55:23.094786
Model ind 579 epoch 578 head A head_i_epoch 0 batch 100: avg loss -3.449571 avg loss no lamb -3.449571 time 2019-02-03 11:58:20.225583
Model ind 579 epoch 578 head A head_i_epoch 0 batch 200: avg loss -3.383452 avg loss no lamb -3.383452 time 2019-02-03 12:01:18.228392
Pre: time 2019-02-03 12:04:39.006587: 
 	std: 0.004439639
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 18), (12, 15), (13, 19), (14, 1), (15, 13), (16, 6), (17, 3), (18, 5), (19, 12)]
	test_accs: [0.24528334, 0.24593334, 0.23451667, 0.24513334, 0.24598333]
	train_accs: [0.24528334, 0.24593334, 0.23451667, 0.24513334, 0.24598333]
	best_train_sub_head: 4
	worst: 0.23451667
	avg: 0.24337001
	best: 0.24598333

Starting e_i: 579
Model ind 579 epoch 579 head B head_i_epoch 0 batch 0: avg loss -1.826095 avg loss no lamb -1.826095 time 2019-02-03 12:04:42.403118
Model ind 579 epoch 579 head B head_i_epoch 0 batch 100: avg loss -1.755589 avg loss no lamb -1.755589 time 2019-02-03 12:07:39.442775
Model ind 579 epoch 579 head B head_i_epoch 0 batch 200: avg loss -1.779753 avg loss no lamb -1.779753 time 2019-02-03 12:10:36.472696
Model ind 579 epoch 579 head A head_i_epoch 0 batch 0: avg loss -3.412939 avg loss no lamb -3.412939 time 2019-02-03 12:13:34.320611
Model ind 579 epoch 579 head A head_i_epoch 0 batch 100: avg loss -3.366401 avg loss no lamb -3.366401 time 2019-02-03 12:16:32.248515
Model ind 579 epoch 579 head A head_i_epoch 0 batch 200: avg loss -3.455971 avg loss no lamb -3.455971 time 2019-02-03 12:19:30.658932
Pre: time 2019-02-03 12:22:54.576218: 
 	std: 0.004729803
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 13), (19, 18)]
	test_accs: [0.24778333, 0.24773334, 0.23613334, 0.24815, 0.24813333]
	train_accs: [0.24778333, 0.24773334, 0.23613334, 0.24815, 0.24813333]
	best_train_sub_head: 3
	worst: 0.23613334
	avg: 0.24558666
	best: 0.24815

Starting e_i: 580
Model ind 579 epoch 580 head B head_i_epoch 0 batch 0: avg loss -1.813519 avg loss no lamb -1.813519 time 2019-02-03 12:22:58.551720
Model ind 579 epoch 580 head B head_i_epoch 0 batch 100: avg loss -1.630931 avg loss no lamb -1.630931 time 2019-02-03 12:25:56.192242
Model ind 579 epoch 580 head B head_i_epoch 0 batch 200: avg loss -1.775348 avg loss no lamb -1.775348 time 2019-02-03 12:28:53.912157
Model ind 579 epoch 580 head A head_i_epoch 0 batch 0: avg loss -3.419735 avg loss no lamb -3.419735 time 2019-02-03 12:31:50.341897
Model ind 579 epoch 580 head A head_i_epoch 0 batch 100: avg loss -3.342673 avg loss no lamb -3.342673 time 2019-02-03 12:34:48.294312
Model ind 579 epoch 580 head A head_i_epoch 0 batch 200: avg loss -3.394002 avg loss no lamb -3.394002 time 2019-02-03 12:37:47.780614
Pre: time 2019-02-03 12:41:10.434258: 
 	std: 0.0039441963
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 13), (19, 18)]
	test_accs: [0.2484, 0.24873333, 0.23886667, 0.24896666, 0.24876666]
	train_accs: [0.2484, 0.24873333, 0.23886667, 0.24896666, 0.24876666]
	best_train_sub_head: 3
	worst: 0.23886667
	avg: 0.24674666
	best: 0.24896666

Starting e_i: 581
Model ind 579 epoch 581 head B head_i_epoch 0 batch 0: avg loss -1.759690 avg loss no lamb -1.759690 time 2019-02-03 12:41:17.449776
Model ind 579 epoch 581 head B head_i_epoch 0 batch 100: avg loss -1.728099 avg loss no lamb -1.728099 time 2019-02-03 12:44:13.878753
Model ind 579 epoch 581 head B head_i_epoch 0 batch 200: avg loss -1.789061 avg loss no lamb -1.789061 time 2019-02-03 12:47:10.217359
Model ind 579 epoch 581 head A head_i_epoch 0 batch 0: avg loss -3.404254 avg loss no lamb -3.404254 time 2019-02-03 12:50:05.745906
Model ind 579 epoch 581 head A head_i_epoch 0 batch 100: avg loss -3.449524 avg loss no lamb -3.449524 time 2019-02-03 12:53:03.329053
Model ind 579 epoch 581 head A head_i_epoch 0 batch 200: avg loss -3.365438 avg loss no lamb -3.365438 time 2019-02-03 12:56:01.699396
Pre: time 2019-02-03 12:59:24.739150: 
 	std: 0.0044249888
	best_train_sub_head_match: [(0, 13), (1, 0), (2, 2), (3, 5), (4, 4), (5, 3), (6, 18), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 15), (19, 19)]
	test_accs: [0.24958333, 0.25013334, 0.239, 0.25026667, 0.2502]
	train_accs: [0.24958333, 0.25013334, 0.239, 0.25026667, 0.2502]
	best_train_sub_head: 3
	worst: 0.239
	avg: 0.24783666
	best: 0.25026667

Starting e_i: 582
Model ind 579 epoch 582 head B head_i_epoch 0 batch 0: avg loss -1.882074 avg loss no lamb -1.882074 time 2019-02-03 12:59:28.316111
Model ind 579 epoch 582 head B head_i_epoch 0 batch 100: avg loss -1.797168 avg loss no lamb -1.797168 time 2019-02-03 13:02:24.901519
Model ind 579 epoch 582 head B head_i_epoch 0 batch 200: avg loss -1.788811 avg loss no lamb -1.788811 time 2019-02-03 13:05:23.364183
Model ind 579 epoch 582 head A head_i_epoch 0 batch 0: avg loss -3.427531 avg loss no lamb -3.427531 time 2019-02-03 13:08:20.147942
Model ind 579 epoch 582 head A head_i_epoch 0 batch 100: avg loss -3.461501 avg loss no lamb -3.461501 time 2019-02-03 13:11:19.752581
Model ind 579 epoch 582 head A head_i_epoch 0 batch 200: avg loss -3.454098 avg loss no lamb -3.454098 time 2019-02-03 13:14:17.509440
Pre: time 2019-02-03 13:17:40.289085: 
 	std: 0.004901234
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.24645, 0.24723333, 0.23478334, 0.24703333, 0.24733333]
	train_accs: [0.24645, 0.24723333, 0.23478334, 0.24703333, 0.24733333]
	best_train_sub_head: 4
	worst: 0.23478334
	avg: 0.24456665
	best: 0.24733333

Starting e_i: 583
Model ind 579 epoch 583 head B head_i_epoch 0 batch 0: avg loss -1.731615 avg loss no lamb -1.731615 time 2019-02-03 13:17:43.678457
Model ind 579 epoch 583 head B head_i_epoch 0 batch 100: avg loss -1.675669 avg loss no lamb -1.675669 time 2019-02-03 13:20:41.918211
Model ind 579 epoch 583 head B head_i_epoch 0 batch 200: avg loss -1.769501 avg loss no lamb -1.769501 time 2019-02-03 13:23:40.659069
Model ind 579 epoch 583 head A head_i_epoch 0 batch 0: avg loss -3.448751 avg loss no lamb -3.448751 time 2019-02-03 13:26:36.511846
Model ind 579 epoch 583 head A head_i_epoch 0 batch 100: avg loss -3.465461 avg loss no lamb -3.465461 time 2019-02-03 13:29:33.330644
Model ind 579 epoch 583 head A head_i_epoch 0 batch 200: avg loss -3.461753 avg loss no lamb -3.461753 time 2019-02-03 13:32:31.427912
Pre: time 2019-02-03 13:35:53.867295: 
 	std: 0.0040680114
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 7), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 13), (19, 12)]
	test_accs: [0.2447, 0.245, 0.235, 0.24501666, 0.2458]
	train_accs: [0.2447, 0.245, 0.235, 0.24501666, 0.2458]
	best_train_sub_head: 4
	worst: 0.235
	avg: 0.24310334
	best: 0.2458

Starting e_i: 584
Model ind 579 epoch 584 head B head_i_epoch 0 batch 0: avg loss -1.807806 avg loss no lamb -1.807806 time 2019-02-03 13:35:57.505913
Model ind 579 epoch 584 head B head_i_epoch 0 batch 100: avg loss -1.727697 avg loss no lamb -1.727697 time 2019-02-03 13:38:57.101590
Model ind 579 epoch 584 head B head_i_epoch 0 batch 200: avg loss -1.744554 avg loss no lamb -1.744554 time 2019-02-03 13:41:54.751695
Model ind 579 epoch 584 head A head_i_epoch 0 batch 0: avg loss -3.408566 avg loss no lamb -3.408566 time 2019-02-03 13:44:52.792260
Model ind 579 epoch 584 head A head_i_epoch 0 batch 100: avg loss -3.452913 avg loss no lamb -3.452913 time 2019-02-03 13:47:52.353376
Model ind 579 epoch 584 head A head_i_epoch 0 batch 200: avg loss -3.375633 avg loss no lamb -3.375633 time 2019-02-03 13:50:51.931062
Pre: time 2019-02-03 13:54:19.484452: 
 	std: 0.0040046503
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.24363333, 0.24491666, 0.23476666, 0.24498333, 0.2452]
	train_accs: [0.24363333, 0.24491666, 0.23476666, 0.24498333, 0.2452]
	best_train_sub_head: 4
	worst: 0.23476666
	avg: 0.24270001
	best: 0.2452

Starting e_i: 585
Model ind 579 epoch 585 head B head_i_epoch 0 batch 0: avg loss -1.864332 avg loss no lamb -1.864332 time 2019-02-03 13:54:23.091395
Model ind 579 epoch 585 head B head_i_epoch 0 batch 100: avg loss -1.805172 avg loss no lamb -1.805172 time 2019-02-03 13:57:20.238793
Model ind 579 epoch 585 head B head_i_epoch 0 batch 200: avg loss -1.734671 avg loss no lamb -1.734671 time 2019-02-03 14:00:17.533486
Model ind 579 epoch 585 head A head_i_epoch 0 batch 0: avg loss -3.406425 avg loss no lamb -3.406425 time 2019-02-03 14:03:13.364693
Model ind 579 epoch 585 head A head_i_epoch 0 batch 100: avg loss -3.432331 avg loss no lamb -3.432331 time 2019-02-03 14:06:11.890756
Model ind 579 epoch 585 head A head_i_epoch 0 batch 200: avg loss -3.444521 avg loss no lamb -3.444521 time 2019-02-03 14:09:10.623432
Pre: time 2019-02-03 14:12:35.426117: 
 	std: 0.0038778926
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 13), (4, 4), (5, 3), (6, 18), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2484, 0.24875, 0.2389, 0.24888334, 0.24828333]
	train_accs: [0.2484, 0.24875, 0.2389, 0.24888334, 0.24828333]
	best_train_sub_head: 3
	worst: 0.2389
	avg: 0.24664335
	best: 0.24888334

Starting e_i: 586
Model ind 579 epoch 586 head B head_i_epoch 0 batch 0: avg loss -1.861898 avg loss no lamb -1.861898 time 2019-02-03 14:12:39.562856
Model ind 579 epoch 586 head B head_i_epoch 0 batch 100: avg loss -1.733988 avg loss no lamb -1.733988 time 2019-02-03 14:15:38.187774
Model ind 579 epoch 586 head B head_i_epoch 0 batch 200: avg loss -1.715826 avg loss no lamb -1.715826 time 2019-02-03 14:18:35.382768
Model ind 579 epoch 586 head A head_i_epoch 0 batch 0: avg loss -3.325884 avg loss no lamb -3.325884 time 2019-02-03 14:21:31.618747
Model ind 579 epoch 586 head A head_i_epoch 0 batch 100: avg loss -3.435684 avg loss no lamb -3.435684 time 2019-02-03 14:24:30.453898
Model ind 579 epoch 586 head A head_i_epoch 0 batch 200: avg loss -3.402792 avg loss no lamb -3.402792 time 2019-02-03 14:27:27.957790
Pre: time 2019-02-03 14:30:52.633904: 
 	std: 0.0043902337
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24673334, 0.24763334, 0.23623334, 0.24693333, 0.24741666]
	train_accs: [0.24673334, 0.24763334, 0.23623334, 0.24693333, 0.24741666]
	best_train_sub_head: 1
	worst: 0.23623334
	avg: 0.24498999
	best: 0.24763334

Starting e_i: 587
Model ind 579 epoch 587 head B head_i_epoch 0 batch 0: avg loss -1.778190 avg loss no lamb -1.778190 time 2019-02-03 14:30:56.027068
Model ind 579 epoch 587 head B head_i_epoch 0 batch 100: avg loss -1.742236 avg loss no lamb -1.742236 time 2019-02-03 14:33:52.581756
Model ind 579 epoch 587 head B head_i_epoch 0 batch 200: avg loss -1.823262 avg loss no lamb -1.823262 time 2019-02-03 14:36:49.961113
Model ind 579 epoch 587 head A head_i_epoch 0 batch 0: avg loss -3.426560 avg loss no lamb -3.426560 time 2019-02-03 14:39:47.358935
Model ind 579 epoch 587 head A head_i_epoch 0 batch 100: avg loss -3.462253 avg loss no lamb -3.462253 time 2019-02-03 14:42:47.008997
Model ind 579 epoch 587 head A head_i_epoch 0 batch 200: avg loss -3.408159 avg loss no lamb -3.408159 time 2019-02-03 14:45:46.697553
Pre: time 2019-02-03 14:49:11.651891: 
 	std: 0.0042200247
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.24361667, 0.2437, 0.23341666, 0.24385, 0.24456666]
	train_accs: [0.24361667, 0.2437, 0.23341666, 0.24385, 0.24456666]
	best_train_sub_head: 4
	worst: 0.23341666
	avg: 0.24182999
	best: 0.24456666

Starting e_i: 588
Model ind 579 epoch 588 head B head_i_epoch 0 batch 0: avg loss -1.756501 avg loss no lamb -1.756501 time 2019-02-03 14:49:15.172181
Model ind 579 epoch 588 head B head_i_epoch 0 batch 100: avg loss -1.808436 avg loss no lamb -1.808436 time 2019-02-03 14:52:13.713386
Model ind 579 epoch 588 head B head_i_epoch 0 batch 200: avg loss -1.844662 avg loss no lamb -1.844662 time 2019-02-03 14:55:10.562655
Model ind 579 epoch 588 head A head_i_epoch 0 batch 0: avg loss -3.394847 avg loss no lamb -3.394847 time 2019-02-03 14:58:07.670311
Model ind 579 epoch 588 head A head_i_epoch 0 batch 100: avg loss -3.409643 avg loss no lamb -3.409643 time 2019-02-03 15:01:06.053914
Model ind 579 epoch 588 head A head_i_epoch 0 batch 200: avg loss -3.412664 avg loss no lamb -3.412664 time 2019-02-03 15:04:03.437036
Pre: time 2019-02-03 15:07:24.713776: 
 	std: 0.004796508
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24945, 0.2485, 0.23706667, 0.24903333, 0.24915]
	train_accs: [0.24945, 0.2485, 0.23706667, 0.24903333, 0.24915]
	best_train_sub_head: 0
	worst: 0.23706667
	avg: 0.24664001
	best: 0.24945

Starting e_i: 589
Model ind 579 epoch 589 head B head_i_epoch 0 batch 0: avg loss -1.802563 avg loss no lamb -1.802563 time 2019-02-03 15:07:28.179675
Model ind 579 epoch 589 head B head_i_epoch 0 batch 100: avg loss -1.762689 avg loss no lamb -1.762689 time 2019-02-03 15:10:24.634382
Model ind 579 epoch 589 head B head_i_epoch 0 batch 200: avg loss -1.733862 avg loss no lamb -1.733862 time 2019-02-03 15:13:22.963645
Model ind 579 epoch 589 head A head_i_epoch 0 batch 0: avg loss -3.428360 avg loss no lamb -3.428360 time 2019-02-03 15:16:20.385667
Model ind 579 epoch 589 head A head_i_epoch 0 batch 100: avg loss -3.392055 avg loss no lamb -3.392055 time 2019-02-03 15:19:21.210291
Model ind 579 epoch 589 head A head_i_epoch 0 batch 200: avg loss -3.430170 avg loss no lamb -3.430170 time 2019-02-03 15:22:20.057299
Pre: time 2019-02-03 15:25:41.885749: 
 	std: 0.004815145
	best_train_sub_head_match: [(0, 13), (1, 15), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 18)]
	test_accs: [0.248, 0.24806666, 0.23593333, 0.24808334, 0.24771667]
	train_accs: [0.248, 0.24806666, 0.23593333, 0.24808334, 0.24771667]
	best_train_sub_head: 3
	worst: 0.23593333
	avg: 0.24556
	best: 0.24808334

Starting e_i: 590
Model ind 579 epoch 590 head B head_i_epoch 0 batch 0: avg loss -1.777439 avg loss no lamb -1.777439 time 2019-02-03 15:25:45.354144
Model ind 579 epoch 590 head B head_i_epoch 0 batch 100: avg loss -1.809002 avg loss no lamb -1.809002 time 2019-02-03 15:28:42.504687
Model ind 579 epoch 590 head B head_i_epoch 0 batch 200: avg loss -1.731736 avg loss no lamb -1.731736 time 2019-02-03 15:31:38.552497
Model ind 579 epoch 590 head A head_i_epoch 0 batch 0: avg loss -3.385258 avg loss no lamb -3.385258 time 2019-02-03 15:34:36.076321
Model ind 579 epoch 590 head A head_i_epoch 0 batch 100: avg loss -3.455756 avg loss no lamb -3.455756 time 2019-02-03 15:37:35.394883
Model ind 579 epoch 590 head A head_i_epoch 0 batch 200: avg loss -3.438334 avg loss no lamb -3.438334 time 2019-02-03 15:40:32.468134
Pre: time 2019-02-03 15:43:54.264753: 
 	std: 0.0048453133
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24673334, 0.24638334, 0.23438333, 0.24651666, 0.24633333]
	train_accs: [0.24673334, 0.24638334, 0.23438333, 0.24651666, 0.24633333]
	best_train_sub_head: 0
	worst: 0.23438333
	avg: 0.24407001
	best: 0.24673334

Starting e_i: 591
Model ind 579 epoch 591 head B head_i_epoch 0 batch 0: avg loss -1.838137 avg loss no lamb -1.838137 time 2019-02-03 15:44:03.242521
Model ind 579 epoch 591 head B head_i_epoch 0 batch 100: avg loss -1.755465 avg loss no lamb -1.755465 time 2019-02-03 15:46:59.920268
Model ind 579 epoch 591 head B head_i_epoch 0 batch 200: avg loss -1.871049 avg loss no lamb -1.871049 time 2019-02-03 15:49:57.031519
Model ind 579 epoch 591 head A head_i_epoch 0 batch 0: avg loss -3.458971 avg loss no lamb -3.458971 time 2019-02-03 15:52:54.978968
Model ind 579 epoch 591 head A head_i_epoch 0 batch 100: avg loss -3.456649 avg loss no lamb -3.456649 time 2019-02-03 15:55:52.002014
Model ind 579 epoch 591 head A head_i_epoch 0 batch 200: avg loss -3.426428 avg loss no lamb -3.426428 time 2019-02-03 15:58:50.859724
Pre: time 2019-02-03 16:02:12.388316: 
 	std: 0.0046684863
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24541667, 0.24581666, 0.23391667, 0.24553333, 0.24556667]
	train_accs: [0.24541667, 0.24581666, 0.23391667, 0.24553333, 0.24556667]
	best_train_sub_head: 1
	worst: 0.23391667
	avg: 0.24324998
	best: 0.24581666

Starting e_i: 592
Model ind 579 epoch 592 head B head_i_epoch 0 batch 0: avg loss -1.867748 avg loss no lamb -1.867748 time 2019-02-03 16:02:16.894444
Model ind 579 epoch 592 head B head_i_epoch 0 batch 100: avg loss -1.772428 avg loss no lamb -1.772428 time 2019-02-03 16:05:13.712462
Model ind 579 epoch 592 head B head_i_epoch 0 batch 200: avg loss -1.909397 avg loss no lamb -1.909397 time 2019-02-03 16:08:10.278400
Model ind 579 epoch 592 head A head_i_epoch 0 batch 0: avg loss -3.424825 avg loss no lamb -3.424825 time 2019-02-03 16:11:07.513742
Model ind 579 epoch 592 head A head_i_epoch 0 batch 100: avg loss -3.419557 avg loss no lamb -3.419557 time 2019-02-03 16:14:06.548904
Model ind 579 epoch 592 head A head_i_epoch 0 batch 200: avg loss -3.407919 avg loss no lamb -3.407919 time 2019-02-03 16:17:04.353945
Pre: time 2019-02-03 16:20:26.821088: 
 	std: 0.0042196
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24561666, 0.2459, 0.23516667, 0.24571666, 0.24561666]
	train_accs: [0.24561666, 0.2459, 0.23516667, 0.24571666, 0.24561666]
	best_train_sub_head: 1
	worst: 0.23516667
	avg: 0.24360332
	best: 0.2459

Starting e_i: 593
Model ind 579 epoch 593 head B head_i_epoch 0 batch 0: avg loss -1.768230 avg loss no lamb -1.768230 time 2019-02-03 16:20:30.340806
Model ind 579 epoch 593 head B head_i_epoch 0 batch 100: avg loss -1.832498 avg loss no lamb -1.832498 time 2019-02-03 16:23:27.825385
Model ind 579 epoch 593 head B head_i_epoch 0 batch 200: avg loss -1.875998 avg loss no lamb -1.875998 time 2019-02-03 16:26:24.823950
Model ind 579 epoch 593 head A head_i_epoch 0 batch 0: avg loss -3.441821 avg loss no lamb -3.441821 time 2019-02-03 16:29:22.414475
Model ind 579 epoch 593 head A head_i_epoch 0 batch 100: avg loss -3.404523 avg loss no lamb -3.404523 time 2019-02-03 16:32:19.707716
Model ind 579 epoch 593 head A head_i_epoch 0 batch 200: avg loss -3.407951 avg loss no lamb -3.407951 time 2019-02-03 16:35:16.958927
Pre: time 2019-02-03 16:38:38.931026: 
 	std: 0.0045132204
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24713333, 0.24745, 0.23616667, 0.24791667, 0.24721667]
	train_accs: [0.24713333, 0.24745, 0.23616667, 0.24791667, 0.24721667]
	best_train_sub_head: 3
	worst: 0.23616667
	avg: 0.24517667
	best: 0.24791667

Starting e_i: 594
Model ind 579 epoch 594 head B head_i_epoch 0 batch 0: avg loss -1.837588 avg loss no lamb -1.837588 time 2019-02-03 16:38:42.397557
Model ind 579 epoch 594 head B head_i_epoch 0 batch 100: avg loss -1.662522 avg loss no lamb -1.662522 time 2019-02-03 16:41:40.193017
Model ind 579 epoch 594 head B head_i_epoch 0 batch 200: avg loss -1.830246 avg loss no lamb -1.830246 time 2019-02-03 16:44:36.102378
Model ind 579 epoch 594 head A head_i_epoch 0 batch 0: avg loss -3.455594 avg loss no lamb -3.455594 time 2019-02-03 16:47:32.595921
Model ind 579 epoch 594 head A head_i_epoch 0 batch 100: avg loss -3.394566 avg loss no lamb -3.394566 time 2019-02-03 16:50:30.028918
Model ind 579 epoch 594 head A head_i_epoch 0 batch 200: avg loss -3.440243 avg loss no lamb -3.440243 time 2019-02-03 16:53:28.363590
Pre: time 2019-02-03 16:56:50.775207: 
 	std: 0.0044659507
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24523333, 0.2456, 0.23433334, 0.24568333, 0.24545]
	train_accs: [0.24523333, 0.2456, 0.23433334, 0.24568333, 0.24545]
	best_train_sub_head: 3
	worst: 0.23433334
	avg: 0.24326
	best: 0.24568333

Starting e_i: 595
Model ind 579 epoch 595 head B head_i_epoch 0 batch 0: avg loss -1.681515 avg loss no lamb -1.681515 time 2019-02-03 16:56:54.270005
Model ind 579 epoch 595 head B head_i_epoch 0 batch 100: avg loss -1.758533 avg loss no lamb -1.758533 time 2019-02-03 16:59:51.328737
Model ind 579 epoch 595 head B head_i_epoch 0 batch 200: avg loss -1.788627 avg loss no lamb -1.788627 time 2019-02-03 17:02:50.478901
Model ind 579 epoch 595 head A head_i_epoch 0 batch 0: avg loss -3.441462 avg loss no lamb -3.441462 time 2019-02-03 17:05:47.655720
Model ind 579 epoch 595 head A head_i_epoch 0 batch 100: avg loss -3.407631 avg loss no lamb -3.407631 time 2019-02-03 17:08:45.242036
Model ind 579 epoch 595 head A head_i_epoch 0 batch 200: avg loss -3.435135 avg loss no lamb -3.435135 time 2019-02-03 17:11:44.324089
Pre: time 2019-02-03 17:15:06.245792: 
 	std: 0.005064204
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.2499, 0.24998334, 0.23746666, 0.25008333, 0.2505]
	train_accs: [0.2499, 0.24998334, 0.23746666, 0.25008333, 0.2505]
	best_train_sub_head: 4
	worst: 0.23746666
	avg: 0.24758665
	best: 0.2505

Starting e_i: 596
Model ind 579 epoch 596 head B head_i_epoch 0 batch 0: avg loss -1.854470 avg loss no lamb -1.854470 time 2019-02-03 17:15:09.973050
Model ind 579 epoch 596 head B head_i_epoch 0 batch 100: avg loss -1.767903 avg loss no lamb -1.767903 time 2019-02-03 17:18:08.686946
Model ind 579 epoch 596 head B head_i_epoch 0 batch 200: avg loss -1.810563 avg loss no lamb -1.810563 time 2019-02-03 17:21:06.024149
Model ind 579 epoch 596 head A head_i_epoch 0 batch 0: avg loss -3.436224 avg loss no lamb -3.436224 time 2019-02-03 17:24:03.156673
Model ind 579 epoch 596 head A head_i_epoch 0 batch 100: avg loss -3.393161 avg loss no lamb -3.393161 time 2019-02-03 17:27:00.755749
Model ind 579 epoch 596 head A head_i_epoch 0 batch 200: avg loss -3.479567 avg loss no lamb -3.479567 time 2019-02-03 17:29:58.769425
Pre: time 2019-02-03 17:33:20.950879: 
 	std: 0.0050187046
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 5), (4, 4), (5, 3), (6, 18), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 13), (19, 19)]
	test_accs: [0.25043333, 0.24995, 0.23778333, 0.25048333, 0.25041667]
	train_accs: [0.25043333, 0.24995, 0.23778333, 0.25048333, 0.25041667]
	best_train_sub_head: 3
	worst: 0.23778333
	avg: 0.24781331
	best: 0.25048333

Starting e_i: 597
Model ind 579 epoch 597 head B head_i_epoch 0 batch 0: avg loss -1.872950 avg loss no lamb -1.872950 time 2019-02-03 17:33:24.632105
Model ind 579 epoch 597 head B head_i_epoch 0 batch 100: avg loss -1.759366 avg loss no lamb -1.759366 time 2019-02-03 17:36:21.494249
Model ind 579 epoch 597 head B head_i_epoch 0 batch 200: avg loss -1.753584 avg loss no lamb -1.753584 time 2019-02-03 17:39:21.179503
Model ind 579 epoch 597 head A head_i_epoch 0 batch 0: avg loss -3.395166 avg loss no lamb -3.395166 time 2019-02-03 17:42:19.991830
Model ind 579 epoch 597 head A head_i_epoch 0 batch 100: avg loss -3.487170 avg loss no lamb -3.487170 time 2019-02-03 17:45:19.465204
Model ind 579 epoch 597 head A head_i_epoch 0 batch 200: avg loss -3.385172 avg loss no lamb -3.385172 time 2019-02-03 17:48:17.695725
Pre: time 2019-02-03 17:51:40.365706: 
 	std: 0.003938069
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 13), (19, 18)]
	test_accs: [0.24926667, 0.24913333, 0.23961666, 0.24971667, 0.24966666]
	train_accs: [0.24926667, 0.24913333, 0.23961666, 0.24971667, 0.24966666]
	best_train_sub_head: 3
	worst: 0.23961666
	avg: 0.24748
	best: 0.24971667

Starting e_i: 598
Model ind 579 epoch 598 head B head_i_epoch 0 batch 0: avg loss -1.816420 avg loss no lamb -1.816420 time 2019-02-03 17:51:43.869584
Model ind 579 epoch 598 head B head_i_epoch 0 batch 100: avg loss -1.741611 avg loss no lamb -1.741611 time 2019-02-03 17:54:41.896732
Model ind 579 epoch 598 head B head_i_epoch 0 batch 200: avg loss -1.790481 avg loss no lamb -1.790481 time 2019-02-03 17:57:37.445427
Model ind 579 epoch 598 head A head_i_epoch 0 batch 0: avg loss -3.478540 avg loss no lamb -3.478540 time 2019-02-03 18:00:33.927891
Model ind 579 epoch 598 head A head_i_epoch 0 batch 100: avg loss -3.404575 avg loss no lamb -3.404575 time 2019-02-03 18:03:32.471561
Model ind 579 epoch 598 head A head_i_epoch 0 batch 200: avg loss -3.415695 avg loss no lamb -3.415695 time 2019-02-03 18:06:30.360487
Pre: time 2019-02-03 18:09:53.341724: 
 	std: 0.0037294233
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 13), (19, 18)]
	test_accs: [0.24745, 0.24768333, 0.23851667, 0.24811667, 0.24803333]
	train_accs: [0.24745, 0.24768333, 0.23851667, 0.24811667, 0.24803333]
	best_train_sub_head: 3
	worst: 0.23851667
	avg: 0.24596
	best: 0.24811667

Starting e_i: 599
Model ind 579 epoch 599 head B head_i_epoch 0 batch 0: avg loss -1.805107 avg loss no lamb -1.805107 time 2019-02-03 18:09:56.815152
Model ind 579 epoch 599 head B head_i_epoch 0 batch 100: avg loss -1.823330 avg loss no lamb -1.823330 time 2019-02-03 18:12:53.815359
Model ind 579 epoch 599 head B head_i_epoch 0 batch 200: avg loss -1.854579 avg loss no lamb -1.854579 time 2019-02-03 18:15:49.529890
Model ind 579 epoch 599 head A head_i_epoch 0 batch 0: avg loss -3.376508 avg loss no lamb -3.376508 time 2019-02-03 18:18:47.092443
Model ind 579 epoch 599 head A head_i_epoch 0 batch 100: avg loss -3.429544 avg loss no lamb -3.429544 time 2019-02-03 18:21:45.246563
Model ind 579 epoch 599 head A head_i_epoch 0 batch 200: avg loss -3.431189 avg loss no lamb -3.431189 time 2019-02-03 18:24:42.614608
Pre: time 2019-02-03 18:28:07.640942: 
 	std: 0.0047592986
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.2488, 0.24981667, 0.23771666, 0.24968334, 0.24998334]
	train_accs: [0.2488, 0.24981667, 0.23771666, 0.24968334, 0.24998334]
	best_train_sub_head: 4
	worst: 0.23771666
	avg: 0.24719998
	best: 0.24998334

Starting e_i: 600
Model ind 579 epoch 600 head B head_i_epoch 0 batch 0: avg loss -1.774336 avg loss no lamb -1.774336 time 2019-02-03 18:28:11.204483
Model ind 579 epoch 600 head B head_i_epoch 0 batch 100: avg loss -1.650883 avg loss no lamb -1.650883 time 2019-02-03 18:31:10.378295
Model ind 579 epoch 600 head B head_i_epoch 0 batch 200: avg loss -1.767199 avg loss no lamb -1.767199 time 2019-02-03 18:34:08.501789
Model ind 579 epoch 600 head A head_i_epoch 0 batch 0: avg loss -3.405383 avg loss no lamb -3.405383 time 2019-02-03 18:37:05.688334
Model ind 579 epoch 600 head A head_i_epoch 0 batch 100: avg loss -3.438735 avg loss no lamb -3.438735 time 2019-02-03 18:40:04.332043
Model ind 579 epoch 600 head A head_i_epoch 0 batch 200: avg loss -3.392764 avg loss no lamb -3.392764 time 2019-02-03 18:43:01.833209
Pre: time 2019-02-03 18:46:24.884944: 
 	std: 0.004287266
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24746667, 0.2485, 0.2373, 0.24823333, 0.24771667]
	train_accs: [0.24746667, 0.2485, 0.2373, 0.24823333, 0.24771667]
	best_train_sub_head: 1
	worst: 0.2373
	avg: 0.24584332
	best: 0.2485

Starting e_i: 601
Model ind 579 epoch 601 head B head_i_epoch 0 batch 0: avg loss -1.769938 avg loss no lamb -1.769938 time 2019-02-03 18:46:33.358335
Model ind 579 epoch 601 head B head_i_epoch 0 batch 100: avg loss -1.749177 avg loss no lamb -1.749177 time 2019-02-03 18:49:29.953432
Model ind 579 epoch 601 head B head_i_epoch 0 batch 200: avg loss -1.756537 avg loss no lamb -1.756537 time 2019-02-03 18:52:27.980843
Model ind 579 epoch 601 head A head_i_epoch 0 batch 0: avg loss -3.365923 avg loss no lamb -3.365923 time 2019-02-03 18:55:25.588365
Model ind 579 epoch 601 head A head_i_epoch 0 batch 100: avg loss -3.475920 avg loss no lamb -3.475920 time 2019-02-03 18:58:25.787748
Model ind 579 epoch 601 head A head_i_epoch 0 batch 200: avg loss -3.438735 avg loss no lamb -3.438735 time 2019-02-03 19:01:23.967057
Pre: time 2019-02-03 19:04:45.931282: 
 	std: 0.005108246
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24965, 0.2488, 0.23636666, 0.24921666, 0.24878334]
	train_accs: [0.24965, 0.2488, 0.23636666, 0.24921666, 0.24878334]
	best_train_sub_head: 0
	worst: 0.23636666
	avg: 0.24656335
	best: 0.24965

Starting e_i: 602
Model ind 579 epoch 602 head B head_i_epoch 0 batch 0: avg loss -1.725211 avg loss no lamb -1.725211 time 2019-02-03 19:04:49.562629
Model ind 579 epoch 602 head B head_i_epoch 0 batch 100: avg loss -1.828054 avg loss no lamb -1.828054 time 2019-02-03 19:07:46.291885
Model ind 579 epoch 602 head B head_i_epoch 0 batch 200: avg loss -1.867513 avg loss no lamb -1.867513 time 2019-02-03 19:10:45.239784
Model ind 579 epoch 602 head A head_i_epoch 0 batch 0: avg loss -3.412175 avg loss no lamb -3.412175 time 2019-02-03 19:13:43.142961
Model ind 579 epoch 602 head A head_i_epoch 0 batch 100: avg loss -3.387516 avg loss no lamb -3.387516 time 2019-02-03 19:16:43.404174
Model ind 579 epoch 602 head A head_i_epoch 0 batch 200: avg loss -3.412921 avg loss no lamb -3.412921 time 2019-02-03 19:19:42.060359
Pre: time 2019-02-03 19:23:05.265909: 
 	std: 0.00443929
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 5), (12, 13), (13, 18), (14, 1), (15, 15), (16, 6), (17, 3), (18, 19), (19, 12)]
	test_accs: [0.24646667, 0.2462, 0.23538333, 0.2466, 0.24663334]
	train_accs: [0.24646667, 0.2462, 0.23538333, 0.2466, 0.24663334]
	best_train_sub_head: 4
	worst: 0.23538333
	avg: 0.24425666
	best: 0.24663334

Starting e_i: 603
Model ind 579 epoch 603 head B head_i_epoch 0 batch 0: avg loss -1.761813 avg loss no lamb -1.761813 time 2019-02-03 19:23:09.264439
Model ind 579 epoch 603 head B head_i_epoch 0 batch 100: avg loss -1.736219 avg loss no lamb -1.736219 time 2019-02-03 19:26:06.320611
Model ind 579 epoch 603 head B head_i_epoch 0 batch 200: avg loss -1.839824 avg loss no lamb -1.839824 time 2019-02-03 19:29:03.758149
Model ind 579 epoch 603 head A head_i_epoch 0 batch 0: avg loss -3.400774 avg loss no lamb -3.400774 time 2019-02-03 19:32:00.879526
Model ind 579 epoch 603 head A head_i_epoch 0 batch 100: avg loss -3.485581 avg loss no lamb -3.485581 time 2019-02-03 19:34:58.788286
Model ind 579 epoch 603 head A head_i_epoch 0 batch 200: avg loss -3.486474 avg loss no lamb -3.486474 time 2019-02-03 19:37:56.474115
Pre: time 2019-02-03 19:41:20.401428: 
 	std: 0.00459407
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24683334, 0.2466, 0.2352, 0.24668333, 0.24661666]
	train_accs: [0.24683334, 0.2466, 0.2352, 0.24668333, 0.24661666]
	best_train_sub_head: 0
	worst: 0.2352
	avg: 0.24438667
	best: 0.24683334

Starting e_i: 604
Model ind 579 epoch 604 head B head_i_epoch 0 batch 0: avg loss -1.747669 avg loss no lamb -1.747669 time 2019-02-03 19:41:23.933359
Model ind 579 epoch 604 head B head_i_epoch 0 batch 100: avg loss -1.836532 avg loss no lamb -1.836532 time 2019-02-03 19:44:20.629580
Model ind 579 epoch 604 head B head_i_epoch 0 batch 200: avg loss -1.875820 avg loss no lamb -1.875820 time 2019-02-03 19:47:17.846022
Model ind 579 epoch 604 head A head_i_epoch 0 batch 0: avg loss -3.386302 avg loss no lamb -3.386302 time 2019-02-03 19:50:15.968880
Model ind 579 epoch 604 head A head_i_epoch 0 batch 100: avg loss -3.426284 avg loss no lamb -3.426284 time 2019-02-03 19:53:17.426827
Model ind 579 epoch 604 head A head_i_epoch 0 batch 200: avg loss -3.392978 avg loss no lamb -3.392978 time 2019-02-03 19:56:16.811345
Pre: time 2019-02-03 19:59:38.627413: 
 	std: 0.004664147
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.24648333, 0.24685, 0.23526667, 0.24688333, 0.2474]
	train_accs: [0.24648333, 0.24685, 0.23526667, 0.24688333, 0.2474]
	best_train_sub_head: 4
	worst: 0.23526667
	avg: 0.24457666
	best: 0.2474

Starting e_i: 605
Model ind 579 epoch 605 head B head_i_epoch 0 batch 0: avg loss -1.789510 avg loss no lamb -1.789510 time 2019-02-03 19:59:42.549504
Model ind 579 epoch 605 head B head_i_epoch 0 batch 100: avg loss -1.835792 avg loss no lamb -1.835792 time 2019-02-03 20:02:40.042549
Model ind 579 epoch 605 head B head_i_epoch 0 batch 200: avg loss -1.800141 avg loss no lamb -1.800141 time 2019-02-03 20:05:38.446439
Model ind 579 epoch 605 head A head_i_epoch 0 batch 0: avg loss -3.348756 avg loss no lamb -3.348756 time 2019-02-03 20:08:36.391553
Model ind 579 epoch 605 head A head_i_epoch 0 batch 100: avg loss -3.426543 avg loss no lamb -3.426543 time 2019-02-03 20:11:35.106938
Model ind 579 epoch 605 head A head_i_epoch 0 batch 200: avg loss -3.412287 avg loss no lamb -3.412287 time 2019-02-03 20:14:34.109485
Pre: time 2019-02-03 20:17:57.558322: 
 	std: 0.004348954
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24908334, 0.24788333, 0.23776667, 0.24853334, 0.24886666]
	train_accs: [0.24908334, 0.24788333, 0.23776667, 0.24853334, 0.24886666]
	best_train_sub_head: 0
	worst: 0.23776667
	avg: 0.24642667
	best: 0.24908334

Starting e_i: 606
Model ind 579 epoch 606 head B head_i_epoch 0 batch 0: avg loss -1.732986 avg loss no lamb -1.732986 time 2019-02-03 20:18:01.097415
Model ind 579 epoch 606 head B head_i_epoch 0 batch 100: avg loss -1.766164 avg loss no lamb -1.766164 time 2019-02-03 20:20:57.612238
Model ind 579 epoch 606 head B head_i_epoch 0 batch 200: avg loss -1.809686 avg loss no lamb -1.809686 time 2019-02-03 20:23:55.700723
Model ind 579 epoch 606 head A head_i_epoch 0 batch 0: avg loss -3.429056 avg loss no lamb -3.429056 time 2019-02-03 20:26:54.194625
Model ind 579 epoch 606 head A head_i_epoch 0 batch 100: avg loss -3.450396 avg loss no lamb -3.450396 time 2019-02-03 20:29:52.628292
Model ind 579 epoch 606 head A head_i_epoch 0 batch 200: avg loss -3.457099 avg loss no lamb -3.457099 time 2019-02-03 20:32:50.212334
Pre: time 2019-02-03 20:36:12.394205: 
 	std: 0.0047787665
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24653333, 0.24615, 0.23413333, 0.24555, 0.24598333]
	train_accs: [0.24653333, 0.24615, 0.23413333, 0.24555, 0.24598333]
	best_train_sub_head: 0
	worst: 0.23413333
	avg: 0.24367002
	best: 0.24653333

Starting e_i: 607
Model ind 579 epoch 607 head B head_i_epoch 0 batch 0: avg loss -1.792040 avg loss no lamb -1.792040 time 2019-02-03 20:36:16.257072
Model ind 579 epoch 607 head B head_i_epoch 0 batch 100: avg loss -1.761739 avg loss no lamb -1.761739 time 2019-02-03 20:39:13.360638
Model ind 579 epoch 607 head B head_i_epoch 0 batch 200: avg loss -1.850349 avg loss no lamb -1.850349 time 2019-02-03 20:42:11.052291
Model ind 579 epoch 607 head A head_i_epoch 0 batch 0: avg loss -3.400543 avg loss no lamb -3.400543 time 2019-02-03 20:45:07.762868
Model ind 579 epoch 607 head A head_i_epoch 0 batch 100: avg loss -3.481807 avg loss no lamb -3.481807 time 2019-02-03 20:48:05.194027
Model ind 579 epoch 607 head A head_i_epoch 0 batch 200: avg loss -3.486250 avg loss no lamb -3.486250 time 2019-02-03 20:51:05.380095
Pre: time 2019-02-03 20:54:27.303047: 
 	std: 0.0036392068
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.24761666, 0.24766667, 0.23851667, 0.24736667, 0.24778333]
	train_accs: [0.24761666, 0.24766667, 0.23851667, 0.24736667, 0.24778333]
	best_train_sub_head: 4
	worst: 0.23851667
	avg: 0.24579
	best: 0.24778333

Starting e_i: 608
Model ind 579 epoch 608 head B head_i_epoch 0 batch 0: avg loss -1.788060 avg loss no lamb -1.788060 time 2019-02-03 20:54:30.905525
Model ind 579 epoch 608 head B head_i_epoch 0 batch 100: avg loss -1.765357 avg loss no lamb -1.765357 time 2019-02-03 20:57:29.330391
Model ind 579 epoch 608 head B head_i_epoch 0 batch 200: avg loss -1.830230 avg loss no lamb -1.830230 time 2019-02-03 21:00:26.179585
Model ind 579 epoch 608 head A head_i_epoch 0 batch 0: avg loss -3.407176 avg loss no lamb -3.407176 time 2019-02-03 21:03:23.654513
Model ind 579 epoch 608 head A head_i_epoch 0 batch 100: avg loss -3.385274 avg loss no lamb -3.385274 time 2019-02-03 21:06:22.997820
Model ind 579 epoch 608 head A head_i_epoch 0 batch 200: avg loss -3.411237 avg loss no lamb -3.411237 time 2019-02-03 21:09:23.525527
Pre: time 2019-02-03 21:12:47.845089: 
 	std: 0.0033634477
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24546666, 0.24605, 0.23763333, 0.24638334, 0.24613333]
	train_accs: [0.24546666, 0.24605, 0.23763333, 0.24638334, 0.24613333]
	best_train_sub_head: 3
	worst: 0.23763333
	avg: 0.24433334
	best: 0.24638334

Starting e_i: 609
Model ind 579 epoch 609 head B head_i_epoch 0 batch 0: avg loss -1.718030 avg loss no lamb -1.718030 time 2019-02-03 21:12:51.792217
Model ind 579 epoch 609 head B head_i_epoch 0 batch 100: avg loss -1.777776 avg loss no lamb -1.777776 time 2019-02-03 21:15:50.980283
Model ind 579 epoch 609 head B head_i_epoch 0 batch 200: avg loss -1.749431 avg loss no lamb -1.749431 time 2019-02-03 21:18:48.908500
Model ind 579 epoch 609 head A head_i_epoch 0 batch 0: avg loss -3.485520 avg loss no lamb -3.485520 time 2019-02-03 21:21:46.357828
Model ind 579 epoch 609 head A head_i_epoch 0 batch 100: avg loss -3.450493 avg loss no lamb -3.450493 time 2019-02-03 21:24:43.861107
Model ind 579 epoch 609 head A head_i_epoch 0 batch 200: avg loss -3.371045 avg loss no lamb -3.371045 time 2019-02-03 21:27:41.396888
Pre: time 2019-02-03 21:31:04.534180: 
 	std: 0.004571673
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.245, 0.24563333, 0.23413333, 0.24558334, 0.24593334]
	train_accs: [0.245, 0.24563333, 0.23413333, 0.24558334, 0.24593334]
	best_train_sub_head: 4
	worst: 0.23413333
	avg: 0.24325666
	best: 0.24593334

Starting e_i: 610
Model ind 579 epoch 610 head B head_i_epoch 0 batch 0: avg loss -1.734661 avg loss no lamb -1.734661 time 2019-02-03 21:31:08.268872
Model ind 579 epoch 610 head B head_i_epoch 0 batch 100: avg loss -1.777023 avg loss no lamb -1.777023 time 2019-02-03 21:34:04.735045
Model ind 579 epoch 610 head B head_i_epoch 0 batch 200: avg loss -1.772334 avg loss no lamb -1.772334 time 2019-02-03 21:37:01.841368
Model ind 579 epoch 610 head A head_i_epoch 0 batch 0: avg loss -3.397613 avg loss no lamb -3.397613 time 2019-02-03 21:40:01.344138
Model ind 579 epoch 610 head A head_i_epoch 0 batch 100: avg loss -3.419257 avg loss no lamb -3.419257 time 2019-02-03 21:42:59.456877
Model ind 579 epoch 610 head A head_i_epoch 0 batch 200: avg loss -3.480066 avg loss no lamb -3.480066 time 2019-02-03 21:45:57.408216
Pre: time 2019-02-03 21:49:20.242706: 
 	std: 0.004583813
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24845, 0.24933334, 0.2375, 0.24903333, 0.24893333]
	train_accs: [0.24845, 0.24933334, 0.2375, 0.24903333, 0.24893333]
	best_train_sub_head: 1
	worst: 0.2375
	avg: 0.24665001
	best: 0.24933334

Starting e_i: 611
Model ind 579 epoch 611 head B head_i_epoch 0 batch 0: avg loss -1.783377 avg loss no lamb -1.783377 time 2019-02-03 21:49:28.308597
Model ind 579 epoch 611 head B head_i_epoch 0 batch 100: avg loss -1.675294 avg loss no lamb -1.675294 time 2019-02-03 21:52:24.699863
Model ind 579 epoch 611 head B head_i_epoch 0 batch 200: avg loss -1.850698 avg loss no lamb -1.850698 time 2019-02-03 21:55:22.206839
Model ind 579 epoch 611 head A head_i_epoch 0 batch 0: avg loss -3.416651 avg loss no lamb -3.416651 time 2019-02-03 21:58:21.041711
Model ind 579 epoch 611 head A head_i_epoch 0 batch 100: avg loss -3.543877 avg loss no lamb -3.543877 time 2019-02-03 22:01:20.696002
Model ind 579 epoch 611 head A head_i_epoch 0 batch 200: avg loss -3.479963 avg loss no lamb -3.479963 time 2019-02-03 22:04:19.542078
Pre: time 2019-02-03 22:07:42.917284: 
 	std: 0.004215443
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25043333, 0.25111666, 0.24038333, 0.25121668, 0.25083333]
	train_accs: [0.25043333, 0.25111666, 0.24038333, 0.25121668, 0.25083333]
	best_train_sub_head: 3
	worst: 0.24038333
	avg: 0.24879666
	best: 0.25121668

Starting e_i: 612
Model ind 579 epoch 612 head B head_i_epoch 0 batch 0: avg loss -1.829170 avg loss no lamb -1.829170 time 2019-02-03 22:07:50.144386
Model ind 579 epoch 612 head B head_i_epoch 0 batch 100: avg loss -1.858396 avg loss no lamb -1.858396 time 2019-02-03 22:10:47.502485
Model ind 579 epoch 612 head B head_i_epoch 0 batch 200: avg loss -1.792429 avg loss no lamb -1.792429 time 2019-02-03 22:13:44.179201
Model ind 579 epoch 612 head A head_i_epoch 0 batch 0: avg loss -3.455757 avg loss no lamb -3.455757 time 2019-02-03 22:16:41.007019
Model ind 579 epoch 612 head A head_i_epoch 0 batch 100: avg loss -3.430697 avg loss no lamb -3.430697 time 2019-02-03 22:19:40.071591
Model ind 579 epoch 612 head A head_i_epoch 0 batch 200: avg loss -3.489743 avg loss no lamb -3.489743 time 2019-02-03 22:22:39.126323
Pre: time 2019-02-03 22:26:03.028196: 
 	std: 0.0044220593
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25093332, 0.25171667, 0.24015, 0.25121668, 0.25085]
	train_accs: [0.25093332, 0.25171667, 0.24015, 0.25121668, 0.25085]
	best_train_sub_head: 1
	worst: 0.24015
	avg: 0.24897332
	best: 0.25171667

Starting e_i: 613
Model ind 579 epoch 613 head B head_i_epoch 0 batch 0: avg loss -1.839562 avg loss no lamb -1.839562 time 2019-02-03 22:26:11.430685
Model ind 579 epoch 613 head B head_i_epoch 0 batch 100: avg loss -1.748429 avg loss no lamb -1.748429 time 2019-02-03 22:29:07.759876
Model ind 579 epoch 613 head B head_i_epoch 0 batch 200: avg loss -1.896795 avg loss no lamb -1.896795 time 2019-02-03 22:32:06.319192
Model ind 579 epoch 613 head A head_i_epoch 0 batch 0: avg loss -3.452683 avg loss no lamb -3.452683 time 2019-02-03 22:35:03.123946
Model ind 579 epoch 613 head A head_i_epoch 0 batch 100: avg loss -3.434130 avg loss no lamb -3.434130 time 2019-02-03 22:38:03.120148
Model ind 579 epoch 613 head A head_i_epoch 0 batch 200: avg loss -3.499059 avg loss no lamb -3.499059 time 2019-02-03 22:41:02.632912
Pre: time 2019-02-03 22:44:27.397262: 
 	std: 0.0037354825
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24816667, 0.24925, 0.23933333, 0.24866667, 0.24843334]
	train_accs: [0.24816667, 0.24925, 0.23933333, 0.24866667, 0.24843334]
	best_train_sub_head: 1
	worst: 0.23933333
	avg: 0.24677
	best: 0.24925

Starting e_i: 614
Model ind 579 epoch 614 head B head_i_epoch 0 batch 0: avg loss -1.811343 avg loss no lamb -1.811343 time 2019-02-03 22:44:30.893074
Model ind 579 epoch 614 head B head_i_epoch 0 batch 100: avg loss -1.740515 avg loss no lamb -1.740515 time 2019-02-03 22:47:27.096313
Model ind 579 epoch 614 head B head_i_epoch 0 batch 200: avg loss -1.800161 avg loss no lamb -1.800161 time 2019-02-03 22:50:23.459625
Model ind 579 epoch 614 head A head_i_epoch 0 batch 0: avg loss -3.369668 avg loss no lamb -3.369668 time 2019-02-03 22:53:20.180784
Model ind 579 epoch 614 head A head_i_epoch 0 batch 100: avg loss -3.486298 avg loss no lamb -3.486298 time 2019-02-03 22:56:18.980093
Model ind 579 epoch 614 head A head_i_epoch 0 batch 200: avg loss -3.463771 avg loss no lamb -3.463771 time 2019-02-03 22:59:16.647969
Pre: time 2019-02-03 23:02:41.152186: 
 	std: 0.0044406136
	best_train_sub_head_match: [(0, 13), (1, 15), (2, 2), (3, 5), (4, 4), (5, 3), (6, 18), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24621667, 0.24666667, 0.23538333, 0.24696666, 0.24595]
	train_accs: [0.24621667, 0.24666667, 0.23538333, 0.24696666, 0.24595]
	best_train_sub_head: 3
	worst: 0.23538333
	avg: 0.24423666
	best: 0.24696666

Starting e_i: 615
Model ind 579 epoch 615 head B head_i_epoch 0 batch 0: avg loss -1.757490 avg loss no lamb -1.757490 time 2019-02-03 23:02:44.624481
Model ind 579 epoch 615 head B head_i_epoch 0 batch 100: avg loss -1.859324 avg loss no lamb -1.859324 time 2019-02-03 23:05:40.970422
Model ind 579 epoch 615 head B head_i_epoch 0 batch 200: avg loss -1.768953 avg loss no lamb -1.768953 time 2019-02-03 23:08:37.905170
Model ind 579 epoch 615 head A head_i_epoch 0 batch 0: avg loss -3.444151 avg loss no lamb -3.444151 time 2019-02-03 23:11:33.821005
Model ind 579 epoch 615 head A head_i_epoch 0 batch 100: avg loss -3.427395 avg loss no lamb -3.427395 time 2019-02-03 23:14:31.295658
Model ind 579 epoch 615 head A head_i_epoch 0 batch 200: avg loss -3.557161 avg loss no lamb -3.557161 time 2019-02-03 23:17:30.157042
Pre: time 2019-02-03 23:20:55.266775: 
 	std: 0.0037533487
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 15), (3, 9), (4, 12), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 5), (12, 1), (13, 18), (14, 16), (15, 13), (16, 6), (17, 3), (18, 19), (19, 8)]
	test_accs: [0.24838333, 0.24793333, 0.23871666, 0.24746667, 0.24845]
	train_accs: [0.24838333, 0.24793333, 0.23871666, 0.24746667, 0.24845]
	best_train_sub_head: 4
	worst: 0.23871666
	avg: 0.24619
	best: 0.24845

Starting e_i: 616
Model ind 579 epoch 616 head B head_i_epoch 0 batch 0: avg loss -1.755249 avg loss no lamb -1.755249 time 2019-02-03 23:20:59.147567
Model ind 579 epoch 616 head B head_i_epoch 0 batch 100: avg loss -1.780097 avg loss no lamb -1.780097 time 2019-02-03 23:23:55.067534
Model ind 579 epoch 616 head B head_i_epoch 0 batch 200: avg loss -1.778634 avg loss no lamb -1.778634 time 2019-02-03 23:26:53.697873
Model ind 579 epoch 616 head A head_i_epoch 0 batch 0: avg loss -3.398039 avg loss no lamb -3.398039 time 2019-02-03 23:29:51.362062
Model ind 579 epoch 616 head A head_i_epoch 0 batch 100: avg loss -3.461880 avg loss no lamb -3.461880 time 2019-02-03 23:32:50.838514
Model ind 579 epoch 616 head A head_i_epoch 0 batch 200: avg loss -3.395691 avg loss no lamb -3.395691 time 2019-02-03 23:35:48.595516
Pre: time 2019-02-03 23:39:13.417769: 
 	std: 0.003948804
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 5), (4, 4), (5, 3), (6, 18), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 13), (19, 19)]
	test_accs: [0.24888334, 0.24873333, 0.23916666, 0.24933334, 0.24915]
	train_accs: [0.24888334, 0.24873333, 0.23916666, 0.24933334, 0.24915]
	best_train_sub_head: 3
	worst: 0.23916666
	avg: 0.24705334
	best: 0.24933334

Starting e_i: 617
Model ind 579 epoch 617 head B head_i_epoch 0 batch 0: avg loss -1.835894 avg loss no lamb -1.835894 time 2019-02-03 23:39:16.992374
Model ind 579 epoch 617 head B head_i_epoch 0 batch 100: avg loss -1.775488 avg loss no lamb -1.775488 time 2019-02-03 23:42:14.181650
Model ind 579 epoch 617 head B head_i_epoch 0 batch 200: avg loss -1.899644 avg loss no lamb -1.899644 time 2019-02-03 23:45:11.938215
Model ind 579 epoch 617 head A head_i_epoch 0 batch 0: avg loss -3.367989 avg loss no lamb -3.367989 time 2019-02-03 23:48:10.900003
Model ind 579 epoch 617 head A head_i_epoch 0 batch 100: avg loss -3.428545 avg loss no lamb -3.428545 time 2019-02-03 23:51:09.187938
Model ind 579 epoch 617 head A head_i_epoch 0 batch 200: avg loss -3.407810 avg loss no lamb -3.407810 time 2019-02-03 23:54:06.556104
Pre: time 2019-02-03 23:57:29.479513: 
 	std: 0.0038701901
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 5), (4, 4), (5, 3), (6, 18), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 13), (19, 19)]
	test_accs: [0.25045, 0.25043333, 0.2409, 0.25075, 0.25065]
	train_accs: [0.25045, 0.25043333, 0.2409, 0.25075, 0.25065]
	best_train_sub_head: 3
	worst: 0.2409
	avg: 0.24863668
	best: 0.25075

Starting e_i: 618
Model ind 579 epoch 618 head B head_i_epoch 0 batch 0: avg loss -1.879684 avg loss no lamb -1.879684 time 2019-02-03 23:57:33.374871
Model ind 579 epoch 618 head B head_i_epoch 0 batch 100: avg loss -1.794460 avg loss no lamb -1.794460 time 2019-02-04 00:00:29.623667
Model ind 579 epoch 618 head B head_i_epoch 0 batch 200: avg loss -1.797411 avg loss no lamb -1.797411 time 2019-02-04 00:03:26.819434
Model ind 579 epoch 618 head A head_i_epoch 0 batch 0: avg loss -3.473408 avg loss no lamb -3.473408 time 2019-02-04 00:06:24.264918
Model ind 579 epoch 618 head A head_i_epoch 0 batch 100: avg loss -3.444970 avg loss no lamb -3.444970 time 2019-02-04 00:09:22.522936
Model ind 579 epoch 618 head A head_i_epoch 0 batch 200: avg loss -3.447335 avg loss no lamb -3.447335 time 2019-02-04 00:12:20.908379
Pre: time 2019-02-04 00:15:45.686728: 
 	std: 0.0048974007
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25055, 0.25156668, 0.23888333, 0.25116667, 0.25111666]
	train_accs: [0.25055, 0.25156668, 0.23888333, 0.25116667, 0.25111666]
	best_train_sub_head: 1
	worst: 0.23888333
	avg: 0.24865666
	best: 0.25156668

Starting e_i: 619
Model ind 579 epoch 619 head B head_i_epoch 0 batch 0: avg loss -1.856061 avg loss no lamb -1.856061 time 2019-02-04 00:15:49.289464
Model ind 579 epoch 619 head B head_i_epoch 0 batch 100: avg loss -1.744781 avg loss no lamb -1.744781 time 2019-02-04 00:18:47.862749
Model ind 579 epoch 619 head B head_i_epoch 0 batch 200: avg loss -1.728366 avg loss no lamb -1.728366 time 2019-02-04 00:21:43.938249
Model ind 579 epoch 619 head A head_i_epoch 0 batch 0: avg loss -3.417511 avg loss no lamb -3.417511 time 2019-02-04 00:24:43.382470
Model ind 579 epoch 619 head A head_i_epoch 0 batch 100: avg loss -3.446155 avg loss no lamb -3.446155 time 2019-02-04 00:27:41.186733
Model ind 579 epoch 619 head A head_i_epoch 0 batch 200: avg loss -3.452538 avg loss no lamb -3.452538 time 2019-02-04 00:30:39.676941
Pre: time 2019-02-04 00:34:02.974697: 
 	std: 0.0039274725
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24853334, 0.24843334, 0.23873334, 0.24868333, 0.24855]
	train_accs: [0.24853334, 0.24843334, 0.23873334, 0.24868333, 0.24855]
	best_train_sub_head: 3
	worst: 0.23873334
	avg: 0.24658665
	best: 0.24868333

Starting e_i: 620
Model ind 579 epoch 620 head B head_i_epoch 0 batch 0: avg loss -1.808561 avg loss no lamb -1.808561 time 2019-02-04 00:34:07.289920
Model ind 579 epoch 620 head B head_i_epoch 0 batch 100: avg loss -1.753802 avg loss no lamb -1.753802 time 2019-02-04 00:37:03.840666
Model ind 579 epoch 620 head B head_i_epoch 0 batch 200: avg loss -1.790855 avg loss no lamb -1.790855 time 2019-02-04 00:39:59.901156
Model ind 579 epoch 620 head A head_i_epoch 0 batch 0: avg loss -3.402821 avg loss no lamb -3.402821 time 2019-02-04 00:42:57.201375
Model ind 579 epoch 620 head A head_i_epoch 0 batch 100: avg loss -3.473095 avg loss no lamb -3.473095 time 2019-02-04 00:45:55.684879
Model ind 579 epoch 620 head A head_i_epoch 0 batch 200: avg loss -3.451078 avg loss no lamb -3.451078 time 2019-02-04 00:48:53.128313
Pre: time 2019-02-04 00:52:14.447085: 
 	std: 0.0039852248
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24938333, 0.24801667, 0.23881666, 0.24846667, 0.24898334]
	train_accs: [0.24938333, 0.24801667, 0.23881666, 0.24846667, 0.24898334]
	best_train_sub_head: 0
	worst: 0.23881666
	avg: 0.24673334
	best: 0.24938333

Starting e_i: 621
Model ind 579 epoch 621 head B head_i_epoch 0 batch 0: avg loss -1.846801 avg loss no lamb -1.846801 time 2019-02-04 00:52:23.463535
Model ind 579 epoch 621 head B head_i_epoch 0 batch 100: avg loss -1.777397 avg loss no lamb -1.777397 time 2019-02-04 00:55:20.629384
Model ind 579 epoch 621 head B head_i_epoch 0 batch 200: avg loss -1.730762 avg loss no lamb -1.730762 time 2019-02-04 00:58:19.327468
Model ind 579 epoch 621 head A head_i_epoch 0 batch 0: avg loss -3.454976 avg loss no lamb -3.454976 time 2019-02-04 01:01:18.096825
Model ind 579 epoch 621 head A head_i_epoch 0 batch 100: avg loss -3.448776 avg loss no lamb -3.448776 time 2019-02-04 01:04:17.591689
Model ind 579 epoch 621 head A head_i_epoch 0 batch 200: avg loss -3.505071 avg loss no lamb -3.505071 time 2019-02-04 01:07:16.773690
Pre: time 2019-02-04 01:10:39.902586: 
 	std: 0.004712956
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24931666, 0.24923334, 0.23768333, 0.24966666, 0.24961667]
	train_accs: [0.24931666, 0.24923334, 0.23768333, 0.24966666, 0.24961667]
	best_train_sub_head: 3
	worst: 0.23768333
	avg: 0.24710333
	best: 0.24966666

Starting e_i: 622
Model ind 579 epoch 622 head B head_i_epoch 0 batch 0: avg loss -1.804104 avg loss no lamb -1.804104 time 2019-02-04 01:10:43.464258
Model ind 579 epoch 622 head B head_i_epoch 0 batch 100: avg loss -1.826568 avg loss no lamb -1.826568 time 2019-02-04 01:13:40.716774
Model ind 579 epoch 622 head B head_i_epoch 0 batch 200: avg loss -1.782802 avg loss no lamb -1.782802 time 2019-02-04 01:16:36.205211
Model ind 579 epoch 622 head A head_i_epoch 0 batch 0: avg loss -3.408670 avg loss no lamb -3.408670 time 2019-02-04 01:19:33.261408
Model ind 579 epoch 622 head A head_i_epoch 0 batch 100: avg loss -3.419082 avg loss no lamb -3.419082 time 2019-02-04 01:22:31.191352
Model ind 579 epoch 622 head A head_i_epoch 0 batch 200: avg loss -3.473928 avg loss no lamb -3.473928 time 2019-02-04 01:25:29.644926
Pre: time 2019-02-04 01:28:53.182157: 
 	std: 0.0042909645
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.24845, 0.2484, 0.2377, 0.24828333, 0.24856667]
	train_accs: [0.24845, 0.2484, 0.2377, 0.24828333, 0.24856667]
	best_train_sub_head: 4
	worst: 0.2377
	avg: 0.24628
	best: 0.24856667

Starting e_i: 623
Model ind 579 epoch 623 head B head_i_epoch 0 batch 0: avg loss -1.873529 avg loss no lamb -1.873529 time 2019-02-04 01:28:56.697347
Model ind 579 epoch 623 head B head_i_epoch 0 batch 100: avg loss -1.774477 avg loss no lamb -1.774477 time 2019-02-04 01:31:52.911158
Model ind 579 epoch 623 head B head_i_epoch 0 batch 200: avg loss -1.771902 avg loss no lamb -1.771902 time 2019-02-04 01:34:49.316142
Model ind 579 epoch 623 head A head_i_epoch 0 batch 0: avg loss -3.425920 avg loss no lamb -3.425920 time 2019-02-04 01:37:46.076551
Model ind 579 epoch 623 head A head_i_epoch 0 batch 100: avg loss -3.416548 avg loss no lamb -3.416548 time 2019-02-04 01:40:45.082665
Model ind 579 epoch 623 head A head_i_epoch 0 batch 200: avg loss -3.451684 avg loss no lamb -3.451684 time 2019-02-04 01:43:43.576165
Pre: time 2019-02-04 01:47:06.636038: 
 	std: 0.0037637271
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24821667, 0.24751666, 0.2382, 0.24713333, 0.2474]
	train_accs: [0.24821667, 0.24751666, 0.2382, 0.24713333, 0.2474]
	best_train_sub_head: 0
	worst: 0.2382
	avg: 0.24569333
	best: 0.24821667

Starting e_i: 624
Model ind 579 epoch 624 head B head_i_epoch 0 batch 0: avg loss -1.744271 avg loss no lamb -1.744271 time 2019-02-04 01:47:10.158875
Model ind 579 epoch 624 head B head_i_epoch 0 batch 100: avg loss -1.741482 avg loss no lamb -1.741482 time 2019-02-04 01:50:06.362112
Model ind 579 epoch 624 head B head_i_epoch 0 batch 200: avg loss -1.836514 avg loss no lamb -1.836514 time 2019-02-04 01:53:03.258288
Model ind 579 epoch 624 head A head_i_epoch 0 batch 0: avg loss -3.463135 avg loss no lamb -3.463135 time 2019-02-04 01:55:59.626539
Model ind 579 epoch 624 head A head_i_epoch 0 batch 100: avg loss -3.492303 avg loss no lamb -3.492303 time 2019-02-04 01:59:00.583413
Model ind 579 epoch 624 head A head_i_epoch 0 batch 200: avg loss -3.452813 avg loss no lamb -3.452813 time 2019-02-04 02:01:59.333689
Pre: time 2019-02-04 02:05:24.183353: 
 	std: 0.0038223662
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24883333, 0.2481, 0.23863333, 0.24801667, 0.2476]
	train_accs: [0.24883333, 0.2481, 0.23863333, 0.24801667, 0.2476]
	best_train_sub_head: 0
	worst: 0.23863333
	avg: 0.24623665
	best: 0.24883333

Starting e_i: 625
Model ind 579 epoch 625 head B head_i_epoch 0 batch 0: avg loss -1.781496 avg loss no lamb -1.781496 time 2019-02-04 02:05:28.320960
Model ind 579 epoch 625 head B head_i_epoch 0 batch 100: avg loss -1.720081 avg loss no lamb -1.720081 time 2019-02-04 02:08:24.639409
Model ind 579 epoch 625 head B head_i_epoch 0 batch 200: avg loss -1.810096 avg loss no lamb -1.810096 time 2019-02-04 02:11:22.527880
Model ind 579 epoch 625 head A head_i_epoch 0 batch 0: avg loss -3.424839 avg loss no lamb -3.424839 time 2019-02-04 02:14:20.550997
Model ind 579 epoch 625 head A head_i_epoch 0 batch 100: avg loss -3.447210 avg loss no lamb -3.447210 time 2019-02-04 02:17:19.604247
Model ind 579 epoch 625 head A head_i_epoch 0 batch 200: avg loss -3.452247 avg loss no lamb -3.452247 time 2019-02-04 02:20:18.960266
Pre: time 2019-02-04 02:23:41.478198: 
 	std: 0.0043433714
	best_train_sub_head_match: [(0, 5), (1, 0), (2, 14), (3, 15), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 13), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24853334, 0.24835, 0.23748334, 0.24831666, 0.24815]
	train_accs: [0.24853334, 0.24835, 0.23748334, 0.24831666, 0.24815]
	best_train_sub_head: 0
	worst: 0.23748334
	avg: 0.24616666
	best: 0.24853334

Starting e_i: 626
Model ind 579 epoch 626 head B head_i_epoch 0 batch 0: avg loss -1.844892 avg loss no lamb -1.844892 time 2019-02-04 02:23:45.140803
Model ind 579 epoch 626 head B head_i_epoch 0 batch 100: avg loss -1.711778 avg loss no lamb -1.711778 time 2019-02-04 02:26:41.434793
Model ind 579 epoch 626 head B head_i_epoch 0 batch 200: avg loss -1.832603 avg loss no lamb -1.832603 time 2019-02-04 02:29:37.400589
Model ind 579 epoch 626 head A head_i_epoch 0 batch 0: avg loss -3.450392 avg loss no lamb -3.450392 time 2019-02-04 02:32:35.448954
Model ind 579 epoch 626 head A head_i_epoch 0 batch 100: avg loss -3.409374 avg loss no lamb -3.409374 time 2019-02-04 02:35:32.434053
Model ind 579 epoch 626 head A head_i_epoch 0 batch 200: avg loss -3.442036 avg loss no lamb -3.442036 time 2019-02-04 02:38:29.880900
Pre: time 2019-02-04 02:41:51.255705: 
 	std: 0.0040720706
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24735, 0.24625, 0.2365, 0.24661666, 0.24631667]
	train_accs: [0.24735, 0.24625, 0.2365, 0.24661666, 0.24631667]
	best_train_sub_head: 0
	worst: 0.2365
	avg: 0.24460669
	best: 0.24735

Starting e_i: 627
Model ind 579 epoch 627 head B head_i_epoch 0 batch 0: avg loss -1.764356 avg loss no lamb -1.764356 time 2019-02-04 02:41:55.510153
Model ind 579 epoch 627 head B head_i_epoch 0 batch 100: avg loss -1.838293 avg loss no lamb -1.838293 time 2019-02-04 02:44:51.755084
Model ind 579 epoch 627 head B head_i_epoch 0 batch 200: avg loss -1.766952 avg loss no lamb -1.766952 time 2019-02-04 02:47:48.122012
Model ind 579 epoch 627 head A head_i_epoch 0 batch 0: avg loss -3.411882 avg loss no lamb -3.411882 time 2019-02-04 02:50:45.259078
Model ind 579 epoch 627 head A head_i_epoch 0 batch 100: avg loss -3.365822 avg loss no lamb -3.365822 time 2019-02-04 02:53:43.419643
Model ind 579 epoch 627 head A head_i_epoch 0 batch 200: avg loss -3.396138 avg loss no lamb -3.396138 time 2019-02-04 02:56:41.338647
Pre: time 2019-02-04 03:00:03.991315: 
 	std: 0.004581245
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.248, 0.24776667, 0.23665, 0.24823333, 0.24836667]
	train_accs: [0.248, 0.24776667, 0.23665, 0.24823333, 0.24836667]
	best_train_sub_head: 4
	worst: 0.23665
	avg: 0.24580333
	best: 0.24836667

Starting e_i: 628
Model ind 579 epoch 628 head B head_i_epoch 0 batch 0: avg loss -1.838873 avg loss no lamb -1.838873 time 2019-02-04 03:00:09.852394
Model ind 579 epoch 628 head B head_i_epoch 0 batch 100: avg loss -1.848273 avg loss no lamb -1.848273 time 2019-02-04 03:03:07.493383
Model ind 579 epoch 628 head B head_i_epoch 0 batch 200: avg loss -1.813866 avg loss no lamb -1.813866 time 2019-02-04 03:06:06.362384
Model ind 579 epoch 628 head A head_i_epoch 0 batch 0: avg loss -3.432302 avg loss no lamb -3.432302 time 2019-02-04 03:09:04.257060
Model ind 579 epoch 628 head A head_i_epoch 0 batch 100: avg loss -3.449155 avg loss no lamb -3.449155 time 2019-02-04 03:12:02.978847
Model ind 579 epoch 628 head A head_i_epoch 0 batch 200: avg loss -3.418083 avg loss no lamb -3.418083 time 2019-02-04 03:15:00.010874
Pre: time 2019-02-04 03:18:22.373010: 
 	std: 0.00320539
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24605, 0.2454, 0.23781666, 0.24575, 0.24603334]
	train_accs: [0.24605, 0.2454, 0.23781666, 0.24575, 0.24603334]
	best_train_sub_head: 0
	worst: 0.23781666
	avg: 0.24421
	best: 0.24605

Starting e_i: 629
Model ind 579 epoch 629 head B head_i_epoch 0 batch 0: avg loss -1.808537 avg loss no lamb -1.808537 time 2019-02-04 03:18:26.183172
Model ind 579 epoch 629 head B head_i_epoch 0 batch 100: avg loss -1.843782 avg loss no lamb -1.843782 time 2019-02-04 03:21:22.488597
Model ind 579 epoch 629 head B head_i_epoch 0 batch 200: avg loss -1.842834 avg loss no lamb -1.842834 time 2019-02-04 03:24:19.091519
Model ind 579 epoch 629 head A head_i_epoch 0 batch 0: avg loss -3.386916 avg loss no lamb -3.386916 time 2019-02-04 03:27:17.443301
Model ind 579 epoch 629 head A head_i_epoch 0 batch 100: avg loss -3.449497 avg loss no lamb -3.449497 time 2019-02-04 03:30:15.128644
Model ind 579 epoch 629 head A head_i_epoch 0 batch 200: avg loss -3.429843 avg loss no lamb -3.429843 time 2019-02-04 03:33:12.419816
Pre: time 2019-02-04 03:36:34.616350: 
 	std: 0.0039793253
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24876666, 0.24786666, 0.23821667, 0.24805, 0.24783333]
	train_accs: [0.24876666, 0.24786666, 0.23821667, 0.24805, 0.24783333]
	best_train_sub_head: 0
	worst: 0.23821667
	avg: 0.24614668
	best: 0.24876666

Starting e_i: 630
Model ind 579 epoch 630 head B head_i_epoch 0 batch 0: avg loss -1.866973 avg loss no lamb -1.866973 time 2019-02-04 03:36:38.136199
Model ind 579 epoch 630 head B head_i_epoch 0 batch 100: avg loss -1.808897 avg loss no lamb -1.808897 time 2019-02-04 03:39:34.147098
Model ind 579 epoch 630 head B head_i_epoch 0 batch 200: avg loss -1.791268 avg loss no lamb -1.791268 time 2019-02-04 03:42:30.364161
Model ind 579 epoch 630 head A head_i_epoch 0 batch 0: avg loss -3.397461 avg loss no lamb -3.397461 time 2019-02-04 03:45:28.925241
Model ind 579 epoch 630 head A head_i_epoch 0 batch 100: avg loss -3.405476 avg loss no lamb -3.405476 time 2019-02-04 03:48:27.578602
Model ind 579 epoch 630 head A head_i_epoch 0 batch 200: avg loss -3.464613 avg loss no lamb -3.464613 time 2019-02-04 03:51:26.354888
Pre: time 2019-02-04 03:54:49.096826: 
 	std: 0.004685449
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24625, 0.24498333, 0.23408334, 0.24593334, 0.24583334]
	train_accs: [0.24625, 0.24498333, 0.23408334, 0.24593334, 0.24583334]
	best_train_sub_head: 0
	worst: 0.23408334
	avg: 0.2434167
	best: 0.24625

Starting e_i: 631
Model ind 579 epoch 631 head B head_i_epoch 0 batch 0: avg loss -1.746833 avg loss no lamb -1.746833 time 2019-02-04 03:54:56.580615
Model ind 579 epoch 631 head B head_i_epoch 0 batch 100: avg loss -1.743279 avg loss no lamb -1.743279 time 2019-02-04 03:57:52.690002
Model ind 579 epoch 631 head B head_i_epoch 0 batch 200: avg loss -1.763610 avg loss no lamb -1.763610 time 2019-02-04 04:00:50.033246
Model ind 579 epoch 631 head A head_i_epoch 0 batch 0: avg loss -3.417506 avg loss no lamb -3.417506 time 2019-02-04 04:03:46.502295
Model ind 579 epoch 631 head A head_i_epoch 0 batch 100: avg loss -3.461823 avg loss no lamb -3.461823 time 2019-02-04 04:06:45.722983
Model ind 579 epoch 631 head A head_i_epoch 0 batch 200: avg loss -3.464390 avg loss no lamb -3.464390 time 2019-02-04 04:09:44.319805
Pre: time 2019-02-04 04:13:07.968209: 
 	std: 0.0053722067
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 15), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 13), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24975, 0.24895, 0.23581667, 0.24888334, 0.24931666]
	train_accs: [0.24975, 0.24895, 0.23581667, 0.24888334, 0.24931666]
	best_train_sub_head: 0
	worst: 0.23581667
	avg: 0.24654333
	best: 0.24975

Starting e_i: 632
Model ind 579 epoch 632 head B head_i_epoch 0 batch 0: avg loss -1.785322 avg loss no lamb -1.785322 time 2019-02-04 04:13:11.474216
Model ind 579 epoch 632 head B head_i_epoch 0 batch 100: avg loss -1.750185 avg loss no lamb -1.750185 time 2019-02-04 04:16:07.726955
Model ind 579 epoch 632 head B head_i_epoch 0 batch 200: avg loss -1.869375 avg loss no lamb -1.869375 time 2019-02-04 04:19:04.881580
Model ind 579 epoch 632 head A head_i_epoch 0 batch 0: avg loss -3.381937 avg loss no lamb -3.381937 time 2019-02-04 04:22:01.142456
Model ind 579 epoch 632 head A head_i_epoch 0 batch 100: avg loss -3.432782 avg loss no lamb -3.432782 time 2019-02-04 04:24:58.397990
Model ind 579 epoch 632 head A head_i_epoch 0 batch 200: avg loss -3.460828 avg loss no lamb -3.460828 time 2019-02-04 04:27:56.553566
Pre: time 2019-02-04 04:31:19.482274: 
 	std: 0.0045710425
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25043333, 0.24983333, 0.23878333, 0.25023332, 0.2503]
	train_accs: [0.25043333, 0.24983333, 0.23878333, 0.25023332, 0.2503]
	best_train_sub_head: 0
	worst: 0.23878333
	avg: 0.24791665
	best: 0.25043333

Starting e_i: 633
Model ind 579 epoch 633 head B head_i_epoch 0 batch 0: avg loss -1.770512 avg loss no lamb -1.770512 time 2019-02-04 04:31:22.988326
Model ind 579 epoch 633 head B head_i_epoch 0 batch 100: avg loss -1.808099 avg loss no lamb -1.808099 time 2019-02-04 04:34:21.895430
Model ind 579 epoch 633 head B head_i_epoch 0 batch 200: avg loss -1.833439 avg loss no lamb -1.833439 time 2019-02-04 04:37:20.104486
Model ind 579 epoch 633 head A head_i_epoch 0 batch 0: avg loss -3.441110 avg loss no lamb -3.441110 time 2019-02-04 04:40:17.124631
Model ind 579 epoch 633 head A head_i_epoch 0 batch 100: avg loss -3.428090 avg loss no lamb -3.428090 time 2019-02-04 04:43:14.689397
Model ind 579 epoch 633 head A head_i_epoch 0 batch 200: avg loss -3.471382 avg loss no lamb -3.471382 time 2019-02-04 04:46:12.575146
Pre: time 2019-02-04 04:49:34.231904: 
 	std: 0.004734843
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.24698333, 0.24616666, 0.23503333, 0.24701667, 0.24718334]
	train_accs: [0.24698333, 0.24616666, 0.23503333, 0.24701667, 0.24718334]
	best_train_sub_head: 4
	worst: 0.23503333
	avg: 0.24447668
	best: 0.24718334

Starting e_i: 634
Model ind 579 epoch 634 head B head_i_epoch 0 batch 0: avg loss -1.858649 avg loss no lamb -1.858649 time 2019-02-04 04:49:38.341679
Model ind 579 epoch 634 head B head_i_epoch 0 batch 100: avg loss -1.772943 avg loss no lamb -1.772943 time 2019-02-04 04:52:34.907966
Model ind 579 epoch 634 head B head_i_epoch 0 batch 200: avg loss -1.891195 avg loss no lamb -1.891195 time 2019-02-04 04:55:31.151763
Model ind 579 epoch 634 head A head_i_epoch 0 batch 0: avg loss -3.416631 avg loss no lamb -3.416631 time 2019-02-04 04:58:28.746886
Model ind 579 epoch 634 head A head_i_epoch 0 batch 100: avg loss -3.417509 avg loss no lamb -3.417509 time 2019-02-04 05:01:26.966924
Model ind 579 epoch 634 head A head_i_epoch 0 batch 200: avg loss -3.445706 avg loss no lamb -3.445706 time 2019-02-04 05:04:26.235945
Pre: time 2019-02-04 05:07:48.846561: 
 	std: 0.004635885
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24956666, 0.24963333, 0.23815, 0.25001666, 0.24971667]
	train_accs: [0.24956666, 0.24963333, 0.23815, 0.25001666, 0.24971667]
	best_train_sub_head: 3
	worst: 0.23815
	avg: 0.24741666
	best: 0.25001666

Starting e_i: 635
Model ind 579 epoch 635 head B head_i_epoch 0 batch 0: avg loss -1.797865 avg loss no lamb -1.797865 time 2019-02-04 05:07:52.423830
Model ind 579 epoch 635 head B head_i_epoch 0 batch 100: avg loss -1.748466 avg loss no lamb -1.748466 time 2019-02-04 05:10:48.473677
Model ind 579 epoch 635 head B head_i_epoch 0 batch 200: avg loss -1.769453 avg loss no lamb -1.769453 time 2019-02-04 05:13:44.597609
Model ind 579 epoch 635 head A head_i_epoch 0 batch 0: avg loss -3.433135 avg loss no lamb -3.433135 time 2019-02-04 05:16:43.244231
Model ind 579 epoch 635 head A head_i_epoch 0 batch 100: avg loss -3.490834 avg loss no lamb -3.490834 time 2019-02-04 05:19:42.551087
Model ind 579 epoch 635 head A head_i_epoch 0 batch 200: avg loss -3.437228 avg loss no lamb -3.437228 time 2019-02-04 05:22:40.865730
Pre: time 2019-02-04 05:26:02.768440: 
 	std: 0.004189989
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25001666, 0.24941666, 0.23941667, 0.25021666, 0.24983333]
	train_accs: [0.25001666, 0.24941666, 0.23941667, 0.25021666, 0.24983333]
	best_train_sub_head: 3
	worst: 0.23941667
	avg: 0.24778
	best: 0.25021666

Starting e_i: 636
Model ind 579 epoch 636 head B head_i_epoch 0 batch 0: avg loss -1.778182 avg loss no lamb -1.778182 time 2019-02-04 05:26:06.872362
Model ind 579 epoch 636 head B head_i_epoch 0 batch 100: avg loss -1.793489 avg loss no lamb -1.793489 time 2019-02-04 05:29:03.369062
Model ind 579 epoch 636 head B head_i_epoch 0 batch 200: avg loss -1.840105 avg loss no lamb -1.840105 time 2019-02-04 05:32:01.361322
Model ind 579 epoch 636 head A head_i_epoch 0 batch 0: avg loss -3.445070 avg loss no lamb -3.445070 time 2019-02-04 05:34:59.272638
Model ind 579 epoch 636 head A head_i_epoch 0 batch 100: avg loss -3.490568 avg loss no lamb -3.490568 time 2019-02-04 05:37:58.331926
Model ind 579 epoch 636 head A head_i_epoch 0 batch 200: avg loss -3.466067 avg loss no lamb -3.466067 time 2019-02-04 05:40:55.733187
Pre: time 2019-02-04 05:44:19.142370: 
 	std: 0.00470181
	best_train_sub_head_match: [(0, 13), (1, 15), (2, 2), (3, 5), (4, 4), (5, 3), (6, 18), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24933334, 0.24908334, 0.23756666, 0.24948333, 0.24936667]
	train_accs: [0.24933334, 0.24908334, 0.23756666, 0.24948333, 0.24936667]
	best_train_sub_head: 3
	worst: 0.23756666
	avg: 0.24696667
	best: 0.24948333

Starting e_i: 637
Model ind 579 epoch 637 head B head_i_epoch 0 batch 0: avg loss -1.842416 avg loss no lamb -1.842416 time 2019-02-04 05:44:22.798185
Model ind 579 epoch 637 head B head_i_epoch 0 batch 100: avg loss -1.817955 avg loss no lamb -1.817955 time 2019-02-04 05:47:22.280402
Model ind 579 epoch 637 head B head_i_epoch 0 batch 200: avg loss -1.790682 avg loss no lamb -1.790682 time 2019-02-04 05:50:19.011938
Model ind 579 epoch 637 head A head_i_epoch 0 batch 0: avg loss -3.380886 avg loss no lamb -3.380886 time 2019-02-04 05:53:16.798950
Model ind 579 epoch 637 head A head_i_epoch 0 batch 100: avg loss -3.395263 avg loss no lamb -3.395263 time 2019-02-04 05:56:14.151416
Model ind 579 epoch 637 head A head_i_epoch 0 batch 200: avg loss -3.436348 avg loss no lamb -3.436348 time 2019-02-04 05:59:14.497958
Pre: time 2019-02-04 06:02:37.157661: 
 	std: 0.0045527807
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24796666, 0.24833333, 0.2368, 0.24845, 0.24793333]
	train_accs: [0.24796666, 0.24833333, 0.2368, 0.24845, 0.24793333]
	best_train_sub_head: 3
	worst: 0.2368
	avg: 0.24589667
	best: 0.24845

Starting e_i: 638
Model ind 579 epoch 638 head B head_i_epoch 0 batch 0: avg loss -1.828761 avg loss no lamb -1.828761 time 2019-02-04 06:02:40.687213
Model ind 579 epoch 638 head B head_i_epoch 0 batch 100: avg loss -1.758621 avg loss no lamb -1.758621 time 2019-02-04 06:05:37.573353
Model ind 579 epoch 638 head B head_i_epoch 0 batch 200: avg loss -1.819631 avg loss no lamb -1.819631 time 2019-02-04 06:08:34.536717
Model ind 579 epoch 638 head A head_i_epoch 0 batch 0: avg loss -3.395876 avg loss no lamb -3.395876 time 2019-02-04 06:11:31.152013
Model ind 579 epoch 638 head A head_i_epoch 0 batch 100: avg loss -3.450711 avg loss no lamb -3.450711 time 2019-02-04 06:14:28.330319
Model ind 579 epoch 638 head A head_i_epoch 0 batch 200: avg loss -3.448508 avg loss no lamb -3.448508 time 2019-02-04 06:17:27.557312
Pre: time 2019-02-04 06:20:50.790386: 
 	std: 0.00432563
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 18), (12, 13), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 5), (19, 12)]
	test_accs: [0.24661666, 0.24685, 0.23611666, 0.24706666, 0.24715]
	train_accs: [0.24661666, 0.24685, 0.23611666, 0.24706666, 0.24715]
	best_train_sub_head: 4
	worst: 0.23611666
	avg: 0.24475999
	best: 0.24715

Starting e_i: 639
Model ind 579 epoch 639 head B head_i_epoch 0 batch 0: avg loss -1.833111 avg loss no lamb -1.833111 time 2019-02-04 06:20:54.325866
Model ind 579 epoch 639 head B head_i_epoch 0 batch 100: avg loss -1.800758 avg loss no lamb -1.800758 time 2019-02-04 06:23:50.326066
Model ind 579 epoch 639 head B head_i_epoch 0 batch 200: avg loss -1.804847 avg loss no lamb -1.804847 time 2019-02-04 06:26:46.556325
Model ind 579 epoch 639 head A head_i_epoch 0 batch 0: avg loss -3.421088 avg loss no lamb -3.421088 time 2019-02-04 06:29:42.605912
Model ind 579 epoch 639 head A head_i_epoch 0 batch 100: avg loss -3.431274 avg loss no lamb -3.431274 time 2019-02-04 06:32:41.241281
Model ind 579 epoch 639 head A head_i_epoch 0 batch 200: avg loss -3.462584 avg loss no lamb -3.462584 time 2019-02-04 06:35:40.468902
Pre: time 2019-02-04 06:39:03.075569: 
 	std: 0.004738325
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2486, 0.24938333, 0.23713334, 0.2492, 0.24863334]
	train_accs: [0.2486, 0.24938333, 0.23713334, 0.2492, 0.24863334]
	best_train_sub_head: 1
	worst: 0.23713334
	avg: 0.24658999
	best: 0.24938333

Starting e_i: 640
Model ind 579 epoch 640 head B head_i_epoch 0 batch 0: avg loss -1.873518 avg loss no lamb -1.873518 time 2019-02-04 06:39:06.723316
Model ind 579 epoch 640 head B head_i_epoch 0 batch 100: avg loss -1.702864 avg loss no lamb -1.702864 time 2019-02-04 06:42:03.826724
Model ind 579 epoch 640 head B head_i_epoch 0 batch 200: avg loss -1.852222 avg loss no lamb -1.852222 time 2019-02-04 06:45:00.362279
Model ind 579 epoch 640 head A head_i_epoch 0 batch 0: avg loss -3.464079 avg loss no lamb -3.464079 time 2019-02-04 06:47:57.693384
Model ind 579 epoch 640 head A head_i_epoch 0 batch 100: avg loss -3.431216 avg loss no lamb -3.431216 time 2019-02-04 06:50:57.694791
Model ind 579 epoch 640 head A head_i_epoch 0 batch 200: avg loss -3.470737 avg loss no lamb -3.470737 time 2019-02-04 06:53:56.627357
Pre: time 2019-02-04 06:57:20.425767: 
 	std: 0.0048258873
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24945, 0.24996667, 0.23746666, 0.24936667, 0.24928333]
	train_accs: [0.24945, 0.24996667, 0.23746666, 0.24936667, 0.24928333]
	best_train_sub_head: 1
	worst: 0.23746666
	avg: 0.24710664
	best: 0.24996667

Starting e_i: 641
Model ind 579 epoch 641 head B head_i_epoch 0 batch 0: avg loss -1.837690 avg loss no lamb -1.837690 time 2019-02-04 06:57:28.525309
Model ind 579 epoch 641 head B head_i_epoch 0 batch 100: avg loss -1.935847 avg loss no lamb -1.935847 time 2019-02-04 07:00:25.003861
Model ind 579 epoch 641 head B head_i_epoch 0 batch 200: avg loss -1.800207 avg loss no lamb -1.800207 time 2019-02-04 07:03:22.497159
Model ind 579 epoch 641 head A head_i_epoch 0 batch 0: avg loss -3.402650 avg loss no lamb -3.402650 time 2019-02-04 07:06:19.579238
Model ind 579 epoch 641 head A head_i_epoch 0 batch 100: avg loss -3.449816 avg loss no lamb -3.449816 time 2019-02-04 07:09:17.486238
Model ind 579 epoch 641 head A head_i_epoch 0 batch 200: avg loss -3.434411 avg loss no lamb -3.434411 time 2019-02-04 07:12:17.142448
Pre: time 2019-02-04 07:15:41.923025: 
 	std: 0.004418995
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24768333, 0.24868333, 0.23708333, 0.2478, 0.24821667]
	train_accs: [0.24768333, 0.24868333, 0.23708333, 0.2478, 0.24821667]
	best_train_sub_head: 1
	worst: 0.23708333
	avg: 0.24589333
	best: 0.24868333

Starting e_i: 642
Model ind 579 epoch 642 head B head_i_epoch 0 batch 0: avg loss -1.794624 avg loss no lamb -1.794624 time 2019-02-04 07:15:46.035567
Model ind 579 epoch 642 head B head_i_epoch 0 batch 100: avg loss -1.730657 avg loss no lamb -1.730657 time 2019-02-04 07:18:42.433880
Model ind 579 epoch 642 head B head_i_epoch 0 batch 200: avg loss -1.860687 avg loss no lamb -1.860687 time 2019-02-04 07:21:39.651448
Model ind 579 epoch 642 head A head_i_epoch 0 batch 0: avg loss -3.392439 avg loss no lamb -3.392439 time 2019-02-04 07:24:37.154804
Model ind 579 epoch 642 head A head_i_epoch 0 batch 100: avg loss -3.456163 avg loss no lamb -3.456163 time 2019-02-04 07:27:36.743230
Model ind 579 epoch 642 head A head_i_epoch 0 batch 200: avg loss -3.464073 avg loss no lamb -3.464073 time 2019-02-04 07:30:36.072514
Pre: time 2019-02-04 07:33:59.073666: 
 	std: 0.004341955
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2498, 0.24896666, 0.23841667, 0.249, 0.24921666]
	train_accs: [0.2498, 0.24896666, 0.23841667, 0.249, 0.24921666]
	best_train_sub_head: 0
	worst: 0.23841667
	avg: 0.24708
	best: 0.2498

Starting e_i: 643
Model ind 579 epoch 643 head B head_i_epoch 0 batch 0: avg loss -1.758572 avg loss no lamb -1.758572 time 2019-02-04 07:34:02.660125
Model ind 579 epoch 643 head B head_i_epoch 0 batch 100: avg loss -1.817398 avg loss no lamb -1.817398 time 2019-02-04 07:37:00.721736
Model ind 579 epoch 643 head B head_i_epoch 0 batch 200: avg loss -1.881935 avg loss no lamb -1.881935 time 2019-02-04 07:39:59.170768
Model ind 579 epoch 643 head A head_i_epoch 0 batch 0: avg loss -3.445812 avg loss no lamb -3.445812 time 2019-02-04 07:42:56.500257
Model ind 579 epoch 643 head A head_i_epoch 0 batch 100: avg loss -3.461779 avg loss no lamb -3.461779 time 2019-02-04 07:45:53.553428
Model ind 579 epoch 643 head A head_i_epoch 0 batch 200: avg loss -3.406370 avg loss no lamb -3.406370 time 2019-02-04 07:48:52.303675
Pre: time 2019-02-04 07:52:15.506698: 
 	std: 0.0047761407
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24686667, 0.2473, 0.23503333, 0.24701667, 0.24666667]
	train_accs: [0.24686667, 0.2473, 0.23503333, 0.24701667, 0.24666667]
	best_train_sub_head: 1
	worst: 0.23503333
	avg: 0.24457666
	best: 0.2473

Starting e_i: 644
Model ind 579 epoch 644 head B head_i_epoch 0 batch 0: avg loss -1.788261 avg loss no lamb -1.788261 time 2019-02-04 07:52:19.101836
Model ind 579 epoch 644 head B head_i_epoch 0 batch 100: avg loss -1.804723 avg loss no lamb -1.804723 time 2019-02-04 07:55:15.911063
Model ind 579 epoch 644 head B head_i_epoch 0 batch 200: avg loss -1.784817 avg loss no lamb -1.784817 time 2019-02-04 07:58:12.354187
Model ind 579 epoch 644 head A head_i_epoch 0 batch 0: avg loss -3.462188 avg loss no lamb -3.462188 time 2019-02-04 08:01:09.922379
Model ind 579 epoch 644 head A head_i_epoch 0 batch 100: avg loss -3.545475 avg loss no lamb -3.545475 time 2019-02-04 08:04:09.470648
Model ind 579 epoch 644 head A head_i_epoch 0 batch 200: avg loss -3.514591 avg loss no lamb -3.514591 time 2019-02-04 08:07:07.732769
Pre: time 2019-02-04 08:10:30.261918: 
 	std: 0.0043936176
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2465, 0.2476, 0.23591666, 0.24633333, 0.24695]
	train_accs: [0.2465, 0.2476, 0.23591666, 0.24633333, 0.24695]
	best_train_sub_head: 1
	worst: 0.23591666
	avg: 0.24465999
	best: 0.2476

Starting e_i: 645
Model ind 579 epoch 645 head B head_i_epoch 0 batch 0: avg loss -1.842019 avg loss no lamb -1.842019 time 2019-02-04 08:10:34.303745
Model ind 579 epoch 645 head B head_i_epoch 0 batch 100: avg loss -1.837257 avg loss no lamb -1.837257 time 2019-02-04 08:13:31.848211
Model ind 579 epoch 645 head B head_i_epoch 0 batch 200: avg loss -1.874019 avg loss no lamb -1.874019 time 2019-02-04 08:16:27.520392
Model ind 579 epoch 645 head A head_i_epoch 0 batch 0: avg loss -3.455459 avg loss no lamb -3.455459 time 2019-02-04 08:19:23.781001
Model ind 579 epoch 645 head A head_i_epoch 0 batch 100: avg loss -3.479523 avg loss no lamb -3.479523 time 2019-02-04 08:22:21.151725
Model ind 579 epoch 645 head A head_i_epoch 0 batch 200: avg loss -3.495005 avg loss no lamb -3.495005 time 2019-02-04 08:25:18.781241
Pre: time 2019-02-04 08:28:40.388525: 
 	std: 0.0044744643
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24668333, 0.2473, 0.23566666, 0.24623333, 0.24705]
	train_accs: [0.24668333, 0.2473, 0.23566666, 0.24623333, 0.24705]
	best_train_sub_head: 1
	worst: 0.23566666
	avg: 0.24458668
	best: 0.2473

Starting e_i: 646
Model ind 579 epoch 646 head B head_i_epoch 0 batch 0: avg loss -1.810438 avg loss no lamb -1.810438 time 2019-02-04 08:28:44.068688
Model ind 579 epoch 646 head B head_i_epoch 0 batch 100: avg loss -1.740110 avg loss no lamb -1.740110 time 2019-02-04 08:31:43.335449
Model ind 579 epoch 646 head B head_i_epoch 0 batch 200: avg loss -1.820903 avg loss no lamb -1.820903 time 2019-02-04 08:34:41.376719
Model ind 579 epoch 646 head A head_i_epoch 0 batch 0: avg loss -3.525599 avg loss no lamb -3.525599 time 2019-02-04 08:37:39.412019
Model ind 579 epoch 646 head A head_i_epoch 0 batch 100: avg loss -3.417085 avg loss no lamb -3.417085 time 2019-02-04 08:40:37.786003
Model ind 579 epoch 646 head A head_i_epoch 0 batch 200: avg loss -3.460017 avg loss no lamb -3.460017 time 2019-02-04 08:43:37.734369
Pre: time 2019-02-04 08:47:00.628742: 
 	std: 0.0046894737
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25001666, 0.25156668, 0.23928334, 0.25116667, 0.251]
	train_accs: [0.25001666, 0.25156668, 0.23928334, 0.25116667, 0.251]
	best_train_sub_head: 1
	worst: 0.23928334
	avg: 0.24860668
	best: 0.25156668

Starting e_i: 647
Model ind 579 epoch 647 head B head_i_epoch 0 batch 0: avg loss -1.822902 avg loss no lamb -1.822902 time 2019-02-04 08:47:04.862450
Model ind 579 epoch 647 head B head_i_epoch 0 batch 100: avg loss -1.770670 avg loss no lamb -1.770670 time 2019-02-04 08:50:01.580917
Model ind 579 epoch 647 head B head_i_epoch 0 batch 200: avg loss -1.865646 avg loss no lamb -1.865646 time 2019-02-04 08:52:58.402006
Model ind 579 epoch 647 head A head_i_epoch 0 batch 0: avg loss -3.416445 avg loss no lamb -3.416445 time 2019-02-04 08:55:55.114406
Model ind 579 epoch 647 head A head_i_epoch 0 batch 100: avg loss -3.434716 avg loss no lamb -3.434716 time 2019-02-04 08:58:54.710595
Model ind 579 epoch 647 head A head_i_epoch 0 batch 200: avg loss -3.476508 avg loss no lamb -3.476508 time 2019-02-04 09:01:53.171526
Pre: time 2019-02-04 09:05:15.832182: 
 	std: 0.004891008
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24911667, 0.24998334, 0.23743333, 0.24988334, 0.24956666]
	train_accs: [0.24911667, 0.24998334, 0.23743333, 0.24988334, 0.24956666]
	best_train_sub_head: 1
	worst: 0.23743333
	avg: 0.24719667
	best: 0.24998334

Starting e_i: 648
Model ind 579 epoch 648 head B head_i_epoch 0 batch 0: avg loss -1.933653 avg loss no lamb -1.933653 time 2019-02-04 09:05:19.488333
Model ind 579 epoch 648 head B head_i_epoch 0 batch 100: avg loss -1.776036 avg loss no lamb -1.776036 time 2019-02-04 09:08:18.652540
Model ind 579 epoch 648 head B head_i_epoch 0 batch 200: avg loss -1.809065 avg loss no lamb -1.809065 time 2019-02-04 09:11:16.288392
Model ind 579 epoch 648 head A head_i_epoch 0 batch 0: avg loss -3.437551 avg loss no lamb -3.437551 time 2019-02-04 09:14:13.761553
Model ind 579 epoch 648 head A head_i_epoch 0 batch 100: avg loss -3.452389 avg loss no lamb -3.452389 time 2019-02-04 09:17:12.325452
Model ind 579 epoch 648 head A head_i_epoch 0 batch 200: avg loss -3.430394 avg loss no lamb -3.430394 time 2019-02-04 09:20:10.420013
Pre: time 2019-02-04 09:23:34.066279: 
 	std: 0.0039885
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 5), (12, 13), (13, 18), (14, 1), (15, 15), (16, 6), (17, 3), (18, 19), (19, 12)]
	test_accs: [0.24743333, 0.24816667, 0.23793334, 0.24765, 0.24825]
	train_accs: [0.24743333, 0.24816667, 0.23793334, 0.24765, 0.24825]
	best_train_sub_head: 4
	worst: 0.23793334
	avg: 0.24588665
	best: 0.24825

Starting e_i: 649
Model ind 579 epoch 649 head B head_i_epoch 0 batch 0: avg loss -1.896047 avg loss no lamb -1.896047 time 2019-02-04 09:23:38.201986
Model ind 579 epoch 649 head B head_i_epoch 0 batch 100: avg loss -1.787255 avg loss no lamb -1.787255 time 2019-02-04 09:26:34.347949
Model ind 579 epoch 649 head B head_i_epoch 0 batch 200: avg loss -1.757294 avg loss no lamb -1.757294 time 2019-02-04 09:29:31.860558
Model ind 579 epoch 649 head A head_i_epoch 0 batch 0: avg loss -3.436131 avg loss no lamb -3.436131 time 2019-02-04 09:32:30.060130
Model ind 579 epoch 649 head A head_i_epoch 0 batch 100: avg loss -3.450907 avg loss no lamb -3.450907 time 2019-02-04 09:35:27.486485
Model ind 579 epoch 649 head A head_i_epoch 0 batch 200: avg loss -3.501543 avg loss no lamb -3.501543 time 2019-02-04 09:38:25.464996
Pre: time 2019-02-04 09:41:49.646816: 
 	std: 0.004304988
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24525, 0.2462, 0.23558334, 0.24678333, 0.24678333]
	train_accs: [0.24525, 0.2462, 0.23558334, 0.24678333, 0.24678333]
	best_train_sub_head: 3
	worst: 0.23558334
	avg: 0.24412
	best: 0.24678333

Starting e_i: 650
Model ind 579 epoch 650 head B head_i_epoch 0 batch 0: avg loss -1.795486 avg loss no lamb -1.795486 time 2019-02-04 09:41:53.319365
Model ind 579 epoch 650 head B head_i_epoch 0 batch 100: avg loss -1.781938 avg loss no lamb -1.781938 time 2019-02-04 09:44:51.321475
Model ind 579 epoch 650 head B head_i_epoch 0 batch 200: avg loss -1.872183 avg loss no lamb -1.872183 time 2019-02-04 09:47:50.255193
Model ind 579 epoch 650 head A head_i_epoch 0 batch 0: avg loss -3.485610 avg loss no lamb -3.485610 time 2019-02-04 09:50:50.345433
Model ind 579 epoch 650 head A head_i_epoch 0 batch 100: avg loss -3.505766 avg loss no lamb -3.505766 time 2019-02-04 09:53:48.881021
Model ind 579 epoch 650 head A head_i_epoch 0 batch 200: avg loss -3.490469 avg loss no lamb -3.490469 time 2019-02-04 09:56:48.112888
Pre: time 2019-02-04 10:00:10.398537: 
 	std: 0.0041171797
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24926667, 0.2508, 0.24011667, 0.25048333, 0.25071666]
	train_accs: [0.24926667, 0.2508, 0.24011667, 0.25048333, 0.25071666]
	best_train_sub_head: 1
	worst: 0.24011667
	avg: 0.24827667
	best: 0.2508

Starting e_i: 651
Model ind 579 epoch 651 head B head_i_epoch 0 batch 0: avg loss -1.732590 avg loss no lamb -1.732590 time 2019-02-04 10:00:18.433065
Model ind 579 epoch 651 head B head_i_epoch 0 batch 100: avg loss -1.885990 avg loss no lamb -1.885990 time 2019-02-04 10:03:15.227430
Model ind 579 epoch 651 head B head_i_epoch 0 batch 200: avg loss -1.835729 avg loss no lamb -1.835729 time 2019-02-04 10:06:11.504926
Model ind 579 epoch 651 head A head_i_epoch 0 batch 0: avg loss -3.406424 avg loss no lamb -3.406424 time 2019-02-04 10:09:13.335740
Model ind 579 epoch 651 head A head_i_epoch 0 batch 100: avg loss -3.452805 avg loss no lamb -3.452805 time 2019-02-04 10:12:11.860680
Model ind 579 epoch 651 head A head_i_epoch 0 batch 200: avg loss -3.479603 avg loss no lamb -3.479603 time 2019-02-04 10:15:09.517109
Pre: time 2019-02-04 10:18:31.406749: 
 	std: 0.0040864735
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.24655, 0.24646667, 0.23635, 0.24646667, 0.24676667]
	train_accs: [0.24655, 0.24646667, 0.23635, 0.24646667, 0.24676667]
	best_train_sub_head: 4
	worst: 0.23635
	avg: 0.24452
	best: 0.24676667

Starting e_i: 652
Model ind 579 epoch 652 head B head_i_epoch 0 batch 0: avg loss -1.862493 avg loss no lamb -1.862493 time 2019-02-04 10:18:35.236196
Model ind 579 epoch 652 head B head_i_epoch 0 batch 100: avg loss -1.655376 avg loss no lamb -1.655376 time 2019-02-04 10:21:33.861219
Model ind 579 epoch 652 head B head_i_epoch 0 batch 200: avg loss -1.889160 avg loss no lamb -1.889160 time 2019-02-04 10:24:30.519897
Model ind 579 epoch 652 head A head_i_epoch 0 batch 0: avg loss -3.411791 avg loss no lamb -3.411791 time 2019-02-04 10:27:27.795154
Model ind 579 epoch 652 head A head_i_epoch 0 batch 100: avg loss -3.399212 avg loss no lamb -3.399212 time 2019-02-04 10:30:28.049315
Model ind 579 epoch 652 head A head_i_epoch 0 batch 200: avg loss -3.487045 avg loss no lamb -3.487045 time 2019-02-04 10:33:25.551127
Pre: time 2019-02-04 10:36:49.663042: 
 	std: 0.0044957115
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25053334, 0.2504, 0.23916666, 0.25013334, 0.25053334]
	train_accs: [0.25053334, 0.2504, 0.23916666, 0.25013334, 0.25053334]
	best_train_sub_head: 0
	worst: 0.23916666
	avg: 0.24815336
	best: 0.25053334

Starting e_i: 653
Model ind 579 epoch 653 head B head_i_epoch 0 batch 0: avg loss -1.844361 avg loss no lamb -1.844361 time 2019-02-04 10:36:53.462086
Model ind 579 epoch 653 head B head_i_epoch 0 batch 100: avg loss -1.750035 avg loss no lamb -1.750035 time 2019-02-04 10:39:52.850626
Model ind 579 epoch 653 head B head_i_epoch 0 batch 200: avg loss -1.844723 avg loss no lamb -1.844723 time 2019-02-04 10:42:49.900345
Model ind 579 epoch 653 head A head_i_epoch 0 batch 0: avg loss -3.444427 avg loss no lamb -3.444427 time 2019-02-04 10:45:47.632661
Model ind 579 epoch 653 head A head_i_epoch 0 batch 100: avg loss -3.436627 avg loss no lamb -3.436627 time 2019-02-04 10:48:46.213200
Model ind 579 epoch 653 head A head_i_epoch 0 batch 200: avg loss -3.468158 avg loss no lamb -3.468158 time 2019-02-04 10:51:45.381732
Pre: time 2019-02-04 10:55:13.175265: 
 	std: 0.0042211185
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25078332, 0.24993333, 0.24016666, 0.2508, 0.25116667]
	train_accs: [0.25078332, 0.24993333, 0.24016666, 0.2508, 0.25116667]
	best_train_sub_head: 4
	worst: 0.24016666
	avg: 0.24857001
	best: 0.25116667

Starting e_i: 654
Model ind 579 epoch 654 head B head_i_epoch 0 batch 0: avg loss -1.817117 avg loss no lamb -1.817117 time 2019-02-04 10:55:16.902872
Model ind 579 epoch 654 head B head_i_epoch 0 batch 100: avg loss -1.836695 avg loss no lamb -1.836695 time 2019-02-04 10:58:14.998806
Model ind 579 epoch 654 head B head_i_epoch 0 batch 200: avg loss -1.938700 avg loss no lamb -1.938700 time 2019-02-04 11:01:13.175094
Model ind 579 epoch 654 head A head_i_epoch 0 batch 0: avg loss -3.393046 avg loss no lamb -3.393046 time 2019-02-04 11:04:10.071494
Model ind 579 epoch 654 head A head_i_epoch 0 batch 100: avg loss -3.476866 avg loss no lamb -3.476866 time 2019-02-04 11:07:08.481838
Model ind 579 epoch 654 head A head_i_epoch 0 batch 200: avg loss -3.427235 avg loss no lamb -3.427235 time 2019-02-04 11:10:07.968108
Pre: time 2019-02-04 11:13:31.743671: 
 	std: 0.003339517
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 5), (12, 13), (13, 18), (14, 1), (15, 15), (16, 6), (17, 3), (18, 19), (19, 12)]
	test_accs: [0.2496, 0.24965, 0.24135, 0.24925, 0.25016665]
	train_accs: [0.2496, 0.24965, 0.24135, 0.24925, 0.25016665]
	best_train_sub_head: 4
	worst: 0.24135
	avg: 0.24800333
	best: 0.25016665

Starting e_i: 655
Model ind 579 epoch 655 head B head_i_epoch 0 batch 0: avg loss -1.709356 avg loss no lamb -1.709356 time 2019-02-04 11:13:35.416138
Model ind 579 epoch 655 head B head_i_epoch 0 batch 100: avg loss -1.807107 avg loss no lamb -1.807107 time 2019-02-04 11:16:32.419868
Model ind 579 epoch 655 head B head_i_epoch 0 batch 200: avg loss -1.757082 avg loss no lamb -1.757082 time 2019-02-04 11:19:29.088693
Model ind 579 epoch 655 head A head_i_epoch 0 batch 0: avg loss -3.386488 avg loss no lamb -3.386488 time 2019-02-04 11:22:26.862040
Model ind 579 epoch 655 head A head_i_epoch 0 batch 100: avg loss -3.457307 avg loss no lamb -3.457307 time 2019-02-04 11:25:23.988452
Model ind 579 epoch 655 head A head_i_epoch 0 batch 200: avg loss -3.468027 avg loss no lamb -3.468027 time 2019-02-04 11:28:21.064940
Pre: time 2019-02-04 11:31:43.940944: 
 	std: 0.0035675778
	best_train_sub_head_match: [(0, 5), (1, 12), (2, 14), (3, 0), (4, 16), (5, 4), (6, 8), (7, 6), (8, 15), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 13), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2475, 0.24703333, 0.23835, 0.24701667, 0.24746667]
	train_accs: [0.2475, 0.24703333, 0.23835, 0.24701667, 0.24746667]
	best_train_sub_head: 0
	worst: 0.23835
	avg: 0.24547334
	best: 0.2475

Starting e_i: 656
Model ind 579 epoch 656 head B head_i_epoch 0 batch 0: avg loss -1.857975 avg loss no lamb -1.857975 time 2019-02-04 11:31:47.497666
Model ind 579 epoch 656 head B head_i_epoch 0 batch 100: avg loss -1.739704 avg loss no lamb -1.739704 time 2019-02-04 11:34:45.221346
Model ind 579 epoch 656 head B head_i_epoch 0 batch 200: avg loss -1.815805 avg loss no lamb -1.815805 time 2019-02-04 11:37:45.272810
Model ind 579 epoch 656 head A head_i_epoch 0 batch 0: avg loss -3.459737 avg loss no lamb -3.459737 time 2019-02-04 11:40:41.978911
Model ind 579 epoch 656 head A head_i_epoch 0 batch 100: avg loss -3.455628 avg loss no lamb -3.455628 time 2019-02-04 11:43:40.570466
Model ind 579 epoch 656 head A head_i_epoch 0 batch 200: avg loss -3.481944 avg loss no lamb -3.481944 time 2019-02-04 11:46:38.070875
Pre: time 2019-02-04 11:50:01.741365: 
 	std: 0.0035100705
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2483, 0.24735, 0.23918334, 0.24778333, 0.24823333]
	train_accs: [0.2483, 0.24735, 0.23918334, 0.24778333, 0.24823333]
	best_train_sub_head: 0
	worst: 0.23918334
	avg: 0.24617
	best: 0.2483

Starting e_i: 657
Model ind 579 epoch 657 head B head_i_epoch 0 batch 0: avg loss -1.796619 avg loss no lamb -1.796619 time 2019-02-04 11:50:05.329441
Model ind 579 epoch 657 head B head_i_epoch 0 batch 100: avg loss -1.755765 avg loss no lamb -1.755765 time 2019-02-04 11:53:03.091366
Model ind 579 epoch 657 head B head_i_epoch 0 batch 200: avg loss -1.719772 avg loss no lamb -1.719772 time 2019-02-04 11:56:03.390607
Model ind 579 epoch 657 head A head_i_epoch 0 batch 0: avg loss -3.397043 avg loss no lamb -3.397043 time 2019-02-04 11:59:01.522402
Model ind 579 epoch 657 head A head_i_epoch 0 batch 100: avg loss -3.396656 avg loss no lamb -3.396656 time 2019-02-04 12:01:59.825796
Model ind 579 epoch 657 head A head_i_epoch 0 batch 200: avg loss -3.470339 avg loss no lamb -3.470339 time 2019-02-04 12:05:00.576293
Pre: time 2019-02-04 12:08:23.226235: 
 	std: 0.0045373915
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25025, 0.25016665, 0.23895, 0.25016665, 0.25056666]
	train_accs: [0.25025, 0.25016665, 0.23895, 0.25016665, 0.25056666]
	best_train_sub_head: 4
	worst: 0.23895
	avg: 0.24801998
	best: 0.25056666

Starting e_i: 658
Model ind 579 epoch 658 head B head_i_epoch 0 batch 0: avg loss -1.803452 avg loss no lamb -1.803452 time 2019-02-04 12:08:27.260700
Model ind 579 epoch 658 head B head_i_epoch 0 batch 100: avg loss -1.796327 avg loss no lamb -1.796327 time 2019-02-04 12:11:23.653057
Model ind 579 epoch 658 head B head_i_epoch 0 batch 200: avg loss -1.690952 avg loss no lamb -1.690952 time 2019-02-04 12:14:20.051209
Model ind 579 epoch 658 head A head_i_epoch 0 batch 0: avg loss -3.436437 avg loss no lamb -3.436437 time 2019-02-04 12:17:17.017090
Model ind 579 epoch 658 head A head_i_epoch 0 batch 100: avg loss -3.459314 avg loss no lamb -3.459314 time 2019-02-04 12:20:16.545584
Model ind 579 epoch 658 head A head_i_epoch 0 batch 200: avg loss -3.494778 avg loss no lamb -3.494778 time 2019-02-04 12:23:14.283139
Pre: time 2019-02-04 12:26:38.464970: 
 	std: 0.004046553
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25095, 0.25066668, 0.2406, 0.25045, 0.25076666]
	train_accs: [0.25095, 0.25066668, 0.2406, 0.25045, 0.25076666]
	best_train_sub_head: 0
	worst: 0.2406
	avg: 0.24868667
	best: 0.25095

Starting e_i: 659
Model ind 579 epoch 659 head B head_i_epoch 0 batch 0: avg loss -1.784258 avg loss no lamb -1.784258 time 2019-02-04 12:26:42.144599
Model ind 579 epoch 659 head B head_i_epoch 0 batch 100: avg loss -1.833668 avg loss no lamb -1.833668 time 2019-02-04 12:29:39.614681
Model ind 579 epoch 659 head B head_i_epoch 0 batch 200: avg loss -1.795977 avg loss no lamb -1.795977 time 2019-02-04 12:32:36.366712
Model ind 579 epoch 659 head A head_i_epoch 0 batch 0: avg loss -3.379159 avg loss no lamb -3.379159 time 2019-02-04 12:35:33.408068
Model ind 579 epoch 659 head A head_i_epoch 0 batch 100: avg loss -3.454714 avg loss no lamb -3.454714 time 2019-02-04 12:38:32.636726
Model ind 579 epoch 659 head A head_i_epoch 0 batch 200: avg loss -3.514211 avg loss no lamb -3.514211 time 2019-02-04 12:41:30.701242
Pre: time 2019-02-04 12:44:52.664808: 
 	std: 0.0045603877
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 15), (3, 13), (4, 4), (5, 5), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24845, 0.24861667, 0.23703334, 0.24808334, 0.24855]
	train_accs: [0.24845, 0.24861667, 0.23703334, 0.24808334, 0.24855]
	best_train_sub_head: 1
	worst: 0.23703334
	avg: 0.24614668
	best: 0.24861667

Starting e_i: 660
Model ind 579 epoch 660 head B head_i_epoch 0 batch 0: avg loss -1.832268 avg loss no lamb -1.832268 time 2019-02-04 12:44:56.733725
Model ind 579 epoch 660 head B head_i_epoch 0 batch 100: avg loss -1.719026 avg loss no lamb -1.719026 time 2019-02-04 12:47:52.120252
Model ind 579 epoch 660 head B head_i_epoch 0 batch 200: avg loss -1.786943 avg loss no lamb -1.786943 time 2019-02-04 12:50:47.164119
Model ind 579 epoch 660 head A head_i_epoch 0 batch 0: avg loss -3.429108 avg loss no lamb -3.429108 time 2019-02-04 12:53:43.361362
Model ind 579 epoch 660 head A head_i_epoch 0 batch 100: avg loss -3.493256 avg loss no lamb -3.493256 time 2019-02-04 12:56:40.385153
Model ind 579 epoch 660 head A head_i_epoch 0 batch 200: avg loss -3.448336 avg loss no lamb -3.448336 time 2019-02-04 12:59:39.751076
Pre: time 2019-02-04 13:03:01.674032: 
 	std: 0.0044392515
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2488, 0.24871667, 0.23756666, 0.24858333, 0.24855]
	train_accs: [0.2488, 0.24871667, 0.23756666, 0.24858333, 0.24855]
	best_train_sub_head: 0
	worst: 0.23756666
	avg: 0.24644332
	best: 0.2488

Starting e_i: 661
Model ind 579 epoch 661 head B head_i_epoch 0 batch 0: avg loss -1.884081 avg loss no lamb -1.884081 time 2019-02-04 13:03:11.597807
Model ind 579 epoch 661 head B head_i_epoch 0 batch 100: avg loss -1.800983 avg loss no lamb -1.800983 time 2019-02-04 13:06:09.640290
Model ind 579 epoch 661 head B head_i_epoch 0 batch 200: avg loss -1.849379 avg loss no lamb -1.849379 time 2019-02-04 13:09:06.527219
Model ind 579 epoch 661 head A head_i_epoch 0 batch 0: avg loss -3.421031 avg loss no lamb -3.421031 time 2019-02-04 13:12:03.070982
Model ind 579 epoch 661 head A head_i_epoch 0 batch 100: avg loss -3.467925 avg loss no lamb -3.467925 time 2019-02-04 13:15:01.825101
Model ind 579 epoch 661 head A head_i_epoch 0 batch 200: avg loss -3.517979 avg loss no lamb -3.517979 time 2019-02-04 13:17:59.190072
Pre: time 2019-02-04 13:21:23.379263: 
 	std: 0.0048359768
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25243333, 0.25245, 0.24018334, 0.25188333, 0.25228333]
	train_accs: [0.25243333, 0.25245, 0.24018334, 0.25188333, 0.25228333]
	best_train_sub_head: 1
	worst: 0.24018334
	avg: 0.24984665
	best: 0.25245

Starting e_i: 662
Model ind 579 epoch 662 head B head_i_epoch 0 batch 0: avg loss -1.797804 avg loss no lamb -1.797804 time 2019-02-04 13:21:31.171158
Model ind 579 epoch 662 head B head_i_epoch 0 batch 100: avg loss -1.813013 avg loss no lamb -1.813013 time 2019-02-04 13:24:28.693418
Model ind 579 epoch 662 head B head_i_epoch 0 batch 200: avg loss -1.876621 avg loss no lamb -1.876621 time 2019-02-04 13:27:24.392613
Model ind 579 epoch 662 head A head_i_epoch 0 batch 0: avg loss -3.429279 avg loss no lamb -3.429279 time 2019-02-04 13:30:21.100000
Model ind 579 epoch 662 head A head_i_epoch 0 batch 100: avg loss -3.454880 avg loss no lamb -3.454880 time 2019-02-04 13:33:18.496646
Model ind 579 epoch 662 head A head_i_epoch 0 batch 200: avg loss -3.492653 avg loss no lamb -3.492653 time 2019-02-04 13:36:14.917033
Pre: time 2019-02-04 13:39:36.245281: 
 	std: 0.0038386253
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25016665, 0.24975, 0.24026667, 0.24981667, 0.24968334]
	train_accs: [0.25016665, 0.24975, 0.24026667, 0.24981667, 0.24968334]
	best_train_sub_head: 0
	worst: 0.24026667
	avg: 0.24793668
	best: 0.25016665

Starting e_i: 663
Model ind 579 epoch 663 head B head_i_epoch 0 batch 0: avg loss -1.794681 avg loss no lamb -1.794681 time 2019-02-04 13:39:39.885866
Model ind 579 epoch 663 head B head_i_epoch 0 batch 100: avg loss -1.861697 avg loss no lamb -1.861697 time 2019-02-04 13:42:37.022736
Model ind 579 epoch 663 head B head_i_epoch 0 batch 200: avg loss -1.824766 avg loss no lamb -1.824766 time 2019-02-04 13:45:33.969228
Model ind 579 epoch 663 head A head_i_epoch 0 batch 0: avg loss -3.440810 avg loss no lamb -3.440810 time 2019-02-04 13:48:31.429319
Model ind 579 epoch 663 head A head_i_epoch 0 batch 100: avg loss -3.411826 avg loss no lamb -3.411826 time 2019-02-04 13:51:31.224102
Model ind 579 epoch 663 head A head_i_epoch 0 batch 200: avg loss -3.519885 avg loss no lamb -3.519885 time 2019-02-04 13:54:29.766355
Pre: time 2019-02-04 13:57:53.252715: 
 	std: 0.004326884
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2491, 0.24955, 0.23821667, 0.2487, 0.24866667]
	train_accs: [0.2491, 0.24955, 0.23821667, 0.2487, 0.24866667]
	best_train_sub_head: 1
	worst: 0.23821667
	avg: 0.24684668
	best: 0.24955

Starting e_i: 664
Model ind 579 epoch 664 head B head_i_epoch 0 batch 0: avg loss -1.878549 avg loss no lamb -1.878549 time 2019-02-04 13:57:56.929421
Model ind 579 epoch 664 head B head_i_epoch 0 batch 100: avg loss -1.800748 avg loss no lamb -1.800748 time 2019-02-04 14:01:01.285599
Model ind 579 epoch 664 head B head_i_epoch 0 batch 200: avg loss -1.807756 avg loss no lamb -1.807756 time 2019-02-04 14:04:00.689646
Model ind 579 epoch 664 head A head_i_epoch 0 batch 0: avg loss -3.482691 avg loss no lamb -3.482691 time 2019-02-04 14:06:59.444528
Model ind 579 epoch 664 head A head_i_epoch 0 batch 100: avg loss -3.515266 avg loss no lamb -3.515266 time 2019-02-04 14:09:57.233014
Model ind 579 epoch 664 head A head_i_epoch 0 batch 200: avg loss -3.471934 avg loss no lamb -3.471934 time 2019-02-04 14:12:55.488481
Pre: time 2019-02-04 14:16:25.540971: 
 	std: 0.0043918365
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 7), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 13), (19, 12)]
	test_accs: [0.25058332, 0.25053334, 0.23961666, 0.25061667, 0.25065]
	train_accs: [0.25058332, 0.25053334, 0.23961666, 0.25061667, 0.25065]
	best_train_sub_head: 4
	worst: 0.23961666
	avg: 0.24839997
	best: 0.25065

Starting e_i: 665
Model ind 579 epoch 665 head B head_i_epoch 0 batch 0: avg loss -1.801695 avg loss no lamb -1.801695 time 2019-02-04 14:16:29.243164
Model ind 579 epoch 665 head B head_i_epoch 0 batch 100: avg loss -1.778943 avg loss no lamb -1.778943 time 2019-02-04 14:19:34.541773
Model ind 579 epoch 665 head B head_i_epoch 0 batch 200: avg loss -1.884735 avg loss no lamb -1.884735 time 2019-02-04 14:22:33.906097
Model ind 579 epoch 665 head A head_i_epoch 0 batch 0: avg loss -3.370366 avg loss no lamb -3.370366 time 2019-02-04 14:25:41.219491
Model ind 579 epoch 665 head A head_i_epoch 0 batch 100: avg loss -3.498819 avg loss no lamb -3.498819 time 2019-02-04 14:28:49.419343
Model ind 579 epoch 665 head A head_i_epoch 0 batch 200: avg loss -3.464863 avg loss no lamb -3.464863 time 2019-02-04 14:31:48.952672
Pre: time 2019-02-04 14:35:15.137153: 
 	std: 0.0039365054
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25218335, 0.25146666, 0.24171667, 0.25128335, 0.25113332]
	train_accs: [0.25218335, 0.25146666, 0.24171667, 0.25128335, 0.25113332]
	best_train_sub_head: 0
	worst: 0.24171667
	avg: 0.24955669
	best: 0.25218335

Starting e_i: 666
Model ind 579 epoch 666 head B head_i_epoch 0 batch 0: avg loss -1.760024 avg loss no lamb -1.760024 time 2019-02-04 14:35:18.797356
Model ind 579 epoch 666 head B head_i_epoch 0 batch 100: avg loss -1.682617 avg loss no lamb -1.682617 time 2019-02-04 14:38:16.194033
Model ind 579 epoch 666 head B head_i_epoch 0 batch 200: avg loss -1.856525 avg loss no lamb -1.856525 time 2019-02-04 14:41:15.775628
Model ind 579 epoch 666 head A head_i_epoch 0 batch 0: avg loss -3.424694 avg loss no lamb -3.424694 time 2019-02-04 14:44:27.009324
Model ind 579 epoch 666 head A head_i_epoch 0 batch 100: avg loss -3.507990 avg loss no lamb -3.507990 time 2019-02-04 14:47:33.976685
Model ind 579 epoch 666 head A head_i_epoch 0 batch 200: avg loss -3.521412 avg loss no lamb -3.521412 time 2019-02-04 14:50:36.001116
Pre: time 2019-02-04 14:54:02.960866: 
 	std: 0.0040020053
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25201666, 0.25191668, 0.24178334, 0.25161666, 0.25156668]
	train_accs: [0.25201666, 0.25191668, 0.24178334, 0.25161666, 0.25156668]
	best_train_sub_head: 0
	worst: 0.24178334
	avg: 0.24977998
	best: 0.25201666

Starting e_i: 667
Model ind 579 epoch 667 head B head_i_epoch 0 batch 0: avg loss -1.773438 avg loss no lamb -1.773438 time 2019-02-04 14:54:07.334728
Model ind 579 epoch 667 head B head_i_epoch 0 batch 100: avg loss -1.794490 avg loss no lamb -1.794490 time 2019-02-04 14:57:06.138113
Model ind 579 epoch 667 head B head_i_epoch 0 batch 200: avg loss -1.773606 avg loss no lamb -1.773606 time 2019-02-04 15:00:03.758241
Model ind 579 epoch 667 head A head_i_epoch 0 batch 0: avg loss -3.445398 avg loss no lamb -3.445398 time 2019-02-04 15:02:59.968692
Model ind 579 epoch 667 head A head_i_epoch 0 batch 100: avg loss -3.479572 avg loss no lamb -3.479572 time 2019-02-04 15:05:58.357136
Model ind 579 epoch 667 head A head_i_epoch 0 batch 200: avg loss -3.475549 avg loss no lamb -3.475549 time 2019-02-04 15:08:57.244826
Pre: time 2019-02-04 15:12:24.197122: 
 	std: 0.0048819217
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24938333, 0.24941666, 0.23701666, 0.24925, 0.24878334]
	train_accs: [0.24938333, 0.24941666, 0.23701666, 0.24925, 0.24878334]
	best_train_sub_head: 1
	worst: 0.23701666
	avg: 0.24677
	best: 0.24941666

Starting e_i: 668
Model ind 579 epoch 668 head B head_i_epoch 0 batch 0: avg loss -1.886791 avg loss no lamb -1.886791 time 2019-02-04 15:12:28.178837
Model ind 579 epoch 668 head B head_i_epoch 0 batch 100: avg loss -1.756575 avg loss no lamb -1.756575 time 2019-02-04 15:15:26.779459
Model ind 579 epoch 668 head B head_i_epoch 0 batch 200: avg loss -1.837637 avg loss no lamb -1.837637 time 2019-02-04 15:18:25.545935
Model ind 579 epoch 668 head A head_i_epoch 0 batch 0: avg loss -3.458164 avg loss no lamb -3.458164 time 2019-02-04 15:21:28.917010
Model ind 579 epoch 668 head A head_i_epoch 0 batch 100: avg loss -3.493130 avg loss no lamb -3.493130 time 2019-02-04 15:24:29.735377
Model ind 579 epoch 668 head A head_i_epoch 0 batch 200: avg loss -3.475232 avg loss no lamb -3.475232 time 2019-02-04 15:27:38.169245
Pre: time 2019-02-04 15:31:05.915253: 
 	std: 0.0047845417
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25061667, 0.25048333, 0.23843333, 0.25055, 0.24985]
	train_accs: [0.25061667, 0.25048333, 0.23843333, 0.25055, 0.24985]
	best_train_sub_head: 0
	worst: 0.23843333
	avg: 0.24798667
	best: 0.25061667

Starting e_i: 669
Model ind 579 epoch 669 head B head_i_epoch 0 batch 0: avg loss -1.895299 avg loss no lamb -1.895299 time 2019-02-04 15:31:11.112932
Model ind 579 epoch 669 head B head_i_epoch 0 batch 100: avg loss -1.812303 avg loss no lamb -1.812303 time 2019-02-04 15:34:09.423223
Model ind 579 epoch 669 head B head_i_epoch 0 batch 200: avg loss -1.824551 avg loss no lamb -1.824551 time 2019-02-04 15:37:10.324023
Model ind 579 epoch 669 head A head_i_epoch 0 batch 0: avg loss -3.403013 avg loss no lamb -3.403013 time 2019-02-04 15:40:17.150470
Model ind 579 epoch 669 head A head_i_epoch 0 batch 100: avg loss -3.479470 avg loss no lamb -3.479470 time 2019-02-04 15:43:16.698381
Model ind 579 epoch 669 head A head_i_epoch 0 batch 200: avg loss -3.500158 avg loss no lamb -3.500158 time 2019-02-04 15:46:17.473076
Pre: time 2019-02-04 15:49:44.032428: 
 	std: 0.0048494567
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24833333, 0.24896666, 0.23635, 0.24836667, 0.24815]
	train_accs: [0.24833333, 0.24896666, 0.23635, 0.24836667, 0.24815]
	best_train_sub_head: 1
	worst: 0.23635
	avg: 0.24603334
	best: 0.24896666

Starting e_i: 670
Model ind 579 epoch 670 head B head_i_epoch 0 batch 0: avg loss -1.787186 avg loss no lamb -1.787186 time 2019-02-04 15:49:47.911871
Model ind 579 epoch 670 head B head_i_epoch 0 batch 100: avg loss -1.792623 avg loss no lamb -1.792623 time 2019-02-04 15:52:46.521832
Model ind 579 epoch 670 head B head_i_epoch 0 batch 200: avg loss -1.859810 avg loss no lamb -1.859810 time 2019-02-04 15:55:43.678954
Model ind 579 epoch 670 head A head_i_epoch 0 batch 0: avg loss -3.474823 avg loss no lamb -3.474823 time 2019-02-04 15:58:41.151961
Model ind 579 epoch 670 head A head_i_epoch 0 batch 100: avg loss -3.430481 avg loss no lamb -3.430481 time 2019-02-04 16:01:39.510778
Model ind 579 epoch 670 head A head_i_epoch 0 batch 200: avg loss -3.413437 avg loss no lamb -3.413437 time 2019-02-04 16:04:38.563869
Pre: time 2019-02-04 16:08:02.700151: 
 	std: 0.0042813844
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2497, 0.25013334, 0.23906666, 0.24978334, 0.2494]
	train_accs: [0.2497, 0.25013334, 0.23906666, 0.24978334, 0.2494]
	best_train_sub_head: 1
	worst: 0.23906666
	avg: 0.24761668
	best: 0.25013334

Starting e_i: 671
Model ind 579 epoch 671 head B head_i_epoch 0 batch 0: avg loss -1.855173 avg loss no lamb -1.855173 time 2019-02-04 16:08:10.902795
Model ind 579 epoch 671 head B head_i_epoch 0 batch 100: avg loss -1.809059 avg loss no lamb -1.809059 time 2019-02-04 16:11:08.233600
Model ind 579 epoch 671 head B head_i_epoch 0 batch 200: avg loss -1.794050 avg loss no lamb -1.794050 time 2019-02-04 16:14:05.785844
Model ind 579 epoch 671 head A head_i_epoch 0 batch 0: avg loss -3.368309 avg loss no lamb -3.368309 time 2019-02-04 16:17:02.509243
Model ind 579 epoch 671 head A head_i_epoch 0 batch 100: avg loss -3.447351 avg loss no lamb -3.447351 time 2019-02-04 16:20:00.422943
Model ind 579 epoch 671 head A head_i_epoch 0 batch 200: avg loss -3.467932 avg loss no lamb -3.467932 time 2019-02-04 16:22:58.906381
Pre: time 2019-02-04 16:26:25.162918: 
 	std: 0.0048341183
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 5), (4, 4), (5, 3), (6, 18), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 13), (19, 19)]
	test_accs: [0.25091666, 0.25055, 0.2387, 0.25106665, 0.25056666]
	train_accs: [0.25091666, 0.25055, 0.2387, 0.25106665, 0.25056666]
	best_train_sub_head: 3
	worst: 0.2387
	avg: 0.24836001
	best: 0.25106665

Starting e_i: 672
Model ind 579 epoch 672 head B head_i_epoch 0 batch 0: avg loss -1.861318 avg loss no lamb -1.861318 time 2019-02-04 16:26:29.676997
Model ind 579 epoch 672 head B head_i_epoch 0 batch 100: avg loss -1.800998 avg loss no lamb -1.800998 time 2019-02-04 16:29:28.091254
Model ind 579 epoch 672 head B head_i_epoch 0 batch 200: avg loss -1.818516 avg loss no lamb -1.818516 time 2019-02-04 16:32:24.639939
Model ind 579 epoch 672 head A head_i_epoch 0 batch 0: avg loss -3.431632 avg loss no lamb -3.431632 time 2019-02-04 16:35:21.401219
Model ind 579 epoch 672 head A head_i_epoch 0 batch 100: avg loss -3.479357 avg loss no lamb -3.479357 time 2019-02-04 16:38:19.006793
Model ind 579 epoch 672 head A head_i_epoch 0 batch 200: avg loss -3.431432 avg loss no lamb -3.431432 time 2019-02-04 16:41:16.890303
Pre: time 2019-02-04 16:44:38.703226: 
 	std: 0.0049223676
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24665, 0.24708334, 0.2345, 0.24678333, 0.24668333]
	train_accs: [0.24665, 0.24708334, 0.2345, 0.24678333, 0.24668333]
	best_train_sub_head: 1
	worst: 0.2345
	avg: 0.24433999
	best: 0.24708334

Starting e_i: 673
Model ind 579 epoch 673 head B head_i_epoch 0 batch 0: avg loss -1.848286 avg loss no lamb -1.848286 time 2019-02-04 16:44:42.477093
Model ind 579 epoch 673 head B head_i_epoch 0 batch 100: avg loss -1.833318 avg loss no lamb -1.833318 time 2019-02-04 16:47:40.191071
Model ind 579 epoch 673 head B head_i_epoch 0 batch 200: avg loss -1.824054 avg loss no lamb -1.824054 time 2019-02-04 16:50:37.400189
Model ind 579 epoch 673 head A head_i_epoch 0 batch 0: avg loss -3.401515 avg loss no lamb -3.401515 time 2019-02-04 16:53:34.465910
Model ind 579 epoch 673 head A head_i_epoch 0 batch 100: avg loss -3.394555 avg loss no lamb -3.394555 time 2019-02-04 16:56:33.429840
Model ind 579 epoch 673 head A head_i_epoch 0 batch 200: avg loss -3.430236 avg loss no lamb -3.430236 time 2019-02-04 16:59:33.567885
Pre: time 2019-02-04 17:02:57.535099: 
 	std: 0.0049026017
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25065, 0.25038335, 0.23823333, 0.25051665, 0.2504]
	train_accs: [0.25065, 0.25038335, 0.23823333, 0.25051665, 0.2504]
	best_train_sub_head: 0
	worst: 0.23823333
	avg: 0.24803667
	best: 0.25065

Starting e_i: 674
Model ind 579 epoch 674 head B head_i_epoch 0 batch 0: avg loss -1.778285 avg loss no lamb -1.778285 time 2019-02-04 17:03:01.376693
Model ind 579 epoch 674 head B head_i_epoch 0 batch 100: avg loss -1.813691 avg loss no lamb -1.813691 time 2019-02-04 17:05:58.577902
Model ind 579 epoch 674 head B head_i_epoch 0 batch 200: avg loss -1.843600 avg loss no lamb -1.843600 time 2019-02-04 17:08:55.801275
Model ind 579 epoch 674 head A head_i_epoch 0 batch 0: avg loss -3.452101 avg loss no lamb -3.452101 time 2019-02-04 17:11:53.256111
Model ind 579 epoch 674 head A head_i_epoch 0 batch 100: avg loss -3.478042 avg loss no lamb -3.478042 time 2019-02-04 17:14:50.923203
Model ind 579 epoch 674 head A head_i_epoch 0 batch 200: avg loss -3.432049 avg loss no lamb -3.432049 time 2019-02-04 17:17:48.899790
Pre: time 2019-02-04 17:21:13.159017: 
 	std: 0.004494397
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25065, 0.25135, 0.23948333, 0.25036666, 0.25036666]
	train_accs: [0.25065, 0.25135, 0.23948333, 0.25036666, 0.25036666]
	best_train_sub_head: 1
	worst: 0.23948333
	avg: 0.24844334
	best: 0.25135

Starting e_i: 675
Model ind 579 epoch 675 head B head_i_epoch 0 batch 0: avg loss -1.748658 avg loss no lamb -1.748658 time 2019-02-04 17:21:16.903049
Model ind 579 epoch 675 head B head_i_epoch 0 batch 100: avg loss -1.798866 avg loss no lamb -1.798866 time 2019-02-04 17:24:15.029116
Model ind 579 epoch 675 head B head_i_epoch 0 batch 200: avg loss -1.898108 avg loss no lamb -1.898108 time 2019-02-04 17:27:13.728192
Model ind 579 epoch 675 head A head_i_epoch 0 batch 0: avg loss -3.390888 avg loss no lamb -3.390888 time 2019-02-04 17:30:11.394072
Model ind 579 epoch 675 head A head_i_epoch 0 batch 100: avg loss -3.481509 avg loss no lamb -3.481509 time 2019-02-04 17:33:10.895896
Model ind 579 epoch 675 head A head_i_epoch 0 batch 200: avg loss -3.463666 avg loss no lamb -3.463666 time 2019-02-04 17:36:09.314830
Pre: time 2019-02-04 17:39:31.577025: 
 	std: 0.005290595
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 5), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25293332, 0.25333333, 0.2396, 0.25233334, 0.2526]
	train_accs: [0.25293332, 0.25333333, 0.2396, 0.25233334, 0.2526]
	best_train_sub_head: 1
	worst: 0.2396
	avg: 0.25016
	best: 0.25333333

Starting e_i: 676
Model ind 579 epoch 676 head B head_i_epoch 0 batch 0: avg loss -1.841521 avg loss no lamb -1.841521 time 2019-02-04 17:39:42.743464
Model ind 579 epoch 676 head B head_i_epoch 0 batch 100: avg loss -1.720133 avg loss no lamb -1.720133 time 2019-02-04 17:42:39.054086
Model ind 579 epoch 676 head B head_i_epoch 0 batch 200: avg loss -1.764900 avg loss no lamb -1.764900 time 2019-02-04 17:45:35.603997
Model ind 579 epoch 676 head A head_i_epoch 0 batch 0: avg loss -3.395880 avg loss no lamb -3.395880 time 2019-02-04 17:48:33.716823
Model ind 579 epoch 676 head A head_i_epoch 0 batch 100: avg loss -3.438184 avg loss no lamb -3.438184 time 2019-02-04 17:51:31.772712
Model ind 579 epoch 676 head A head_i_epoch 0 batch 200: avg loss -3.523551 avg loss no lamb -3.523551 time 2019-02-04 17:54:29.893770
Pre: time 2019-02-04 17:57:52.097653: 
 	std: 0.005159472
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25151667, 0.2519, 0.2385, 0.25088334, 0.25118333]
	train_accs: [0.25151667, 0.2519, 0.2385, 0.25088334, 0.25118333]
	best_train_sub_head: 1
	worst: 0.2385
	avg: 0.24879666
	best: 0.2519

Starting e_i: 677
Model ind 579 epoch 677 head B head_i_epoch 0 batch 0: avg loss -1.843508 avg loss no lamb -1.843508 time 2019-02-04 17:57:55.683232
Model ind 579 epoch 677 head B head_i_epoch 0 batch 100: avg loss -1.732180 avg loss no lamb -1.732180 time 2019-02-04 18:00:51.805187
Model ind 579 epoch 677 head B head_i_epoch 0 batch 200: avg loss -1.848940 avg loss no lamb -1.848940 time 2019-02-04 18:03:48.668020
Model ind 579 epoch 677 head A head_i_epoch 0 batch 0: avg loss -3.409782 avg loss no lamb -3.409782 time 2019-02-04 18:06:45.762954
Model ind 579 epoch 677 head A head_i_epoch 0 batch 100: avg loss -3.517881 avg loss no lamb -3.517881 time 2019-02-04 18:09:52.435878
Model ind 579 epoch 677 head A head_i_epoch 0 batch 200: avg loss -3.457693 avg loss no lamb -3.457693 time 2019-02-04 18:12:51.567506
Pre: time 2019-02-04 18:16:15.394118: 
 	std: 0.00436721
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24958333, 0.24928333, 0.23833333, 0.24861667, 0.2494]
	train_accs: [0.24958333, 0.24928333, 0.23833333, 0.24861667, 0.2494]
	best_train_sub_head: 0
	worst: 0.23833333
	avg: 0.24704334
	best: 0.24958333

Starting e_i: 678
Model ind 579 epoch 678 head B head_i_epoch 0 batch 0: avg loss -1.828688 avg loss no lamb -1.828688 time 2019-02-04 18:16:19.591224
Model ind 579 epoch 678 head B head_i_epoch 0 batch 100: avg loss -1.744586 avg loss no lamb -1.744586 time 2019-02-04 18:19:15.136273
Model ind 579 epoch 678 head B head_i_epoch 0 batch 200: avg loss -1.856351 avg loss no lamb -1.856351 time 2019-02-04 18:22:11.314115
Model ind 579 epoch 678 head A head_i_epoch 0 batch 0: avg loss -3.411173 avg loss no lamb -3.411173 time 2019-02-04 18:25:09.466011
Model ind 579 epoch 678 head A head_i_epoch 0 batch 100: avg loss -3.373528 avg loss no lamb -3.373528 time 2019-02-04 18:28:06.301971
Model ind 579 epoch 678 head A head_i_epoch 0 batch 200: avg loss -3.481161 avg loss no lamb -3.481161 time 2019-02-04 18:31:04.151690
Pre: time 2019-02-04 18:34:27.195636: 
 	std: 0.0044070696
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24895, 0.24875, 0.23768333, 0.24821667, 0.24881667]
	train_accs: [0.24895, 0.24875, 0.23768333, 0.24821667, 0.24881667]
	best_train_sub_head: 0
	worst: 0.23768333
	avg: 0.24648333
	best: 0.24895

Starting e_i: 679
Model ind 579 epoch 679 head B head_i_epoch 0 batch 0: avg loss -1.881717 avg loss no lamb -1.881717 time 2019-02-04 18:34:31.056939
Model ind 579 epoch 679 head B head_i_epoch 0 batch 100: avg loss -1.822112 avg loss no lamb -1.822112 time 2019-02-04 18:37:37.111350
Model ind 579 epoch 679 head B head_i_epoch 0 batch 200: avg loss -1.837150 avg loss no lamb -1.837150 time 2019-02-04 18:40:35.231343
Model ind 579 epoch 679 head A head_i_epoch 0 batch 0: avg loss -3.447343 avg loss no lamb -3.447343 time 2019-02-04 18:43:33.986263
Model ind 579 epoch 679 head A head_i_epoch 0 batch 100: avg loss -3.421703 avg loss no lamb -3.421703 time 2019-02-04 18:46:32.005139
Model ind 579 epoch 679 head A head_i_epoch 0 batch 200: avg loss -3.472369 avg loss no lamb -3.472369 time 2019-02-04 18:49:30.376289
Pre: time 2019-02-04 18:52:55.592408: 
 	std: 0.0048679947
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25065, 0.25033334, 0.23821667, 0.25011668, 0.25041667]
	train_accs: [0.25065, 0.25033334, 0.23821667, 0.25011668, 0.25041667]
	best_train_sub_head: 0
	worst: 0.23821667
	avg: 0.24794666
	best: 0.25065

Starting e_i: 680
Model ind 579 epoch 680 head B head_i_epoch 0 batch 0: avg loss -1.844122 avg loss no lamb -1.844122 time 2019-02-04 18:53:00.045155
Model ind 579 epoch 680 head B head_i_epoch 0 batch 100: avg loss -1.772829 avg loss no lamb -1.772829 time 2019-02-04 18:55:58.582997
Model ind 579 epoch 680 head B head_i_epoch 0 batch 200: avg loss -1.862804 avg loss no lamb -1.862804 time 2019-02-04 18:58:57.170132
Model ind 579 epoch 680 head A head_i_epoch 0 batch 0: avg loss -3.398533 avg loss no lamb -3.398533 time 2019-02-04 19:01:55.655032
Model ind 579 epoch 680 head A head_i_epoch 0 batch 100: avg loss -3.495708 avg loss no lamb -3.495708 time 2019-02-04 19:04:54.504824
Model ind 579 epoch 680 head A head_i_epoch 0 batch 200: avg loss -3.473800 avg loss no lamb -3.473800 time 2019-02-04 19:07:56.259285
Pre: time 2019-02-04 19:11:20.104728: 
 	std: 0.004440777
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2509, 0.25131667, 0.23973334, 0.25038335, 0.25063333]
	train_accs: [0.2509, 0.25131667, 0.23973334, 0.25038335, 0.25063333]
	best_train_sub_head: 1
	worst: 0.23973334
	avg: 0.24859336
	best: 0.25131667

Starting e_i: 681
Model ind 579 epoch 681 head B head_i_epoch 0 batch 0: avg loss -1.913360 avg loss no lamb -1.913360 time 2019-02-04 19:11:29.856614
Model ind 579 epoch 681 head B head_i_epoch 0 batch 100: avg loss -1.885010 avg loss no lamb -1.885010 time 2019-02-04 19:14:27.515414
Model ind 579 epoch 681 head B head_i_epoch 0 batch 200: avg loss -1.828162 avg loss no lamb -1.828162 time 2019-02-04 19:17:25.723644
Model ind 579 epoch 681 head A head_i_epoch 0 batch 0: avg loss -3.427573 avg loss no lamb -3.427573 time 2019-02-04 19:20:25.846388
Model ind 579 epoch 681 head A head_i_epoch 0 batch 100: avg loss -3.506892 avg loss no lamb -3.506892 time 2019-02-04 19:23:26.607657
Model ind 579 epoch 681 head A head_i_epoch 0 batch 200: avg loss -3.447509 avg loss no lamb -3.447509 time 2019-02-04 19:26:25.060262
Pre: time 2019-02-04 19:29:49.633900: 
 	std: 0.004235397
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25158334, 0.25115, 0.24063334, 0.25063333, 0.2514]
	train_accs: [0.25158334, 0.25115, 0.24063334, 0.25063333, 0.2514]
	best_train_sub_head: 0
	worst: 0.24063334
	avg: 0.24908002
	best: 0.25158334

Starting e_i: 682
Model ind 579 epoch 682 head B head_i_epoch 0 batch 0: avg loss -1.819896 avg loss no lamb -1.819896 time 2019-02-04 19:29:54.056492
Model ind 579 epoch 682 head B head_i_epoch 0 batch 100: avg loss -1.869043 avg loss no lamb -1.869043 time 2019-02-04 19:32:51.344961
Model ind 579 epoch 682 head B head_i_epoch 0 batch 200: avg loss -1.820770 avg loss no lamb -1.820770 time 2019-02-04 19:35:48.888883
Model ind 579 epoch 682 head A head_i_epoch 0 batch 0: avg loss -3.482331 avg loss no lamb -3.482331 time 2019-02-04 19:38:46.657923
Model ind 579 epoch 682 head A head_i_epoch 0 batch 100: avg loss -3.447693 avg loss no lamb -3.447693 time 2019-02-04 19:41:44.611666
Model ind 579 epoch 682 head A head_i_epoch 0 batch 200: avg loss -3.489124 avg loss no lamb -3.489124 time 2019-02-04 19:44:43.712191
Pre: time 2019-02-04 19:48:08.246001: 
 	std: 0.004555235
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 15), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 13), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24898334, 0.24896666, 0.23755, 0.24895, 0.24885]
	train_accs: [0.24898334, 0.24896666, 0.23755, 0.24895, 0.24885]
	best_train_sub_head: 0
	worst: 0.23755
	avg: 0.24666002
	best: 0.24898334

Starting e_i: 683
Model ind 579 epoch 683 head B head_i_epoch 0 batch 0: avg loss -1.900195 avg loss no lamb -1.900195 time 2019-02-04 19:48:11.883436
Model ind 579 epoch 683 head B head_i_epoch 0 batch 100: avg loss -1.824657 avg loss no lamb -1.824657 time 2019-02-04 19:51:10.310816
Model ind 579 epoch 683 head B head_i_epoch 0 batch 200: avg loss -1.791930 avg loss no lamb -1.791930 time 2019-02-04 19:54:08.853966
Model ind 579 epoch 683 head A head_i_epoch 0 batch 0: avg loss -3.466750 avg loss no lamb -3.466750 time 2019-02-04 19:57:06.664957
Model ind 579 epoch 683 head A head_i_epoch 0 batch 100: avg loss -3.421865 avg loss no lamb -3.421865 time 2019-02-04 20:00:05.723868
Model ind 579 epoch 683 head A head_i_epoch 0 batch 200: avg loss -3.418975 avg loss no lamb -3.418975 time 2019-02-04 20:03:06.422776
Pre: time 2019-02-04 20:06:29.801983: 
 	std: 0.0051820036
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 15), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 13), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25416666, 0.25375, 0.24095, 0.25388333, 0.2538]
	train_accs: [0.25416666, 0.25375, 0.24095, 0.25388333, 0.2538]
	best_train_sub_head: 0
	worst: 0.24095
	avg: 0.25131002
	best: 0.25416666

Starting e_i: 684
Model ind 579 epoch 684 head B head_i_epoch 0 batch 0: avg loss -1.853763 avg loss no lamb -1.853763 time 2019-02-04 20:06:41.673287
Model ind 579 epoch 684 head B head_i_epoch 0 batch 100: avg loss -1.811005 avg loss no lamb -1.811005 time 2019-02-04 20:09:41.597623
Model ind 579 epoch 684 head B head_i_epoch 0 batch 200: avg loss -1.855639 avg loss no lamb -1.855639 time 2019-02-04 20:12:41.392879
Model ind 579 epoch 684 head A head_i_epoch 0 batch 0: avg loss -3.409643 avg loss no lamb -3.409643 time 2019-02-04 20:15:40.151397
Model ind 579 epoch 684 head A head_i_epoch 0 batch 100: avg loss -3.481865 avg loss no lamb -3.481865 time 2019-02-04 20:18:39.785978
Model ind 579 epoch 684 head A head_i_epoch 0 batch 200: avg loss -3.503920 avg loss no lamb -3.503920 time 2019-02-04 20:21:37.823012
Pre: time 2019-02-04 20:25:01.906416: 
 	std: 0.0053938357
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 15), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 13), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24873333, 0.24771667, 0.2347, 0.24796666, 0.24821667]
	train_accs: [0.24873333, 0.24771667, 0.2347, 0.24796666, 0.24821667]
	best_train_sub_head: 0
	worst: 0.2347
	avg: 0.24546666
	best: 0.24873333

Starting e_i: 685
Model ind 579 epoch 685 head B head_i_epoch 0 batch 0: avg loss -1.800955 avg loss no lamb -1.800955 time 2019-02-04 20:25:05.772303
Model ind 579 epoch 685 head B head_i_epoch 0 batch 100: avg loss -1.789706 avg loss no lamb -1.789706 time 2019-02-04 20:28:04.324245
Model ind 579 epoch 685 head B head_i_epoch 0 batch 200: avg loss -1.815800 avg loss no lamb -1.815800 time 2019-02-04 20:31:01.925173
Model ind 579 epoch 685 head A head_i_epoch 0 batch 0: avg loss -3.456433 avg loss no lamb -3.456433 time 2019-02-04 20:34:00.894570
Model ind 579 epoch 685 head A head_i_epoch 0 batch 100: avg loss -3.502465 avg loss no lamb -3.502465 time 2019-02-04 20:37:00.075047
Model ind 579 epoch 685 head A head_i_epoch 0 batch 200: avg loss -3.456776 avg loss no lamb -3.456776 time 2019-02-04 20:39:58.897400
Pre: time 2019-02-04 20:43:25.765407: 
 	std: 0.0043965937
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25156668, 0.25043333, 0.2398, 0.24968334, 0.25103334]
	train_accs: [0.25156668, 0.25043333, 0.2398, 0.24968334, 0.25103334]
	best_train_sub_head: 0
	worst: 0.2398
	avg: 0.24850333
	best: 0.25156668

Starting e_i: 686
Model ind 579 epoch 686 head B head_i_epoch 0 batch 0: avg loss -1.819420 avg loss no lamb -1.819420 time 2019-02-04 20:43:29.531636
Model ind 579 epoch 686 head B head_i_epoch 0 batch 100: avg loss -1.834974 avg loss no lamb -1.834974 time 2019-02-04 20:46:28.155677
Model ind 579 epoch 686 head B head_i_epoch 0 batch 200: avg loss -1.821082 avg loss no lamb -1.821082 time 2019-02-04 20:49:26.102122
Model ind 579 epoch 686 head A head_i_epoch 0 batch 0: avg loss -3.392554 avg loss no lamb -3.392554 time 2019-02-04 20:52:25.104923
Model ind 579 epoch 686 head A head_i_epoch 0 batch 100: avg loss -3.436766 avg loss no lamb -3.436766 time 2019-02-04 20:55:23.892971
Model ind 579 epoch 686 head A head_i_epoch 0 batch 200: avg loss -3.465780 avg loss no lamb -3.465780 time 2019-02-04 20:58:22.815515
Pre: time 2019-02-04 21:01:47.640115: 
 	std: 0.004712893
	best_train_sub_head_match: [(0, 18), (1, 15), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 13), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24798334, 0.2475, 0.23578334, 0.24698333, 0.24768333]
	train_accs: [0.24798334, 0.2475, 0.23578334, 0.24698333, 0.24768333]
	best_train_sub_head: 0
	worst: 0.23578334
	avg: 0.24518666
	best: 0.24798334

Starting e_i: 687
Model ind 579 epoch 687 head B head_i_epoch 0 batch 0: avg loss -1.847958 avg loss no lamb -1.847958 time 2019-02-04 21:01:51.332270
Model ind 579 epoch 687 head B head_i_epoch 0 batch 100: avg loss -1.900083 avg loss no lamb -1.900083 time 2019-02-04 21:04:49.578528
Model ind 579 epoch 687 head B head_i_epoch 0 batch 200: avg loss -1.830441 avg loss no lamb -1.830441 time 2019-02-04 21:07:45.342796
Model ind 579 epoch 687 head A head_i_epoch 0 batch 0: avg loss -3.499425 avg loss no lamb -3.499425 time 2019-02-04 21:10:42.196722
Model ind 579 epoch 687 head A head_i_epoch 0 batch 100: avg loss -3.500108 avg loss no lamb -3.500108 time 2019-02-04 21:13:41.395145
Model ind 579 epoch 687 head A head_i_epoch 0 batch 200: avg loss -3.500751 avg loss no lamb -3.500751 time 2019-02-04 21:16:40.647469
Pre: time 2019-02-04 21:20:06.088233: 
 	std: 0.0047814623
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25278333, 0.25195, 0.24016666, 0.25115, 0.2523]
	train_accs: [0.25278333, 0.25195, 0.24016666, 0.25115, 0.2523]
	best_train_sub_head: 0
	worst: 0.24016666
	avg: 0.24967
	best: 0.25278333

Starting e_i: 688
Model ind 579 epoch 688 head B head_i_epoch 0 batch 0: avg loss -1.837901 avg loss no lamb -1.837901 time 2019-02-04 21:20:09.748778
Model ind 579 epoch 688 head B head_i_epoch 0 batch 100: avg loss -1.821498 avg loss no lamb -1.821498 time 2019-02-04 21:23:07.553242
Model ind 579 epoch 688 head B head_i_epoch 0 batch 200: avg loss -1.841627 avg loss no lamb -1.841627 time 2019-02-04 21:26:04.419330
Model ind 579 epoch 688 head A head_i_epoch 0 batch 0: avg loss -3.386865 avg loss no lamb -3.386865 time 2019-02-04 21:29:02.406734
Model ind 579 epoch 688 head A head_i_epoch 0 batch 100: avg loss -3.449148 avg loss no lamb -3.449148 time 2019-02-04 21:32:02.615719
Model ind 579 epoch 688 head A head_i_epoch 0 batch 200: avg loss -3.500811 avg loss no lamb -3.500811 time 2019-02-04 21:35:01.961975
Pre: time 2019-02-04 21:38:26.819306: 
 	std: 0.0044530444
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.24773334, 0.24846667, 0.23696667, 0.24723333, 0.24866667]
	train_accs: [0.24773334, 0.24846667, 0.23696667, 0.24723333, 0.24866667]
	best_train_sub_head: 4
	worst: 0.23696667
	avg: 0.24581334
	best: 0.24866667

Starting e_i: 689
Model ind 579 epoch 689 head B head_i_epoch 0 batch 0: avg loss -1.848801 avg loss no lamb -1.848801 time 2019-02-04 21:38:31.332667
Model ind 579 epoch 689 head B head_i_epoch 0 batch 100: avg loss -1.781072 avg loss no lamb -1.781072 time 2019-02-04 21:41:29.360586
Model ind 579 epoch 689 head B head_i_epoch 0 batch 200: avg loss -1.896451 avg loss no lamb -1.896451 time 2019-02-04 21:44:26.797197
Model ind 579 epoch 689 head A head_i_epoch 0 batch 0: avg loss -3.497079 avg loss no lamb -3.497079 time 2019-02-04 21:47:23.337420
Model ind 579 epoch 689 head A head_i_epoch 0 batch 100: avg loss -3.459871 avg loss no lamb -3.459871 time 2019-02-04 21:50:22.129719
Model ind 579 epoch 689 head A head_i_epoch 0 batch 200: avg loss -3.477123 avg loss no lamb -3.477123 time 2019-02-04 21:53:21.143026
Pre: time 2019-02-04 21:56:46.801512: 
 	std: 0.0043217083
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25175, 0.25143334, 0.24078333, 0.25146666, 0.25168332]
	train_accs: [0.25175, 0.25143334, 0.24078333, 0.25146666, 0.25168332]
	best_train_sub_head: 0
	worst: 0.24078333
	avg: 0.24942334
	best: 0.25175

Starting e_i: 690
Model ind 579 epoch 690 head B head_i_epoch 0 batch 0: avg loss -1.845315 avg loss no lamb -1.845315 time 2019-02-04 21:56:50.725268
Model ind 579 epoch 690 head B head_i_epoch 0 batch 100: avg loss -1.830738 avg loss no lamb -1.830738 time 2019-02-04 21:59:49.211823
Model ind 579 epoch 690 head B head_i_epoch 0 batch 200: avg loss -1.750608 avg loss no lamb -1.750608 time 2019-02-04 22:02:48.113595
Model ind 579 epoch 690 head A head_i_epoch 0 batch 0: avg loss -3.435506 avg loss no lamb -3.435506 time 2019-02-04 22:05:46.378998
Model ind 579 epoch 690 head A head_i_epoch 0 batch 100: avg loss -3.450326 avg loss no lamb -3.450326 time 2019-02-04 22:08:46.095634
Model ind 579 epoch 690 head A head_i_epoch 0 batch 200: avg loss -3.504205 avg loss no lamb -3.504205 time 2019-02-04 22:11:45.065038
Pre: time 2019-02-04 22:15:09.496891: 
 	std: 0.0040982575
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25016665, 0.25026667, 0.2401, 0.25018334, 0.25071666]
	train_accs: [0.25016665, 0.25026667, 0.2401, 0.25018334, 0.25071666]
	best_train_sub_head: 4
	worst: 0.2401
	avg: 0.24828668
	best: 0.25071666

Starting e_i: 691
Model ind 579 epoch 691 head B head_i_epoch 0 batch 0: avg loss -1.804152 avg loss no lamb -1.804152 time 2019-02-04 22:15:16.748553
Model ind 579 epoch 691 head B head_i_epoch 0 batch 100: avg loss -1.817210 avg loss no lamb -1.817210 time 2019-02-04 22:18:13.712867
Model ind 579 epoch 691 head B head_i_epoch 0 batch 200: avg loss -1.770098 avg loss no lamb -1.770098 time 2019-02-04 22:21:10.106889
Model ind 579 epoch 691 head A head_i_epoch 0 batch 0: avg loss -3.416569 avg loss no lamb -3.416569 time 2019-02-04 22:24:07.072780
Model ind 579 epoch 691 head A head_i_epoch 0 batch 100: avg loss -3.442513 avg loss no lamb -3.442513 time 2019-02-04 22:27:05.977541
Model ind 579 epoch 691 head A head_i_epoch 0 batch 200: avg loss -3.537130 avg loss no lamb -3.537130 time 2019-02-04 22:30:04.772164
Pre: time 2019-02-04 22:33:26.799189: 
 	std: 0.004262933
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25196666, 0.25255, 0.24143334, 0.25176665, 0.252]
	train_accs: [0.25196666, 0.25255, 0.24143334, 0.25176665, 0.252]
	best_train_sub_head: 1
	worst: 0.24143334
	avg: 0.24994333
	best: 0.25255

Starting e_i: 692
Model ind 579 epoch 692 head B head_i_epoch 0 batch 0: avg loss -1.854612 avg loss no lamb -1.854612 time 2019-02-04 22:33:30.476732
Model ind 579 epoch 692 head B head_i_epoch 0 batch 100: avg loss -1.774619 avg loss no lamb -1.774619 time 2019-02-04 22:36:27.767600
Model ind 579 epoch 692 head B head_i_epoch 0 batch 200: avg loss -1.874223 avg loss no lamb -1.874223 time 2019-02-04 22:39:26.682198
Model ind 579 epoch 692 head A head_i_epoch 0 batch 0: avg loss -3.446301 avg loss no lamb -3.446301 time 2019-02-04 22:42:25.547183
Model ind 579 epoch 692 head A head_i_epoch 0 batch 100: avg loss -3.493513 avg loss no lamb -3.493513 time 2019-02-04 22:45:25.278615
Model ind 579 epoch 692 head A head_i_epoch 0 batch 200: avg loss -3.510905 avg loss no lamb -3.510905 time 2019-02-04 22:48:25.475197
Pre: time 2019-02-04 22:51:50.550848: 
 	std: 0.0043438454
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25031668, 0.25073335, 0.23933333, 0.24965, 0.24991667]
	train_accs: [0.25031668, 0.25073335, 0.23933333, 0.24965, 0.24991667]
	best_train_sub_head: 1
	worst: 0.23933333
	avg: 0.24798998
	best: 0.25073335

Starting e_i: 693
Model ind 579 epoch 693 head B head_i_epoch 0 batch 0: avg loss -1.797210 avg loss no lamb -1.797210 time 2019-02-04 22:51:54.352135
Model ind 579 epoch 693 head B head_i_epoch 0 batch 100: avg loss -1.771481 avg loss no lamb -1.771481 time 2019-02-04 22:54:52.084257
Model ind 579 epoch 693 head B head_i_epoch 0 batch 200: avg loss -1.758134 avg loss no lamb -1.758134 time 2019-02-04 22:57:51.414111
Model ind 579 epoch 693 head A head_i_epoch 0 batch 0: avg loss -3.399776 avg loss no lamb -3.399776 time 2019-02-04 23:00:49.629382
Model ind 579 epoch 693 head A head_i_epoch 0 batch 100: avg loss -3.487625 avg loss no lamb -3.487625 time 2019-02-04 23:03:49.431473
Model ind 579 epoch 693 head A head_i_epoch 0 batch 200: avg loss -3.459905 avg loss no lamb -3.459905 time 2019-02-04 23:06:47.783860
Pre: time 2019-02-04 23:10:12.749854: 
 	std: 0.0037273963
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 5), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24898334, 0.24911667, 0.23966667, 0.24893333, 0.2489]
	train_accs: [0.24898334, 0.24911667, 0.23966667, 0.24893333, 0.2489]
	best_train_sub_head: 1
	worst: 0.23966667
	avg: 0.24712
	best: 0.24911667

Starting e_i: 694
Model ind 579 epoch 694 head B head_i_epoch 0 batch 0: avg loss -1.929414 avg loss no lamb -1.929414 time 2019-02-04 23:10:16.505375
Model ind 579 epoch 694 head B head_i_epoch 0 batch 100: avg loss -1.775041 avg loss no lamb -1.775041 time 2019-02-04 23:13:14.642275
Model ind 579 epoch 694 head B head_i_epoch 0 batch 200: avg loss -1.870199 avg loss no lamb -1.870199 time 2019-02-04 23:16:12.772116
Model ind 579 epoch 694 head A head_i_epoch 0 batch 0: avg loss -3.439391 avg loss no lamb -3.439391 time 2019-02-04 23:19:10.630544
Model ind 579 epoch 694 head A head_i_epoch 0 batch 100: avg loss -3.574054 avg loss no lamb -3.574054 time 2019-02-04 23:22:09.770209
Model ind 579 epoch 694 head A head_i_epoch 0 batch 200: avg loss -3.455853 avg loss no lamb -3.455853 time 2019-02-04 23:25:08.622102
Pre: time 2019-02-04 23:28:32.433237: 
 	std: 0.00415215
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24976666, 0.25001666, 0.23945, 0.2499, 0.24961667]
	train_accs: [0.24976666, 0.25001666, 0.23945, 0.2499, 0.24961667]
	best_train_sub_head: 1
	worst: 0.23945
	avg: 0.24775
	best: 0.25001666

Starting e_i: 695
Model ind 579 epoch 695 head B head_i_epoch 0 batch 0: avg loss -1.861423 avg loss no lamb -1.861423 time 2019-02-04 23:28:36.202324
Model ind 579 epoch 695 head B head_i_epoch 0 batch 100: avg loss -1.752836 avg loss no lamb -1.752836 time 2019-02-04 23:31:32.797442
Model ind 579 epoch 695 head B head_i_epoch 0 batch 200: avg loss -1.840680 avg loss no lamb -1.840680 time 2019-02-04 23:34:30.617987
Model ind 579 epoch 695 head A head_i_epoch 0 batch 0: avg loss -3.409269 avg loss no lamb -3.409269 time 2019-02-04 23:37:28.342856
Model ind 579 epoch 695 head A head_i_epoch 0 batch 100: avg loss -3.471191 avg loss no lamb -3.471191 time 2019-02-04 23:40:27.331091
Model ind 579 epoch 695 head A head_i_epoch 0 batch 200: avg loss -3.482492 avg loss no lamb -3.482492 time 2019-02-04 23:43:26.672982
Pre: time 2019-02-04 23:46:50.671945: 
 	std: 0.0047785332
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24845, 0.24838333, 0.23646666, 0.24873333, 0.24803333]
	train_accs: [0.24845, 0.24838333, 0.23646666, 0.24873333, 0.24803333]
	best_train_sub_head: 3
	worst: 0.23646666
	avg: 0.24601333
	best: 0.24873333

Starting e_i: 696
Model ind 579 epoch 696 head B head_i_epoch 0 batch 0: avg loss -1.873639 avg loss no lamb -1.873639 time 2019-02-04 23:46:54.956163
Model ind 579 epoch 696 head B head_i_epoch 0 batch 100: avg loss -1.745722 avg loss no lamb -1.745722 time 2019-02-04 23:49:52.847047
Model ind 579 epoch 696 head B head_i_epoch 0 batch 200: avg loss -1.808058 avg loss no lamb -1.808058 time 2019-02-04 23:52:51.417359
Model ind 579 epoch 696 head A head_i_epoch 0 batch 0: avg loss -3.451287 avg loss no lamb -3.451287 time 2019-02-04 23:55:48.150136
Model ind 579 epoch 696 head A head_i_epoch 0 batch 100: avg loss -3.464468 avg loss no lamb -3.464468 time 2019-02-04 23:58:45.750466
Model ind 579 epoch 696 head A head_i_epoch 0 batch 200: avg loss -3.494170 avg loss no lamb -3.494170 time 2019-02-05 00:01:43.409368
Pre: time 2019-02-05 00:05:07.244122: 
 	std: 0.004334133
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24953334, 0.24931666, 0.23848334, 0.24941666, 0.24896666]
	train_accs: [0.24953334, 0.24931666, 0.23848334, 0.24941666, 0.24896666]
	best_train_sub_head: 0
	worst: 0.23848334
	avg: 0.24714331
	best: 0.24953334

Starting e_i: 697
Model ind 579 epoch 697 head B head_i_epoch 0 batch 0: avg loss -1.833863 avg loss no lamb -1.833863 time 2019-02-05 00:05:11.104716
Model ind 579 epoch 697 head B head_i_epoch 0 batch 100: avg loss -1.735070 avg loss no lamb -1.735070 time 2019-02-05 00:08:09.886996
Model ind 579 epoch 697 head B head_i_epoch 0 batch 200: avg loss -1.799471 avg loss no lamb -1.799471 time 2019-02-05 00:11:07.865800
Model ind 579 epoch 697 head A head_i_epoch 0 batch 0: avg loss -3.454821 avg loss no lamb -3.454821 time 2019-02-05 00:14:05.676799
Model ind 579 epoch 697 head A head_i_epoch 0 batch 100: avg loss -3.446793 avg loss no lamb -3.446793 time 2019-02-05 00:17:05.045187
Model ind 579 epoch 697 head A head_i_epoch 0 batch 200: avg loss -3.518639 avg loss no lamb -3.518639 time 2019-02-05 00:20:04.659538
Pre: time 2019-02-05 00:23:30.373306: 
 	std: 0.004143291
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25056666, 0.2505, 0.23998334, 0.25043333, 0.24976666]
	train_accs: [0.25056666, 0.2505, 0.23998334, 0.25043333, 0.24976666]
	best_train_sub_head: 0
	worst: 0.23998334
	avg: 0.24825001
	best: 0.25056666

Starting e_i: 698
Model ind 579 epoch 698 head B head_i_epoch 0 batch 0: avg loss -1.896541 avg loss no lamb -1.896541 time 2019-02-05 00:23:34.037105
Model ind 579 epoch 698 head B head_i_epoch 0 batch 100: avg loss -1.905839 avg loss no lamb -1.905839 time 2019-02-05 00:26:32.184520
Model ind 579 epoch 698 head B head_i_epoch 0 batch 200: avg loss -1.883080 avg loss no lamb -1.883080 time 2019-02-05 00:29:29.660997
Model ind 579 epoch 698 head A head_i_epoch 0 batch 0: avg loss -3.407112 avg loss no lamb -3.407112 time 2019-02-05 00:32:29.655336
Model ind 579 epoch 698 head A head_i_epoch 0 batch 100: avg loss -3.529884 avg loss no lamb -3.529884 time 2019-02-05 00:35:29.689068
Model ind 579 epoch 698 head A head_i_epoch 0 batch 200: avg loss -3.472250 avg loss no lamb -3.472250 time 2019-02-05 00:38:28.787057
Pre: time 2019-02-05 00:41:53.973583: 
 	std: 0.0049115475
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24896666, 0.24865, 0.23636666, 0.24881667, 0.24805]
	train_accs: [0.24896666, 0.24865, 0.23636666, 0.24881667, 0.24805]
	best_train_sub_head: 0
	worst: 0.23636666
	avg: 0.24617
	best: 0.24896666

Starting e_i: 699
Model ind 579 epoch 699 head B head_i_epoch 0 batch 0: avg loss -1.904402 avg loss no lamb -1.904402 time 2019-02-05 00:41:57.630011
Model ind 579 epoch 699 head B head_i_epoch 0 batch 100: avg loss -1.826709 avg loss no lamb -1.826709 time 2019-02-05 00:44:54.893269
Model ind 579 epoch 699 head B head_i_epoch 0 batch 200: avg loss -1.842755 avg loss no lamb -1.842755 time 2019-02-05 00:47:52.743955
Model ind 579 epoch 699 head A head_i_epoch 0 batch 0: avg loss -3.496943 avg loss no lamb -3.496943 time 2019-02-05 00:50:49.652435
Model ind 579 epoch 699 head A head_i_epoch 0 batch 100: avg loss -3.454108 avg loss no lamb -3.454108 time 2019-02-05 00:53:49.323337
Model ind 579 epoch 699 head A head_i_epoch 0 batch 200: avg loss -3.474083 avg loss no lamb -3.474083 time 2019-02-05 00:56:48.092040
Pre: time 2019-02-05 01:00:12.541087: 
 	std: 0.0049417573
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2508, 0.25043333, 0.23811667, 0.25036666, 0.25025]
	train_accs: [0.2508, 0.25043333, 0.23811667, 0.25036666, 0.25025]
	best_train_sub_head: 0
	worst: 0.23811667
	avg: 0.24799332
	best: 0.2508

Starting e_i: 700
Model ind 579 epoch 700 head B head_i_epoch 0 batch 0: avg loss -1.847021 avg loss no lamb -1.847021 time 2019-02-05 01:00:16.518328
Model ind 579 epoch 700 head B head_i_epoch 0 batch 100: avg loss -1.851436 avg loss no lamb -1.851436 time 2019-02-05 01:03:14.038320
Model ind 579 epoch 700 head B head_i_epoch 0 batch 200: avg loss -1.854725 avg loss no lamb -1.854725 time 2019-02-05 01:06:11.011017
Model ind 579 epoch 700 head A head_i_epoch 0 batch 0: avg loss -3.454695 avg loss no lamb -3.454695 time 2019-02-05 01:09:08.348334
Model ind 579 epoch 700 head A head_i_epoch 0 batch 100: avg loss -3.547325 avg loss no lamb -3.547325 time 2019-02-05 01:12:06.669461
Model ind 579 epoch 700 head A head_i_epoch 0 batch 200: avg loss -3.434245 avg loss no lamb -3.434245 time 2019-02-05 01:15:05.094258
Pre: time 2019-02-05 01:18:30.052928: 
 	std: 0.00502943
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25151667, 0.2517, 0.23876667, 0.25126666, 0.25078332]
	train_accs: [0.25151667, 0.2517, 0.23876667, 0.25126666, 0.25078332]
	best_train_sub_head: 1
	worst: 0.23876667
	avg: 0.24880667
	best: 0.2517

Starting e_i: 701
Model ind 579 epoch 701 head B head_i_epoch 0 batch 0: avg loss -1.793639 avg loss no lamb -1.793639 time 2019-02-05 01:18:37.185649
Model ind 579 epoch 701 head B head_i_epoch 0 batch 100: avg loss -1.720062 avg loss no lamb -1.720062 time 2019-02-05 01:21:35.765960
Model ind 579 epoch 701 head B head_i_epoch 0 batch 200: avg loss -1.890315 avg loss no lamb -1.890315 time 2019-02-05 01:24:33.894844
Model ind 579 epoch 701 head A head_i_epoch 0 batch 0: avg loss -3.480879 avg loss no lamb -3.480879 time 2019-02-05 01:27:31.833835
Model ind 579 epoch 701 head A head_i_epoch 0 batch 100: avg loss -3.588668 avg loss no lamb -3.588668 time 2019-02-05 01:30:30.663718
Model ind 579 epoch 701 head A head_i_epoch 0 batch 200: avg loss -3.451394 avg loss no lamb -3.451394 time 2019-02-05 01:33:28.561119
Pre: time 2019-02-05 01:36:52.760726: 
 	std: 0.0042608604
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25045, 0.24998334, 0.23925, 0.24946667, 0.24956666]
	train_accs: [0.25045, 0.24998334, 0.23925, 0.24946667, 0.24956666]
	best_train_sub_head: 0
	worst: 0.23925
	avg: 0.24774332
	best: 0.25045

Starting e_i: 702
Model ind 579 epoch 702 head B head_i_epoch 0 batch 0: avg loss -1.929418 avg loss no lamb -1.929418 time 2019-02-05 01:36:56.506785
Model ind 579 epoch 702 head B head_i_epoch 0 batch 100: avg loss -1.858972 avg loss no lamb -1.858972 time 2019-02-05 01:39:53.627597
Model ind 579 epoch 702 head B head_i_epoch 0 batch 200: avg loss -1.886334 avg loss no lamb -1.886334 time 2019-02-05 01:42:50.882105
Model ind 579 epoch 702 head A head_i_epoch 0 batch 0: avg loss -3.528427 avg loss no lamb -3.528427 time 2019-02-05 01:45:48.012548
Model ind 579 epoch 702 head A head_i_epoch 0 batch 100: avg loss -3.585795 avg loss no lamb -3.585795 time 2019-02-05 01:48:45.992042
Model ind 579 epoch 702 head A head_i_epoch 0 batch 200: avg loss -3.442007 avg loss no lamb -3.442007 time 2019-02-05 01:51:45.137120
Pre: time 2019-02-05 01:55:07.631648: 
 	std: 0.0045547145
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24686667, 0.24703333, 0.23536667, 0.24665, 0.24641667]
	train_accs: [0.24686667, 0.24703333, 0.23536667, 0.24665, 0.24641667]
	best_train_sub_head: 1
	worst: 0.23536667
	avg: 0.24446666
	best: 0.24703333

Starting e_i: 703
Model ind 579 epoch 703 head B head_i_epoch 0 batch 0: avg loss -1.825154 avg loss no lamb -1.825154 time 2019-02-05 01:55:11.395701
Model ind 579 epoch 703 head B head_i_epoch 0 batch 100: avg loss -1.855062 avg loss no lamb -1.855062 time 2019-02-05 01:58:09.464665
Model ind 579 epoch 703 head B head_i_epoch 0 batch 200: avg loss -1.844467 avg loss no lamb -1.844467 time 2019-02-05 02:01:06.504509
Model ind 579 epoch 703 head A head_i_epoch 0 batch 0: avg loss -3.432171 avg loss no lamb -3.432171 time 2019-02-05 02:04:03.479106
Model ind 579 epoch 703 head A head_i_epoch 0 batch 100: avg loss -3.524746 avg loss no lamb -3.524746 time 2019-02-05 02:07:01.848105
Model ind 579 epoch 703 head A head_i_epoch 0 batch 200: avg loss -3.478181 avg loss no lamb -3.478181 time 2019-02-05 02:10:00.118145
Pre: time 2019-02-05 02:13:23.975339: 
 	std: 0.00414479
	best_train_sub_head_match: [(0, 5), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 19), (11, 7), (12, 18), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24998334, 0.24978334, 0.23926666, 0.24951667, 0.24913333]
	train_accs: [0.24998334, 0.24978334, 0.23926666, 0.24951667, 0.24913333]
	best_train_sub_head: 0
	worst: 0.23926666
	avg: 0.24753666
	best: 0.24998334

Starting e_i: 704
Model ind 579 epoch 704 head B head_i_epoch 0 batch 0: avg loss -1.800947 avg loss no lamb -1.800947 time 2019-02-05 02:13:27.689108
Model ind 579 epoch 704 head B head_i_epoch 0 batch 100: avg loss -1.791066 avg loss no lamb -1.791066 time 2019-02-05 02:16:25.632795
Model ind 579 epoch 704 head B head_i_epoch 0 batch 200: avg loss -1.851711 avg loss no lamb -1.851711 time 2019-02-05 02:19:22.957683
Model ind 579 epoch 704 head A head_i_epoch 0 batch 0: avg loss -3.503330 avg loss no lamb -3.503330 time 2019-02-05 02:22:20.655577
Model ind 579 epoch 704 head A head_i_epoch 0 batch 100: avg loss -3.490342 avg loss no lamb -3.490342 time 2019-02-05 02:25:19.683017
Model ind 579 epoch 704 head A head_i_epoch 0 batch 200: avg loss -3.556213 avg loss no lamb -3.556213 time 2019-02-05 02:28:18.972060
Pre: time 2019-02-05 02:31:43.150087: 
 	std: 0.0045941244
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25123334, 0.25121668, 0.23956667, 0.2511, 0.2506]
	train_accs: [0.25123334, 0.25121668, 0.23956667, 0.2511, 0.2506]
	best_train_sub_head: 0
	worst: 0.23956667
	avg: 0.24874334
	best: 0.25123334

Starting e_i: 705
Model ind 579 epoch 705 head B head_i_epoch 0 batch 0: avg loss -1.858684 avg loss no lamb -1.858684 time 2019-02-05 02:31:46.923880
Model ind 579 epoch 705 head B head_i_epoch 0 batch 100: avg loss -1.767121 avg loss no lamb -1.767121 time 2019-02-05 02:34:45.002663
Model ind 579 epoch 705 head B head_i_epoch 0 batch 200: avg loss -1.805053 avg loss no lamb -1.805053 time 2019-02-05 02:37:45.056050
Model ind 579 epoch 705 head A head_i_epoch 0 batch 0: avg loss -3.467450 avg loss no lamb -3.467450 time 2019-02-05 02:40:43.936685
Model ind 579 epoch 705 head A head_i_epoch 0 batch 100: avg loss -3.501214 avg loss no lamb -3.501214 time 2019-02-05 02:43:41.843615
Model ind 579 epoch 705 head A head_i_epoch 0 batch 200: avg loss -3.506696 avg loss no lamb -3.506696 time 2019-02-05 02:46:41.548548
Pre: time 2019-02-05 02:50:06.542209: 
 	std: 0.00404065
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24791667, 0.24731667, 0.23743333, 0.2475, 0.24735]
	train_accs: [0.24791667, 0.24731667, 0.23743333, 0.2475, 0.24735]
	best_train_sub_head: 0
	worst: 0.23743333
	avg: 0.24550334
	best: 0.24791667

Starting e_i: 706
Model ind 579 epoch 706 head B head_i_epoch 0 batch 0: avg loss -1.799974 avg loss no lamb -1.799974 time 2019-02-05 02:50:10.841771
Model ind 579 epoch 706 head B head_i_epoch 0 batch 100: avg loss -1.837731 avg loss no lamb -1.837731 time 2019-02-05 02:53:08.288960
Model ind 579 epoch 706 head B head_i_epoch 0 batch 200: avg loss -1.831060 avg loss no lamb -1.831060 time 2019-02-05 02:56:07.117758
Model ind 579 epoch 706 head A head_i_epoch 0 batch 0: avg loss -3.515152 avg loss no lamb -3.515152 time 2019-02-05 02:59:06.031425
Model ind 579 epoch 706 head A head_i_epoch 0 batch 100: avg loss -3.467830 avg loss no lamb -3.467830 time 2019-02-05 03:02:04.565842
Model ind 579 epoch 706 head A head_i_epoch 0 batch 200: avg loss -3.505087 avg loss no lamb -3.505087 time 2019-02-05 03:05:04.358688
Pre: time 2019-02-05 03:08:29.634715: 
 	std: 0.004241828
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24848333, 0.24815, 0.23735, 0.24746667, 0.24755]
	train_accs: [0.24848333, 0.24815, 0.23735, 0.24746667, 0.24755]
	best_train_sub_head: 0
	worst: 0.23735
	avg: 0.24579999
	best: 0.24848333

Starting e_i: 707
Model ind 579 epoch 707 head B head_i_epoch 0 batch 0: avg loss -1.855987 avg loss no lamb -1.855987 time 2019-02-05 03:08:33.369435
Model ind 579 epoch 707 head B head_i_epoch 0 batch 100: avg loss -1.789199 avg loss no lamb -1.789199 time 2019-02-05 03:11:31.415567
Model ind 579 epoch 707 head B head_i_epoch 0 batch 200: avg loss -1.748842 avg loss no lamb -1.748842 time 2019-02-05 03:14:28.894608
Model ind 579 epoch 707 head A head_i_epoch 0 batch 0: avg loss -3.438461 avg loss no lamb -3.438461 time 2019-02-05 03:17:27.622674
Model ind 579 epoch 707 head A head_i_epoch 0 batch 100: avg loss -3.467441 avg loss no lamb -3.467441 time 2019-02-05 03:20:26.830966
Model ind 579 epoch 707 head A head_i_epoch 0 batch 200: avg loss -3.564984 avg loss no lamb -3.564984 time 2019-02-05 03:23:26.404360
Pre: time 2019-02-05 03:26:51.397779: 
 	std: 0.004360711
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24828333, 0.24785, 0.23703334, 0.24781667, 0.24775]
	train_accs: [0.24828333, 0.24785, 0.23703334, 0.24781667, 0.24775]
	best_train_sub_head: 0
	worst: 0.23703334
	avg: 0.24574669
	best: 0.24828333

Starting e_i: 708
Model ind 579 epoch 708 head B head_i_epoch 0 batch 0: avg loss -1.811345 avg loss no lamb -1.811345 time 2019-02-05 03:26:55.654459
Model ind 579 epoch 708 head B head_i_epoch 0 batch 100: avg loss -1.779634 avg loss no lamb -1.779634 time 2019-02-05 03:29:53.431161
Model ind 579 epoch 708 head B head_i_epoch 0 batch 200: avg loss -1.848177 avg loss no lamb -1.848177 time 2019-02-05 03:32:51.682048
Model ind 579 epoch 708 head A head_i_epoch 0 batch 0: avg loss -3.467947 avg loss no lamb -3.467947 time 2019-02-05 03:35:49.092021
Model ind 579 epoch 708 head A head_i_epoch 0 batch 100: avg loss -3.567903 avg loss no lamb -3.567903 time 2019-02-05 03:38:46.823094
Model ind 579 epoch 708 head A head_i_epoch 0 batch 200: avg loss -3.525314 avg loss no lamb -3.525314 time 2019-02-05 03:41:46.331682
Pre: time 2019-02-05 03:45:10.838475: 
 	std: 0.0042652655
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 15), (3, 13), (4, 4), (5, 19), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 5), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 18)]
	test_accs: [0.249, 0.24915, 0.23828334, 0.24881667, 0.2488]
	train_accs: [0.249, 0.24915, 0.23828334, 0.24881667, 0.2488]
	best_train_sub_head: 1
	worst: 0.23828334
	avg: 0.24681
	best: 0.24915

Starting e_i: 709
Model ind 579 epoch 709 head B head_i_epoch 0 batch 0: avg loss -1.835853 avg loss no lamb -1.835853 time 2019-02-05 03:45:14.561768
Model ind 579 epoch 709 head B head_i_epoch 0 batch 100: avg loss -1.903607 avg loss no lamb -1.903607 time 2019-02-05 03:48:13.601192
Model ind 579 epoch 709 head B head_i_epoch 0 batch 200: avg loss -1.840349 avg loss no lamb -1.840349 time 2019-02-05 03:51:13.489445
Model ind 579 epoch 709 head A head_i_epoch 0 batch 0: avg loss -3.476759 avg loss no lamb -3.476759 time 2019-02-05 03:54:14.756451
Model ind 579 epoch 709 head A head_i_epoch 0 batch 100: avg loss -3.541016 avg loss no lamb -3.541016 time 2019-02-05 03:57:14.000149
Model ind 579 epoch 709 head A head_i_epoch 0 batch 200: avg loss -3.450778 avg loss no lamb -3.450778 time 2019-02-05 04:00:14.449599
Pre: time 2019-02-05 04:03:40.359696: 
 	std: 0.004496576
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25065, 0.25041667, 0.23906666, 0.25026667, 0.24981667]
	train_accs: [0.25065, 0.25041667, 0.23906666, 0.25026667, 0.24981667]
	best_train_sub_head: 0
	worst: 0.23906666
	avg: 0.24804334
	best: 0.25065

Starting e_i: 710
Model ind 579 epoch 710 head B head_i_epoch 0 batch 0: avg loss -1.927737 avg loss no lamb -1.927737 time 2019-02-05 04:03:44.265359
Model ind 579 epoch 710 head B head_i_epoch 0 batch 100: avg loss -1.871145 avg loss no lamb -1.871145 time 2019-02-05 04:06:44.431887
Model ind 579 epoch 710 head B head_i_epoch 0 batch 200: avg loss -1.882429 avg loss no lamb -1.882429 time 2019-02-05 04:09:45.596126
Model ind 579 epoch 710 head A head_i_epoch 0 batch 0: avg loss -3.476562 avg loss no lamb -3.476562 time 2019-02-05 04:12:47.725728
Model ind 579 epoch 710 head A head_i_epoch 0 batch 100: avg loss -3.538139 avg loss no lamb -3.538139 time 2019-02-05 04:15:52.276397
Model ind 579 epoch 710 head A head_i_epoch 0 batch 200: avg loss -3.417220 avg loss no lamb -3.417220 time 2019-02-05 04:18:55.579843
Pre: time 2019-02-05 04:22:24.362125: 
 	std: 0.004354978
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25086668, 0.25065, 0.23978333, 0.25088334, 0.25021666]
	train_accs: [0.25086668, 0.25065, 0.23978333, 0.25088334, 0.25021666]
	best_train_sub_head: 3
	worst: 0.23978333
	avg: 0.24848
	best: 0.25088334

Starting e_i: 711
Model ind 579 epoch 711 head B head_i_epoch 0 batch 0: avg loss -1.870419 avg loss no lamb -1.870419 time 2019-02-05 04:22:32.124437
Model ind 579 epoch 711 head B head_i_epoch 0 batch 100: avg loss -1.818185 avg loss no lamb -1.818185 time 2019-02-05 04:25:33.268890
Model ind 579 epoch 711 head B head_i_epoch 0 batch 200: avg loss -1.866441 avg loss no lamb -1.866441 time 2019-02-05 04:28:33.073741
Model ind 579 epoch 711 head A head_i_epoch 0 batch 0: avg loss -3.435668 avg loss no lamb -3.435668 time 2019-02-05 04:31:34.194091
Model ind 579 epoch 711 head A head_i_epoch 0 batch 100: avg loss -3.515961 avg loss no lamb -3.515961 time 2019-02-05 04:34:35.801616
Model ind 579 epoch 711 head A head_i_epoch 0 batch 200: avg loss -3.478633 avg loss no lamb -3.478633 time 2019-02-05 04:37:35.866670
Pre: time 2019-02-05 04:41:01.159530: 
 	std: 0.004463212
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24903333, 0.24893333, 0.23755, 0.24831666, 0.24846667]
	train_accs: [0.24903333, 0.24893333, 0.23755, 0.24831666, 0.24846667]
	best_train_sub_head: 0
	worst: 0.23755
	avg: 0.24646
	best: 0.24903333

Starting e_i: 712
Model ind 579 epoch 712 head B head_i_epoch 0 batch 0: avg loss -1.797184 avg loss no lamb -1.797184 time 2019-02-05 04:41:05.012489
Model ind 579 epoch 712 head B head_i_epoch 0 batch 100: avg loss -1.880201 avg loss no lamb -1.880201 time 2019-02-05 04:44:04.544730
Model ind 579 epoch 712 head B head_i_epoch 0 batch 200: avg loss -1.834936 avg loss no lamb -1.834936 time 2019-02-05 04:47:03.057331
Model ind 579 epoch 712 head A head_i_epoch 0 batch 0: avg loss -3.415453 avg loss no lamb -3.415453 time 2019-02-05 04:50:02.696058
Model ind 579 epoch 712 head A head_i_epoch 0 batch 100: avg loss -3.507837 avg loss no lamb -3.507837 time 2019-02-05 04:53:02.971823
Model ind 579 epoch 712 head A head_i_epoch 0 batch 200: avg loss -3.461979 avg loss no lamb -3.461979 time 2019-02-05 04:56:02.620202
Pre: time 2019-02-05 04:59:26.997102: 
 	std: 0.0046628146
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25021666, 0.25023332, 0.2383, 0.24986666, 0.24941666]
	train_accs: [0.25021666, 0.25023332, 0.2383, 0.24986666, 0.24941666]
	best_train_sub_head: 1
	worst: 0.2383
	avg: 0.24760666
	best: 0.25023332

Starting e_i: 713
Model ind 579 epoch 713 head B head_i_epoch 0 batch 0: avg loss -1.845627 avg loss no lamb -1.845627 time 2019-02-05 04:59:32.202514
Model ind 579 epoch 713 head B head_i_epoch 0 batch 100: avg loss -1.732604 avg loss no lamb -1.732604 time 2019-02-05 05:02:31.523585
Model ind 579 epoch 713 head B head_i_epoch 0 batch 200: avg loss -1.833620 avg loss no lamb -1.833620 time 2019-02-05 05:05:30.036663
Model ind 579 epoch 713 head A head_i_epoch 0 batch 0: avg loss -3.485653 avg loss no lamb -3.485653 time 2019-02-05 05:08:27.731612
Model ind 579 epoch 713 head A head_i_epoch 0 batch 100: avg loss -3.453251 avg loss no lamb -3.453251 time 2019-02-05 05:11:27.410776
Model ind 579 epoch 713 head A head_i_epoch 0 batch 200: avg loss -3.514177 avg loss no lamb -3.514177 time 2019-02-05 05:14:26.521240
Pre: time 2019-02-05 05:17:50.132831: 
 	std: 0.0043718494
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24968334, 0.24998334, 0.23868333, 0.24966666, 0.249]
	train_accs: [0.24968334, 0.24998334, 0.23868333, 0.24966666, 0.249]
	best_train_sub_head: 1
	worst: 0.23868333
	avg: 0.24740334
	best: 0.24998334

Starting e_i: 714
Model ind 579 epoch 714 head B head_i_epoch 0 batch 0: avg loss -1.743823 avg loss no lamb -1.743823 time 2019-02-05 05:17:54.001973
Model ind 579 epoch 714 head B head_i_epoch 0 batch 100: avg loss -1.853928 avg loss no lamb -1.853928 time 2019-02-05 05:20:53.913373
Model ind 579 epoch 714 head B head_i_epoch 0 batch 200: avg loss -1.784386 avg loss no lamb -1.784386 time 2019-02-05 05:23:52.457978
Model ind 579 epoch 714 head A head_i_epoch 0 batch 0: avg loss -3.445302 avg loss no lamb -3.445302 time 2019-02-05 05:26:51.008036
Model ind 579 epoch 714 head A head_i_epoch 0 batch 100: avg loss -3.507532 avg loss no lamb -3.507532 time 2019-02-05 05:29:51.291301
Model ind 579 epoch 714 head A head_i_epoch 0 batch 200: avg loss -3.472256 avg loss no lamb -3.472256 time 2019-02-05 05:32:51.182591
Pre: time 2019-02-05 05:36:15.438204: 
 	std: 0.0036533303
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2484, 0.24836667, 0.23905, 0.24798334, 0.24793333]
	train_accs: [0.2484, 0.24836667, 0.23905, 0.24798334, 0.24793333]
	best_train_sub_head: 0
	worst: 0.23905
	avg: 0.24634667
	best: 0.2484

Starting e_i: 715
Model ind 579 epoch 715 head B head_i_epoch 0 batch 0: avg loss -1.878147 avg loss no lamb -1.878147 time 2019-02-05 05:36:19.259715
Model ind 579 epoch 715 head B head_i_epoch 0 batch 100: avg loss -1.815343 avg loss no lamb -1.815343 time 2019-02-05 05:39:18.898581
Model ind 579 epoch 715 head B head_i_epoch 0 batch 200: avg loss -1.778417 avg loss no lamb -1.778417 time 2019-02-05 05:42:18.087892
Model ind 579 epoch 715 head A head_i_epoch 0 batch 0: avg loss -3.457639 avg loss no lamb -3.457639 time 2019-02-05 05:45:17.598052
Model ind 579 epoch 715 head A head_i_epoch 0 batch 100: avg loss -3.504535 avg loss no lamb -3.504535 time 2019-02-05 05:48:17.448506
Model ind 579 epoch 715 head A head_i_epoch 0 batch 200: avg loss -3.507612 avg loss no lamb -3.507612 time 2019-02-05 05:51:17.441562
Pre: time 2019-02-05 05:54:43.605429: 
 	std: 0.0040825526
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2496, 0.24991667, 0.2393, 0.24881667, 0.24953334]
	train_accs: [0.2496, 0.24991667, 0.2393, 0.24881667, 0.24953334]
	best_train_sub_head: 1
	worst: 0.2393
	avg: 0.24743333
	best: 0.24991667

Starting e_i: 716
Model ind 579 epoch 716 head B head_i_epoch 0 batch 0: avg loss -1.846423 avg loss no lamb -1.846423 time 2019-02-05 05:54:47.482188
Model ind 579 epoch 716 head B head_i_epoch 0 batch 100: avg loss -1.779713 avg loss no lamb -1.779713 time 2019-02-05 05:57:45.866773
Model ind 579 epoch 716 head B head_i_epoch 0 batch 200: avg loss -1.785544 avg loss no lamb -1.785544 time 2019-02-05 06:00:43.647651
Model ind 579 epoch 716 head A head_i_epoch 0 batch 0: avg loss -3.416298 avg loss no lamb -3.416298 time 2019-02-05 06:03:42.807525
Model ind 579 epoch 716 head A head_i_epoch 0 batch 100: avg loss -3.466059 avg loss no lamb -3.466059 time 2019-02-05 06:06:43.524173
Model ind 579 epoch 716 head A head_i_epoch 0 batch 200: avg loss -3.446179 avg loss no lamb -3.446179 time 2019-02-05 06:09:43.441554
Pre: time 2019-02-05 06:13:08.157933: 
 	std: 0.0038930362
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2505, 0.25038335, 0.24051666, 0.25026667, 0.24976666]
	train_accs: [0.2505, 0.25038335, 0.24051666, 0.25026667, 0.24976666]
	best_train_sub_head: 0
	worst: 0.24051666
	avg: 0.24828668
	best: 0.2505

Starting e_i: 717
Model ind 579 epoch 717 head B head_i_epoch 0 batch 0: avg loss -1.776896 avg loss no lamb -1.776896 time 2019-02-05 06:13:11.980536
Model ind 579 epoch 717 head B head_i_epoch 0 batch 100: avg loss -1.872219 avg loss no lamb -1.872219 time 2019-02-05 06:16:11.114588
Model ind 579 epoch 717 head B head_i_epoch 0 batch 200: avg loss -1.903981 avg loss no lamb -1.903981 time 2019-02-05 06:19:08.723620
Model ind 579 epoch 717 head A head_i_epoch 0 batch 0: avg loss -3.447767 avg loss no lamb -3.447767 time 2019-02-05 06:22:06.598639
Model ind 579 epoch 717 head A head_i_epoch 0 batch 100: avg loss -3.500598 avg loss no lamb -3.500598 time 2019-02-05 06:25:06.035223
Model ind 579 epoch 717 head A head_i_epoch 0 batch 200: avg loss -3.439834 avg loss no lamb -3.439834 time 2019-02-05 06:28:04.955469
Pre: time 2019-02-05 06:31:31.033018: 
 	std: 0.004708274
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2493, 0.24876666, 0.23721667, 0.24893333, 0.24891667]
	train_accs: [0.2493, 0.24876666, 0.23721667, 0.24893333, 0.24891667]
	best_train_sub_head: 0
	worst: 0.23721667
	avg: 0.24662666
	best: 0.2493

Starting e_i: 718
Model ind 579 epoch 718 head B head_i_epoch 0 batch 0: avg loss -1.799791 avg loss no lamb -1.799791 time 2019-02-05 06:31:34.930315
Model ind 579 epoch 718 head B head_i_epoch 0 batch 100: avg loss -1.793536 avg loss no lamb -1.793536 time 2019-02-05 06:34:33.699146
Model ind 579 epoch 718 head B head_i_epoch 0 batch 200: avg loss -1.838731 avg loss no lamb -1.838731 time 2019-02-05 06:37:31.525298
Model ind 579 epoch 718 head A head_i_epoch 0 batch 0: avg loss -3.460519 avg loss no lamb -3.460519 time 2019-02-05 06:40:29.769580
Model ind 579 epoch 718 head A head_i_epoch 0 batch 100: avg loss -3.484679 avg loss no lamb -3.484679 time 2019-02-05 06:43:30.015207
Model ind 579 epoch 718 head A head_i_epoch 0 batch 200: avg loss -3.542852 avg loss no lamb -3.542852 time 2019-02-05 06:46:29.607328
Pre: time 2019-02-05 06:49:54.554994: 
 	std: 0.0047714966
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25091666, 0.2504, 0.23878333, 0.25081667, 0.25068334]
	train_accs: [0.25091666, 0.2504, 0.23878333, 0.25081667, 0.25068334]
	best_train_sub_head: 0
	worst: 0.23878333
	avg: 0.24832001
	best: 0.25091666

Starting e_i: 719
Model ind 579 epoch 719 head B head_i_epoch 0 batch 0: avg loss -1.838019 avg loss no lamb -1.838019 time 2019-02-05 06:49:58.293249
Model ind 579 epoch 719 head B head_i_epoch 0 batch 100: avg loss -1.869923 avg loss no lamb -1.869923 time 2019-02-05 06:52:56.260312
Model ind 579 epoch 719 head B head_i_epoch 0 batch 200: avg loss -1.792629 avg loss no lamb -1.792629 time 2019-02-05 06:55:53.149703
Model ind 579 epoch 719 head A head_i_epoch 0 batch 0: avg loss -3.485706 avg loss no lamb -3.485706 time 2019-02-05 06:58:50.438497
Model ind 579 epoch 719 head A head_i_epoch 0 batch 100: avg loss -3.518069 avg loss no lamb -3.518069 time 2019-02-05 07:01:49.380650
Model ind 579 epoch 719 head A head_i_epoch 0 batch 200: avg loss -3.496125 avg loss no lamb -3.496125 time 2019-02-05 07:04:48.616486
Pre: time 2019-02-05 07:08:13.159112: 
 	std: 0.004450861
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.24713333, 0.24701667, 0.23625, 0.24758333, 0.2477]
	train_accs: [0.24713333, 0.24701667, 0.23625, 0.24758333, 0.2477]
	best_train_sub_head: 4
	worst: 0.23625
	avg: 0.24513666
	best: 0.2477

Starting e_i: 720
Model ind 579 epoch 720 head B head_i_epoch 0 batch 0: avg loss -1.824619 avg loss no lamb -1.824619 time 2019-02-05 07:08:16.904923
Model ind 579 epoch 720 head B head_i_epoch 0 batch 100: avg loss -1.790229 avg loss no lamb -1.790229 time 2019-02-05 07:11:14.649016
Model ind 579 epoch 720 head B head_i_epoch 0 batch 200: avg loss -1.905886 avg loss no lamb -1.905886 time 2019-02-05 07:14:12.828098
Model ind 579 epoch 720 head A head_i_epoch 0 batch 0: avg loss -3.474377 avg loss no lamb -3.474377 time 2019-02-05 07:17:11.620431
Model ind 579 epoch 720 head A head_i_epoch 0 batch 100: avg loss -3.552482 avg loss no lamb -3.552482 time 2019-02-05 07:20:10.409732
Model ind 579 epoch 720 head A head_i_epoch 0 batch 200: avg loss -3.444495 avg loss no lamb -3.444495 time 2019-02-05 07:23:08.923380
Pre: time 2019-02-05 07:26:34.241686: 
 	std: 0.0046251398
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.24975, 0.24976666, 0.23823333, 0.24981667, 0.24985]
	train_accs: [0.24975, 0.24976666, 0.23823333, 0.24981667, 0.24985]
	best_train_sub_head: 4
	worst: 0.23823333
	avg: 0.24748333
	best: 0.24985

Starting e_i: 721
Model ind 579 epoch 721 head B head_i_epoch 0 batch 0: avg loss -1.842587 avg loss no lamb -1.842587 time 2019-02-05 07:26:41.742856
Model ind 579 epoch 721 head B head_i_epoch 0 batch 100: avg loss -1.916406 avg loss no lamb -1.916406 time 2019-02-05 07:29:41.098751
Model ind 579 epoch 721 head B head_i_epoch 0 batch 200: avg loss -1.831859 avg loss no lamb -1.831859 time 2019-02-05 07:32:37.658899
Model ind 579 epoch 721 head A head_i_epoch 0 batch 0: avg loss -3.432180 avg loss no lamb -3.432180 time 2019-02-05 07:35:35.534285
Model ind 579 epoch 721 head A head_i_epoch 0 batch 100: avg loss -3.478673 avg loss no lamb -3.478673 time 2019-02-05 07:38:35.816697
Model ind 579 epoch 721 head A head_i_epoch 0 batch 200: avg loss -3.495683 avg loss no lamb -3.495683 time 2019-02-05 07:41:35.041649
Pre: time 2019-02-05 07:45:00.311822: 
 	std: 0.0048797377
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.24965, 0.24895, 0.23711666, 0.24911667, 0.24948333]
	train_accs: [0.24965, 0.24895, 0.23711666, 0.24911667, 0.24948333]
	best_train_sub_head: 0
	worst: 0.23711666
	avg: 0.24686334
	best: 0.24965

Starting e_i: 722
Model ind 579 epoch 722 head B head_i_epoch 0 batch 0: avg loss -1.841720 avg loss no lamb -1.841720 time 2019-02-05 07:45:04.119005
Model ind 579 epoch 722 head B head_i_epoch 0 batch 100: avg loss -1.759861 avg loss no lamb -1.759861 time 2019-02-05 07:48:02.107788
Model ind 579 epoch 722 head B head_i_epoch 0 batch 200: avg loss -1.857638 avg loss no lamb -1.857638 time 2019-02-05 07:50:59.493308
Model ind 579 epoch 722 head A head_i_epoch 0 batch 0: avg loss -3.442177 avg loss no lamb -3.442177 time 2019-02-05 07:53:57.834284
Model ind 579 epoch 722 head A head_i_epoch 0 batch 100: avg loss -3.488739 avg loss no lamb -3.488739 time 2019-02-05 07:56:58.519641
Model ind 579 epoch 722 head A head_i_epoch 0 batch 200: avg loss -3.447102 avg loss no lamb -3.447102 time 2019-02-05 07:59:58.015422
Pre: time 2019-02-05 08:03:23.783266: 
 	std: 0.0048320587
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2502, 0.249, 0.23753333, 0.24945, 0.24965]
	train_accs: [0.2502, 0.249, 0.23753333, 0.24945, 0.24965]
	best_train_sub_head: 0
	worst: 0.23753333
	avg: 0.24716666
	best: 0.2502

Starting e_i: 723
Model ind 579 epoch 723 head B head_i_epoch 0 batch 0: avg loss -1.865167 avg loss no lamb -1.865167 time 2019-02-05 08:03:27.483741
Model ind 579 epoch 723 head B head_i_epoch 0 batch 100: avg loss -1.849717 avg loss no lamb -1.849717 time 2019-02-05 08:06:25.702687
Model ind 579 epoch 723 head B head_i_epoch 0 batch 200: avg loss -1.907496 avg loss no lamb -1.907496 time 2019-02-05 08:09:24.093765
Model ind 579 epoch 723 head A head_i_epoch 0 batch 0: avg loss -3.475860 avg loss no lamb -3.475860 time 2019-02-05 08:12:22.259354
Model ind 579 epoch 723 head A head_i_epoch 0 batch 100: avg loss -3.482692 avg loss no lamb -3.482692 time 2019-02-05 08:15:22.531374
Model ind 579 epoch 723 head A head_i_epoch 0 batch 200: avg loss -3.541613 avg loss no lamb -3.541613 time 2019-02-05 08:18:22.481334
Pre: time 2019-02-05 08:21:47.262994: 
 	std: 0.0042344304
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25035, 0.24965, 0.23951666, 0.25, 0.25033334]
	train_accs: [0.25035, 0.24965, 0.23951666, 0.25, 0.25033334]
	best_train_sub_head: 0
	worst: 0.23951666
	avg: 0.24797001
	best: 0.25035

Starting e_i: 724
Model ind 579 epoch 724 head B head_i_epoch 0 batch 0: avg loss -1.775052 avg loss no lamb -1.775052 time 2019-02-05 08:21:51.032739
Model ind 579 epoch 724 head B head_i_epoch 0 batch 100: avg loss -1.848657 avg loss no lamb -1.848657 time 2019-02-05 08:24:49.016770
Model ind 579 epoch 724 head B head_i_epoch 0 batch 200: avg loss -1.839133 avg loss no lamb -1.839133 time 2019-02-05 08:27:48.505814
Model ind 579 epoch 724 head A head_i_epoch 0 batch 0: avg loss -3.430245 avg loss no lamb -3.430245 time 2019-02-05 08:30:47.702865
Model ind 579 epoch 724 head A head_i_epoch 0 batch 100: avg loss -3.430619 avg loss no lamb -3.430619 time 2019-02-05 08:33:46.517681
Model ind 579 epoch 724 head A head_i_epoch 0 batch 200: avg loss -3.519600 avg loss no lamb -3.519600 time 2019-02-05 08:36:46.809243
Pre: time 2019-02-05 08:40:10.108232: 
 	std: 0.003721504
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2519, 0.25121668, 0.2423, 0.25156668, 0.25166667]
	train_accs: [0.2519, 0.25121668, 0.2423, 0.25156668, 0.25166667]
	best_train_sub_head: 0
	worst: 0.2423
	avg: 0.24972999
	best: 0.2519

Starting e_i: 725
Model ind 579 epoch 725 head B head_i_epoch 0 batch 0: avg loss -1.881331 avg loss no lamb -1.881331 time 2019-02-05 08:40:14.668135
Model ind 579 epoch 725 head B head_i_epoch 0 batch 100: avg loss -1.726446 avg loss no lamb -1.726446 time 2019-02-05 08:43:12.709322
Model ind 579 epoch 725 head B head_i_epoch 0 batch 200: avg loss -1.857743 avg loss no lamb -1.857743 time 2019-02-05 08:46:09.742653
Model ind 579 epoch 725 head A head_i_epoch 0 batch 0: avg loss -3.410801 avg loss no lamb -3.410801 time 2019-02-05 08:49:07.139478
Model ind 579 epoch 725 head A head_i_epoch 0 batch 100: avg loss -3.498560 avg loss no lamb -3.498560 time 2019-02-05 08:52:06.633653
Model ind 579 epoch 725 head A head_i_epoch 0 batch 200: avg loss -3.550861 avg loss no lamb -3.550861 time 2019-02-05 08:55:03.549471
Pre: time 2019-02-05 08:58:32.251167: 
 	std: 0.0044740774
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 5), (4, 4), (5, 3), (6, 18), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 13), (19, 19)]
	test_accs: [0.24585, 0.24541667, 0.23475, 0.2462, 0.24618334]
	train_accs: [0.24585, 0.24541667, 0.23475, 0.2462, 0.24618334]
	best_train_sub_head: 3
	worst: 0.23475
	avg: 0.24368
	best: 0.2462

Starting e_i: 726
Model ind 579 epoch 726 head B head_i_epoch 0 batch 0: avg loss -1.893324 avg loss no lamb -1.893324 time 2019-02-05 08:58:36.827029
Model ind 579 epoch 726 head B head_i_epoch 0 batch 100: avg loss -1.717745 avg loss no lamb -1.717745 time 2019-02-05 09:01:35.399645
Model ind 579 epoch 726 head B head_i_epoch 0 batch 200: avg loss -1.961787 avg loss no lamb -1.961787 time 2019-02-05 09:04:33.921241
Model ind 579 epoch 726 head A head_i_epoch 0 batch 0: avg loss -3.488655 avg loss no lamb -3.488655 time 2019-02-05 09:07:31.836518
Model ind 579 epoch 726 head A head_i_epoch 0 batch 100: avg loss -3.465274 avg loss no lamb -3.465274 time 2019-02-05 09:10:33.238538
Model ind 579 epoch 726 head A head_i_epoch 0 batch 200: avg loss -3.440337 avg loss no lamb -3.440337 time 2019-02-05 09:13:34.126684
Pre: time 2019-02-05 09:17:00.015860: 
 	std: 0.0043039722
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25038335, 0.25038335, 0.23963334, 0.25051665, 0.25028333]
	train_accs: [0.25038335, 0.25038335, 0.23963334, 0.25051665, 0.25028333]
	best_train_sub_head: 3
	worst: 0.23963334
	avg: 0.24824
	best: 0.25051665

Starting e_i: 727
Model ind 579 epoch 727 head B head_i_epoch 0 batch 0: avg loss -1.877420 avg loss no lamb -1.877420 time 2019-02-05 09:17:05.035868
Model ind 579 epoch 727 head B head_i_epoch 0 batch 100: avg loss -1.810613 avg loss no lamb -1.810613 time 2019-02-05 09:20:07.654914
Model ind 579 epoch 727 head B head_i_epoch 0 batch 200: avg loss -1.874589 avg loss no lamb -1.874589 time 2019-02-05 09:23:04.932771
Model ind 579 epoch 727 head A head_i_epoch 0 batch 0: avg loss -3.443614 avg loss no lamb -3.443614 time 2019-02-05 09:26:03.352504
Model ind 579 epoch 727 head A head_i_epoch 0 batch 100: avg loss -3.464206 avg loss no lamb -3.464206 time 2019-02-05 09:29:02.753953
Model ind 579 epoch 727 head A head_i_epoch 0 batch 200: avg loss -3.533745 avg loss no lamb -3.533745 time 2019-02-05 09:32:01.873224
Pre: time 2019-02-05 09:35:25.812169: 
 	std: 0.003812966
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.24851666, 0.24833333, 0.23893334, 0.24838333, 0.24861667]
	train_accs: [0.24851666, 0.24833333, 0.23893334, 0.24838333, 0.24861667]
	best_train_sub_head: 4
	worst: 0.23893334
	avg: 0.24655667
	best: 0.24861667

Starting e_i: 728
Model ind 579 epoch 728 head B head_i_epoch 0 batch 0: avg loss -1.860048 avg loss no lamb -1.860048 time 2019-02-05 09:35:29.561988
Model ind 579 epoch 728 head B head_i_epoch 0 batch 100: avg loss -1.882969 avg loss no lamb -1.882969 time 2019-02-05 09:38:27.031691
Model ind 579 epoch 728 head B head_i_epoch 0 batch 200: avg loss -1.828842 avg loss no lamb -1.828842 time 2019-02-05 09:41:25.283663
Model ind 579 epoch 728 head A head_i_epoch 0 batch 0: avg loss -3.542661 avg loss no lamb -3.542661 time 2019-02-05 09:44:23.659442
Model ind 579 epoch 728 head A head_i_epoch 0 batch 100: avg loss -3.552598 avg loss no lamb -3.552598 time 2019-02-05 09:47:22.997302
Model ind 579 epoch 728 head A head_i_epoch 0 batch 200: avg loss -3.440378 avg loss no lamb -3.440378 time 2019-02-05 09:50:22.582144
Pre: time 2019-02-05 09:53:45.724142: 
 	std: 0.0047206883
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25215, 0.25161666, 0.2402, 0.25208333, 0.25211668]
	train_accs: [0.25215, 0.25161666, 0.2402, 0.25208333, 0.25211668]
	best_train_sub_head: 0
	worst: 0.2402
	avg: 0.24963334
	best: 0.25215

Starting e_i: 729
Model ind 579 epoch 729 head B head_i_epoch 0 batch 0: avg loss -1.844490 avg loss no lamb -1.844490 time 2019-02-05 09:53:49.528692
Model ind 579 epoch 729 head B head_i_epoch 0 batch 100: avg loss -1.812558 avg loss no lamb -1.812558 time 2019-02-05 09:56:47.353581
Model ind 579 epoch 729 head B head_i_epoch 0 batch 200: avg loss -1.927360 avg loss no lamb -1.927360 time 2019-02-05 09:59:44.794205
Model ind 579 epoch 729 head A head_i_epoch 0 batch 0: avg loss -3.507905 avg loss no lamb -3.507905 time 2019-02-05 10:02:42.694441
Model ind 579 epoch 729 head A head_i_epoch 0 batch 100: avg loss -3.511225 avg loss no lamb -3.511225 time 2019-02-05 10:05:41.765018
Model ind 579 epoch 729 head A head_i_epoch 0 batch 200: avg loss -3.548255 avg loss no lamb -3.548255 time 2019-02-05 10:08:40.914823
Pre: time 2019-02-05 10:12:06.394383: 
 	std: 0.0049694846
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25215, 0.25138333, 0.23966667, 0.25231665, 0.25238332]
	train_accs: [0.25215, 0.25138333, 0.23966667, 0.25231665, 0.25238332]
	best_train_sub_head: 4
	worst: 0.23966667
	avg: 0.24958
	best: 0.25238332

Starting e_i: 730
Model ind 579 epoch 730 head B head_i_epoch 0 batch 0: avg loss -1.893147 avg loss no lamb -1.893147 time 2019-02-05 10:12:10.168594
Model ind 579 epoch 730 head B head_i_epoch 0 batch 100: avg loss -1.784658 avg loss no lamb -1.784658 time 2019-02-05 10:15:09.041284
Model ind 579 epoch 730 head B head_i_epoch 0 batch 200: avg loss -1.828328 avg loss no lamb -1.828328 time 2019-02-05 10:18:07.903357
Model ind 579 epoch 730 head A head_i_epoch 0 batch 0: avg loss -3.486085 avg loss no lamb -3.486085 time 2019-02-05 10:21:05.831902
Model ind 579 epoch 730 head A head_i_epoch 0 batch 100: avg loss -3.438507 avg loss no lamb -3.438507 time 2019-02-05 10:24:05.657949
Model ind 579 epoch 730 head A head_i_epoch 0 batch 200: avg loss -3.469305 avg loss no lamb -3.469305 time 2019-02-05 10:27:05.582868
Pre: time 2019-02-05 10:30:30.587787: 
 	std: 0.0038926427
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25031668, 0.24978334, 0.24035, 0.24998334, 0.2502]
	train_accs: [0.25031668, 0.24978334, 0.24035, 0.24998334, 0.2502]
	best_train_sub_head: 0
	worst: 0.24035
	avg: 0.24812667
	best: 0.25031668

Starting e_i: 731
Model ind 579 epoch 731 head B head_i_epoch 0 batch 0: avg loss -1.852917 avg loss no lamb -1.852917 time 2019-02-05 10:30:41.048696
Model ind 579 epoch 731 head B head_i_epoch 0 batch 100: avg loss -1.822601 avg loss no lamb -1.822601 time 2019-02-05 10:33:39.977567
Model ind 579 epoch 731 head B head_i_epoch 0 batch 200: avg loss -1.867258 avg loss no lamb -1.867258 time 2019-02-05 10:36:37.682621
Model ind 579 epoch 731 head A head_i_epoch 0 batch 0: avg loss -3.438270 avg loss no lamb -3.438270 time 2019-02-05 10:39:35.969467
Model ind 579 epoch 731 head A head_i_epoch 0 batch 100: avg loss -3.561696 avg loss no lamb -3.561696 time 2019-02-05 10:42:35.750232
Model ind 579 epoch 731 head A head_i_epoch 0 batch 200: avg loss -3.471827 avg loss no lamb -3.471827 time 2019-02-05 10:45:35.882289
Pre: time 2019-02-05 10:49:00.256006: 
 	std: 0.004524519
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25145, 0.251, 0.24013333, 0.25205, 0.25113332]
	train_accs: [0.25145, 0.251, 0.24013333, 0.25205, 0.25113332]
	best_train_sub_head: 3
	worst: 0.24013333
	avg: 0.24915333
	best: 0.25205

Starting e_i: 732
Model ind 579 epoch 732 head B head_i_epoch 0 batch 0: avg loss -1.940482 avg loss no lamb -1.940482 time 2019-02-05 10:49:04.929118
Model ind 579 epoch 732 head B head_i_epoch 0 batch 100: avg loss -1.846996 avg loss no lamb -1.846996 time 2019-02-05 10:52:03.094918
Model ind 579 epoch 732 head B head_i_epoch 0 batch 200: avg loss -1.904137 avg loss no lamb -1.904137 time 2019-02-05 10:55:01.453920
Model ind 579 epoch 732 head A head_i_epoch 0 batch 0: avg loss -3.514531 avg loss no lamb -3.514531 time 2019-02-05 10:57:59.356411
Model ind 579 epoch 732 head A head_i_epoch 0 batch 100: avg loss -3.483600 avg loss no lamb -3.483600 time 2019-02-05 11:00:58.352298
Model ind 579 epoch 732 head A head_i_epoch 0 batch 200: avg loss -3.554786 avg loss no lamb -3.554786 time 2019-02-05 11:03:57.281020
Pre: time 2019-02-05 11:07:21.415017: 
 	std: 0.0041700345
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 5), (4, 4), (5, 3), (6, 18), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 13), (19, 19)]
	test_accs: [0.2532, 0.25356665, 0.2431, 0.25368333, 0.25361666]
	train_accs: [0.2532, 0.25356665, 0.2431, 0.25368333, 0.25361666]
	best_train_sub_head: 3
	worst: 0.2431
	avg: 0.25143334
	best: 0.25368333

Starting e_i: 733
Model ind 579 epoch 733 head B head_i_epoch 0 batch 0: avg loss -1.801236 avg loss no lamb -1.801236 time 2019-02-05 11:07:25.249586
Model ind 579 epoch 733 head B head_i_epoch 0 batch 100: avg loss -1.848416 avg loss no lamb -1.848416 time 2019-02-05 11:10:22.918079
Model ind 579 epoch 733 head B head_i_epoch 0 batch 200: avg loss -1.832368 avg loss no lamb -1.832368 time 2019-02-05 11:13:20.737357
Model ind 579 epoch 733 head A head_i_epoch 0 batch 0: avg loss -3.519529 avg loss no lamb -3.519529 time 2019-02-05 11:16:18.310399
Model ind 579 epoch 733 head A head_i_epoch 0 batch 100: avg loss -3.551008 avg loss no lamb -3.551008 time 2019-02-05 11:19:16.578915
Model ind 579 epoch 733 head A head_i_epoch 0 batch 200: avg loss -3.502086 avg loss no lamb -3.502086 time 2019-02-05 11:22:16.780330
Pre: time 2019-02-05 11:25:42.267902: 
 	std: 0.00415502
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 15), (3, 13), (4, 4), (5, 5), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25043333, 0.25115, 0.24035, 0.25066668, 0.25063333]
	train_accs: [0.25043333, 0.25115, 0.24035, 0.25066668, 0.25063333]
	best_train_sub_head: 1
	worst: 0.24035
	avg: 0.24864666
	best: 0.25115

Starting e_i: 734
Model ind 579 epoch 734 head B head_i_epoch 0 batch 0: avg loss -1.833902 avg loss no lamb -1.833902 time 2019-02-05 11:25:46.639661
Model ind 579 epoch 734 head B head_i_epoch 0 batch 100: avg loss -1.840846 avg loss no lamb -1.840846 time 2019-02-05 11:28:44.717651
Model ind 579 epoch 734 head B head_i_epoch 0 batch 200: avg loss -1.822355 avg loss no lamb -1.822355 time 2019-02-05 11:31:42.822177
Model ind 579 epoch 734 head A head_i_epoch 0 batch 0: avg loss -3.492961 avg loss no lamb -3.492961 time 2019-02-05 11:34:41.484538
Model ind 579 epoch 734 head A head_i_epoch 0 batch 100: avg loss -3.492405 avg loss no lamb -3.492405 time 2019-02-05 11:37:41.066707
Model ind 579 epoch 734 head A head_i_epoch 0 batch 200: avg loss -3.510445 avg loss no lamb -3.510445 time 2019-02-05 11:40:40.970666
Pre: time 2019-02-05 11:44:08.186663: 
 	std: 0.00437268
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2506, 0.25196666, 0.24028334, 0.2512, 0.25085]
	train_accs: [0.2506, 0.25196666, 0.24028334, 0.2512, 0.25085]
	best_train_sub_head: 1
	worst: 0.24028334
	avg: 0.24898
	best: 0.25196666

Starting e_i: 735
Model ind 579 epoch 735 head B head_i_epoch 0 batch 0: avg loss -1.809921 avg loss no lamb -1.809921 time 2019-02-05 11:44:12.311386
Model ind 579 epoch 735 head B head_i_epoch 0 batch 100: avg loss -1.826890 avg loss no lamb -1.826890 time 2019-02-05 11:47:10.669421
Model ind 579 epoch 735 head B head_i_epoch 0 batch 200: avg loss -1.856477 avg loss no lamb -1.856477 time 2019-02-05 11:50:09.442823
Model ind 579 epoch 735 head A head_i_epoch 0 batch 0: avg loss -3.468186 avg loss no lamb -3.468186 time 2019-02-05 11:53:09.865054
Model ind 579 epoch 735 head A head_i_epoch 0 batch 100: avg loss -3.452404 avg loss no lamb -3.452404 time 2019-02-05 11:56:09.851582
Model ind 579 epoch 735 head A head_i_epoch 0 batch 200: avg loss -3.527431 avg loss no lamb -3.527431 time 2019-02-05 11:59:10.293187
Pre: time 2019-02-05 12:02:36.424514: 
 	std: 0.004466087
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2502, 0.25101668, 0.23951666, 0.25073335, 0.2507]
	train_accs: [0.2502, 0.25101668, 0.23951666, 0.25073335, 0.2507]
	best_train_sub_head: 1
	worst: 0.23951666
	avg: 0.24843332
	best: 0.25101668

Starting e_i: 736
Model ind 579 epoch 736 head B head_i_epoch 0 batch 0: avg loss -1.817717 avg loss no lamb -1.817717 time 2019-02-05 12:02:40.209777
Model ind 579 epoch 736 head B head_i_epoch 0 batch 100: avg loss -1.893113 avg loss no lamb -1.893113 time 2019-02-05 12:05:38.439706
Model ind 579 epoch 736 head B head_i_epoch 0 batch 200: avg loss -1.879799 avg loss no lamb -1.879799 time 2019-02-05 12:08:36.744103
Model ind 579 epoch 736 head A head_i_epoch 0 batch 0: avg loss -3.427777 avg loss no lamb -3.427777 time 2019-02-05 12:11:34.426457
Model ind 579 epoch 736 head A head_i_epoch 0 batch 100: avg loss -3.448998 avg loss no lamb -3.448998 time 2019-02-05 12:14:33.887490
Model ind 579 epoch 736 head A head_i_epoch 0 batch 200: avg loss -3.562309 avg loss no lamb -3.562309 time 2019-02-05 12:17:32.571315
Pre: time 2019-02-05 12:20:56.268845: 
 	std: 0.0038809278
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25073335, 0.25173333, 0.2414, 0.2509, 0.25088334]
	train_accs: [0.25073335, 0.25173333, 0.2414, 0.2509, 0.25088334]
	best_train_sub_head: 1
	worst: 0.2414
	avg: 0.24913001
	best: 0.25173333

Starting e_i: 737
Model ind 579 epoch 737 head B head_i_epoch 0 batch 0: avg loss -1.952410 avg loss no lamb -1.952410 time 2019-02-05 12:21:00.013386
Model ind 579 epoch 737 head B head_i_epoch 0 batch 100: avg loss -1.873841 avg loss no lamb -1.873841 time 2019-02-05 12:23:58.327419
Model ind 579 epoch 737 head B head_i_epoch 0 batch 200: avg loss -1.872912 avg loss no lamb -1.872912 time 2019-02-05 12:26:57.588811
Model ind 579 epoch 737 head A head_i_epoch 0 batch 0: avg loss -3.447484 avg loss no lamb -3.447484 time 2019-02-05 12:29:56.180341
Model ind 579 epoch 737 head A head_i_epoch 0 batch 100: avg loss -3.482527 avg loss no lamb -3.482527 time 2019-02-05 12:32:56.436068
Model ind 579 epoch 737 head A head_i_epoch 0 batch 200: avg loss -3.506505 avg loss no lamb -3.506505 time 2019-02-05 12:35:56.339718
Pre: time 2019-02-05 12:39:21.466500: 
 	std: 0.004301615
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25276667, 0.2539, 0.24225, 0.25278333, 0.25221667]
	train_accs: [0.25276667, 0.2539, 0.24225, 0.25278333, 0.25221667]
	best_train_sub_head: 1
	worst: 0.24225
	avg: 0.25078332
	best: 0.2539

Starting e_i: 738
Model ind 579 epoch 738 head B head_i_epoch 0 batch 0: avg loss -1.829976 avg loss no lamb -1.829976 time 2019-02-05 12:39:25.354216
Model ind 579 epoch 738 head B head_i_epoch 0 batch 100: avg loss -1.827803 avg loss no lamb -1.827803 time 2019-02-05 12:42:23.602671
Model ind 579 epoch 738 head B head_i_epoch 0 batch 200: avg loss -1.826528 avg loss no lamb -1.826528 time 2019-02-05 12:45:21.532745
Model ind 579 epoch 738 head A head_i_epoch 0 batch 0: avg loss -3.467993 avg loss no lamb -3.467993 time 2019-02-05 12:48:19.177418
Model ind 579 epoch 738 head A head_i_epoch 0 batch 100: avg loss -3.439793 avg loss no lamb -3.439793 time 2019-02-05 12:51:17.563985
Model ind 579 epoch 738 head A head_i_epoch 0 batch 200: avg loss -3.494622 avg loss no lamb -3.494622 time 2019-02-05 12:54:22.613957
Pre: time 2019-02-05 12:57:45.572927: 
 	std: 0.004427971
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25021666, 0.25175, 0.23991667, 0.25133333, 0.25023332]
	train_accs: [0.25021666, 0.25175, 0.23991667, 0.25133333, 0.25023332]
	best_train_sub_head: 1
	worst: 0.23991667
	avg: 0.24868998
	best: 0.25175

Starting e_i: 739
Model ind 579 epoch 739 head B head_i_epoch 0 batch 0: avg loss -1.807885 avg loss no lamb -1.807885 time 2019-02-05 12:57:50.037144
Model ind 579 epoch 739 head B head_i_epoch 0 batch 100: avg loss -1.897243 avg loss no lamb -1.897243 time 2019-02-05 13:00:47.591315
Model ind 579 epoch 739 head B head_i_epoch 0 batch 200: avg loss -1.909549 avg loss no lamb -1.909549 time 2019-02-05 13:03:45.300284
Model ind 579 epoch 739 head A head_i_epoch 0 batch 0: avg loss -3.506406 avg loss no lamb -3.506406 time 2019-02-05 13:06:42.585106
Model ind 579 epoch 739 head A head_i_epoch 0 batch 100: avg loss -3.518348 avg loss no lamb -3.518348 time 2019-02-05 13:09:42.023412
Model ind 579 epoch 739 head A head_i_epoch 0 batch 200: avg loss -3.545663 avg loss no lamb -3.545663 time 2019-02-05 13:12:41.394379
Pre: time 2019-02-05 13:16:04.448312: 
 	std: 0.0042893733
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24976666, 0.25051665, 0.23933333, 0.24973333, 0.25011668]
	train_accs: [0.24976666, 0.25051665, 0.23933333, 0.24973333, 0.25011668]
	best_train_sub_head: 1
	worst: 0.23933333
	avg: 0.24789333
	best: 0.25051665

Starting e_i: 740
Model ind 579 epoch 740 head B head_i_epoch 0 batch 0: avg loss -1.859991 avg loss no lamb -1.859991 time 2019-02-05 13:16:08.191039
Model ind 579 epoch 740 head B head_i_epoch 0 batch 100: avg loss -1.860759 avg loss no lamb -1.860759 time 2019-02-05 13:19:06.790820
Model ind 579 epoch 740 head B head_i_epoch 0 batch 200: avg loss -1.839588 avg loss no lamb -1.839588 time 2019-02-05 13:22:05.187194
Model ind 579 epoch 740 head A head_i_epoch 0 batch 0: avg loss -3.491359 avg loss no lamb -3.491359 time 2019-02-05 13:25:04.389238
Model ind 579 epoch 740 head A head_i_epoch 0 batch 100: avg loss -3.512914 avg loss no lamb -3.512914 time 2019-02-05 13:28:10.816070
Model ind 579 epoch 740 head A head_i_epoch 0 batch 200: avg loss -3.465593 avg loss no lamb -3.465593 time 2019-02-05 13:31:11.116932
Pre: time 2019-02-05 13:34:34.825185: 
 	std: 0.0042807544
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.24865, 0.24893333, 0.2382, 0.2491, 0.2489]
	train_accs: [0.24865, 0.24893333, 0.2382, 0.2491, 0.2489]
	best_train_sub_head: 3
	worst: 0.2382
	avg: 0.24675664
	best: 0.2491

Starting e_i: 741
Model ind 579 epoch 741 head B head_i_epoch 0 batch 0: avg loss -1.873480 avg loss no lamb -1.873480 time 2019-02-05 13:34:42.754907
Model ind 579 epoch 741 head B head_i_epoch 0 batch 100: avg loss -1.852931 avg loss no lamb -1.852931 time 2019-02-05 13:37:41.178643
Model ind 579 epoch 741 head B head_i_epoch 0 batch 200: avg loss -1.940775 avg loss no lamb -1.940775 time 2019-02-05 13:40:39.564401
Model ind 579 epoch 741 head A head_i_epoch 0 batch 0: avg loss -3.535927 avg loss no lamb -3.535927 time 2019-02-05 13:43:38.925172
Model ind 579 epoch 741 head A head_i_epoch 0 batch 100: avg loss -3.473704 avg loss no lamb -3.473704 time 2019-02-05 13:46:37.781127
Model ind 579 epoch 741 head A head_i_epoch 0 batch 200: avg loss -3.525694 avg loss no lamb -3.525694 time 2019-02-05 13:49:37.015111
Pre: time 2019-02-05 13:53:01.289856: 
 	std: 0.0048583457
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2511, 0.25226668, 0.23955, 0.25148332, 0.25178334]
	train_accs: [0.2511, 0.25226668, 0.23955, 0.25148332, 0.25178334]
	best_train_sub_head: 1
	worst: 0.23955
	avg: 0.24923667
	best: 0.25226668

Starting e_i: 742
Model ind 579 epoch 742 head B head_i_epoch 0 batch 0: avg loss -1.893857 avg loss no lamb -1.893857 time 2019-02-05 13:53:05.029147
Model ind 579 epoch 742 head B head_i_epoch 0 batch 100: avg loss -1.778950 avg loss no lamb -1.778950 time 2019-02-05 13:56:03.724147
Model ind 579 epoch 742 head B head_i_epoch 0 batch 200: avg loss -1.877497 avg loss no lamb -1.877497 time 2019-02-05 13:59:01.680732
Model ind 579 epoch 742 head A head_i_epoch 0 batch 0: avg loss -3.462777 avg loss no lamb -3.462777 time 2019-02-05 14:02:02.191893
Model ind 579 epoch 742 head A head_i_epoch 0 batch 100: avg loss -3.447069 avg loss no lamb -3.447069 time 2019-02-05 14:05:03.580933
Model ind 579 epoch 742 head A head_i_epoch 0 batch 200: avg loss -3.499352 avg loss no lamb -3.499352 time 2019-02-05 14:08:04.989093
Pre: time 2019-02-05 14:11:30.124148: 
 	std: 0.0038231893
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24813333, 0.24965, 0.2394, 0.2484, 0.24925]
	train_accs: [0.24813333, 0.24965, 0.2394, 0.2484, 0.24925]
	best_train_sub_head: 1
	worst: 0.2394
	avg: 0.24696665
	best: 0.24965

Starting e_i: 743
Model ind 579 epoch 743 head B head_i_epoch 0 batch 0: avg loss -1.834593 avg loss no lamb -1.834593 time 2019-02-05 14:11:34.002858
Model ind 579 epoch 743 head B head_i_epoch 0 batch 100: avg loss -1.903534 avg loss no lamb -1.903534 time 2019-02-05 14:14:33.247608
Model ind 579 epoch 743 head B head_i_epoch 0 batch 200: avg loss -1.745595 avg loss no lamb -1.745595 time 2019-02-05 14:17:32.938282
Model ind 579 epoch 743 head A head_i_epoch 0 batch 0: avg loss -3.502635 avg loss no lamb -3.502635 time 2019-02-05 14:20:32.370452
Model ind 579 epoch 743 head A head_i_epoch 0 batch 100: avg loss -3.515378 avg loss no lamb -3.515378 time 2019-02-05 14:23:32.892552
Model ind 579 epoch 743 head A head_i_epoch 0 batch 200: avg loss -3.546257 avg loss no lamb -3.546257 time 2019-02-05 14:26:36.628567
Pre: time 2019-02-05 14:30:03.130582: 
 	std: 0.0044817347
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 5), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24936667, 0.25018334, 0.23856667, 0.24986666, 0.24958333]
	train_accs: [0.24936667, 0.25018334, 0.23856667, 0.24986666, 0.24958333]
	best_train_sub_head: 1
	worst: 0.23856667
	avg: 0.24751334
	best: 0.25018334

Starting e_i: 744
Model ind 579 epoch 744 head B head_i_epoch 0 batch 0: avg loss -1.989413 avg loss no lamb -1.989413 time 2019-02-05 14:30:07.583279
Model ind 579 epoch 744 head B head_i_epoch 0 batch 100: avg loss -1.757199 avg loss no lamb -1.757199 time 2019-02-05 14:33:06.746526
Model ind 579 epoch 744 head B head_i_epoch 0 batch 200: avg loss -1.834601 avg loss no lamb -1.834601 time 2019-02-05 14:36:05.170620
Model ind 579 epoch 744 head A head_i_epoch 0 batch 0: avg loss -3.523321 avg loss no lamb -3.523321 time 2019-02-05 14:39:04.400345
Model ind 579 epoch 744 head A head_i_epoch 0 batch 100: avg loss -3.475138 avg loss no lamb -3.475138 time 2019-02-05 14:42:03.841208
Model ind 579 epoch 744 head A head_i_epoch 0 batch 200: avg loss -3.503142 avg loss no lamb -3.503142 time 2019-02-05 14:45:04.390393
Pre: time 2019-02-05 14:48:29.093064: 
 	std: 0.004143261
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24991667, 0.25036666, 0.23971666, 0.25006667, 0.24991667]
	train_accs: [0.24991667, 0.25036666, 0.23971666, 0.25006667, 0.24991667]
	best_train_sub_head: 1
	worst: 0.23971666
	avg: 0.24799666
	best: 0.25036666

Starting e_i: 745
Model ind 579 epoch 745 head B head_i_epoch 0 batch 0: avg loss -1.872951 avg loss no lamb -1.872951 time 2019-02-05 14:48:33.021438
Model ind 579 epoch 745 head B head_i_epoch 0 batch 100: avg loss -1.764417 avg loss no lamb -1.764417 time 2019-02-05 14:51:31.750982
Model ind 579 epoch 745 head B head_i_epoch 0 batch 200: avg loss -1.756695 avg loss no lamb -1.756695 time 2019-02-05 14:54:29.562406
Model ind 579 epoch 745 head A head_i_epoch 0 batch 0: avg loss -3.471918 avg loss no lamb -3.471918 time 2019-02-05 14:57:28.647294
Model ind 579 epoch 745 head A head_i_epoch 0 batch 100: avg loss -3.531411 avg loss no lamb -3.531411 time 2019-02-05 15:00:27.010495
Model ind 579 epoch 745 head A head_i_epoch 0 batch 200: avg loss -3.487797 avg loss no lamb -3.487797 time 2019-02-05 15:03:27.240336
Pre: time 2019-02-05 15:06:50.935254: 
 	std: 0.004808607
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25155, 0.25221667, 0.2398, 0.25166667, 0.2518]
	train_accs: [0.25155, 0.25221667, 0.2398, 0.25166667, 0.2518]
	best_train_sub_head: 1
	worst: 0.2398
	avg: 0.24940667
	best: 0.25221667

Starting e_i: 746
Model ind 579 epoch 746 head B head_i_epoch 0 batch 0: avg loss -1.926278 avg loss no lamb -1.926278 time 2019-02-05 15:06:54.785345
Model ind 579 epoch 746 head B head_i_epoch 0 batch 100: avg loss -1.896949 avg loss no lamb -1.896949 time 2019-02-05 15:09:52.252020
Model ind 579 epoch 746 head B head_i_epoch 0 batch 200: avg loss -1.880379 avg loss no lamb -1.880379 time 2019-02-05 15:12:59.343883
Model ind 579 epoch 746 head A head_i_epoch 0 batch 0: avg loss -3.504295 avg loss no lamb -3.504295 time 2019-02-05 15:15:59.538241
Model ind 579 epoch 746 head A head_i_epoch 0 batch 100: avg loss -3.534607 avg loss no lamb -3.534607 time 2019-02-05 15:18:58.394174
Model ind 579 epoch 746 head A head_i_epoch 0 batch 200: avg loss -3.492063 avg loss no lamb -3.492063 time 2019-02-05 15:21:57.539462
Pre: time 2019-02-05 15:25:22.276225: 
 	std: 0.004157047
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2491, 0.2497, 0.23895, 0.24915, 0.24936667]
	train_accs: [0.2491, 0.2497, 0.23895, 0.24915, 0.24936667]
	best_train_sub_head: 1
	worst: 0.23895
	avg: 0.24725333
	best: 0.2497

Starting e_i: 747
Model ind 579 epoch 747 head B head_i_epoch 0 batch 0: avg loss -1.846147 avg loss no lamb -1.846147 time 2019-02-05 15:25:26.807530
Model ind 579 epoch 747 head B head_i_epoch 0 batch 100: avg loss -1.788503 avg loss no lamb -1.788503 time 2019-02-05 15:28:24.453214
Model ind 579 epoch 747 head B head_i_epoch 0 batch 200: avg loss -1.862842 avg loss no lamb -1.862842 time 2019-02-05 15:31:22.091900
Model ind 579 epoch 747 head A head_i_epoch 0 batch 0: avg loss -3.489031 avg loss no lamb -3.489031 time 2019-02-05 15:34:22.138685
Model ind 579 epoch 747 head A head_i_epoch 0 batch 100: avg loss -3.532920 avg loss no lamb -3.532920 time 2019-02-05 15:37:30.071122
Model ind 579 epoch 747 head A head_i_epoch 0 batch 200: avg loss -3.504329 avg loss no lamb -3.504329 time 2019-02-05 15:40:33.252995
Pre: time 2019-02-05 15:43:58.801753: 
 	std: 0.0047568814
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25091666, 0.25106665, 0.23898333, 0.25065, 0.25085]
	train_accs: [0.25091666, 0.25106665, 0.23898333, 0.25065, 0.25085]
	best_train_sub_head: 1
	worst: 0.23898333
	avg: 0.24849331
	best: 0.25106665

Starting e_i: 748
Model ind 579 epoch 748 head B head_i_epoch 0 batch 0: avg loss -1.937901 avg loss no lamb -1.937901 time 2019-02-05 15:44:02.707700
Model ind 579 epoch 748 head B head_i_epoch 0 batch 100: avg loss -1.820867 avg loss no lamb -1.820867 time 2019-02-05 15:47:01.965356
Model ind 579 epoch 748 head B head_i_epoch 0 batch 200: avg loss -1.792443 avg loss no lamb -1.792443 time 2019-02-05 15:50:01.050132
Model ind 579 epoch 748 head A head_i_epoch 0 batch 0: avg loss -3.445502 avg loss no lamb -3.445502 time 2019-02-05 15:53:04.022940
Model ind 579 epoch 748 head A head_i_epoch 0 batch 100: avg loss -3.529300 avg loss no lamb -3.529300 time 2019-02-05 15:56:03.210763
Model ind 579 epoch 748 head A head_i_epoch 0 batch 200: avg loss -3.525652 avg loss no lamb -3.525652 time 2019-02-05 15:59:02.768555
Pre: time 2019-02-05 16:02:28.099763: 
 	std: 0.0043735136
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25186667, 0.25168332, 0.24075, 0.2517, 0.25146666]
	train_accs: [0.25186667, 0.25168332, 0.24075, 0.2517, 0.25146666]
	best_train_sub_head: 0
	worst: 0.24075
	avg: 0.24949333
	best: 0.25186667

Starting e_i: 749
Model ind 579 epoch 749 head B head_i_epoch 0 batch 0: avg loss -1.853393 avg loss no lamb -1.853393 time 2019-02-05 16:02:31.934103
Model ind 579 epoch 749 head B head_i_epoch 0 batch 100: avg loss -1.835262 avg loss no lamb -1.835262 time 2019-02-05 16:05:30.964630
Model ind 579 epoch 749 head B head_i_epoch 0 batch 200: avg loss -1.849441 avg loss no lamb -1.849441 time 2019-02-05 16:08:29.250408
Model ind 579 epoch 749 head A head_i_epoch 0 batch 0: avg loss -3.520332 avg loss no lamb -3.520332 time 2019-02-05 16:11:27.351092
Model ind 579 epoch 749 head A head_i_epoch 0 batch 100: avg loss -3.503205 avg loss no lamb -3.503205 time 2019-02-05 16:14:30.319827
Model ind 579 epoch 749 head A head_i_epoch 0 batch 200: avg loss -3.541643 avg loss no lamb -3.541643 time 2019-02-05 16:17:32.217365
Pre: time 2019-02-05 16:20:56.675530: 
 	std: 0.004349522
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25016665, 0.2503, 0.23941667, 0.25021666, 0.25046667]
	train_accs: [0.25016665, 0.2503, 0.23941667, 0.25021666, 0.25046667]
	best_train_sub_head: 4
	worst: 0.23941667
	avg: 0.24811332
	best: 0.25046667

Starting e_i: 750
Model ind 579 epoch 750 head B head_i_epoch 0 batch 0: avg loss -1.859863 avg loss no lamb -1.859863 time 2019-02-05 16:21:00.624181
Model ind 579 epoch 750 head B head_i_epoch 0 batch 100: avg loss -1.860760 avg loss no lamb -1.860760 time 2019-02-05 16:23:59.363750
Model ind 579 epoch 750 head B head_i_epoch 0 batch 200: avg loss -1.778471 avg loss no lamb -1.778471 time 2019-02-05 16:26:58.095704
Model ind 579 epoch 750 head A head_i_epoch 0 batch 0: avg loss -3.457968 avg loss no lamb -3.457968 time 2019-02-05 16:29:56.650399
Model ind 579 epoch 750 head A head_i_epoch 0 batch 100: avg loss -3.470587 avg loss no lamb -3.470587 time 2019-02-05 16:32:56.614154
Model ind 579 epoch 750 head A head_i_epoch 0 batch 200: avg loss -3.493746 avg loss no lamb -3.493746 time 2019-02-05 16:35:57.523144
Pre: time 2019-02-05 16:39:22.810684: 
 	std: 0.004559159
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.24976666, 0.24955, 0.23836666, 0.2497, 0.25001666]
	train_accs: [0.24976666, 0.24955, 0.23836666, 0.2497, 0.25001666]
	best_train_sub_head: 4
	worst: 0.23836666
	avg: 0.24747999
	best: 0.25001666

Starting e_i: 751
Model ind 579 epoch 751 head B head_i_epoch 0 batch 0: avg loss -1.896314 avg loss no lamb -1.896314 time 2019-02-05 16:39:31.267300
Model ind 579 epoch 751 head B head_i_epoch 0 batch 100: avg loss -1.843022 avg loss no lamb -1.843022 time 2019-02-05 16:42:29.030965
Model ind 579 epoch 751 head B head_i_epoch 0 batch 200: avg loss -1.887099 avg loss no lamb -1.887099 time 2019-02-05 16:45:27.933736
Model ind 579 epoch 751 head A head_i_epoch 0 batch 0: avg loss -3.456899 avg loss no lamb -3.456899 time 2019-02-05 16:48:26.691303
Model ind 579 epoch 751 head A head_i_epoch 0 batch 100: avg loss -3.480251 avg loss no lamb -3.480251 time 2019-02-05 16:51:26.725064
Model ind 579 epoch 751 head A head_i_epoch 0 batch 200: avg loss -3.546348 avg loss no lamb -3.546348 time 2019-02-05 16:54:25.561001
Pre: time 2019-02-05 16:57:49.878985: 
 	std: 0.0041757165
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.24995, 0.24973333, 0.23938334, 0.24951667, 0.25005]
	train_accs: [0.24995, 0.24973333, 0.23938334, 0.24951667, 0.25005]
	best_train_sub_head: 4
	worst: 0.23938334
	avg: 0.24772668
	best: 0.25005

Starting e_i: 752
Model ind 579 epoch 752 head B head_i_epoch 0 batch 0: avg loss -1.910186 avg loss no lamb -1.910186 time 2019-02-05 16:57:54.620243
Model ind 579 epoch 752 head B head_i_epoch 0 batch 100: avg loss -1.763316 avg loss no lamb -1.763316 time 2019-02-05 17:00:53.077289
Model ind 579 epoch 752 head B head_i_epoch 0 batch 200: avg loss -1.897959 avg loss no lamb -1.897959 time 2019-02-05 17:03:52.006913
Model ind 579 epoch 752 head A head_i_epoch 0 batch 0: avg loss -3.446302 avg loss no lamb -3.446302 time 2019-02-05 17:06:50.511725
Model ind 579 epoch 752 head A head_i_epoch 0 batch 100: avg loss -3.539366 avg loss no lamb -3.539366 time 2019-02-05 17:09:50.466413
Model ind 579 epoch 752 head A head_i_epoch 0 batch 200: avg loss -3.512207 avg loss no lamb -3.512207 time 2019-02-05 17:12:49.876469
Pre: time 2019-02-05 17:16:14.787830: 
 	std: 0.004311917
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.2502, 0.25013334, 0.2394, 0.24998334, 0.25038335]
	train_accs: [0.2502, 0.25013334, 0.2394, 0.24998334, 0.25038335]
	best_train_sub_head: 4
	worst: 0.2394
	avg: 0.24802001
	best: 0.25038335

Starting e_i: 753
Model ind 579 epoch 753 head B head_i_epoch 0 batch 0: avg loss -1.840173 avg loss no lamb -1.840173 time 2019-02-05 17:16:20.166981
Model ind 579 epoch 753 head B head_i_epoch 0 batch 100: avg loss -1.861335 avg loss no lamb -1.861335 time 2019-02-05 17:19:18.808374
Model ind 579 epoch 753 head B head_i_epoch 0 batch 200: avg loss -1.901279 avg loss no lamb -1.901279 time 2019-02-05 17:22:16.486374
Model ind 579 epoch 753 head A head_i_epoch 0 batch 0: avg loss -3.453543 avg loss no lamb -3.453543 time 2019-02-05 17:25:14.983326
Model ind 579 epoch 753 head A head_i_epoch 0 batch 100: avg loss -3.532322 avg loss no lamb -3.532322 time 2019-02-05 17:28:13.730662
Model ind 579 epoch 753 head A head_i_epoch 0 batch 200: avg loss -3.567628 avg loss no lamb -3.567628 time 2019-02-05 17:31:13.771218
Pre: time 2019-02-05 17:34:38.088795: 
 	std: 0.004291071
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25146666, 0.25143334, 0.24071667, 0.25128335, 0.25158334]
	train_accs: [0.25146666, 0.25143334, 0.24071667, 0.25128335, 0.25158334]
	best_train_sub_head: 4
	worst: 0.24071667
	avg: 0.24929667
	best: 0.25158334

Starting e_i: 754
Model ind 579 epoch 754 head B head_i_epoch 0 batch 0: avg loss -1.852460 avg loss no lamb -1.852460 time 2019-02-05 17:34:42.569559
Model ind 579 epoch 754 head B head_i_epoch 0 batch 100: avg loss -1.876559 avg loss no lamb -1.876559 time 2019-02-05 17:37:41.264116
Model ind 579 epoch 754 head B head_i_epoch 0 batch 200: avg loss -1.914625 avg loss no lamb -1.914625 time 2019-02-05 17:40:38.954269
Model ind 579 epoch 754 head A head_i_epoch 0 batch 0: avg loss -3.468801 avg loss no lamb -3.468801 time 2019-02-05 17:43:36.390869
Model ind 579 epoch 754 head A head_i_epoch 0 batch 100: avg loss -3.553853 avg loss no lamb -3.553853 time 2019-02-05 17:46:36.050413
Model ind 579 epoch 754 head A head_i_epoch 0 batch 200: avg loss -3.505192 avg loss no lamb -3.505192 time 2019-02-05 17:49:36.657581
Pre: time 2019-02-05 17:53:01.183565: 
 	std: 0.0043080477
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24978334, 0.25, 0.23888333, 0.24895, 0.24973333]
	train_accs: [0.24978334, 0.25, 0.23888333, 0.24895, 0.24973333]
	best_train_sub_head: 1
	worst: 0.23888333
	avg: 0.24746999
	best: 0.25

Starting e_i: 755
Model ind 579 epoch 755 head B head_i_epoch 0 batch 0: avg loss -1.928335 avg loss no lamb -1.928335 time 2019-02-05 17:53:05.016090
Model ind 579 epoch 755 head B head_i_epoch 0 batch 100: avg loss -1.797473 avg loss no lamb -1.797473 time 2019-02-05 17:56:02.616032
Model ind 579 epoch 755 head B head_i_epoch 0 batch 200: avg loss -1.962101 avg loss no lamb -1.962101 time 2019-02-05 17:59:00.598394
Model ind 579 epoch 755 head A head_i_epoch 0 batch 0: avg loss -3.469497 avg loss no lamb -3.469497 time 2019-02-05 18:01:59.404305
Model ind 579 epoch 755 head A head_i_epoch 0 batch 100: avg loss -3.581674 avg loss no lamb -3.581674 time 2019-02-05 18:04:59.069963
Model ind 579 epoch 755 head A head_i_epoch 0 batch 200: avg loss -3.541255 avg loss no lamb -3.541255 time 2019-02-05 18:07:59.126109
Pre: time 2019-02-05 18:11:23.663546: 
 	std: 0.004866997
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25075, 0.25068334, 0.23855, 0.25063333, 0.2508]
	train_accs: [0.25075, 0.25068334, 0.23855, 0.25063333, 0.2508]
	best_train_sub_head: 4
	worst: 0.23855
	avg: 0.24828334
	best: 0.2508

Starting e_i: 756
Model ind 579 epoch 756 head B head_i_epoch 0 batch 0: avg loss -1.864449 avg loss no lamb -1.864449 time 2019-02-05 18:11:28.967316
Model ind 579 epoch 756 head B head_i_epoch 0 batch 100: avg loss -1.777143 avg loss no lamb -1.777143 time 2019-02-05 18:14:26.236945
Model ind 579 epoch 756 head B head_i_epoch 0 batch 200: avg loss -1.875835 avg loss no lamb -1.875835 time 2019-02-05 18:17:23.970857
Model ind 579 epoch 756 head A head_i_epoch 0 batch 0: avg loss -3.494236 avg loss no lamb -3.494236 time 2019-02-05 18:20:21.314635
Model ind 579 epoch 756 head A head_i_epoch 0 batch 100: avg loss -3.513429 avg loss no lamb -3.513429 time 2019-02-05 18:23:20.312797
Model ind 579 epoch 756 head A head_i_epoch 0 batch 200: avg loss -3.543252 avg loss no lamb -3.543252 time 2019-02-05 18:26:18.603510
Pre: time 2019-02-05 18:29:42.869309: 
 	std: 0.004623555
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25043333, 0.2505, 0.23896667, 0.25038335, 0.25076666]
	train_accs: [0.25043333, 0.2505, 0.23896667, 0.25038335, 0.25076666]
	best_train_sub_head: 4
	worst: 0.23896667
	avg: 0.24821
	best: 0.25076666

Starting e_i: 757
Model ind 579 epoch 757 head B head_i_epoch 0 batch 0: avg loss -1.888378 avg loss no lamb -1.888378 time 2019-02-05 18:29:46.771720
Model ind 579 epoch 757 head B head_i_epoch 0 batch 100: avg loss -1.878489 avg loss no lamb -1.878489 time 2019-02-05 18:32:45.682473
Model ind 579 epoch 757 head B head_i_epoch 0 batch 200: avg loss -1.874174 avg loss no lamb -1.874174 time 2019-02-05 18:35:45.329061
Model ind 579 epoch 757 head A head_i_epoch 0 batch 0: avg loss -3.416505 avg loss no lamb -3.416505 time 2019-02-05 18:38:44.230308
Model ind 579 epoch 757 head A head_i_epoch 0 batch 100: avg loss -3.522232 avg loss no lamb -3.522232 time 2019-02-05 18:41:43.628408
Model ind 579 epoch 757 head A head_i_epoch 0 batch 200: avg loss -3.507225 avg loss no lamb -3.507225 time 2019-02-05 18:44:45.265297
Pre: time 2019-02-05 18:48:11.741616: 
 	std: 0.0044129924
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25171667, 0.2518, 0.24046667, 0.25096667, 0.25141665]
	train_accs: [0.25171667, 0.2518, 0.24046667, 0.25096667, 0.25141665]
	best_train_sub_head: 1
	worst: 0.24046667
	avg: 0.24927333
	best: 0.2518

Starting e_i: 758
Model ind 579 epoch 758 head B head_i_epoch 0 batch 0: avg loss -2.044972 avg loss no lamb -2.044972 time 2019-02-05 18:48:15.535021
Model ind 579 epoch 758 head B head_i_epoch 0 batch 100: avg loss -1.846546 avg loss no lamb -1.846546 time 2019-02-05 18:51:13.556578
Model ind 579 epoch 758 head B head_i_epoch 0 batch 200: avg loss -1.862358 avg loss no lamb -1.862358 time 2019-02-05 18:54:12.503162
Model ind 579 epoch 758 head A head_i_epoch 0 batch 0: avg loss -3.485696 avg loss no lamb -3.485696 time 2019-02-05 18:57:11.323998
Model ind 579 epoch 758 head A head_i_epoch 0 batch 100: avg loss -3.531359 avg loss no lamb -3.531359 time 2019-02-05 19:00:12.887877
Model ind 579 epoch 758 head A head_i_epoch 0 batch 200: avg loss -3.528824 avg loss no lamb -3.528824 time 2019-02-05 19:03:12.975136
Pre: time 2019-02-05 19:06:38.312653: 
 	std: 0.00456084
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.24975, 0.24951667, 0.23821667, 0.2493, 0.24986666]
	train_accs: [0.24975, 0.24951667, 0.23821667, 0.2493, 0.24986666]
	best_train_sub_head: 4
	worst: 0.23821667
	avg: 0.24733
	best: 0.24986666

Starting e_i: 759
Model ind 579 epoch 759 head B head_i_epoch 0 batch 0: avg loss -1.959229 avg loss no lamb -1.959229 time 2019-02-05 19:06:42.088147
Model ind 579 epoch 759 head B head_i_epoch 0 batch 100: avg loss -1.865911 avg loss no lamb -1.865911 time 2019-02-05 19:09:40.411658
Model ind 579 epoch 759 head B head_i_epoch 0 batch 200: avg loss -1.838009 avg loss no lamb -1.838009 time 2019-02-05 19:12:39.471859
Model ind 579 epoch 759 head A head_i_epoch 0 batch 0: avg loss -3.489466 avg loss no lamb -3.489466 time 2019-02-05 19:15:38.734958
Model ind 579 epoch 759 head A head_i_epoch 0 batch 100: avg loss -3.559156 avg loss no lamb -3.559156 time 2019-02-05 19:18:38.531175
Model ind 579 epoch 759 head A head_i_epoch 0 batch 200: avg loss -3.445246 avg loss no lamb -3.445246 time 2019-02-05 19:21:38.015921
Pre: time 2019-02-05 19:25:03.074540: 
 	std: 0.0040615746
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.24911667, 0.24848333, 0.23876667, 0.24878334, 0.24921666]
	train_accs: [0.24911667, 0.24848333, 0.23876667, 0.24878334, 0.24921666]
	best_train_sub_head: 4
	worst: 0.23876667
	avg: 0.24687333
	best: 0.24921666

Starting e_i: 760
Model ind 579 epoch 760 head B head_i_epoch 0 batch 0: avg loss -1.932182 avg loss no lamb -1.932182 time 2019-02-05 19:25:06.875847
Model ind 579 epoch 760 head B head_i_epoch 0 batch 100: avg loss -1.866232 avg loss no lamb -1.866232 time 2019-02-05 19:28:06.277500
Model ind 579 epoch 760 head B head_i_epoch 0 batch 200: avg loss -1.884429 avg loss no lamb -1.884429 time 2019-02-05 19:31:03.322703
Model ind 579 epoch 760 head A head_i_epoch 0 batch 0: avg loss -3.436414 avg loss no lamb -3.436414 time 2019-02-05 19:34:02.386815
Model ind 579 epoch 760 head A head_i_epoch 0 batch 100: avg loss -3.578448 avg loss no lamb -3.578448 time 2019-02-05 19:37:01.982082
Model ind 579 epoch 760 head A head_i_epoch 0 batch 200: avg loss -3.569336 avg loss no lamb -3.569336 time 2019-02-05 19:40:01.806539
Pre: time 2019-02-05 19:43:27.016700: 
 	std: 0.004484674
	best_train_sub_head_match: [(0, 15), (1, 0), (2, 2), (3, 19), (4, 4), (5, 3), (6, 5), (7, 7), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 13), (19, 18)]
	test_accs: [0.24861667, 0.24826667, 0.23743333, 0.24885, 0.2488]
	train_accs: [0.24861667, 0.24826667, 0.23743333, 0.24885, 0.2488]
	best_train_sub_head: 3
	worst: 0.23743333
	avg: 0.24639332
	best: 0.24885

Starting e_i: 761
Model ind 579 epoch 761 head B head_i_epoch 0 batch 0: avg loss -1.829227 avg loss no lamb -1.829227 time 2019-02-05 19:43:34.806782
Model ind 579 epoch 761 head B head_i_epoch 0 batch 100: avg loss -1.870432 avg loss no lamb -1.870432 time 2019-02-05 19:46:33.828643
Model ind 579 epoch 761 head B head_i_epoch 0 batch 200: avg loss -1.877542 avg loss no lamb -1.877542 time 2019-02-05 19:49:32.154158
Model ind 579 epoch 761 head A head_i_epoch 0 batch 0: avg loss -3.503487 avg loss no lamb -3.503487 time 2019-02-05 19:52:29.751460
Model ind 579 epoch 761 head A head_i_epoch 0 batch 100: avg loss -3.526495 avg loss no lamb -3.526495 time 2019-02-05 19:55:28.986030
Model ind 579 epoch 761 head A head_i_epoch 0 batch 200: avg loss -3.519014 avg loss no lamb -3.519014 time 2019-02-05 19:58:28.486909
Pre: time 2019-02-05 20:01:52.339951: 
 	std: 0.0045554535
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25098333, 0.25155, 0.23993333, 0.2514, 0.25131667]
	train_accs: [0.25098333, 0.25155, 0.23993333, 0.2514, 0.25131667]
	best_train_sub_head: 1
	worst: 0.23993333
	avg: 0.24903664
	best: 0.25155

Starting e_i: 762
Model ind 579 epoch 762 head B head_i_epoch 0 batch 0: avg loss -1.893238 avg loss no lamb -1.893238 time 2019-02-05 20:01:56.671966
Model ind 579 epoch 762 head B head_i_epoch 0 batch 100: avg loss -1.901698 avg loss no lamb -1.901698 time 2019-02-05 20:04:54.864059
Model ind 579 epoch 762 head B head_i_epoch 0 batch 200: avg loss -1.869540 avg loss no lamb -1.869540 time 2019-02-05 20:07:53.898153
Model ind 579 epoch 762 head A head_i_epoch 0 batch 0: avg loss -3.501860 avg loss no lamb -3.501860 time 2019-02-05 20:10:53.156735
Model ind 579 epoch 762 head A head_i_epoch 0 batch 100: avg loss -3.555325 avg loss no lamb -3.555325 time 2019-02-05 20:13:53.464383
Model ind 579 epoch 762 head A head_i_epoch 0 batch 200: avg loss -3.500429 avg loss no lamb -3.500429 time 2019-02-05 20:16:53.282560
Pre: time 2019-02-05 20:20:17.074313: 
 	std: 0.0041632885
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25365, 0.25263333, 0.2427, 0.25271666, 0.25326666]
	train_accs: [0.25365, 0.25263333, 0.2427, 0.25271666, 0.25326666]
	best_train_sub_head: 0
	worst: 0.2427
	avg: 0.2509933
	best: 0.25365

Starting e_i: 763
Model ind 579 epoch 763 head B head_i_epoch 0 batch 0: avg loss -1.927139 avg loss no lamb -1.927139 time 2019-02-05 20:20:21.825368
Model ind 579 epoch 763 head B head_i_epoch 0 batch 100: avg loss -1.810968 avg loss no lamb -1.810968 time 2019-02-05 20:23:18.968336
Model ind 579 epoch 763 head B head_i_epoch 0 batch 200: avg loss -1.885420 avg loss no lamb -1.885420 time 2019-02-05 20:26:17.053530
Model ind 579 epoch 763 head A head_i_epoch 0 batch 0: avg loss -3.431777 avg loss no lamb -3.431777 time 2019-02-05 20:29:14.920394
Model ind 579 epoch 763 head A head_i_epoch 0 batch 100: avg loss -3.495946 avg loss no lamb -3.495946 time 2019-02-05 20:32:14.073569
Model ind 579 epoch 763 head A head_i_epoch 0 batch 200: avg loss -3.529752 avg loss no lamb -3.529752 time 2019-02-05 20:35:12.565760
Pre: time 2019-02-05 20:38:36.931506: 
 	std: 0.0048815887
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25195, 0.25166667, 0.23966667, 0.2516, 0.25221667]
	train_accs: [0.25195, 0.25166667, 0.23966667, 0.2516, 0.25221667]
	best_train_sub_head: 4
	worst: 0.23966667
	avg: 0.24942002
	best: 0.25221667

Starting e_i: 764
Model ind 579 epoch 764 head B head_i_epoch 0 batch 0: avg loss -1.926954 avg loss no lamb -1.926954 time 2019-02-05 20:38:40.992575
Model ind 579 epoch 764 head B head_i_epoch 0 batch 100: avg loss -1.883708 avg loss no lamb -1.883708 time 2019-02-05 20:41:39.941565
Model ind 579 epoch 764 head B head_i_epoch 0 batch 200: avg loss -1.824626 avg loss no lamb -1.824626 time 2019-02-05 20:44:37.320177
Model ind 579 epoch 764 head A head_i_epoch 0 batch 0: avg loss -3.484311 avg loss no lamb -3.484311 time 2019-02-05 20:47:35.460720
Model ind 579 epoch 764 head A head_i_epoch 0 batch 100: avg loss -3.554689 avg loss no lamb -3.554689 time 2019-02-05 20:50:35.131385
Model ind 579 epoch 764 head A head_i_epoch 0 batch 200: avg loss -3.587097 avg loss no lamb -3.587097 time 2019-02-05 20:53:34.872921
Pre: time 2019-02-05 20:56:59.315915: 
 	std: 0.004154258
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24758333, 0.24776667, 0.23711666, 0.24701667, 0.24756667]
	train_accs: [0.24758333, 0.24776667, 0.23711666, 0.24701667, 0.24756667]
	best_train_sub_head: 1
	worst: 0.23711666
	avg: 0.24541001
	best: 0.24776667

Starting e_i: 765
Model ind 579 epoch 765 head B head_i_epoch 0 batch 0: avg loss -1.861720 avg loss no lamb -1.861720 time 2019-02-05 20:57:03.257947
Model ind 579 epoch 765 head B head_i_epoch 0 batch 100: avg loss -1.863178 avg loss no lamb -1.863178 time 2019-02-05 21:00:00.651319
Model ind 579 epoch 765 head B head_i_epoch 0 batch 200: avg loss -1.939298 avg loss no lamb -1.939298 time 2019-02-05 21:02:58.326479
Model ind 579 epoch 765 head A head_i_epoch 0 batch 0: avg loss -3.543749 avg loss no lamb -3.543749 time 2019-02-05 21:05:56.869078
Model ind 579 epoch 765 head A head_i_epoch 0 batch 100: avg loss -3.595068 avg loss no lamb -3.595068 time 2019-02-05 21:08:54.687346
Model ind 579 epoch 765 head A head_i_epoch 0 batch 200: avg loss -3.546460 avg loss no lamb -3.546460 time 2019-02-05 21:11:53.314795
Pre: time 2019-02-05 21:15:17.686116: 
 	std: 0.00444709
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.249, 0.2485, 0.23743333, 0.24835, 0.24828333]
	train_accs: [0.249, 0.2485, 0.23743333, 0.24835, 0.24828333]
	best_train_sub_head: 0
	worst: 0.23743333
	avg: 0.24631333
	best: 0.249

Starting e_i: 766
Model ind 579 epoch 766 head B head_i_epoch 0 batch 0: avg loss -1.881784 avg loss no lamb -1.881784 time 2019-02-05 21:15:21.903882
Model ind 579 epoch 766 head B head_i_epoch 0 batch 100: avg loss -1.877014 avg loss no lamb -1.877014 time 2019-02-05 21:18:19.833038
Model ind 579 epoch 766 head B head_i_epoch 0 batch 200: avg loss -1.778724 avg loss no lamb -1.778724 time 2019-02-05 21:21:17.907205
Model ind 579 epoch 766 head A head_i_epoch 0 batch 0: avg loss -3.446346 avg loss no lamb -3.446346 time 2019-02-05 21:24:15.312171
Model ind 579 epoch 766 head A head_i_epoch 0 batch 100: avg loss -3.526568 avg loss no lamb -3.526568 time 2019-02-05 21:27:14.439232
Model ind 579 epoch 766 head A head_i_epoch 0 batch 200: avg loss -3.530515 avg loss no lamb -3.530515 time 2019-02-05 21:30:14.304641
Pre: time 2019-02-05 21:33:39.134699: 
 	std: 0.004620128
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 5), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25135, 0.25165, 0.23963334, 0.25106665, 0.25051665]
	train_accs: [0.25135, 0.25165, 0.23963334, 0.25106665, 0.25051665]
	best_train_sub_head: 1
	worst: 0.23963334
	avg: 0.24884334
	best: 0.25165

Starting e_i: 767
Model ind 579 epoch 767 head B head_i_epoch 0 batch 0: avg loss -1.914186 avg loss no lamb -1.914186 time 2019-02-05 21:33:44.739036
Model ind 579 epoch 767 head B head_i_epoch 0 batch 100: avg loss -1.960132 avg loss no lamb -1.960132 time 2019-02-05 21:36:41.601478
Model ind 579 epoch 767 head B head_i_epoch 0 batch 200: avg loss -1.855217 avg loss no lamb -1.855217 time 2019-02-05 21:39:38.665441
Model ind 579 epoch 767 head A head_i_epoch 0 batch 0: avg loss -3.509736 avg loss no lamb -3.509736 time 2019-02-05 21:42:36.743050
Model ind 579 epoch 767 head A head_i_epoch 0 batch 100: avg loss -3.518450 avg loss no lamb -3.518450 time 2019-02-05 21:45:35.821860
Model ind 579 epoch 767 head A head_i_epoch 0 batch 200: avg loss -3.593915 avg loss no lamb -3.593915 time 2019-02-05 21:48:33.966088
Pre: time 2019-02-05 21:51:59.465235: 
 	std: 0.004540545
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2537, 0.25303334, 0.24181667, 0.25253335, 0.25325]
	train_accs: [0.2537, 0.25303334, 0.24181667, 0.25253335, 0.25325]
	best_train_sub_head: 0
	worst: 0.24181667
	avg: 0.25086665
	best: 0.2537

Starting e_i: 768
Model ind 579 epoch 768 head B head_i_epoch 0 batch 0: avg loss -1.924252 avg loss no lamb -1.924252 time 2019-02-05 21:52:03.595318
Model ind 579 epoch 768 head B head_i_epoch 0 batch 100: avg loss -1.873244 avg loss no lamb -1.873244 time 2019-02-05 21:55:02.218276
Model ind 579 epoch 768 head B head_i_epoch 0 batch 200: avg loss -1.932988 avg loss no lamb -1.932988 time 2019-02-05 21:58:00.839733
Model ind 579 epoch 768 head A head_i_epoch 0 batch 0: avg loss -3.509820 avg loss no lamb -3.509820 time 2019-02-05 22:00:58.085780
Model ind 579 epoch 768 head A head_i_epoch 0 batch 100: avg loss -3.507137 avg loss no lamb -3.507137 time 2019-02-05 22:03:57.570517
Model ind 579 epoch 768 head A head_i_epoch 0 batch 200: avg loss -3.504403 avg loss no lamb -3.504403 time 2019-02-05 22:06:56.583968
Pre: time 2019-02-05 22:10:20.823971: 
 	std: 0.0045765485
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25143334, 0.25175, 0.24016666, 0.25151667, 0.25171667]
	train_accs: [0.25143334, 0.25175, 0.24016666, 0.25151667, 0.25171667]
	best_train_sub_head: 1
	worst: 0.24016666
	avg: 0.24931669
	best: 0.25175

Starting e_i: 769
Model ind 579 epoch 769 head B head_i_epoch 0 batch 0: avg loss -1.892864 avg loss no lamb -1.892864 time 2019-02-05 22:10:24.881321
Model ind 579 epoch 769 head B head_i_epoch 0 batch 100: avg loss -1.777696 avg loss no lamb -1.777696 time 2019-02-05 22:13:22.479515
Model ind 579 epoch 769 head B head_i_epoch 0 batch 200: avg loss -1.866601 avg loss no lamb -1.866601 time 2019-02-05 22:16:20.711977
Model ind 579 epoch 769 head A head_i_epoch 0 batch 0: avg loss -3.480195 avg loss no lamb -3.480195 time 2019-02-05 22:19:18.280309
Model ind 579 epoch 769 head A head_i_epoch 0 batch 100: avg loss -3.552506 avg loss no lamb -3.552506 time 2019-02-05 22:22:18.508714
Model ind 579 epoch 769 head A head_i_epoch 0 batch 200: avg loss -3.526375 avg loss no lamb -3.526375 time 2019-02-05 22:25:17.670697
Pre: time 2019-02-05 22:28:40.445745: 
 	std: 0.0044416003
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25118333, 0.25051665, 0.23963334, 0.25018334, 0.25093332]
	train_accs: [0.25118333, 0.25051665, 0.23963334, 0.25018334, 0.25093332]
	best_train_sub_head: 0
	worst: 0.23963334
	avg: 0.24849
	best: 0.25118333

Starting e_i: 770
Model ind 579 epoch 770 head B head_i_epoch 0 batch 0: avg loss -1.872735 avg loss no lamb -1.872735 time 2019-02-05 22:28:44.721734
Model ind 579 epoch 770 head B head_i_epoch 0 batch 100: avg loss -1.877935 avg loss no lamb -1.877935 time 2019-02-05 22:31:44.097588
Model ind 579 epoch 770 head B head_i_epoch 0 batch 200: avg loss -1.813101 avg loss no lamb -1.813101 time 2019-02-05 22:34:43.140661
Model ind 579 epoch 770 head A head_i_epoch 0 batch 0: avg loss -3.543514 avg loss no lamb -3.543514 time 2019-02-05 22:37:40.921125
Model ind 579 epoch 770 head A head_i_epoch 0 batch 100: avg loss -3.602774 avg loss no lamb -3.602774 time 2019-02-05 22:40:41.245856
Model ind 579 epoch 770 head A head_i_epoch 0 batch 200: avg loss -3.496674 avg loss no lamb -3.496674 time 2019-02-05 22:43:41.804330
Pre: time 2019-02-05 22:47:06.908025: 
 	std: 0.0046781036
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25218335, 0.25135, 0.24003333, 0.25121668, 0.25201666]
	train_accs: [0.25218335, 0.25135, 0.24003333, 0.25121668, 0.25201666]
	best_train_sub_head: 0
	worst: 0.24003333
	avg: 0.24936001
	best: 0.25218335

Starting e_i: 771
Model ind 579 epoch 771 head B head_i_epoch 0 batch 0: avg loss -1.944207 avg loss no lamb -1.944207 time 2019-02-05 22:47:15.749689
Model ind 579 epoch 771 head B head_i_epoch 0 batch 100: avg loss -1.861140 avg loss no lamb -1.861140 time 2019-02-05 22:50:14.528122
Model ind 579 epoch 771 head B head_i_epoch 0 batch 200: avg loss -1.817758 avg loss no lamb -1.817758 time 2019-02-05 22:53:13.326327
Model ind 579 epoch 771 head A head_i_epoch 0 batch 0: avg loss -3.475066 avg loss no lamb -3.475066 time 2019-02-05 22:56:10.449183
Model ind 579 epoch 771 head A head_i_epoch 0 batch 100: avg loss -3.523825 avg loss no lamb -3.523825 time 2019-02-05 22:59:09.305552
Model ind 579 epoch 771 head A head_i_epoch 0 batch 200: avg loss -3.471703 avg loss no lamb -3.471703 time 2019-02-05 23:02:08.640774
Pre: time 2019-02-05 23:05:31.916180: 
 	std: 0.0041252286
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25186667, 0.25178334, 0.24138333, 0.2516, 0.25151667]
	train_accs: [0.25186667, 0.25178334, 0.24138333, 0.2516, 0.25151667]
	best_train_sub_head: 0
	worst: 0.24138333
	avg: 0.24963
	best: 0.25186667

Starting e_i: 772
Model ind 579 epoch 772 head B head_i_epoch 0 batch 0: avg loss -1.913473 avg loss no lamb -1.913473 time 2019-02-05 23:05:36.647191
Model ind 579 epoch 772 head B head_i_epoch 0 batch 100: avg loss -1.805247 avg loss no lamb -1.805247 time 2019-02-05 23:08:34.489236
Model ind 579 epoch 772 head B head_i_epoch 0 batch 200: avg loss -1.872602 avg loss no lamb -1.872602 time 2019-02-05 23:11:32.522365
Model ind 579 epoch 772 head A head_i_epoch 0 batch 0: avg loss -3.470472 avg loss no lamb -3.470472 time 2019-02-05 23:14:29.646591
Model ind 579 epoch 772 head A head_i_epoch 0 batch 100: avg loss -3.560125 avg loss no lamb -3.560125 time 2019-02-05 23:17:29.804377
Model ind 579 epoch 772 head A head_i_epoch 0 batch 200: avg loss -3.601107 avg loss no lamb -3.601107 time 2019-02-05 23:20:30.273104
Pre: time 2019-02-05 23:23:53.942080: 
 	std: 0.0047207973
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25375, 0.25313333, 0.24166666, 0.25343335, 0.25351667]
	train_accs: [0.25375, 0.25313333, 0.24166666, 0.25343335, 0.25351667]
	best_train_sub_head: 0
	worst: 0.24166666
	avg: 0.2511
	best: 0.25375

Starting e_i: 773
Model ind 579 epoch 773 head B head_i_epoch 0 batch 0: avg loss -1.812394 avg loss no lamb -1.812394 time 2019-02-05 23:23:58.033432
Model ind 579 epoch 773 head B head_i_epoch 0 batch 100: avg loss -1.860005 avg loss no lamb -1.860005 time 2019-02-05 23:26:56.000004
Model ind 579 epoch 773 head B head_i_epoch 0 batch 200: avg loss -1.917845 avg loss no lamb -1.917845 time 2019-02-05 23:29:53.292980
Model ind 579 epoch 773 head A head_i_epoch 0 batch 0: avg loss -3.481810 avg loss no lamb -3.481810 time 2019-02-05 23:32:51.895736
Model ind 579 epoch 773 head A head_i_epoch 0 batch 100: avg loss -3.496516 avg loss no lamb -3.496516 time 2019-02-05 23:35:51.359755
Model ind 579 epoch 773 head A head_i_epoch 0 batch 200: avg loss -3.536716 avg loss no lamb -3.536716 time 2019-02-05 23:38:50.631097
Pre: time 2019-02-05 23:42:15.231942: 
 	std: 0.0046878154
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25216666, 0.2518, 0.24005, 0.25123334, 0.25178334]
	train_accs: [0.25216666, 0.2518, 0.24005, 0.25123334, 0.25178334]
	best_train_sub_head: 0
	worst: 0.24005
	avg: 0.24940667
	best: 0.25216666

Starting e_i: 774
Model ind 579 epoch 774 head B head_i_epoch 0 batch 0: avg loss -1.851758 avg loss no lamb -1.851758 time 2019-02-05 23:42:19.144106
Model ind 579 epoch 774 head B head_i_epoch 0 batch 100: avg loss -1.845313 avg loss no lamb -1.845313 time 2019-02-05 23:45:16.841018
Model ind 579 epoch 774 head B head_i_epoch 0 batch 200: avg loss -1.907126 avg loss no lamb -1.907126 time 2019-02-05 23:48:15.307077
Model ind 579 epoch 774 head A head_i_epoch 0 batch 0: avg loss -3.483525 avg loss no lamb -3.483525 time 2019-02-05 23:51:13.688287
Model ind 579 epoch 774 head A head_i_epoch 0 batch 100: avg loss -3.513243 avg loss no lamb -3.513243 time 2019-02-05 23:54:13.286601
Model ind 579 epoch 774 head A head_i_epoch 0 batch 200: avg loss -3.544774 avg loss no lamb -3.544774 time 2019-02-05 23:57:13.290174
Pre: time 2019-02-06 00:00:38.219983: 
 	std: 0.0047356966
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25085, 0.25098333, 0.23933333, 0.25106665, 0.2517]
	train_accs: [0.25085, 0.25098333, 0.23933333, 0.25106665, 0.2517]
	best_train_sub_head: 4
	worst: 0.23933333
	avg: 0.24878666
	best: 0.2517

Starting e_i: 775
Model ind 579 epoch 775 head B head_i_epoch 0 batch 0: avg loss -1.858318 avg loss no lamb -1.858318 time 2019-02-06 00:00:42.072474
Model ind 579 epoch 775 head B head_i_epoch 0 batch 100: avg loss -1.816602 avg loss no lamb -1.816602 time 2019-02-06 00:03:40.109478
Model ind 579 epoch 775 head B head_i_epoch 0 batch 200: avg loss -1.852663 avg loss no lamb -1.852663 time 2019-02-06 00:06:37.944892
Model ind 579 epoch 775 head A head_i_epoch 0 batch 0: avg loss -3.506428 avg loss no lamb -3.506428 time 2019-02-06 00:09:37.187450
Model ind 579 epoch 775 head A head_i_epoch 0 batch 100: avg loss -3.574396 avg loss no lamb -3.574396 time 2019-02-06 00:12:36.972203
Model ind 579 epoch 775 head A head_i_epoch 0 batch 200: avg loss -3.531039 avg loss no lamb -3.531039 time 2019-02-06 00:15:36.538208
Pre: time 2019-02-06 00:19:01.338527: 
 	std: 0.0040973523
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.24916667, 0.2488, 0.23888333, 0.24841666, 0.24985]
	train_accs: [0.24916667, 0.2488, 0.23888333, 0.24841666, 0.24985]
	best_train_sub_head: 4
	worst: 0.23888333
	avg: 0.24702331
	best: 0.24985

Starting e_i: 776
Model ind 579 epoch 776 head B head_i_epoch 0 batch 0: avg loss -1.867537 avg loss no lamb -1.867537 time 2019-02-06 00:19:06.156647
Model ind 579 epoch 776 head B head_i_epoch 0 batch 100: avg loss -1.835096 avg loss no lamb -1.835096 time 2019-02-06 00:22:05.032847
Model ind 579 epoch 776 head B head_i_epoch 0 batch 200: avg loss -1.879051 avg loss no lamb -1.879051 time 2019-02-06 00:25:03.556759
Model ind 579 epoch 776 head A head_i_epoch 0 batch 0: avg loss -3.497517 avg loss no lamb -3.497517 time 2019-02-06 00:28:01.646200
Model ind 579 epoch 776 head A head_i_epoch 0 batch 100: avg loss -3.519768 avg loss no lamb -3.519768 time 2019-02-06 00:31:01.754394
Model ind 579 epoch 776 head A head_i_epoch 0 batch 200: avg loss -3.554343 avg loss no lamb -3.554343 time 2019-02-06 00:34:00.827414
Pre: time 2019-02-06 00:37:24.613122: 
 	std: 0.0043385685
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25168332, 0.25206667, 0.24121666, 0.25198334, 0.25245]
	train_accs: [0.25168332, 0.25206667, 0.24121666, 0.25198334, 0.25245]
	best_train_sub_head: 4
	worst: 0.24121666
	avg: 0.24987999
	best: 0.25245

Starting e_i: 777
Model ind 579 epoch 777 head B head_i_epoch 0 batch 0: avg loss -1.861016 avg loss no lamb -1.861016 time 2019-02-06 00:37:29.636471
Model ind 579 epoch 777 head B head_i_epoch 0 batch 100: avg loss -1.913143 avg loss no lamb -1.913143 time 2019-02-06 00:40:29.176937
Model ind 579 epoch 777 head B head_i_epoch 0 batch 200: avg loss -1.896645 avg loss no lamb -1.896645 time 2019-02-06 00:43:27.922063
Model ind 579 epoch 777 head A head_i_epoch 0 batch 0: avg loss -3.481806 avg loss no lamb -3.481806 time 2019-02-06 00:46:25.664165
Model ind 579 epoch 777 head A head_i_epoch 0 batch 100: avg loss -3.481655 avg loss no lamb -3.481655 time 2019-02-06 00:49:25.550382
Model ind 579 epoch 777 head A head_i_epoch 0 batch 200: avg loss -3.487786 avg loss no lamb -3.487786 time 2019-02-06 00:52:24.953487
Pre: time 2019-02-06 00:55:49.786063: 
 	std: 0.004238286
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25055, 0.25045, 0.24025, 0.25055, 0.25161666]
	train_accs: [0.25055, 0.25045, 0.24025, 0.25055, 0.25161666]
	best_train_sub_head: 4
	worst: 0.24025
	avg: 0.2486833
	best: 0.25161666

Starting e_i: 778
Model ind 579 epoch 778 head B head_i_epoch 0 batch 0: avg loss -1.785443 avg loss no lamb -1.785443 time 2019-02-06 00:55:53.789972
Model ind 579 epoch 778 head B head_i_epoch 0 batch 100: avg loss -1.842125 avg loss no lamb -1.842125 time 2019-02-06 00:58:52.298733
Model ind 579 epoch 778 head B head_i_epoch 0 batch 200: avg loss -1.888216 avg loss no lamb -1.888216 time 2019-02-06 01:01:50.761553
Model ind 579 epoch 778 head A head_i_epoch 0 batch 0: avg loss -3.574324 avg loss no lamb -3.574324 time 2019-02-06 01:04:48.558082
Model ind 579 epoch 778 head A head_i_epoch 0 batch 100: avg loss -3.505813 avg loss no lamb -3.505813 time 2019-02-06 01:07:46.457773
Model ind 579 epoch 778 head A head_i_epoch 0 batch 200: avg loss -3.472476 avg loss no lamb -3.472476 time 2019-02-06 01:10:46.575418
Pre: time 2019-02-06 01:14:10.916445: 
 	std: 0.004944939
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25195, 0.25176665, 0.23973334, 0.2519, 0.25266665]
	train_accs: [0.25195, 0.25176665, 0.23973334, 0.2519, 0.25266665]
	best_train_sub_head: 4
	worst: 0.23973334
	avg: 0.24960332
	best: 0.25266665

Starting e_i: 779
Model ind 579 epoch 779 head B head_i_epoch 0 batch 0: avg loss -1.889925 avg loss no lamb -1.889925 time 2019-02-06 01:14:15.033518
Model ind 579 epoch 779 head B head_i_epoch 0 batch 100: avg loss -1.892449 avg loss no lamb -1.892449 time 2019-02-06 01:17:13.724339
Model ind 579 epoch 779 head B head_i_epoch 0 batch 200: avg loss -1.844961 avg loss no lamb -1.844961 time 2019-02-06 01:20:12.998164
Model ind 579 epoch 779 head A head_i_epoch 0 batch 0: avg loss -3.527169 avg loss no lamb -3.527169 time 2019-02-06 01:23:11.976077
Model ind 579 epoch 779 head A head_i_epoch 0 batch 100: avg loss -3.568699 avg loss no lamb -3.568699 time 2019-02-06 01:26:11.243859
Model ind 579 epoch 779 head A head_i_epoch 0 batch 200: avg loss -3.577034 avg loss no lamb -3.577034 time 2019-02-06 01:29:10.875410
Pre: time 2019-02-06 01:32:36.316911: 
 	std: 0.0043151393
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25278333, 0.25191668, 0.24178334, 0.25245, 0.25298333]
	train_accs: [0.25278333, 0.25191668, 0.24178334, 0.25245, 0.25298333]
	best_train_sub_head: 4
	worst: 0.24178334
	avg: 0.25038332
	best: 0.25298333

Starting e_i: 780
Model ind 579 epoch 780 head B head_i_epoch 0 batch 0: avg loss -1.881250 avg loss no lamb -1.881250 time 2019-02-06 01:32:40.199722
Model ind 579 epoch 780 head B head_i_epoch 0 batch 100: avg loss -1.860585 avg loss no lamb -1.860585 time 2019-02-06 01:35:38.561117
Model ind 579 epoch 780 head B head_i_epoch 0 batch 200: avg loss -1.804365 avg loss no lamb -1.804365 time 2019-02-06 01:38:37.123375
Model ind 579 epoch 780 head A head_i_epoch 0 batch 0: avg loss -3.487053 avg loss no lamb -3.487053 time 2019-02-06 01:41:36.079271
Model ind 579 epoch 780 head A head_i_epoch 0 batch 100: avg loss -3.583997 avg loss no lamb -3.583997 time 2019-02-06 01:44:36.805828
Model ind 579 epoch 780 head A head_i_epoch 0 batch 200: avg loss -3.499020 avg loss no lamb -3.499020 time 2019-02-06 01:47:36.205788
Pre: time 2019-02-06 01:50:59.103915: 
 	std: 0.0047679553
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25116667, 0.25131667, 0.23963334, 0.25141665, 0.25218335]
	train_accs: [0.25116667, 0.25131667, 0.23963334, 0.25141665, 0.25218335]
	best_train_sub_head: 4
	worst: 0.23963334
	avg: 0.24914333
	best: 0.25218335

Starting e_i: 781
Model ind 579 epoch 781 head B head_i_epoch 0 batch 0: avg loss -1.888660 avg loss no lamb -1.888660 time 2019-02-06 01:51:08.253527
Model ind 579 epoch 781 head B head_i_epoch 0 batch 100: avg loss -1.914362 avg loss no lamb -1.914362 time 2019-02-06 01:54:06.660168
Model ind 579 epoch 781 head B head_i_epoch 0 batch 200: avg loss -1.807114 avg loss no lamb -1.807114 time 2019-02-06 01:57:51.068177
Model ind 579 epoch 781 head A head_i_epoch 0 batch 0: avg loss -3.486415 avg loss no lamb -3.486415 time 2019-02-06 02:01:44.823681
Model ind 579 epoch 781 head A head_i_epoch 0 batch 100: avg loss -3.549555 avg loss no lamb -3.549555 time 2019-02-06 02:05:39.885364
Model ind 579 epoch 781 head A head_i_epoch 0 batch 200: avg loss -3.491517 avg loss no lamb -3.491517 time 2019-02-06 02:09:35.279893
Pre: time 2019-02-06 02:14:03.612905: 
 	std: 0.004841957
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25131667, 0.2512, 0.23948333, 0.25153333, 0.25218335]
	train_accs: [0.25131667, 0.2512, 0.23948333, 0.25153333, 0.25218335]
	best_train_sub_head: 4
	worst: 0.23948333
	avg: 0.24914333
	best: 0.25218335

Starting e_i: 782
Model ind 579 epoch 782 head B head_i_epoch 0 batch 0: avg loss -1.857147 avg loss no lamb -1.857147 time 2019-02-06 02:14:08.760130
Model ind 579 epoch 782 head B head_i_epoch 0 batch 100: avg loss -1.855130 avg loss no lamb -1.855130 time 2019-02-06 02:18:02.905017
Model ind 579 epoch 782 head B head_i_epoch 0 batch 200: avg loss -1.870999 avg loss no lamb -1.870999 time 2019-02-06 02:21:58.994914
Model ind 579 epoch 782 head A head_i_epoch 0 batch 0: avg loss -3.521600 avg loss no lamb -3.521600 time 2019-02-06 02:25:55.506529
Model ind 579 epoch 782 head A head_i_epoch 0 batch 100: avg loss -3.593419 avg loss no lamb -3.593419 time 2019-02-06 02:28:57.845505
Model ind 579 epoch 782 head A head_i_epoch 0 batch 200: avg loss -3.524476 avg loss no lamb -3.524476 time 2019-02-06 02:31:58.227452
Pre: time 2019-02-06 02:35:23.920473: 
 	std: 0.0048268572
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25311667, 0.2529, 0.24115, 0.25296667, 0.25378335]
	train_accs: [0.25311667, 0.2529, 0.24115, 0.25296667, 0.25378335]
	best_train_sub_head: 4
	worst: 0.24115
	avg: 0.25078335
	best: 0.25378335

Starting e_i: 783
Model ind 579 epoch 783 head B head_i_epoch 0 batch 0: avg loss -1.837280 avg loss no lamb -1.837280 time 2019-02-06 02:35:27.841480
Model ind 579 epoch 783 head B head_i_epoch 0 batch 100: avg loss -1.959902 avg loss no lamb -1.959902 time 2019-02-06 02:38:25.264185
Model ind 579 epoch 783 head B head_i_epoch 0 batch 200: avg loss -1.866628 avg loss no lamb -1.866628 time 2019-02-06 02:41:23.538078
Model ind 579 epoch 783 head A head_i_epoch 0 batch 0: avg loss -3.459398 avg loss no lamb -3.459398 time 2019-02-06 02:44:22.232544
Model ind 579 epoch 783 head A head_i_epoch 0 batch 100: avg loss -3.558532 avg loss no lamb -3.558532 time 2019-02-06 02:47:21.704099
Model ind 579 epoch 783 head A head_i_epoch 0 batch 200: avg loss -3.596156 avg loss no lamb -3.596156 time 2019-02-06 02:50:21.652856
Pre: time 2019-02-06 02:53:45.497904: 
 	std: 0.0042944364
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25321665, 0.25335, 0.24253333, 0.25281668, 0.25361666]
	train_accs: [0.25321665, 0.25335, 0.24253333, 0.25281668, 0.25361666]
	best_train_sub_head: 4
	worst: 0.24253333
	avg: 0.25110668
	best: 0.25361666

Starting e_i: 784
Model ind 579 epoch 784 head B head_i_epoch 0 batch 0: avg loss -1.891686 avg loss no lamb -1.891686 time 2019-02-06 02:53:49.525768
Model ind 579 epoch 784 head B head_i_epoch 0 batch 100: avg loss -1.907540 avg loss no lamb -1.907540 time 2019-02-06 02:56:47.908670
Model ind 579 epoch 784 head B head_i_epoch 0 batch 200: avg loss -1.866945 avg loss no lamb -1.866945 time 2019-02-06 02:59:46.328821
Model ind 579 epoch 784 head A head_i_epoch 0 batch 0: avg loss -3.505230 avg loss no lamb -3.505230 time 2019-02-06 03:02:44.639800
Model ind 579 epoch 784 head A head_i_epoch 0 batch 100: avg loss -3.506255 avg loss no lamb -3.506255 time 2019-02-06 03:05:43.881169
Model ind 579 epoch 784 head A head_i_epoch 0 batch 200: avg loss -3.542501 avg loss no lamb -3.542501 time 2019-02-06 03:08:43.314235
Pre: time 2019-02-06 03:12:07.925067: 
 	std: 0.004532246
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2526, 0.25345, 0.24163334, 0.25238332, 0.25325]
	train_accs: [0.2526, 0.25345, 0.24163334, 0.25238332, 0.25325]
	best_train_sub_head: 1
	worst: 0.24163334
	avg: 0.25066334
	best: 0.25345

Starting e_i: 785
Model ind 579 epoch 785 head B head_i_epoch 0 batch 0: avg loss -1.985315 avg loss no lamb -1.985315 time 2019-02-06 03:12:11.846280
Model ind 579 epoch 785 head B head_i_epoch 0 batch 100: avg loss -1.918876 avg loss no lamb -1.918876 time 2019-02-06 03:15:10.682261
Model ind 579 epoch 785 head B head_i_epoch 0 batch 200: avg loss -1.908143 avg loss no lamb -1.908143 time 2019-02-06 03:18:08.761524
Model ind 579 epoch 785 head A head_i_epoch 0 batch 0: avg loss -3.463851 avg loss no lamb -3.463851 time 2019-02-06 03:21:07.773149
Model ind 579 epoch 785 head A head_i_epoch 0 batch 100: avg loss -3.568349 avg loss no lamb -3.568349 time 2019-02-06 03:24:07.873797
Model ind 579 epoch 785 head A head_i_epoch 0 batch 200: avg loss -3.550965 avg loss no lamb -3.550965 time 2019-02-06 03:27:07.074586
Pre: time 2019-02-06 03:30:32.395678: 
 	std: 0.0050659208
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25088334, 0.25166667, 0.23865, 0.25095, 0.25165]
	train_accs: [0.25088334, 0.25166667, 0.23865, 0.25095, 0.25165]
	best_train_sub_head: 1
	worst: 0.23865
	avg: 0.24875998
	best: 0.25166667

Starting e_i: 786
Model ind 579 epoch 786 head B head_i_epoch 0 batch 0: avg loss -1.916845 avg loss no lamb -1.916845 time 2019-02-06 03:30:36.430065
Model ind 579 epoch 786 head B head_i_epoch 0 batch 100: avg loss -1.797090 avg loss no lamb -1.797090 time 2019-02-06 03:33:36.200319
Model ind 579 epoch 786 head B head_i_epoch 0 batch 200: avg loss -1.853854 avg loss no lamb -1.853854 time 2019-02-06 03:36:34.544507
Model ind 579 epoch 786 head A head_i_epoch 0 batch 0: avg loss -3.479407 avg loss no lamb -3.479407 time 2019-02-06 03:39:33.906659
Model ind 579 epoch 786 head A head_i_epoch 0 batch 100: avg loss -3.532838 avg loss no lamb -3.532838 time 2019-02-06 03:42:33.433462
Model ind 579 epoch 786 head A head_i_epoch 0 batch 200: avg loss -3.486447 avg loss no lamb -3.486447 time 2019-02-06 03:45:32.900404
Pre: time 2019-02-06 03:48:56.736269: 
 	std: 0.0047293603
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25221667, 0.25225, 0.24048333, 0.25213334, 0.2526]
	train_accs: [0.25221667, 0.25225, 0.24048333, 0.25213334, 0.2526]
	best_train_sub_head: 4
	worst: 0.24048333
	avg: 0.24993667
	best: 0.2526

Starting e_i: 787
Model ind 579 epoch 787 head B head_i_epoch 0 batch 0: avg loss -1.875131 avg loss no lamb -1.875131 time 2019-02-06 03:49:00.734717
Model ind 579 epoch 787 head B head_i_epoch 0 batch 100: avg loss -1.852700 avg loss no lamb -1.852700 time 2019-02-06 03:51:59.509698
Model ind 579 epoch 787 head B head_i_epoch 0 batch 200: avg loss -1.953235 avg loss no lamb -1.953235 time 2019-02-06 03:54:59.648131
Model ind 579 epoch 787 head A head_i_epoch 0 batch 0: avg loss -3.461224 avg loss no lamb -3.461224 time 2019-02-06 03:57:57.330718
Model ind 579 epoch 787 head A head_i_epoch 0 batch 100: avg loss -3.469545 avg loss no lamb -3.469545 time 2019-02-06 04:00:57.288632
Model ind 579 epoch 787 head A head_i_epoch 0 batch 200: avg loss -3.538645 avg loss no lamb -3.538645 time 2019-02-06 04:03:57.002571
Pre: time 2019-02-06 04:07:20.220565: 
 	std: 0.0043955473
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2511, 0.2509, 0.2398, 0.25033334, 0.25075]
	train_accs: [0.2511, 0.2509, 0.2398, 0.25033334, 0.25075]
	best_train_sub_head: 0
	worst: 0.2398
	avg: 0.24857664
	best: 0.2511

Starting e_i: 788
Model ind 579 epoch 788 head B head_i_epoch 0 batch 0: avg loss -1.880881 avg loss no lamb -1.880881 time 2019-02-06 04:07:24.166586
Model ind 579 epoch 788 head B head_i_epoch 0 batch 100: avg loss -1.851556 avg loss no lamb -1.851556 time 2019-02-06 04:10:23.336340
Model ind 579 epoch 788 head B head_i_epoch 0 batch 200: avg loss -1.930154 avg loss no lamb -1.930154 time 2019-02-06 04:13:21.559048
Model ind 579 epoch 788 head A head_i_epoch 0 batch 0: avg loss -3.539858 avg loss no lamb -3.539858 time 2019-02-06 04:16:19.487386
Model ind 579 epoch 788 head A head_i_epoch 0 batch 100: avg loss -3.493343 avg loss no lamb -3.493343 time 2019-02-06 04:19:19.333645
Model ind 579 epoch 788 head A head_i_epoch 0 batch 200: avg loss -3.480032 avg loss no lamb -3.480032 time 2019-02-06 04:22:19.764558
Pre: time 2019-02-06 04:25:43.215759: 
 	std: 0.004751495
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.2513, 0.25106665, 0.23931667, 0.2508, 0.25155]
	train_accs: [0.2513, 0.25106665, 0.23931667, 0.2508, 0.25155]
	best_train_sub_head: 4
	worst: 0.23931667
	avg: 0.24880667
	best: 0.25155

Starting e_i: 789
Model ind 579 epoch 789 head B head_i_epoch 0 batch 0: avg loss -1.845269 avg loss no lamb -1.845269 time 2019-02-06 04:25:47.858826
Model ind 579 epoch 789 head B head_i_epoch 0 batch 100: avg loss -1.883475 avg loss no lamb -1.883475 time 2019-02-06 04:28:46.567367
Model ind 579 epoch 789 head B head_i_epoch 0 batch 200: avg loss -1.893860 avg loss no lamb -1.893860 time 2019-02-06 04:31:44.456716
Model ind 579 epoch 789 head A head_i_epoch 0 batch 0: avg loss -3.523285 avg loss no lamb -3.523285 time 2019-02-06 04:34:43.864962
Model ind 579 epoch 789 head A head_i_epoch 0 batch 100: avg loss -3.518809 avg loss no lamb -3.518809 time 2019-02-06 04:37:42.809541
Model ind 579 epoch 789 head A head_i_epoch 0 batch 200: avg loss -3.464912 avg loss no lamb -3.464912 time 2019-02-06 04:40:41.987635
Pre: time 2019-02-06 04:44:06.336581: 
 	std: 0.004821799
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25145, 0.25083333, 0.239, 0.25071666, 0.25115]
	train_accs: [0.25145, 0.25083333, 0.239, 0.25071666, 0.25115]
	best_train_sub_head: 0
	worst: 0.239
	avg: 0.24863
	best: 0.25145

Starting e_i: 790
Model ind 579 epoch 790 head B head_i_epoch 0 batch 0: avg loss -1.875961 avg loss no lamb -1.875961 time 2019-02-06 04:44:10.433875
Model ind 579 epoch 790 head B head_i_epoch 0 batch 100: avg loss -1.859710 avg loss no lamb -1.859710 time 2019-02-06 04:47:09.523545
Model ind 579 epoch 790 head B head_i_epoch 0 batch 200: avg loss -1.838900 avg loss no lamb -1.838900 time 2019-02-06 04:50:07.929413
Model ind 579 epoch 790 head A head_i_epoch 0 batch 0: avg loss -3.511876 avg loss no lamb -3.511876 time 2019-02-06 04:53:07.159473
Model ind 579 epoch 790 head A head_i_epoch 0 batch 100: avg loss -3.505252 avg loss no lamb -3.505252 time 2019-02-06 04:56:06.649197
Model ind 579 epoch 790 head A head_i_epoch 0 batch 200: avg loss -3.427379 avg loss no lamb -3.427379 time 2019-02-06 04:59:05.425455
Pre: time 2019-02-06 05:02:28.951967: 
 	std: 0.004795175
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25345, 0.25303334, 0.24143334, 0.25341666, 0.25373334]
	train_accs: [0.25345, 0.25303334, 0.24143334, 0.25341666, 0.25373334]
	best_train_sub_head: 4
	worst: 0.24143334
	avg: 0.25101334
	best: 0.25373334

Starting e_i: 791
Model ind 579 epoch 791 head B head_i_epoch 0 batch 0: avg loss -1.878078 avg loss no lamb -1.878078 time 2019-02-06 05:02:36.036087
Model ind 579 epoch 791 head B head_i_epoch 0 batch 100: avg loss -1.883466 avg loss no lamb -1.883466 time 2019-02-06 05:05:35.353826
Model ind 579 epoch 791 head B head_i_epoch 0 batch 200: avg loss -1.840975 avg loss no lamb -1.840975 time 2019-02-06 05:08:33.388383
Model ind 579 epoch 791 head A head_i_epoch 0 batch 0: avg loss -3.398566 avg loss no lamb -3.398566 time 2019-02-06 05:11:31.562403
Model ind 579 epoch 791 head A head_i_epoch 0 batch 100: avg loss -3.562243 avg loss no lamb -3.562243 time 2019-02-06 05:14:30.880920
Model ind 579 epoch 791 head A head_i_epoch 0 batch 200: avg loss -3.464310 avg loss no lamb -3.464310 time 2019-02-06 05:17:29.534912
Pre: time 2019-02-06 05:20:55.479418: 
 	std: 0.00455308
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25141665, 0.25083333, 0.2395, 0.25041667, 0.25075]
	train_accs: [0.25141665, 0.25083333, 0.2395, 0.25041667, 0.25075]
	best_train_sub_head: 0
	worst: 0.2395
	avg: 0.24858332
	best: 0.25141665

Starting e_i: 792
Model ind 579 epoch 792 head B head_i_epoch 0 batch 0: avg loss -1.822648 avg loss no lamb -1.822648 time 2019-02-06 05:20:59.405764
Model ind 579 epoch 792 head B head_i_epoch 0 batch 100: avg loss -1.771041 avg loss no lamb -1.771041 time 2019-02-06 05:23:58.197070
Model ind 579 epoch 792 head B head_i_epoch 0 batch 200: avg loss -1.894052 avg loss no lamb -1.894052 time 2019-02-06 05:26:56.325450
Model ind 579 epoch 792 head A head_i_epoch 0 batch 0: avg loss -3.560310 avg loss no lamb -3.560310 time 2019-02-06 05:29:55.573364
Model ind 579 epoch 792 head A head_i_epoch 0 batch 100: avg loss -3.534035 avg loss no lamb -3.534035 time 2019-02-06 05:32:54.424383
Model ind 579 epoch 792 head A head_i_epoch 0 batch 200: avg loss -3.540662 avg loss no lamb -3.540662 time 2019-02-06 05:35:53.555872
Pre: time 2019-02-06 05:39:17.168112: 
 	std: 0.0042802286
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25045, 0.2501, 0.23951666, 0.2498, 0.25045]
	train_accs: [0.25045, 0.2501, 0.23951666, 0.2498, 0.25045]
	best_train_sub_head: 0
	worst: 0.23951666
	avg: 0.24806333
	best: 0.25045

Starting e_i: 793
Model ind 579 epoch 793 head B head_i_epoch 0 batch 0: avg loss -1.897414 avg loss no lamb -1.897414 time 2019-02-06 05:39:21.116377
Model ind 579 epoch 793 head B head_i_epoch 0 batch 100: avg loss -1.832974 avg loss no lamb -1.832974 time 2019-02-06 05:42:18.458770
Model ind 579 epoch 793 head B head_i_epoch 0 batch 200: avg loss -1.865432 avg loss no lamb -1.865432 time 2019-02-06 05:45:17.015964
Model ind 579 epoch 793 head A head_i_epoch 0 batch 0: avg loss -3.458231 avg loss no lamb -3.458231 time 2019-02-06 05:48:15.953114
Model ind 579 epoch 793 head A head_i_epoch 0 batch 100: avg loss -3.507247 avg loss no lamb -3.507247 time 2019-02-06 05:51:15.446001
Model ind 579 epoch 793 head A head_i_epoch 0 batch 200: avg loss -3.505294 avg loss no lamb -3.505294 time 2019-02-06 05:54:14.973710
Pre: time 2019-02-06 05:57:39.876175: 
 	std: 0.004395419
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25173333, 0.25136667, 0.24063334, 0.25106665, 0.25216666]
	train_accs: [0.25173333, 0.25136667, 0.24063334, 0.25106665, 0.25216666]
	best_train_sub_head: 4
	worst: 0.24063334
	avg: 0.24939334
	best: 0.25216666

Starting e_i: 794
Model ind 579 epoch 794 head B head_i_epoch 0 batch 0: avg loss -1.895567 avg loss no lamb -1.895567 time 2019-02-06 05:57:44.466290
Model ind 579 epoch 794 head B head_i_epoch 0 batch 100: avg loss -1.788434 avg loss no lamb -1.788434 time 2019-02-06 06:00:42.196472
Model ind 579 epoch 794 head B head_i_epoch 0 batch 200: avg loss -1.931610 avg loss no lamb -1.931610 time 2019-02-06 06:03:39.732544
Model ind 579 epoch 794 head A head_i_epoch 0 batch 0: avg loss -3.496223 avg loss no lamb -3.496223 time 2019-02-06 06:06:37.115750
Model ind 579 epoch 794 head A head_i_epoch 0 batch 100: avg loss -3.582596 avg loss no lamb -3.582596 time 2019-02-06 06:09:35.756626
Model ind 579 epoch 794 head A head_i_epoch 0 batch 200: avg loss -3.498861 avg loss no lamb -3.498861 time 2019-02-06 06:12:33.782356
Pre: time 2019-02-06 06:15:57.374099: 
 	std: 0.004647362
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25106665, 0.25108334, 0.23958333, 0.25085, 0.25171667]
	train_accs: [0.25106665, 0.25108334, 0.23958333, 0.25085, 0.25171667]
	best_train_sub_head: 4
	worst: 0.23958333
	avg: 0.24885997
	best: 0.25171667

Starting e_i: 795
Model ind 579 epoch 795 head B head_i_epoch 0 batch 0: avg loss -1.895684 avg loss no lamb -1.895684 time 2019-02-06 06:16:01.418514
Model ind 579 epoch 795 head B head_i_epoch 0 batch 100: avg loss -1.865951 avg loss no lamb -1.865951 time 2019-02-06 06:19:00.917940
Model ind 579 epoch 795 head B head_i_epoch 0 batch 200: avg loss -1.898111 avg loss no lamb -1.898111 time 2019-02-06 06:21:59.863649
Model ind 579 epoch 795 head A head_i_epoch 0 batch 0: avg loss -3.465445 avg loss no lamb -3.465445 time 2019-02-06 06:24:59.119791
Model ind 579 epoch 795 head A head_i_epoch 0 batch 100: avg loss -3.541736 avg loss no lamb -3.541736 time 2019-02-06 06:27:59.331266
Model ind 579 epoch 795 head A head_i_epoch 0 batch 200: avg loss -3.534338 avg loss no lamb -3.534338 time 2019-02-06 06:30:58.841165
Pre: time 2019-02-06 06:34:23.774595: 
 	std: 0.0044130264
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2506, 0.25048333, 0.2393, 0.25005, 0.25015]
	train_accs: [0.2506, 0.25048333, 0.2393, 0.25005, 0.25015]
	best_train_sub_head: 0
	worst: 0.2393
	avg: 0.24811669
	best: 0.2506

Starting e_i: 796
Model ind 579 epoch 796 head B head_i_epoch 0 batch 0: avg loss -1.928685 avg loss no lamb -1.928685 time 2019-02-06 06:34:27.812251
Model ind 579 epoch 796 head B head_i_epoch 0 batch 100: avg loss -1.856375 avg loss no lamb -1.856375 time 2019-02-06 06:37:25.682567
Model ind 579 epoch 796 head B head_i_epoch 0 batch 200: avg loss -1.896488 avg loss no lamb -1.896488 time 2019-02-06 06:40:23.154779
Model ind 579 epoch 796 head A head_i_epoch 0 batch 0: avg loss -3.532809 avg loss no lamb -3.532809 time 2019-02-06 06:43:21.487877
Model ind 579 epoch 796 head A head_i_epoch 0 batch 100: avg loss -3.516915 avg loss no lamb -3.516915 time 2019-02-06 06:46:20.416657
Model ind 579 epoch 796 head A head_i_epoch 0 batch 200: avg loss -3.531073 avg loss no lamb -3.531073 time 2019-02-06 06:49:19.473135
Pre: time 2019-02-06 06:52:43.594136: 
 	std: 0.0042638197
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25365, 0.25421667, 0.24306667, 0.25308332, 0.2538]
	train_accs: [0.25365, 0.25421667, 0.24306667, 0.25308332, 0.2538]
	best_train_sub_head: 1
	worst: 0.24306667
	avg: 0.25156334
	best: 0.25421667

Starting e_i: 797
Model ind 579 epoch 797 head B head_i_epoch 0 batch 0: avg loss -1.940447 avg loss no lamb -1.940447 time 2019-02-06 06:52:51.560474
Model ind 579 epoch 797 head B head_i_epoch 0 batch 100: avg loss -1.915468 avg loss no lamb -1.915468 time 2019-02-06 06:55:48.475025
Model ind 579 epoch 797 head B head_i_epoch 0 batch 200: avg loss -1.874789 avg loss no lamb -1.874789 time 2019-02-06 06:58:46.170762
Model ind 579 epoch 797 head A head_i_epoch 0 batch 0: avg loss -3.552841 avg loss no lamb -3.552841 time 2019-02-06 07:01:44.459935
Model ind 579 epoch 797 head A head_i_epoch 0 batch 100: avg loss -3.554459 avg loss no lamb -3.554459 time 2019-02-06 07:04:43.082913
Model ind 579 epoch 797 head A head_i_epoch 0 batch 200: avg loss -3.531315 avg loss no lamb -3.531315 time 2019-02-06 07:07:42.059872
Pre: time 2019-02-06 07:11:05.830268: 
 	std: 0.0041570566
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 15), (3, 13), (4, 4), (5, 5), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25116667, 0.25206667, 0.24103333, 0.25105, 0.25126666]
	train_accs: [0.25116667, 0.25206667, 0.24103333, 0.25105, 0.25126666]
	best_train_sub_head: 1
	worst: 0.24103333
	avg: 0.24931665
	best: 0.25206667

Starting e_i: 798
Model ind 579 epoch 798 head B head_i_epoch 0 batch 0: avg loss -1.816844 avg loss no lamb -1.816844 time 2019-02-06 07:11:09.842360
Model ind 579 epoch 798 head B head_i_epoch 0 batch 100: avg loss -1.859898 avg loss no lamb -1.859898 time 2019-02-06 07:14:08.216696
Model ind 579 epoch 798 head B head_i_epoch 0 batch 200: avg loss -1.863451 avg loss no lamb -1.863451 time 2019-02-06 07:17:07.177937
Model ind 579 epoch 798 head A head_i_epoch 0 batch 0: avg loss -3.496901 avg loss no lamb -3.496901 time 2019-02-06 07:20:06.111457
Model ind 579 epoch 798 head A head_i_epoch 0 batch 100: avg loss -3.563591 avg loss no lamb -3.563591 time 2019-02-06 07:23:04.619970
Model ind 579 epoch 798 head A head_i_epoch 0 batch 200: avg loss -3.495740 avg loss no lamb -3.495740 time 2019-02-06 07:26:03.471748
Pre: time 2019-02-06 07:29:27.827302: 
 	std: 0.004468844
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 5), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25115, 0.2519, 0.24021667, 0.25091666, 0.25146666]
	train_accs: [0.25115, 0.2519, 0.24021667, 0.25091666, 0.25146666]
	best_train_sub_head: 1
	worst: 0.24021667
	avg: 0.24912998
	best: 0.2519

Starting e_i: 799
Model ind 579 epoch 799 head B head_i_epoch 0 batch 0: avg loss -1.908826 avg loss no lamb -1.908826 time 2019-02-06 07:29:31.728119
Model ind 579 epoch 799 head B head_i_epoch 0 batch 100: avg loss -1.868795 avg loss no lamb -1.868795 time 2019-02-06 07:32:29.301291
Model ind 579 epoch 799 head B head_i_epoch 0 batch 200: avg loss -1.860999 avg loss no lamb -1.860999 time 2019-02-06 07:35:26.708790
Model ind 579 epoch 799 head A head_i_epoch 0 batch 0: avg loss -3.554460 avg loss no lamb -3.554460 time 2019-02-06 07:38:24.107845
Model ind 579 epoch 799 head A head_i_epoch 0 batch 100: avg loss -3.504893 avg loss no lamb -3.504893 time 2019-02-06 07:41:23.666619
Model ind 579 epoch 799 head A head_i_epoch 0 batch 200: avg loss -3.542844 avg loss no lamb -3.542844 time 2019-02-06 07:44:23.890416
Pre: time 2019-02-06 07:47:47.435213: 
 	std: 0.0049926657
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25275, 0.253, 0.24008334, 0.25193334, 0.25245]
	train_accs: [0.25275, 0.253, 0.24008334, 0.25193334, 0.25245]
	best_train_sub_head: 1
	worst: 0.24008334
	avg: 0.25004333
	best: 0.253

Starting e_i: 800
Model ind 579 epoch 800 head B head_i_epoch 0 batch 0: avg loss -1.938709 avg loss no lamb -1.938709 time 2019-02-06 07:47:51.432595
Model ind 579 epoch 800 head B head_i_epoch 0 batch 100: avg loss -1.854474 avg loss no lamb -1.854474 time 2019-02-06 07:50:49.406781
Model ind 579 epoch 800 head B head_i_epoch 0 batch 200: avg loss -1.928483 avg loss no lamb -1.928483 time 2019-02-06 07:53:47.146596
Model ind 579 epoch 800 head A head_i_epoch 0 batch 0: avg loss -3.545925 avg loss no lamb -3.545925 time 2019-02-06 07:56:44.657647
Model ind 579 epoch 800 head A head_i_epoch 0 batch 100: avg loss -3.479338 avg loss no lamb -3.479338 time 2019-02-06 07:59:43.721960
Model ind 579 epoch 800 head A head_i_epoch 0 batch 200: avg loss -3.533352 avg loss no lamb -3.533352 time 2019-02-06 08:02:43.001155
Pre: time 2019-02-06 08:06:07.276577: 
 	std: 0.004379704
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25116667, 0.25183332, 0.24043334, 0.25151667, 0.2509]
	train_accs: [0.25116667, 0.25183332, 0.24043334, 0.25151667, 0.2509]
	best_train_sub_head: 1
	worst: 0.24043334
	avg: 0.24917002
	best: 0.25183332

Starting e_i: 801
Model ind 579 epoch 801 head B head_i_epoch 0 batch 0: avg loss -1.916824 avg loss no lamb -1.916824 time 2019-02-06 08:06:18.336108
Model ind 579 epoch 801 head B head_i_epoch 0 batch 100: avg loss -1.967902 avg loss no lamb -1.967902 time 2019-02-06 08:09:16.601321
Model ind 579 epoch 801 head B head_i_epoch 0 batch 200: avg loss -1.852645 avg loss no lamb -1.852645 time 2019-02-06 08:12:13.870399
Model ind 579 epoch 801 head A head_i_epoch 0 batch 0: avg loss -3.490513 avg loss no lamb -3.490513 time 2019-02-06 08:15:11.602247
Model ind 579 epoch 801 head A head_i_epoch 0 batch 100: avg loss -3.532556 avg loss no lamb -3.532556 time 2019-02-06 08:18:10.694921
Model ind 579 epoch 801 head A head_i_epoch 0 batch 200: avg loss -3.538485 avg loss no lamb -3.538485 time 2019-02-06 08:21:09.912808
Pre: time 2019-02-06 08:24:32.645231: 
 	std: 0.0045488044
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25278333, 0.25351667, 0.2416, 0.25288334, 0.2526]
	train_accs: [0.25278333, 0.25351667, 0.2416, 0.25288334, 0.2526]
	best_train_sub_head: 1
	worst: 0.2416
	avg: 0.2506767
	best: 0.25351667

Starting e_i: 802
Model ind 579 epoch 802 head B head_i_epoch 0 batch 0: avg loss -1.878369 avg loss no lamb -1.878369 time 2019-02-06 08:24:36.682983
Model ind 579 epoch 802 head B head_i_epoch 0 batch 100: avg loss -1.833845 avg loss no lamb -1.833845 time 2019-02-06 08:27:34.549076
Model ind 579 epoch 802 head B head_i_epoch 0 batch 200: avg loss -1.885655 avg loss no lamb -1.885655 time 2019-02-06 08:30:32.663825
Model ind 579 epoch 802 head A head_i_epoch 0 batch 0: avg loss -3.508204 avg loss no lamb -3.508204 time 2019-02-06 08:33:30.836276
Model ind 579 epoch 802 head A head_i_epoch 0 batch 100: avg loss -3.540216 avg loss no lamb -3.540216 time 2019-02-06 08:36:30.084703
Model ind 579 epoch 802 head A head_i_epoch 0 batch 200: avg loss -3.527027 avg loss no lamb -3.527027 time 2019-02-06 08:39:28.853417
Pre: time 2019-02-06 08:42:52.979855: 
 	std: 0.0044156397
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25198334, 0.2527, 0.2411, 0.25185, 0.25191668]
	train_accs: [0.25198334, 0.2527, 0.2411, 0.25185, 0.25191668]
	best_train_sub_head: 1
	worst: 0.2411
	avg: 0.24991003
	best: 0.2527

Starting e_i: 803
Model ind 579 epoch 803 head B head_i_epoch 0 batch 0: avg loss -1.919764 avg loss no lamb -1.919764 time 2019-02-06 08:42:57.046959
Model ind 579 epoch 803 head B head_i_epoch 0 batch 100: avg loss -2.013786 avg loss no lamb -2.013786 time 2019-02-06 08:45:54.945476
Model ind 579 epoch 803 head B head_i_epoch 0 batch 200: avg loss -1.893061 avg loss no lamb -1.893061 time 2019-02-06 08:48:52.560251
Model ind 579 epoch 803 head A head_i_epoch 0 batch 0: avg loss -3.486040 avg loss no lamb -3.486040 time 2019-02-06 08:51:50.275454
Model ind 579 epoch 803 head A head_i_epoch 0 batch 100: avg loss -3.549880 avg loss no lamb -3.549880 time 2019-02-06 08:54:49.045458
Model ind 579 epoch 803 head A head_i_epoch 0 batch 200: avg loss -3.523019 avg loss no lamb -3.523019 time 2019-02-06 08:57:48.861370
Pre: time 2019-02-06 09:01:15.050609: 
 	std: 0.004917459
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25275, 0.25343335, 0.2407, 0.25288334, 0.25285]
	train_accs: [0.25275, 0.25343335, 0.2407, 0.25288334, 0.25285]
	best_train_sub_head: 1
	worst: 0.2407
	avg: 0.25052333
	best: 0.25343335

Starting e_i: 804
Model ind 579 epoch 804 head B head_i_epoch 0 batch 0: avg loss -1.897516 avg loss no lamb -1.897516 time 2019-02-06 09:01:19.352965
Model ind 579 epoch 804 head B head_i_epoch 0 batch 100: avg loss -1.895674 avg loss no lamb -1.895674 time 2019-02-06 09:04:16.641226
Model ind 579 epoch 804 head B head_i_epoch 0 batch 200: avg loss -1.879045 avg loss no lamb -1.879045 time 2019-02-06 09:07:14.823649
Model ind 579 epoch 804 head A head_i_epoch 0 batch 0: avg loss -3.554314 avg loss no lamb -3.554314 time 2019-02-06 09:10:14.151683
Model ind 579 epoch 804 head A head_i_epoch 0 batch 100: avg loss -3.506529 avg loss no lamb -3.506529 time 2019-02-06 09:13:15.456564
Model ind 579 epoch 804 head A head_i_epoch 0 batch 200: avg loss -3.558486 avg loss no lamb -3.558486 time 2019-02-06 09:16:14.936571
Pre: time 2019-02-06 09:19:38.907437: 
 	std: 0.00464936
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25246668, 0.25211668, 0.24055, 0.25206667, 0.25201666]
	train_accs: [0.25246668, 0.25211668, 0.24055, 0.25206667, 0.25201666]
	best_train_sub_head: 0
	worst: 0.24055
	avg: 0.24984333
	best: 0.25246668

Starting e_i: 805
Model ind 579 epoch 805 head B head_i_epoch 0 batch 0: avg loss -1.972830 avg loss no lamb -1.972830 time 2019-02-06 09:19:42.774126
Model ind 579 epoch 805 head B head_i_epoch 0 batch 100: avg loss -1.948117 avg loss no lamb -1.948117 time 2019-02-06 09:22:41.226177
Model ind 579 epoch 805 head B head_i_epoch 0 batch 200: avg loss -1.862245 avg loss no lamb -1.862245 time 2019-02-06 09:25:40.236832
Model ind 579 epoch 805 head A head_i_epoch 0 batch 0: avg loss -3.523741 avg loss no lamb -3.523741 time 2019-02-06 09:28:40.019400
Model ind 579 epoch 805 head A head_i_epoch 0 batch 100: avg loss -3.570406 avg loss no lamb -3.570406 time 2019-02-06 09:31:39.179417
Model ind 579 epoch 805 head A head_i_epoch 0 batch 200: avg loss -3.475419 avg loss no lamb -3.475419 time 2019-02-06 09:34:39.122964
Pre: time 2019-02-06 09:38:05.701068: 
 	std: 0.004621645
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2523, 0.25255, 0.24078333, 0.25231665, 0.25216666]
	train_accs: [0.2523, 0.25255, 0.24078333, 0.25231665, 0.25216666]
	best_train_sub_head: 1
	worst: 0.24078333
	avg: 0.25002334
	best: 0.25255

Starting e_i: 806
Model ind 579 epoch 806 head B head_i_epoch 0 batch 0: avg loss -1.952355 avg loss no lamb -1.952355 time 2019-02-06 09:38:10.177908
Model ind 579 epoch 806 head B head_i_epoch 0 batch 100: avg loss -1.829362 avg loss no lamb -1.829362 time 2019-02-06 09:41:08.868713
Model ind 579 epoch 806 head B head_i_epoch 0 batch 200: avg loss -1.863948 avg loss no lamb -1.863948 time 2019-02-06 09:44:06.299025
Model ind 579 epoch 806 head A head_i_epoch 0 batch 0: avg loss -3.514828 avg loss no lamb -3.514828 time 2019-02-06 09:47:04.532805
Model ind 579 epoch 806 head A head_i_epoch 0 batch 100: avg loss -3.553076 avg loss no lamb -3.553076 time 2019-02-06 09:50:05.129084
Model ind 579 epoch 806 head A head_i_epoch 0 batch 200: avg loss -3.580639 avg loss no lamb -3.580639 time 2019-02-06 09:53:05.159288
Pre: time 2019-02-06 09:56:29.726978: 
 	std: 0.004692438
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25118333, 0.25156668, 0.23961666, 0.25098333, 0.2516]
	train_accs: [0.25118333, 0.25156668, 0.23961666, 0.25098333, 0.2516]
	best_train_sub_head: 4
	worst: 0.23961666
	avg: 0.24899001
	best: 0.2516

Starting e_i: 807
Model ind 579 epoch 807 head B head_i_epoch 0 batch 0: avg loss -1.976277 avg loss no lamb -1.976277 time 2019-02-06 09:56:33.834964
Model ind 579 epoch 807 head B head_i_epoch 0 batch 100: avg loss -1.910731 avg loss no lamb -1.910731 time 2019-02-06 09:59:32.231112
Model ind 579 epoch 807 head B head_i_epoch 0 batch 200: avg loss -1.987570 avg loss no lamb -1.987570 time 2019-02-06 10:02:32.463835
Model ind 579 epoch 807 head A head_i_epoch 0 batch 0: avg loss -3.434578 avg loss no lamb -3.434578 time 2019-02-06 10:05:36.908950
Model ind 579 epoch 807 head A head_i_epoch 0 batch 100: avg loss -3.563953 avg loss no lamb -3.563953 time 2019-02-06 10:08:37.459165
Model ind 579 epoch 807 head A head_i_epoch 0 batch 200: avg loss -3.548609 avg loss no lamb -3.548609 time 2019-02-06 10:11:36.713145
Pre: time 2019-02-06 10:15:01.414789: 
 	std: 0.0047138254
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.253, 0.25351667, 0.24143334, 0.25283334, 0.25345]
	train_accs: [0.253, 0.25351667, 0.24143334, 0.25283334, 0.25345]
	best_train_sub_head: 1
	worst: 0.24143334
	avg: 0.25084668
	best: 0.25351667

Starting e_i: 808
Model ind 579 epoch 808 head B head_i_epoch 0 batch 0: avg loss -1.896609 avg loss no lamb -1.896609 time 2019-02-06 10:15:05.995967
Model ind 579 epoch 808 head B head_i_epoch 0 batch 100: avg loss -1.865702 avg loss no lamb -1.865702 time 2019-02-06 10:18:03.585827
Model ind 579 epoch 808 head B head_i_epoch 0 batch 200: avg loss -1.836615 avg loss no lamb -1.836615 time 2019-02-06 10:21:01.870964
Model ind 579 epoch 808 head A head_i_epoch 0 batch 0: avg loss -3.542250 avg loss no lamb -3.542250 time 2019-02-06 10:24:00.580135
Model ind 579 epoch 808 head A head_i_epoch 0 batch 100: avg loss -3.561392 avg loss no lamb -3.561392 time 2019-02-06 10:27:00.217055
Model ind 579 epoch 808 head A head_i_epoch 0 batch 200: avg loss -3.536380 avg loss no lamb -3.536380 time 2019-02-06 10:29:58.848293
Pre: time 2019-02-06 10:33:22.339215: 
 	std: 0.004177201
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25126666, 0.25141665, 0.24076666, 0.25101668, 0.25111666]
	train_accs: [0.25126666, 0.25141665, 0.24076666, 0.25101668, 0.25111666]
	best_train_sub_head: 1
	worst: 0.24076666
	avg: 0.24911666
	best: 0.25141665

Starting e_i: 809
Model ind 579 epoch 809 head B head_i_epoch 0 batch 0: avg loss -1.869572 avg loss no lamb -1.869572 time 2019-02-06 10:33:26.575684
Model ind 579 epoch 809 head B head_i_epoch 0 batch 100: avg loss -1.892214 avg loss no lamb -1.892214 time 2019-02-06 10:36:24.931756
Model ind 579 epoch 809 head B head_i_epoch 0 batch 200: avg loss -1.823462 avg loss no lamb -1.823462 time 2019-02-06 10:39:31.208433
Model ind 579 epoch 809 head A head_i_epoch 0 batch 0: avg loss -3.513492 avg loss no lamb -3.513492 time 2019-02-06 10:42:30.030735
Model ind 579 epoch 809 head A head_i_epoch 0 batch 100: avg loss -3.623585 avg loss no lamb -3.623585 time 2019-02-06 10:45:29.152987
Model ind 579 epoch 809 head A head_i_epoch 0 batch 200: avg loss -3.582462 avg loss no lamb -3.582462 time 2019-02-06 10:48:29.718473
Pre: time 2019-02-06 10:52:00.545788: 
 	std: 0.0041856878
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25173333, 0.2521, 0.24153334, 0.25213334, 0.252]
	train_accs: [0.25173333, 0.2521, 0.24153334, 0.25213334, 0.252]
	best_train_sub_head: 3
	worst: 0.24153334
	avg: 0.24989998
	best: 0.25213334

Starting e_i: 810
Model ind 579 epoch 810 head B head_i_epoch 0 batch 0: avg loss -1.910718 avg loss no lamb -1.910718 time 2019-02-06 10:52:05.494582
Model ind 579 epoch 810 head B head_i_epoch 0 batch 100: avg loss -1.903911 avg loss no lamb -1.903911 time 2019-02-06 10:55:04.086208
Model ind 579 epoch 810 head B head_i_epoch 0 batch 200: avg loss -1.980193 avg loss no lamb -1.980193 time 2019-02-06 10:58:01.706283
Model ind 579 epoch 810 head A head_i_epoch 0 batch 0: avg loss -3.483818 avg loss no lamb -3.483818 time 2019-02-06 11:00:59.381190
Model ind 579 epoch 810 head A head_i_epoch 0 batch 100: avg loss -3.626307 avg loss no lamb -3.626307 time 2019-02-06 11:03:58.947615
Model ind 579 epoch 810 head A head_i_epoch 0 batch 200: avg loss -3.627952 avg loss no lamb -3.627952 time 2019-02-06 11:07:04.930730
Pre: time 2019-02-06 11:10:29.399600: 
 	std: 0.004526507
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25255, 0.25253335, 0.24098334, 0.25223333, 0.2518]
	train_accs: [0.25255, 0.25253335, 0.24098334, 0.25223333, 0.2518]
	best_train_sub_head: 0
	worst: 0.24098334
	avg: 0.25002
	best: 0.25255

Starting e_i: 811
Model ind 579 epoch 811 head B head_i_epoch 0 batch 0: avg loss -1.925534 avg loss no lamb -1.925534 time 2019-02-06 11:10:36.824818
Model ind 579 epoch 811 head B head_i_epoch 0 batch 100: avg loss -1.898608 avg loss no lamb -1.898608 time 2019-02-06 11:13:36.069660
Model ind 579 epoch 811 head B head_i_epoch 0 batch 200: avg loss -1.899413 avg loss no lamb -1.899413 time 2019-02-06 11:16:34.638719
Model ind 579 epoch 811 head A head_i_epoch 0 batch 0: avg loss -3.539140 avg loss no lamb -3.539140 time 2019-02-06 11:19:32.358950
Model ind 579 epoch 811 head A head_i_epoch 0 batch 100: avg loss -3.523509 avg loss no lamb -3.523509 time 2019-02-06 11:22:32.613889
Model ind 579 epoch 811 head A head_i_epoch 0 batch 200: avg loss -3.602751 avg loss no lamb -3.602751 time 2019-02-06 11:25:32.778995
Pre: time 2019-02-06 11:28:58.215451: 
 	std: 0.0047538066
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25173333, 0.25176665, 0.23971666, 0.25163335, 0.25123334]
	train_accs: [0.25173333, 0.25176665, 0.23971666, 0.25163335, 0.25123334]
	best_train_sub_head: 1
	worst: 0.23971666
	avg: 0.24921665
	best: 0.25176665

Starting e_i: 812
Model ind 579 epoch 812 head B head_i_epoch 0 batch 0: avg loss -1.912292 avg loss no lamb -1.912292 time 2019-02-06 11:29:02.319493
Model ind 579 epoch 812 head B head_i_epoch 0 batch 100: avg loss -1.824833 avg loss no lamb -1.824833 time 2019-02-06 11:31:59.397737
Model ind 579 epoch 812 head B head_i_epoch 0 batch 200: avg loss -1.845791 avg loss no lamb -1.845791 time 2019-02-06 11:34:56.770796
Model ind 579 epoch 812 head A head_i_epoch 0 batch 0: avg loss -3.493290 avg loss no lamb -3.493290 time 2019-02-06 11:37:56.034473
Model ind 579 epoch 812 head A head_i_epoch 0 batch 100: avg loss -3.516838 avg loss no lamb -3.516838 time 2019-02-06 11:41:02.001145
Model ind 579 epoch 812 head A head_i_epoch 0 batch 200: avg loss -3.502300 avg loss no lamb -3.502300 time 2019-02-06 11:44:13.190309
Pre: time 2019-02-06 11:47:37.905496: 
 	std: 0.0041319025
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25041667, 0.25056666, 0.24003333, 0.25068334, 0.24961667]
	train_accs: [0.25041667, 0.25056666, 0.24003333, 0.25068334, 0.24961667]
	best_train_sub_head: 3
	worst: 0.24003333
	avg: 0.24826333
	best: 0.25068334

Starting e_i: 813
Model ind 579 epoch 813 head B head_i_epoch 0 batch 0: avg loss -1.957614 avg loss no lamb -1.957614 time 2019-02-06 11:47:41.783969
Model ind 579 epoch 813 head B head_i_epoch 0 batch 100: avg loss -1.881536 avg loss no lamb -1.881536 time 2019-02-06 11:50:47.576179
Model ind 579 epoch 813 head B head_i_epoch 0 batch 200: avg loss -1.904052 avg loss no lamb -1.904052 time 2019-02-06 11:53:46.534077
Model ind 579 epoch 813 head A head_i_epoch 0 batch 0: avg loss -3.574446 avg loss no lamb -3.574446 time 2019-02-06 11:56:43.657801
Model ind 579 epoch 813 head A head_i_epoch 0 batch 100: avg loss -3.499892 avg loss no lamb -3.499892 time 2019-02-06 11:59:43.082412
Model ind 579 epoch 813 head A head_i_epoch 0 batch 200: avg loss -3.542101 avg loss no lamb -3.542101 time 2019-02-06 12:02:43.369614
Pre: time 2019-02-06 12:06:08.609379: 
 	std: 0.004069119
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 5), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25128335, 0.2514, 0.2411, 0.25115, 0.25125]
	train_accs: [0.25128335, 0.2514, 0.2411, 0.25115, 0.25125]
	best_train_sub_head: 1
	worst: 0.2411
	avg: 0.24923667
	best: 0.2514

Starting e_i: 814
Model ind 579 epoch 814 head B head_i_epoch 0 batch 0: avg loss -1.889595 avg loss no lamb -1.889595 time 2019-02-06 12:06:12.827238
Model ind 579 epoch 814 head B head_i_epoch 0 batch 100: avg loss -1.927465 avg loss no lamb -1.927465 time 2019-02-06 12:09:11.306440
Model ind 579 epoch 814 head B head_i_epoch 0 batch 200: avg loss -1.941091 avg loss no lamb -1.941091 time 2019-02-06 12:12:10.012069
Model ind 579 epoch 814 head A head_i_epoch 0 batch 0: avg loss -3.507056 avg loss no lamb -3.507056 time 2019-02-06 12:15:09.486375
Model ind 579 epoch 814 head A head_i_epoch 0 batch 100: avg loss -3.545682 avg loss no lamb -3.545682 time 2019-02-06 12:18:08.903542
Model ind 579 epoch 814 head A head_i_epoch 0 batch 200: avg loss -3.573940 avg loss no lamb -3.573940 time 2019-02-06 12:21:12.471302
Pre: time 2019-02-06 12:24:40.270136: 
 	std: 0.0046016187
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25411665, 0.25465, 0.24265, 0.25361666, 0.25411665]
	train_accs: [0.25411665, 0.25465, 0.24265, 0.25361666, 0.25411665]
	best_train_sub_head: 1
	worst: 0.24265
	avg: 0.25183
	best: 0.25465

Starting e_i: 815
Model ind 579 epoch 815 head B head_i_epoch 0 batch 0: avg loss -1.898168 avg loss no lamb -1.898168 time 2019-02-06 12:24:53.985129
Model ind 579 epoch 815 head B head_i_epoch 0 batch 100: avg loss -1.914545 avg loss no lamb -1.914545 time 2019-02-06 12:27:54.254568
Model ind 579 epoch 815 head B head_i_epoch 0 batch 200: avg loss -1.899728 avg loss no lamb -1.899728 time 2019-02-06 12:30:52.592916
Model ind 579 epoch 815 head A head_i_epoch 0 batch 0: avg loss -3.494635 avg loss no lamb -3.494635 time 2019-02-06 12:33:52.258957
Model ind 579 epoch 815 head A head_i_epoch 0 batch 100: avg loss -3.513568 avg loss no lamb -3.513568 time 2019-02-06 12:36:52.116343
Model ind 579 epoch 815 head A head_i_epoch 0 batch 200: avg loss -3.565273 avg loss no lamb -3.565273 time 2019-02-06 12:40:00.308079
Pre: time 2019-02-06 12:43:25.128684: 
 	std: 0.0049103447
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25326666, 0.25351667, 0.241, 0.25293332, 0.25335]
	train_accs: [0.25326666, 0.25351667, 0.241, 0.25293332, 0.25335]
	best_train_sub_head: 1
	worst: 0.241
	avg: 0.25081334
	best: 0.25351667

Starting e_i: 816
Model ind 579 epoch 816 head B head_i_epoch 0 batch 0: avg loss -1.817961 avg loss no lamb -1.817961 time 2019-02-06 12:43:29.464272
Model ind 579 epoch 816 head B head_i_epoch 0 batch 100: avg loss -1.905716 avg loss no lamb -1.905716 time 2019-02-06 12:46:27.763274
Model ind 579 epoch 816 head B head_i_epoch 0 batch 200: avg loss -1.874795 avg loss no lamb -1.874795 time 2019-02-06 12:49:27.665825
Model ind 579 epoch 816 head A head_i_epoch 0 batch 0: avg loss -3.520705 avg loss no lamb -3.520705 time 2019-02-06 12:52:25.788281
Model ind 579 epoch 816 head A head_i_epoch 0 batch 100: avg loss -3.592330 avg loss no lamb -3.592330 time 2019-02-06 12:55:25.934460
Model ind 579 epoch 816 head A head_i_epoch 0 batch 200: avg loss -3.505050 avg loss no lamb -3.505050 time 2019-02-06 12:58:26.045417
Pre: time 2019-02-06 13:01:52.260406: 
 	std: 0.004892732
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25218335, 0.25251666, 0.2402, 0.25233334, 0.25266665]
	train_accs: [0.25218335, 0.25251666, 0.2402, 0.25233334, 0.25266665]
	best_train_sub_head: 4
	worst: 0.2402
	avg: 0.24998
	best: 0.25266665

Starting e_i: 817
Model ind 579 epoch 817 head B head_i_epoch 0 batch 0: avg loss -1.788960 avg loss no lamb -1.788960 time 2019-02-06 13:01:56.319639
Model ind 579 epoch 817 head B head_i_epoch 0 batch 100: avg loss -1.864046 avg loss no lamb -1.864046 time 2019-02-06 13:04:55.365612
Model ind 579 epoch 817 head B head_i_epoch 0 batch 200: avg loss -1.911511 avg loss no lamb -1.911511 time 2019-02-06 13:07:54.709814
Model ind 579 epoch 817 head A head_i_epoch 0 batch 0: avg loss -3.494262 avg loss no lamb -3.494262 time 2019-02-06 13:10:53.101686
Model ind 579 epoch 817 head A head_i_epoch 0 batch 100: avg loss -3.580951 avg loss no lamb -3.580951 time 2019-02-06 13:13:52.021563
Model ind 579 epoch 817 head A head_i_epoch 0 batch 200: avg loss -3.515285 avg loss no lamb -3.515285 time 2019-02-06 13:16:52.004791
Pre: time 2019-02-06 13:20:16.517133: 
 	std: 0.004749119
	best_train_sub_head_match: [(0, 18), (1, 13), (2, 14), (3, 0), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 5), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25121668, 0.2509, 0.23908333, 0.25116667, 0.25046667]
	train_accs: [0.25121668, 0.2509, 0.23908333, 0.25116667, 0.25046667]
	best_train_sub_head: 0
	worst: 0.23908333
	avg: 0.24856667
	best: 0.25121668

Starting e_i: 818
Model ind 579 epoch 818 head B head_i_epoch 0 batch 0: avg loss -1.946185 avg loss no lamb -1.946185 time 2019-02-06 13:20:20.478028
Model ind 579 epoch 818 head B head_i_epoch 0 batch 100: avg loss -1.847128 avg loss no lamb -1.847128 time 2019-02-06 13:23:19.687305
Model ind 579 epoch 818 head B head_i_epoch 0 batch 200: avg loss -1.893908 avg loss no lamb -1.893908 time 2019-02-06 13:26:23.810221
Model ind 579 epoch 818 head A head_i_epoch 0 batch 0: avg loss -3.525158 avg loss no lamb -3.525158 time 2019-02-06 13:29:21.366409
Model ind 579 epoch 818 head A head_i_epoch 0 batch 100: avg loss -3.519446 avg loss no lamb -3.519446 time 2019-02-06 13:32:28.671192
Model ind 579 epoch 818 head A head_i_epoch 0 batch 200: avg loss -3.498127 avg loss no lamb -3.498127 time 2019-02-06 13:35:29.402945
Pre: time 2019-02-06 13:38:54.098355: 
 	std: 0.004113464
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25353333, 0.25356665, 0.24326667, 0.25335, 0.25373334]
	train_accs: [0.25353333, 0.25356665, 0.24326667, 0.25335, 0.25373334]
	best_train_sub_head: 4
	worst: 0.24326667
	avg: 0.25149003
	best: 0.25373334

Starting e_i: 819
Model ind 579 epoch 819 head B head_i_epoch 0 batch 0: avg loss -1.839215 avg loss no lamb -1.839215 time 2019-02-06 13:38:58.209701
Model ind 579 epoch 819 head B head_i_epoch 0 batch 100: avg loss -1.866670 avg loss no lamb -1.866670 time 2019-02-06 13:42:04.665594
Model ind 579 epoch 819 head B head_i_epoch 0 batch 200: avg loss -1.867585 avg loss no lamb -1.867585 time 2019-02-06 13:45:04.852918
Model ind 579 epoch 819 head A head_i_epoch 0 batch 0: avg loss -3.492290 avg loss no lamb -3.492290 time 2019-02-06 13:48:05.400306
Model ind 579 epoch 819 head A head_i_epoch 0 batch 100: avg loss -3.573331 avg loss no lamb -3.573331 time 2019-02-06 13:51:05.651576
Model ind 579 epoch 819 head A head_i_epoch 0 batch 200: avg loss -3.520763 avg loss no lamb -3.520763 time 2019-02-06 13:54:05.751651
Pre: time 2019-02-06 13:57:30.903497: 
 	std: 0.0039174967
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25211668, 0.25261667, 0.24236667, 0.2518, 0.25201666]
	train_accs: [0.25211668, 0.25261667, 0.24236667, 0.2518, 0.25201666]
	best_train_sub_head: 1
	worst: 0.24236667
	avg: 0.25018334
	best: 0.25261667

Starting e_i: 820
Model ind 579 epoch 820 head B head_i_epoch 0 batch 0: avg loss -1.854139 avg loss no lamb -1.854139 time 2019-02-06 13:57:36.885149
Model ind 579 epoch 820 head B head_i_epoch 0 batch 100: avg loss -1.922044 avg loss no lamb -1.922044 time 2019-02-06 14:00:35.703413
Model ind 579 epoch 820 head B head_i_epoch 0 batch 200: avg loss -1.932602 avg loss no lamb -1.932602 time 2019-02-06 14:03:35.650815
Model ind 579 epoch 820 head A head_i_epoch 0 batch 0: avg loss -3.527340 avg loss no lamb -3.527340 time 2019-02-06 14:06:35.231923
Model ind 579 epoch 820 head A head_i_epoch 0 batch 100: avg loss -3.560808 avg loss no lamb -3.560808 time 2019-02-06 14:09:36.801012
Model ind 579 epoch 820 head A head_i_epoch 0 batch 200: avg loss -3.478293 avg loss no lamb -3.478293 time 2019-02-06 14:12:35.994904
Pre: time 2019-02-06 14:16:01.028334: 
 	std: 0.004446551
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25348333, 0.25351667, 0.2424, 0.25325, 0.25378335]
	train_accs: [0.25348333, 0.25351667, 0.2424, 0.25325, 0.25378335]
	best_train_sub_head: 4
	worst: 0.2424
	avg: 0.2512867
	best: 0.25378335

Starting e_i: 821
Model ind 579 epoch 821 head B head_i_epoch 0 batch 0: avg loss -1.947364 avg loss no lamb -1.947364 time 2019-02-06 14:16:10.856135
Model ind 579 epoch 821 head B head_i_epoch 0 batch 100: avg loss -1.881637 avg loss no lamb -1.881637 time 2019-02-06 14:19:10.082325
Model ind 579 epoch 821 head B head_i_epoch 0 batch 200: avg loss -1.841292 avg loss no lamb -1.841292 time 2019-02-06 14:22:09.112643
Model ind 579 epoch 821 head A head_i_epoch 0 batch 0: avg loss -3.552202 avg loss no lamb -3.552202 time 2019-02-06 14:25:09.334647
Model ind 579 epoch 821 head A head_i_epoch 0 batch 100: avg loss -3.533188 avg loss no lamb -3.533188 time 2019-02-06 14:28:09.267785
Model ind 579 epoch 821 head A head_i_epoch 0 batch 200: avg loss -3.608541 avg loss no lamb -3.608541 time 2019-02-06 14:31:10.131013
Pre: time 2019-02-06 14:34:35.779390: 
 	std: 0.004666245
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25255, 0.25256667, 0.24071667, 0.25221667, 0.25216666]
	train_accs: [0.25255, 0.25256667, 0.24071667, 0.25221667, 0.25216666]
	best_train_sub_head: 1
	worst: 0.24071667
	avg: 0.25004333
	best: 0.25256667

Starting e_i: 822
Model ind 579 epoch 822 head B head_i_epoch 0 batch 0: avg loss -1.925033 avg loss no lamb -1.925033 time 2019-02-06 14:34:39.808484
Model ind 579 epoch 822 head B head_i_epoch 0 batch 100: avg loss -1.883559 avg loss no lamb -1.883559 time 2019-02-06 14:37:38.800996
Model ind 579 epoch 822 head B head_i_epoch 0 batch 200: avg loss -1.839577 avg loss no lamb -1.839577 time 2019-02-06 14:40:39.430393
Model ind 579 epoch 822 head A head_i_epoch 0 batch 0: avg loss -3.416055 avg loss no lamb -3.416055 time 2019-02-06 14:43:38.139038
Model ind 579 epoch 822 head A head_i_epoch 0 batch 100: avg loss -3.553517 avg loss no lamb -3.553517 time 2019-02-06 14:46:38.934361
Model ind 579 epoch 822 head A head_i_epoch 0 batch 200: avg loss -3.538621 avg loss no lamb -3.538621 time 2019-02-06 14:49:40.719889
Pre: time 2019-02-06 14:53:06.179115: 
 	std: 0.0041537713
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.2525, 0.25261667, 0.24216667, 0.25233334, 0.25273332]
	train_accs: [0.2525, 0.25261667, 0.24216667, 0.25233334, 0.25273332]
	best_train_sub_head: 4
	worst: 0.24216667
	avg: 0.25046998
	best: 0.25273332

Starting e_i: 823
Model ind 579 epoch 823 head B head_i_epoch 0 batch 0: avg loss -1.862562 avg loss no lamb -1.862562 time 2019-02-06 14:53:10.010480
Model ind 579 epoch 823 head B head_i_epoch 0 batch 100: avg loss -1.862592 avg loss no lamb -1.862592 time 2019-02-06 14:56:08.237232
Model ind 579 epoch 823 head B head_i_epoch 0 batch 200: avg loss -1.874175 avg loss no lamb -1.874175 time 2019-02-06 14:59:05.939553
Model ind 579 epoch 823 head A head_i_epoch 0 batch 0: avg loss -3.447678 avg loss no lamb -3.447678 time 2019-02-06 15:02:03.665009
Model ind 579 epoch 823 head A head_i_epoch 0 batch 100: avg loss -3.555645 avg loss no lamb -3.555645 time 2019-02-06 15:05:03.220386
Model ind 579 epoch 823 head A head_i_epoch 0 batch 200: avg loss -3.526030 avg loss no lamb -3.526030 time 2019-02-06 15:08:01.202995
Pre: time 2019-02-06 15:11:25.796822: 
 	std: 0.0045734956
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25173333, 0.25123334, 0.23986667, 0.25096667, 0.2512]
	train_accs: [0.25173333, 0.25123334, 0.23986667, 0.25096667, 0.2512]
	best_train_sub_head: 0
	worst: 0.23986667
	avg: 0.249
	best: 0.25173333

Starting e_i: 824
Model ind 579 epoch 824 head B head_i_epoch 0 batch 0: avg loss -1.834975 avg loss no lamb -1.834975 time 2019-02-06 15:11:29.884941
Model ind 579 epoch 824 head B head_i_epoch 0 batch 100: avg loss -1.903705 avg loss no lamb -1.903705 time 2019-02-06 15:14:28.723378
Model ind 579 epoch 824 head B head_i_epoch 0 batch 200: avg loss -1.914102 avg loss no lamb -1.914102 time 2019-02-06 15:17:27.241355
Model ind 579 epoch 824 head A head_i_epoch 0 batch 0: avg loss -3.487060 avg loss no lamb -3.487060 time 2019-02-06 15:20:27.426937
Model ind 579 epoch 824 head A head_i_epoch 0 batch 100: avg loss -3.577546 avg loss no lamb -3.577546 time 2019-02-06 15:23:28.775823
Model ind 579 epoch 824 head A head_i_epoch 0 batch 200: avg loss -3.558898 avg loss no lamb -3.558898 time 2019-02-06 15:26:29.406769
Pre: time 2019-02-06 15:29:55.089814: 
 	std: 0.0042804303
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2532, 0.25336668, 0.24245, 0.25301668, 0.253]
	train_accs: [0.2532, 0.25336668, 0.24245, 0.25301668, 0.253]
	best_train_sub_head: 1
	worst: 0.24245
	avg: 0.25100666
	best: 0.25336668

Starting e_i: 825
Model ind 579 epoch 825 head B head_i_epoch 0 batch 0: avg loss -1.880679 avg loss no lamb -1.880679 time 2019-02-06 15:29:59.170828
Model ind 579 epoch 825 head B head_i_epoch 0 batch 100: avg loss -1.863843 avg loss no lamb -1.863843 time 2019-02-06 15:32:58.693764
Model ind 579 epoch 825 head B head_i_epoch 0 batch 200: avg loss -1.880198 avg loss no lamb -1.880198 time 2019-02-06 15:35:57.167489
Model ind 579 epoch 825 head A head_i_epoch 0 batch 0: avg loss -3.552800 avg loss no lamb -3.552800 time 2019-02-06 15:38:55.793717
Model ind 579 epoch 825 head A head_i_epoch 0 batch 100: avg loss -3.550495 avg loss no lamb -3.550495 time 2019-02-06 15:41:55.506808
Model ind 579 epoch 825 head A head_i_epoch 0 batch 200: avg loss -3.554933 avg loss no lamb -3.554933 time 2019-02-06 15:44:56.128048
Pre: time 2019-02-06 15:48:24.004877: 
 	std: 0.0048426124
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25341666, 0.25346667, 0.24125, 0.25335, 0.25318334]
	train_accs: [0.25341666, 0.25346667, 0.24125, 0.25335, 0.25318334]
	best_train_sub_head: 1
	worst: 0.24125
	avg: 0.25093335
	best: 0.25346667

Starting e_i: 826
Model ind 579 epoch 826 head B head_i_epoch 0 batch 0: avg loss -1.961377 avg loss no lamb -1.961377 time 2019-02-06 15:48:27.891266
Model ind 579 epoch 826 head B head_i_epoch 0 batch 100: avg loss -1.861761 avg loss no lamb -1.861761 time 2019-02-06 15:51:52.261547
Model ind 579 epoch 826 head B head_i_epoch 0 batch 200: avg loss -1.857069 avg loss no lamb -1.857069 time 2019-02-06 15:56:07.949810
Model ind 579 epoch 826 head A head_i_epoch 0 batch 0: avg loss -3.544657 avg loss no lamb -3.544657 time 2019-02-06 16:00:34.005247
Model ind 579 epoch 826 head A head_i_epoch 0 batch 100: avg loss -3.520048 avg loss no lamb -3.520048 time 2019-02-06 16:04:55.523433
Model ind 579 epoch 826 head A head_i_epoch 0 batch 200: avg loss -3.491736 avg loss no lamb -3.491736 time 2019-02-06 16:09:21.181662
Pre: time 2019-02-06 16:14:20.231130: 
 	std: 0.00432594
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25441667, 0.25441667, 0.2434, 0.25371668, 0.25423333]
	train_accs: [0.25441667, 0.25441667, 0.2434, 0.25371668, 0.25423333]
	best_train_sub_head: 0
	worst: 0.2434
	avg: 0.25203666
	best: 0.25441667

Starting e_i: 827
Model ind 579 epoch 827 head B head_i_epoch 0 batch 0: avg loss -1.875610 avg loss no lamb -1.875610 time 2019-02-06 16:14:24.832403
Model ind 579 epoch 827 head B head_i_epoch 0 batch 100: avg loss -1.878039 avg loss no lamb -1.878039 time 2019-02-06 16:18:48.175265
Model ind 579 epoch 827 head B head_i_epoch 0 batch 200: avg loss -1.951583 avg loss no lamb -1.951583 time 2019-02-06 16:23:11.370909
Model ind 579 epoch 827 head A head_i_epoch 0 batch 0: avg loss -3.564046 avg loss no lamb -3.564046 time 2019-02-06 16:27:35.519145
Model ind 579 epoch 827 head A head_i_epoch 0 batch 100: avg loss -3.578153 avg loss no lamb -3.578153 time 2019-02-06 16:32:00.531373
Model ind 579 epoch 827 head A head_i_epoch 0 batch 200: avg loss -3.478905 avg loss no lamb -3.478905 time 2019-02-06 16:36:25.166384
Pre: time 2019-02-06 16:40:11.161427: 
 	std: 0.0046517826
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2552, 0.25523335, 0.24325, 0.25441667, 0.25455]
	train_accs: [0.2552, 0.25523335, 0.24325, 0.25441667, 0.25455]
	best_train_sub_head: 1
	worst: 0.24325
	avg: 0.25253
	best: 0.25523335

Starting e_i: 828
Model ind 579 epoch 828 head B head_i_epoch 0 batch 0: avg loss -1.957565 avg loss no lamb -1.957565 time 2019-02-06 16:40:20.420123
Model ind 579 epoch 828 head B head_i_epoch 0 batch 100: avg loss -1.886351 avg loss no lamb -1.886351 time 2019-02-06 16:43:31.485869
Model ind 579 epoch 828 head B head_i_epoch 0 batch 200: avg loss -1.890603 avg loss no lamb -1.890603 time 2019-02-06 16:47:41.283080
Model ind 579 epoch 828 head A head_i_epoch 0 batch 0: avg loss -3.533648 avg loss no lamb -3.533648 time 2019-02-06 16:52:04.655789
Model ind 579 epoch 828 head A head_i_epoch 0 batch 100: avg loss -3.562065 avg loss no lamb -3.562065 time 2019-02-06 16:56:30.638014
Model ind 579 epoch 828 head A head_i_epoch 0 batch 200: avg loss -3.530406 avg loss no lamb -3.530406 time 2019-02-06 17:00:47.225164
Pre: time 2019-02-06 17:05:48.448660: 
 	std: 0.005103537
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.252, 0.2518, 0.23908333, 0.2513, 0.25218335]
	train_accs: [0.252, 0.2518, 0.23908333, 0.2513, 0.25218335]
	best_train_sub_head: 4
	worst: 0.23908333
	avg: 0.24927334
	best: 0.25218335

Starting e_i: 829
Model ind 579 epoch 829 head B head_i_epoch 0 batch 0: avg loss -1.944917 avg loss no lamb -1.944917 time 2019-02-06 17:05:53.231638
Model ind 579 epoch 829 head B head_i_epoch 0 batch 100: avg loss -1.799662 avg loss no lamb -1.799662 time 2019-02-06 17:10:08.326120
Model ind 579 epoch 829 head B head_i_epoch 0 batch 200: avg loss -1.856791 avg loss no lamb -1.856791 time 2019-02-06 17:14:29.072539
Model ind 579 epoch 829 head A head_i_epoch 0 batch 0: avg loss -3.478528 avg loss no lamb -3.478528 time 2019-02-06 17:18:48.615115
Model ind 579 epoch 829 head A head_i_epoch 0 batch 100: avg loss -3.576797 avg loss no lamb -3.576797 time 2019-02-06 17:23:15.364983
Model ind 579 epoch 829 head A head_i_epoch 0 batch 200: avg loss -3.606869 avg loss no lamb -3.606869 time 2019-02-06 17:27:32.227640
Pre: time 2019-02-06 17:32:31.034948: 
 	std: 0.004608056
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2542, 0.25366667, 0.24225, 0.25368333, 0.25346667]
	train_accs: [0.2542, 0.25366667, 0.24225, 0.25368333, 0.25346667]
	best_train_sub_head: 0
	worst: 0.24225
	avg: 0.25145334
	best: 0.2542

Starting e_i: 830
Model ind 579 epoch 830 head B head_i_epoch 0 batch 0: avg loss -1.979201 avg loss no lamb -1.979201 time 2019-02-06 17:32:36.312112
Model ind 579 epoch 830 head B head_i_epoch 0 batch 100: avg loss -1.927972 avg loss no lamb -1.927972 time 2019-02-06 17:36:58.755259
Model ind 579 epoch 830 head B head_i_epoch 0 batch 200: avg loss -1.941769 avg loss no lamb -1.941769 time 2019-02-06 17:41:26.226940
Model ind 579 epoch 830 head A head_i_epoch 0 batch 0: avg loss -3.542633 avg loss no lamb -3.542633 time 2019-02-06 17:45:28.681833
Model ind 579 epoch 830 head A head_i_epoch 0 batch 100: avg loss -3.533650 avg loss no lamb -3.533650 time 2019-02-06 17:48:32.705490
Model ind 579 epoch 830 head A head_i_epoch 0 batch 200: avg loss -3.500031 avg loss no lamb -3.500031 time 2019-02-06 17:51:36.287850
Pre: time 2019-02-06 17:55:02.596850: 
 	std: 0.0046475534
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25198334, 0.25198334, 0.24021667, 0.25178334, 0.25156668]
	train_accs: [0.25198334, 0.25198334, 0.24021667, 0.25178334, 0.25156668]
	best_train_sub_head: 0
	worst: 0.24021667
	avg: 0.24950667
	best: 0.25198334

Starting e_i: 831
Model ind 579 epoch 831 head B head_i_epoch 0 batch 0: avg loss -1.909273 avg loss no lamb -1.909273 time 2019-02-06 17:55:11.434384
Model ind 579 epoch 831 head B head_i_epoch 0 batch 100: avg loss -1.931236 avg loss no lamb -1.931236 time 2019-02-06 17:58:13.512351
Model ind 579 epoch 831 head B head_i_epoch 0 batch 200: avg loss -1.888824 avg loss no lamb -1.888824 time 2019-02-06 18:01:14.074602
Model ind 579 epoch 831 head A head_i_epoch 0 batch 0: avg loss -3.514369 avg loss no lamb -3.514369 time 2019-02-06 18:04:14.429565
Model ind 579 epoch 831 head A head_i_epoch 0 batch 100: avg loss -3.535846 avg loss no lamb -3.535846 time 2019-02-06 18:07:14.617244
Model ind 579 epoch 831 head A head_i_epoch 0 batch 200: avg loss -3.514233 avg loss no lamb -3.514233 time 2019-02-06 18:10:14.506313
Pre: time 2019-02-06 18:13:39.571041: 
 	std: 0.0043859733
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25175, 0.2518, 0.24065, 0.2514, 0.25148332]
	train_accs: [0.25175, 0.2518, 0.24065, 0.2514, 0.25148332]
	best_train_sub_head: 1
	worst: 0.24065
	avg: 0.24941666
	best: 0.2518

Starting e_i: 832
Model ind 579 epoch 832 head B head_i_epoch 0 batch 0: avg loss -1.928326 avg loss no lamb -1.928326 time 2019-02-06 18:13:43.583231
Model ind 579 epoch 832 head B head_i_epoch 0 batch 100: avg loss -1.895466 avg loss no lamb -1.895466 time 2019-02-06 18:16:42.117226
Model ind 579 epoch 832 head B head_i_epoch 0 batch 200: avg loss -1.843196 avg loss no lamb -1.843196 time 2019-02-06 18:19:41.272460
Model ind 579 epoch 832 head A head_i_epoch 0 batch 0: avg loss -3.505602 avg loss no lamb -3.505602 time 2019-02-06 18:22:38.691110
Model ind 579 epoch 832 head A head_i_epoch 0 batch 100: avg loss -3.506738 avg loss no lamb -3.506738 time 2019-02-06 18:25:37.664703
Model ind 579 epoch 832 head A head_i_epoch 0 batch 200: avg loss -3.560381 avg loss no lamb -3.560381 time 2019-02-06 18:28:37.023630
Pre: time 2019-02-06 18:32:03.427094: 
 	std: 0.0042437986
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 5), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.252, 0.25256667, 0.24168333, 0.25226668, 0.2523]
	train_accs: [0.252, 0.25256667, 0.24168333, 0.25226668, 0.2523]
	best_train_sub_head: 1
	worst: 0.24168333
	avg: 0.25016335
	best: 0.25256667

Starting e_i: 833
Model ind 579 epoch 833 head B head_i_epoch 0 batch 0: avg loss -1.911223 avg loss no lamb -1.911223 time 2019-02-06 18:32:09.831184
Model ind 579 epoch 833 head B head_i_epoch 0 batch 100: avg loss -1.863398 avg loss no lamb -1.863398 time 2019-02-06 18:35:08.106389
Model ind 579 epoch 833 head B head_i_epoch 0 batch 200: avg loss -1.927863 avg loss no lamb -1.927863 time 2019-02-06 18:38:06.023734
Model ind 579 epoch 833 head A head_i_epoch 0 batch 0: avg loss -3.514127 avg loss no lamb -3.514127 time 2019-02-06 18:41:03.612507
Model ind 579 epoch 833 head A head_i_epoch 0 batch 100: avg loss -3.548070 avg loss no lamb -3.548070 time 2019-02-06 18:44:02.244566
Model ind 579 epoch 833 head A head_i_epoch 0 batch 200: avg loss -3.523180 avg loss no lamb -3.523180 time 2019-02-06 18:47:01.773431
Pre: time 2019-02-06 18:50:27.179915: 
 	std: 0.004498934
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25136667, 0.25146666, 0.2402, 0.25116667, 0.25175]
	train_accs: [0.25136667, 0.25146666, 0.2402, 0.25116667, 0.25175]
	best_train_sub_head: 4
	worst: 0.2402
	avg: 0.24919
	best: 0.25175

Starting e_i: 834
Model ind 579 epoch 834 head B head_i_epoch 0 batch 0: avg loss -1.910739 avg loss no lamb -1.910739 time 2019-02-06 18:50:31.367937
Model ind 579 epoch 834 head B head_i_epoch 0 batch 100: avg loss -1.915125 avg loss no lamb -1.915125 time 2019-02-06 18:53:30.144775
Model ind 579 epoch 834 head B head_i_epoch 0 batch 200: avg loss -2.016493 avg loss no lamb -2.016493 time 2019-02-06 18:56:28.526416
Model ind 579 epoch 834 head A head_i_epoch 0 batch 0: avg loss -3.550759 avg loss no lamb -3.550759 time 2019-02-06 18:59:26.561454
Model ind 579 epoch 834 head A head_i_epoch 0 batch 100: avg loss -3.529241 avg loss no lamb -3.529241 time 2019-02-06 19:02:24.982934
Model ind 579 epoch 834 head A head_i_epoch 0 batch 200: avg loss -3.542000 avg loss no lamb -3.542000 time 2019-02-06 19:05:24.546040
Pre: time 2019-02-06 19:08:48.596169: 
 	std: 0.0046633882
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25241667, 0.25238332, 0.24073334, 0.25201666, 0.2527]
	train_accs: [0.25241667, 0.25238332, 0.24073334, 0.25201666, 0.2527]
	best_train_sub_head: 4
	worst: 0.24073334
	avg: 0.25005
	best: 0.2527

Starting e_i: 835
Model ind 579 epoch 835 head B head_i_epoch 0 batch 0: avg loss -1.945855 avg loss no lamb -1.945855 time 2019-02-06 19:08:52.502762
Model ind 579 epoch 835 head B head_i_epoch 0 batch 100: avg loss -1.933267 avg loss no lamb -1.933267 time 2019-02-06 19:11:50.022314
Model ind 579 epoch 835 head B head_i_epoch 0 batch 200: avg loss -1.847377 avg loss no lamb -1.847377 time 2019-02-06 19:14:48.702755
Model ind 579 epoch 835 head A head_i_epoch 0 batch 0: avg loss -3.590212 avg loss no lamb -3.590212 time 2019-02-06 19:17:47.090243
Model ind 579 epoch 835 head A head_i_epoch 0 batch 100: avg loss -3.552891 avg loss no lamb -3.552891 time 2019-02-06 19:20:47.841784
Model ind 579 epoch 835 head A head_i_epoch 0 batch 200: avg loss -3.574215 avg loss no lamb -3.574215 time 2019-02-06 19:23:47.090801
Pre: time 2019-02-06 19:27:13.136009: 
 	std: 0.0042796335
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25063333, 0.25098333, 0.24, 0.25065, 0.2505]
	train_accs: [0.25063333, 0.25098333, 0.24, 0.25065, 0.2505]
	best_train_sub_head: 1
	worst: 0.24
	avg: 0.24855332
	best: 0.25098333

Starting e_i: 836
Model ind 579 epoch 836 head B head_i_epoch 0 batch 0: avg loss -1.881719 avg loss no lamb -1.881719 time 2019-02-06 19:27:17.036024
Model ind 579 epoch 836 head B head_i_epoch 0 batch 100: avg loss -1.825470 avg loss no lamb -1.825470 time 2019-02-06 19:30:14.778681
Model ind 579 epoch 836 head B head_i_epoch 0 batch 200: avg loss -1.899357 avg loss no lamb -1.899357 time 2019-02-06 19:33:13.887596
Model ind 579 epoch 836 head A head_i_epoch 0 batch 0: avg loss -3.509285 avg loss no lamb -3.509285 time 2019-02-06 19:36:12.822978
Model ind 579 epoch 836 head A head_i_epoch 0 batch 100: avg loss -3.572570 avg loss no lamb -3.572570 time 2019-02-06 19:39:14.990912
Model ind 579 epoch 836 head A head_i_epoch 0 batch 200: avg loss -3.582743 avg loss no lamb -3.582743 time 2019-02-06 19:42:16.041292
Pre: time 2019-02-06 19:45:44.147335: 
 	std: 0.0043343008
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25356665, 0.25451666, 0.24335, 0.25411665, 0.25441667]
	train_accs: [0.25356665, 0.25451666, 0.24335, 0.25411665, 0.25441667]
	best_train_sub_head: 1
	worst: 0.24335
	avg: 0.25199336
	best: 0.25451666

Starting e_i: 837
Model ind 579 epoch 837 head B head_i_epoch 0 batch 0: avg loss -1.858538 avg loss no lamb -1.858538 time 2019-02-06 19:45:48.513869
Model ind 579 epoch 837 head B head_i_epoch 0 batch 100: avg loss -1.814927 avg loss no lamb -1.814927 time 2019-02-06 19:48:49.489868
Model ind 579 epoch 837 head B head_i_epoch 0 batch 200: avg loss -1.840581 avg loss no lamb -1.840581 time 2019-02-06 19:51:49.921165
Model ind 579 epoch 837 head A head_i_epoch 0 batch 0: avg loss -3.493922 avg loss no lamb -3.493922 time 2019-02-06 19:54:50.169322
Model ind 579 epoch 837 head A head_i_epoch 0 batch 100: avg loss -3.603746 avg loss no lamb -3.603746 time 2019-02-06 19:57:51.167437
Model ind 579 epoch 837 head A head_i_epoch 0 batch 200: avg loss -3.528264 avg loss no lamb -3.528264 time 2019-02-06 20:00:52.529183
Pre: time 2019-02-06 20:04:17.708784: 
 	std: 0.0042384486
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2512, 0.2516, 0.241, 0.2518, 0.25173333]
	train_accs: [0.2512, 0.2516, 0.241, 0.2518, 0.25173333]
	best_train_sub_head: 3
	worst: 0.241
	avg: 0.24946666
	best: 0.2518

Starting e_i: 838
Model ind 579 epoch 838 head B head_i_epoch 0 batch 0: avg loss -1.952621 avg loss no lamb -1.952621 time 2019-02-06 20:04:22.401805
Model ind 579 epoch 838 head B head_i_epoch 0 batch 100: avg loss -1.896257 avg loss no lamb -1.896257 time 2019-02-06 20:07:22.305404
Model ind 579 epoch 838 head B head_i_epoch 0 batch 200: avg loss -1.958892 avg loss no lamb -1.958892 time 2019-02-06 20:10:21.873462
Model ind 579 epoch 838 head A head_i_epoch 0 batch 0: avg loss -3.531178 avg loss no lamb -3.531178 time 2019-02-06 20:13:21.083012
Model ind 579 epoch 838 head A head_i_epoch 0 batch 100: avg loss -3.525064 avg loss no lamb -3.525064 time 2019-02-06 20:16:19.588655
Model ind 579 epoch 838 head A head_i_epoch 0 batch 200: avg loss -3.493345 avg loss no lamb -3.493345 time 2019-02-06 20:19:17.808763
Pre: time 2019-02-06 20:22:41.680763: 
 	std: 0.0045497324
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25188333, 0.25198334, 0.24043334, 0.25205, 0.25121668]
	train_accs: [0.25188333, 0.25198334, 0.24043334, 0.25205, 0.25121668]
	best_train_sub_head: 3
	worst: 0.24043334
	avg: 0.24951334
	best: 0.25205

Starting e_i: 839
Model ind 579 epoch 839 head B head_i_epoch 0 batch 0: avg loss -1.904234 avg loss no lamb -1.904234 time 2019-02-06 20:22:45.910207
Model ind 579 epoch 839 head B head_i_epoch 0 batch 100: avg loss -1.825082 avg loss no lamb -1.825082 time 2019-02-06 20:25:43.850262
Model ind 579 epoch 839 head B head_i_epoch 0 batch 200: avg loss -1.881466 avg loss no lamb -1.881466 time 2019-02-06 20:28:42.032763
Model ind 579 epoch 839 head A head_i_epoch 0 batch 0: avg loss -3.506891 avg loss no lamb -3.506891 time 2019-02-06 20:31:39.299438
Model ind 579 epoch 839 head A head_i_epoch 0 batch 100: avg loss -3.546462 avg loss no lamb -3.546462 time 2019-02-06 20:34:37.826485
Model ind 579 epoch 839 head A head_i_epoch 0 batch 200: avg loss -3.604864 avg loss no lamb -3.604864 time 2019-02-06 20:37:36.492925
Pre: time 2019-02-06 20:41:01.075522: 
 	std: 0.00472307
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25205, 0.25163335, 0.24005, 0.25221667, 0.25145]
	train_accs: [0.25205, 0.25163335, 0.24005, 0.25221667, 0.25145]
	best_train_sub_head: 3
	worst: 0.24005
	avg: 0.24948001
	best: 0.25221667

Starting e_i: 840
Model ind 579 epoch 840 head B head_i_epoch 0 batch 0: avg loss -1.879887 avg loss no lamb -1.879887 time 2019-02-06 20:41:05.268953
Model ind 579 epoch 840 head B head_i_epoch 0 batch 100: avg loss -1.861228 avg loss no lamb -1.861228 time 2019-02-06 20:44:04.264566
Model ind 579 epoch 840 head B head_i_epoch 0 batch 200: avg loss -1.942165 avg loss no lamb -1.942165 time 2019-02-06 20:47:03.182981
Model ind 579 epoch 840 head A head_i_epoch 0 batch 0: avg loss -3.486589 avg loss no lamb -3.486589 time 2019-02-06 20:50:01.083516
Model ind 579 epoch 840 head A head_i_epoch 0 batch 100: avg loss -3.525310 avg loss no lamb -3.525310 time 2019-02-06 20:53:00.323018
Model ind 579 epoch 840 head A head_i_epoch 0 batch 200: avg loss -3.527904 avg loss no lamb -3.527904 time 2019-02-06 20:56:00.628850
Pre: time 2019-02-06 20:59:24.566150: 
 	std: 0.0048615793
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25371668, 0.25378335, 0.24148333, 0.25361666, 0.25341666]
	train_accs: [0.25371668, 0.25378335, 0.24148333, 0.25361666, 0.25341666]
	best_train_sub_head: 1
	worst: 0.24148333
	avg: 0.25120336
	best: 0.25378335

Starting e_i: 841
Model ind 579 epoch 841 head B head_i_epoch 0 batch 0: avg loss -1.979702 avg loss no lamb -1.979702 time 2019-02-06 20:59:33.534795
Model ind 579 epoch 841 head B head_i_epoch 0 batch 100: avg loss -1.818845 avg loss no lamb -1.818845 time 2019-02-06 21:02:32.129421
Model ind 579 epoch 841 head B head_i_epoch 0 batch 200: avg loss -1.846384 avg loss no lamb -1.846384 time 2019-02-06 21:05:29.185086
Model ind 579 epoch 841 head A head_i_epoch 0 batch 0: avg loss -3.518141 avg loss no lamb -3.518141 time 2019-02-06 21:08:26.565015
Model ind 579 epoch 841 head A head_i_epoch 0 batch 100: avg loss -3.545316 avg loss no lamb -3.545316 time 2019-02-06 21:11:25.973376
Model ind 579 epoch 841 head A head_i_epoch 0 batch 200: avg loss -3.542739 avg loss no lamb -3.542739 time 2019-02-06 21:14:25.497339
Pre: time 2019-02-06 21:17:49.133666: 
 	std: 0.0043238415
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25066668, 0.25073335, 0.24003333, 0.2513, 0.2506]
	train_accs: [0.25066668, 0.25073335, 0.24003333, 0.2513, 0.2506]
	best_train_sub_head: 3
	worst: 0.24003333
	avg: 0.24866667
	best: 0.2513

Starting e_i: 842
Model ind 579 epoch 842 head B head_i_epoch 0 batch 0: avg loss -1.824503 avg loss no lamb -1.824503 time 2019-02-06 21:17:53.912140
Model ind 579 epoch 842 head B head_i_epoch 0 batch 100: avg loss -1.853274 avg loss no lamb -1.853274 time 2019-02-06 21:20:51.884430
Model ind 579 epoch 842 head B head_i_epoch 0 batch 200: avg loss -1.915601 avg loss no lamb -1.915601 time 2019-02-06 21:23:51.177055
Model ind 579 epoch 842 head A head_i_epoch 0 batch 0: avg loss -3.518494 avg loss no lamb -3.518494 time 2019-02-06 21:26:50.107131
Model ind 579 epoch 842 head A head_i_epoch 0 batch 100: avg loss -3.569279 avg loss no lamb -3.569279 time 2019-02-06 21:29:50.114861
Model ind 579 epoch 842 head A head_i_epoch 0 batch 200: avg loss -3.534830 avg loss no lamb -3.534830 time 2019-02-06 21:32:49.001905
Pre: time 2019-02-06 21:36:13.553660: 
 	std: 0.0043515363
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25378335, 0.25371668, 0.2429, 0.25415, 0.2534]
	train_accs: [0.25378335, 0.25371668, 0.2429, 0.25415, 0.2534]
	best_train_sub_head: 3
	worst: 0.2429
	avg: 0.25159
	best: 0.25415

Starting e_i: 843
Model ind 579 epoch 843 head B head_i_epoch 0 batch 0: avg loss -1.967456 avg loss no lamb -1.967456 time 2019-02-06 21:36:18.318635
Model ind 579 epoch 843 head B head_i_epoch 0 batch 100: avg loss -1.890204 avg loss no lamb -1.890204 time 2019-02-06 21:39:17.826181
Model ind 579 epoch 843 head B head_i_epoch 0 batch 200: avg loss -1.790515 avg loss no lamb -1.790515 time 2019-02-06 21:42:15.573677
Model ind 579 epoch 843 head A head_i_epoch 0 batch 0: avg loss -3.549512 avg loss no lamb -3.549512 time 2019-02-06 21:45:15.540380
Model ind 579 epoch 843 head A head_i_epoch 0 batch 100: avg loss -3.527611 avg loss no lamb -3.527611 time 2019-02-06 21:48:20.113877
Model ind 579 epoch 843 head A head_i_epoch 0 batch 200: avg loss -3.555026 avg loss no lamb -3.555026 time 2019-02-06 21:51:22.721879
Pre: time 2019-02-06 21:54:48.214898: 
 	std: 0.004514972
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25396666, 0.25385, 0.24263333, 0.25418332, 0.25365]
	train_accs: [0.25396666, 0.25385, 0.24263333, 0.25418332, 0.25365]
	best_train_sub_head: 3
	worst: 0.24263333
	avg: 0.25165668
	best: 0.25418332

Starting e_i: 844
Model ind 579 epoch 844 head B head_i_epoch 0 batch 0: avg loss -1.994048 avg loss no lamb -1.994048 time 2019-02-06 21:54:52.288340
Model ind 579 epoch 844 head B head_i_epoch 0 batch 100: avg loss -1.851965 avg loss no lamb -1.851965 time 2019-02-06 21:57:50.657050
Model ind 579 epoch 844 head B head_i_epoch 0 batch 200: avg loss -1.873017 avg loss no lamb -1.873017 time 2019-02-06 22:00:49.871912
Model ind 579 epoch 844 head A head_i_epoch 0 batch 0: avg loss -3.508674 avg loss no lamb -3.508674 time 2019-02-06 22:03:48.894676
Model ind 579 epoch 844 head A head_i_epoch 0 batch 100: avg loss -3.541706 avg loss no lamb -3.541706 time 2019-02-06 22:06:48.691957
Model ind 579 epoch 844 head A head_i_epoch 0 batch 200: avg loss -3.605678 avg loss no lamb -3.605678 time 2019-02-06 22:09:48.287945
Pre: time 2019-02-06 22:13:11.987176: 
 	std: 0.004818145
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25386667, 0.25398332, 0.24183333, 0.25413334, 0.25348333]
	train_accs: [0.25386667, 0.25398332, 0.24183333, 0.25413334, 0.25348333]
	best_train_sub_head: 3
	worst: 0.24183333
	avg: 0.25146
	best: 0.25413334

Starting e_i: 845
Model ind 579 epoch 845 head B head_i_epoch 0 batch 0: avg loss -1.901904 avg loss no lamb -1.901904 time 2019-02-06 22:13:16.149064
Model ind 579 epoch 845 head B head_i_epoch 0 batch 100: avg loss -1.874329 avg loss no lamb -1.874329 time 2019-02-06 22:16:14.530563
Model ind 579 epoch 845 head B head_i_epoch 0 batch 200: avg loss -1.855025 avg loss no lamb -1.855025 time 2019-02-06 22:19:14.177991
Model ind 579 epoch 845 head A head_i_epoch 0 batch 0: avg loss -3.561648 avg loss no lamb -3.561648 time 2019-02-06 22:22:13.954139
Model ind 579 epoch 845 head A head_i_epoch 0 batch 100: avg loss -3.488249 avg loss no lamb -3.488249 time 2019-02-06 22:25:13.560881
Model ind 579 epoch 845 head A head_i_epoch 0 batch 200: avg loss -3.559944 avg loss no lamb -3.559944 time 2019-02-06 22:28:14.190434
Pre: time 2019-02-06 22:31:39.162188: 
 	std: 0.004916042
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25278333, 0.2524, 0.2404, 0.2533, 0.25211668]
	train_accs: [0.25278333, 0.2524, 0.2404, 0.2533, 0.25211668]
	best_train_sub_head: 3
	worst: 0.2404
	avg: 0.2502
	best: 0.2533

Starting e_i: 846
Model ind 579 epoch 846 head B head_i_epoch 0 batch 0: avg loss -1.960263 avg loss no lamb -1.960263 time 2019-02-06 22:31:43.370218
Model ind 579 epoch 846 head B head_i_epoch 0 batch 100: avg loss -1.911194 avg loss no lamb -1.911194 time 2019-02-06 22:34:40.784181
Model ind 579 epoch 846 head B head_i_epoch 0 batch 200: avg loss -1.999433 avg loss no lamb -1.999433 time 2019-02-06 22:37:37.533172
Model ind 579 epoch 846 head A head_i_epoch 0 batch 0: avg loss -3.557156 avg loss no lamb -3.557156 time 2019-02-06 22:40:36.279267
Model ind 579 epoch 846 head A head_i_epoch 0 batch 100: avg loss -3.587328 avg loss no lamb -3.587328 time 2019-02-06 22:43:35.078066
Model ind 579 epoch 846 head A head_i_epoch 0 batch 200: avg loss -3.572191 avg loss no lamb -3.572191 time 2019-02-06 22:46:35.626862
Pre: time 2019-02-06 22:50:02.289970: 
 	std: 0.0046987166
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25473332, 0.25446665, 0.24286667, 0.25505, 0.2541]
	train_accs: [0.25473332, 0.25446665, 0.24286667, 0.25505, 0.2541]
	best_train_sub_head: 3
	worst: 0.24286667
	avg: 0.2522433
	best: 0.25505

Starting e_i: 847
Model ind 579 epoch 847 head B head_i_epoch 0 batch 0: avg loss -1.920951 avg loss no lamb -1.920951 time 2019-02-06 22:50:06.440946
Model ind 579 epoch 847 head B head_i_epoch 0 batch 100: avg loss -1.854944 avg loss no lamb -1.854944 time 2019-02-06 22:53:03.959497
Model ind 579 epoch 847 head B head_i_epoch 0 batch 200: avg loss -1.909775 avg loss no lamb -1.909775 time 2019-02-06 22:56:03.189350
Model ind 579 epoch 847 head A head_i_epoch 0 batch 0: avg loss -3.523655 avg loss no lamb -3.523655 time 2019-02-06 22:59:02.810677
Model ind 579 epoch 847 head A head_i_epoch 0 batch 100: avg loss -3.534056 avg loss no lamb -3.534056 time 2019-02-06 23:02:02.459405
Model ind 579 epoch 847 head A head_i_epoch 0 batch 200: avg loss -3.551737 avg loss no lamb -3.551737 time 2019-02-06 23:05:02.387537
Pre: time 2019-02-06 23:08:27.070228: 
 	std: 0.004534481
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25451666, 0.25435, 0.24321666, 0.25491667, 0.25438333]
	train_accs: [0.25451666, 0.25435, 0.24321666, 0.25491667, 0.25438333]
	best_train_sub_head: 3
	worst: 0.24321666
	avg: 0.25227666
	best: 0.25491667

Starting e_i: 848
Model ind 579 epoch 848 head B head_i_epoch 0 batch 0: avg loss -1.883062 avg loss no lamb -1.883062 time 2019-02-06 23:08:31.201815
Model ind 579 epoch 848 head B head_i_epoch 0 batch 100: avg loss -1.856178 avg loss no lamb -1.856178 time 2019-02-06 23:11:30.688692
Model ind 579 epoch 848 head B head_i_epoch 0 batch 200: avg loss -1.899694 avg loss no lamb -1.899694 time 2019-02-06 23:14:28.719113
Model ind 579 epoch 848 head A head_i_epoch 0 batch 0: avg loss -3.525882 avg loss no lamb -3.525882 time 2019-02-06 23:17:27.877516
Model ind 579 epoch 848 head A head_i_epoch 0 batch 100: avg loss -3.563158 avg loss no lamb -3.563158 time 2019-02-06 23:20:27.016415
Model ind 579 epoch 848 head A head_i_epoch 0 batch 200: avg loss -3.503895 avg loss no lamb -3.503895 time 2019-02-06 23:23:26.599871
Pre: time 2019-02-06 23:26:52.105745: 
 	std: 0.005138617
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25436667, 0.25401667, 0.24143334, 0.25443333, 0.25428334]
	train_accs: [0.25436667, 0.25401667, 0.24143334, 0.25443333, 0.25428334]
	best_train_sub_head: 3
	worst: 0.24143334
	avg: 0.25170666
	best: 0.25443333

Starting e_i: 849
Model ind 579 epoch 849 head B head_i_epoch 0 batch 0: avg loss -1.829805 avg loss no lamb -1.829805 time 2019-02-06 23:26:56.138909
Model ind 579 epoch 849 head B head_i_epoch 0 batch 100: avg loss -1.904593 avg loss no lamb -1.904593 time 2019-02-06 23:29:54.634781
Model ind 579 epoch 849 head B head_i_epoch 0 batch 200: avg loss -1.928251 avg loss no lamb -1.928251 time 2019-02-06 23:32:52.921173
Model ind 579 epoch 849 head A head_i_epoch 0 batch 0: avg loss -3.563915 avg loss no lamb -3.563915 time 2019-02-06 23:35:52.094971
Model ind 579 epoch 849 head A head_i_epoch 0 batch 100: avg loss -3.605240 avg loss no lamb -3.605240 time 2019-02-06 23:38:50.999348
Model ind 579 epoch 849 head A head_i_epoch 0 batch 200: avg loss -3.574347 avg loss no lamb -3.574347 time 2019-02-06 23:41:49.882023
Pre: time 2019-02-06 23:45:14.282212: 
 	std: 0.004826125
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25331667, 0.2538, 0.24143334, 0.25343335, 0.25341666]
	train_accs: [0.25331667, 0.2538, 0.24143334, 0.25343335, 0.25341666]
	best_train_sub_head: 1
	worst: 0.24143334
	avg: 0.25108
	best: 0.2538

Starting e_i: 850
Model ind 579 epoch 850 head B head_i_epoch 0 batch 0: avg loss -1.879075 avg loss no lamb -1.879075 time 2019-02-06 23:45:18.516012
Model ind 579 epoch 850 head B head_i_epoch 0 batch 100: avg loss -1.969349 avg loss no lamb -1.969349 time 2019-02-06 23:48:17.172991
Model ind 579 epoch 850 head B head_i_epoch 0 batch 200: avg loss -1.848307 avg loss no lamb -1.848307 time 2019-02-06 23:51:14.287280
Model ind 579 epoch 850 head A head_i_epoch 0 batch 0: avg loss -3.552825 avg loss no lamb -3.552825 time 2019-02-06 23:54:12.517287
Model ind 579 epoch 850 head A head_i_epoch 0 batch 100: avg loss -3.557226 avg loss no lamb -3.557226 time 2019-02-06 23:57:12.939427
Model ind 579 epoch 850 head A head_i_epoch 0 batch 200: avg loss -3.612255 avg loss no lamb -3.612255 time 2019-02-07 00:00:13.027469
Pre: time 2019-02-07 00:03:37.462758: 
 	std: 0.0047913142
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25295, 0.253, 0.24131666, 0.25401667, 0.25305]
	train_accs: [0.25295, 0.253, 0.24131666, 0.25401667, 0.25305]
	best_train_sub_head: 3
	worst: 0.24131666
	avg: 0.25086665
	best: 0.25401667

Starting e_i: 851
Model ind 579 epoch 851 head B head_i_epoch 0 batch 0: avg loss -1.908055 avg loss no lamb -1.908055 time 2019-02-07 00:03:47.833892
Model ind 579 epoch 851 head B head_i_epoch 0 batch 100: avg loss -1.824185 avg loss no lamb -1.824185 time 2019-02-07 00:06:45.354787
Model ind 579 epoch 851 head B head_i_epoch 0 batch 200: avg loss -1.907719 avg loss no lamb -1.907719 time 2019-02-07 00:09:43.281356
Model ind 579 epoch 851 head A head_i_epoch 0 batch 0: avg loss -3.474837 avg loss no lamb -3.474837 time 2019-02-07 00:12:40.781418
Model ind 579 epoch 851 head A head_i_epoch 0 batch 100: avg loss -3.520100 avg loss no lamb -3.520100 time 2019-02-07 00:15:40.422248
Model ind 579 epoch 851 head A head_i_epoch 0 batch 200: avg loss -3.505798 avg loss no lamb -3.505798 time 2019-02-07 00:18:38.972980
Pre: time 2019-02-07 00:22:02.286574: 
 	std: 0.004318339
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2522, 0.25208333, 0.24153334, 0.2527, 0.25228333]
	train_accs: [0.2522, 0.25208333, 0.24153334, 0.2527, 0.25228333]
	best_train_sub_head: 3
	worst: 0.24153334
	avg: 0.25016
	best: 0.2527

Starting e_i: 852
Model ind 579 epoch 852 head B head_i_epoch 0 batch 0: avg loss -1.813397 avg loss no lamb -1.813397 time 2019-02-07 00:22:07.758793
Model ind 579 epoch 852 head B head_i_epoch 0 batch 100: avg loss -1.858253 avg loss no lamb -1.858253 time 2019-02-07 00:25:05.454381
Model ind 579 epoch 852 head B head_i_epoch 0 batch 200: avg loss -1.932676 avg loss no lamb -1.932676 time 2019-02-07 00:28:03.284705
Model ind 579 epoch 852 head A head_i_epoch 0 batch 0: avg loss -3.530310 avg loss no lamb -3.530310 time 2019-02-07 00:31:00.813749
Model ind 579 epoch 852 head A head_i_epoch 0 batch 100: avg loss -3.590781 avg loss no lamb -3.590781 time 2019-02-07 00:33:59.613153
Model ind 579 epoch 852 head A head_i_epoch 0 batch 200: avg loss -3.557976 avg loss no lamb -3.557976 time 2019-02-07 00:36:57.814535
Pre: time 2019-02-07 00:40:24.232675: 
 	std: 0.0045251227
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25291666, 0.25231665, 0.2415, 0.25341666, 0.25243333]
	train_accs: [0.25291666, 0.25231665, 0.2415, 0.25341666, 0.25243333]
	best_train_sub_head: 3
	worst: 0.2415
	avg: 0.25051665
	best: 0.25341666

Starting e_i: 853
Model ind 579 epoch 853 head B head_i_epoch 0 batch 0: avg loss -1.812644 avg loss no lamb -1.812644 time 2019-02-07 00:40:29.029572
Model ind 579 epoch 853 head B head_i_epoch 0 batch 100: avg loss -1.860437 avg loss no lamb -1.860437 time 2019-02-07 00:43:27.034945
Model ind 579 epoch 853 head B head_i_epoch 0 batch 200: avg loss -1.881954 avg loss no lamb -1.881954 time 2019-02-07 00:46:26.825892
Model ind 579 epoch 853 head A head_i_epoch 0 batch 0: avg loss -3.524804 avg loss no lamb -3.524804 time 2019-02-07 00:49:28.153888
Model ind 579 epoch 853 head A head_i_epoch 0 batch 100: avg loss -3.557976 avg loss no lamb -3.557976 time 2019-02-07 00:52:27.769620
Model ind 579 epoch 853 head A head_i_epoch 0 batch 200: avg loss -3.527063 avg loss no lamb -3.527063 time 2019-02-07 00:55:27.302950
Pre: time 2019-02-07 00:58:52.330056: 
 	std: 0.0043982915
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25401667, 0.25403333, 0.24315, 0.25435, 0.25416666]
	train_accs: [0.25401667, 0.25403333, 0.24315, 0.25435, 0.25416666]
	best_train_sub_head: 3
	worst: 0.24315
	avg: 0.2519433
	best: 0.25435

Starting e_i: 854
Model ind 579 epoch 854 head B head_i_epoch 0 batch 0: avg loss -1.844961 avg loss no lamb -1.844961 time 2019-02-07 00:58:56.676061
Model ind 579 epoch 854 head B head_i_epoch 0 batch 100: avg loss -1.908865 avg loss no lamb -1.908865 time 2019-02-07 01:01:55.719124
Model ind 579 epoch 854 head B head_i_epoch 0 batch 200: avg loss -1.908548 avg loss no lamb -1.908548 time 2019-02-07 01:04:54.201479
Model ind 579 epoch 854 head A head_i_epoch 0 batch 0: avg loss -3.557438 avg loss no lamb -3.557438 time 2019-02-07 01:07:54.174017
Model ind 579 epoch 854 head A head_i_epoch 0 batch 100: avg loss -3.543298 avg loss no lamb -3.543298 time 2019-02-07 01:10:53.897131
Model ind 579 epoch 854 head A head_i_epoch 0 batch 200: avg loss -3.493120 avg loss no lamb -3.493120 time 2019-02-07 01:13:54.871983
Pre: time 2019-02-07 01:17:19.747818: 
 	std: 0.004622877
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2505, 0.25096667, 0.23936667, 0.25125, 0.25091666]
	train_accs: [0.2505, 0.25096667, 0.23936667, 0.25125, 0.25091666]
	best_train_sub_head: 3
	worst: 0.23936667
	avg: 0.2486
	best: 0.25125

Starting e_i: 855
Model ind 579 epoch 855 head B head_i_epoch 0 batch 0: avg loss -1.935045 avg loss no lamb -1.935045 time 2019-02-07 01:17:24.054434
Model ind 579 epoch 855 head B head_i_epoch 0 batch 100: avg loss -1.877706 avg loss no lamb -1.877706 time 2019-02-07 01:20:22.473111
Model ind 579 epoch 855 head B head_i_epoch 0 batch 200: avg loss -1.915198 avg loss no lamb -1.915198 time 2019-02-07 01:23:20.919656
Model ind 579 epoch 855 head A head_i_epoch 0 batch 0: avg loss -3.590418 avg loss no lamb -3.590418 time 2019-02-07 01:26:19.822028
Model ind 579 epoch 855 head A head_i_epoch 0 batch 100: avg loss -3.619902 avg loss no lamb -3.619902 time 2019-02-07 01:29:21.599002
Model ind 579 epoch 855 head A head_i_epoch 0 batch 200: avg loss -3.539338 avg loss no lamb -3.539338 time 2019-02-07 01:32:21.719882
Pre: time 2019-02-07 01:35:46.542296: 
 	std: 0.0044636214
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 0), (3, 15), (4, 4), (5, 5), (6, 7), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 13), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2507, 0.2512, 0.23978333, 0.25078332, 0.25105]
	train_accs: [0.2507, 0.2512, 0.23978333, 0.25078332, 0.25105]
	best_train_sub_head: 1
	worst: 0.23978333
	avg: 0.24870333
	best: 0.2512

Starting e_i: 856
Model ind 579 epoch 856 head B head_i_epoch 0 batch 0: avg loss -1.958487 avg loss no lamb -1.958487 time 2019-02-07 01:35:50.672554
Model ind 579 epoch 856 head B head_i_epoch 0 batch 100: avg loss -1.853374 avg loss no lamb -1.853374 time 2019-02-07 01:38:48.597254
Model ind 579 epoch 856 head B head_i_epoch 0 batch 200: avg loss -1.901370 avg loss no lamb -1.901370 time 2019-02-07 01:41:47.794840
Model ind 579 epoch 856 head A head_i_epoch 0 batch 0: avg loss -3.524131 avg loss no lamb -3.524131 time 2019-02-07 01:44:45.492427
Model ind 579 epoch 856 head A head_i_epoch 0 batch 100: avg loss -3.660099 avg loss no lamb -3.660099 time 2019-02-07 01:47:43.512484
Model ind 579 epoch 856 head A head_i_epoch 0 batch 200: avg loss -3.601328 avg loss no lamb -3.601328 time 2019-02-07 01:50:43.882763
Pre: time 2019-02-07 01:54:08.219838: 
 	std: 0.004532174
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25135, 0.25148332, 0.24016666, 0.25138333, 0.25175]
	train_accs: [0.25135, 0.25148332, 0.24016666, 0.25138333, 0.25175]
	best_train_sub_head: 4
	worst: 0.24016666
	avg: 0.24922666
	best: 0.25175

Starting e_i: 857
Model ind 579 epoch 857 head B head_i_epoch 0 batch 0: avg loss -1.981666 avg loss no lamb -1.981666 time 2019-02-07 01:54:12.468656
Model ind 579 epoch 857 head B head_i_epoch 0 batch 100: avg loss -1.931838 avg loss no lamb -1.931838 time 2019-02-07 01:57:11.340511
Model ind 579 epoch 857 head B head_i_epoch 0 batch 200: avg loss -1.958105 avg loss no lamb -1.958105 time 2019-02-07 02:00:08.713537
Model ind 579 epoch 857 head A head_i_epoch 0 batch 0: avg loss -3.562485 avg loss no lamb -3.562485 time 2019-02-07 02:03:07.520933
Model ind 579 epoch 857 head A head_i_epoch 0 batch 100: avg loss -3.675941 avg loss no lamb -3.675941 time 2019-02-07 02:06:07.109559
Model ind 579 epoch 857 head A head_i_epoch 0 batch 200: avg loss -3.569716 avg loss no lamb -3.569716 time 2019-02-07 02:09:07.619685
Pre: time 2019-02-07 02:12:32.468844: 
 	std: 0.0044922177
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.2523, 0.25226668, 0.24106666, 0.2522, 0.25241667]
	train_accs: [0.2523, 0.25226668, 0.24106666, 0.2522, 0.25241667]
	best_train_sub_head: 4
	worst: 0.24106666
	avg: 0.25005
	best: 0.25241667

Starting e_i: 858
Model ind 579 epoch 858 head B head_i_epoch 0 batch 0: avg loss -1.916593 avg loss no lamb -1.916593 time 2019-02-07 02:12:38.208109
Model ind 579 epoch 858 head B head_i_epoch 0 batch 100: avg loss -1.835322 avg loss no lamb -1.835322 time 2019-02-07 02:15:37.550499
Model ind 579 epoch 858 head B head_i_epoch 0 batch 200: avg loss -1.907906 avg loss no lamb -1.907906 time 2019-02-07 02:18:35.461707
Model ind 579 epoch 858 head A head_i_epoch 0 batch 0: avg loss -3.538439 avg loss no lamb -3.538439 time 2019-02-07 02:21:34.456133
Model ind 579 epoch 858 head A head_i_epoch 0 batch 100: avg loss -3.573372 avg loss no lamb -3.573372 time 2019-02-07 02:24:34.320372
Model ind 579 epoch 858 head A head_i_epoch 0 batch 200: avg loss -3.524933 avg loss no lamb -3.524933 time 2019-02-07 02:27:33.999970
Pre: time 2019-02-07 02:30:57.819006: 
 	std: 0.0043319063
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.24971667, 0.2507, 0.2394, 0.25031668, 0.25006667]
	train_accs: [0.24971667, 0.2507, 0.2394, 0.25031668, 0.25006667]
	best_train_sub_head: 1
	worst: 0.2394
	avg: 0.24804
	best: 0.2507

Starting e_i: 859
Model ind 579 epoch 859 head B head_i_epoch 0 batch 0: avg loss -1.959235 avg loss no lamb -1.959235 time 2019-02-07 02:31:02.164451
Model ind 579 epoch 859 head B head_i_epoch 0 batch 100: avg loss -1.883978 avg loss no lamb -1.883978 time 2019-02-07 02:34:00.076823
Model ind 579 epoch 859 head B head_i_epoch 0 batch 200: avg loss -1.942387 avg loss no lamb -1.942387 time 2019-02-07 02:37:00.163946
Model ind 579 epoch 859 head A head_i_epoch 0 batch 0: avg loss -3.479033 avg loss no lamb -3.479033 time 2019-02-07 02:39:58.863711
Model ind 579 epoch 859 head A head_i_epoch 0 batch 100: avg loss -3.539509 avg loss no lamb -3.539509 time 2019-02-07 02:43:00.857789
Model ind 579 epoch 859 head A head_i_epoch 0 batch 200: avg loss -3.562083 avg loss no lamb -3.562083 time 2019-02-07 02:46:00.842930
Pre: time 2019-02-07 02:49:26.371442: 
 	std: 0.0048384736
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25355, 0.25318334, 0.24116667, 0.2533, 0.25298333]
	train_accs: [0.25355, 0.25318334, 0.24116667, 0.2533, 0.25298333]
	best_train_sub_head: 0
	worst: 0.24116667
	avg: 0.25083667
	best: 0.25355

Starting e_i: 860
Model ind 579 epoch 860 head B head_i_epoch 0 batch 0: avg loss -1.963831 avg loss no lamb -1.963831 time 2019-02-07 02:49:30.562167
Model ind 579 epoch 860 head B head_i_epoch 0 batch 100: avg loss -1.927132 avg loss no lamb -1.927132 time 2019-02-07 02:52:28.961849
Model ind 579 epoch 860 head B head_i_epoch 0 batch 200: avg loss -1.981484 avg loss no lamb -1.981484 time 2019-02-07 02:55:27.373258
Model ind 579 epoch 860 head A head_i_epoch 0 batch 0: avg loss -3.488569 avg loss no lamb -3.488569 time 2019-02-07 02:58:26.217207
Model ind 579 epoch 860 head A head_i_epoch 0 batch 100: avg loss -3.580463 avg loss no lamb -3.580463 time 2019-02-07 03:01:26.187924
Model ind 579 epoch 860 head A head_i_epoch 0 batch 200: avg loss -3.598010 avg loss no lamb -3.598010 time 2019-02-07 03:04:25.970897
Pre: time 2019-02-07 03:07:52.285265: 
 	std: 0.0048371027
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 18), (12, 13), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 5), (19, 12)]
	test_accs: [0.2533, 0.25356665, 0.24131666, 0.2531, 0.25363332]
	train_accs: [0.2533, 0.25356665, 0.24131666, 0.2531, 0.25363332]
	best_train_sub_head: 4
	worst: 0.24131666
	avg: 0.25098333
	best: 0.25363332

Starting e_i: 861
Model ind 579 epoch 861 head B head_i_epoch 0 batch 0: avg loss -1.975263 avg loss no lamb -1.975263 time 2019-02-07 03:08:02.505721
Model ind 579 epoch 861 head B head_i_epoch 0 batch 100: avg loss -1.961116 avg loss no lamb -1.961116 time 2019-02-07 03:11:02.069904
Model ind 579 epoch 861 head B head_i_epoch 0 batch 200: avg loss -1.832937 avg loss no lamb -1.832937 time 2019-02-07 03:14:01.461683
Model ind 579 epoch 861 head A head_i_epoch 0 batch 0: avg loss -3.536589 avg loss no lamb -3.536589 time 2019-02-07 03:16:59.614647
Model ind 579 epoch 861 head A head_i_epoch 0 batch 100: avg loss -3.574919 avg loss no lamb -3.574919 time 2019-02-07 03:19:58.043751
Model ind 579 epoch 861 head A head_i_epoch 0 batch 200: avg loss -3.552964 avg loss no lamb -3.552964 time 2019-02-07 03:22:58.899269
Pre: time 2019-02-07 03:26:23.421205: 
 	std: 0.004675828
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25251666, 0.25225, 0.24068333, 0.25255, 0.25215]
	train_accs: [0.25251666, 0.25225, 0.24068333, 0.25255, 0.25215]
	best_train_sub_head: 3
	worst: 0.24068333
	avg: 0.25002998
	best: 0.25255

Starting e_i: 862
Model ind 579 epoch 862 head B head_i_epoch 0 batch 0: avg loss -1.901736 avg loss no lamb -1.901736 time 2019-02-07 03:26:27.417081
Model ind 579 epoch 862 head B head_i_epoch 0 batch 100: avg loss -1.943375 avg loss no lamb -1.943375 time 2019-02-07 03:29:26.533599
Model ind 579 epoch 862 head B head_i_epoch 0 batch 200: avg loss -1.854392 avg loss no lamb -1.854392 time 2019-02-07 03:32:25.305479
Model ind 579 epoch 862 head A head_i_epoch 0 batch 0: avg loss -3.536537 avg loss no lamb -3.536537 time 2019-02-07 03:35:24.312623
Model ind 579 epoch 862 head A head_i_epoch 0 batch 100: avg loss -3.591038 avg loss no lamb -3.591038 time 2019-02-07 03:38:25.692580
Model ind 579 epoch 862 head A head_i_epoch 0 batch 200: avg loss -3.590237 avg loss no lamb -3.590237 time 2019-02-07 03:41:26.562358
Pre: time 2019-02-07 03:44:51.041257: 
 	std: 0.0046094973
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2517, 0.25133333, 0.24008334, 0.25181666, 0.25155]
	train_accs: [0.2517, 0.25133333, 0.24008334, 0.25181666, 0.25155]
	best_train_sub_head: 3
	worst: 0.24008334
	avg: 0.24929667
	best: 0.25181666

Starting e_i: 863
Model ind 579 epoch 863 head B head_i_epoch 0 batch 0: avg loss -1.887310 avg loss no lamb -1.887310 time 2019-02-07 03:44:55.065396
Model ind 579 epoch 863 head B head_i_epoch 0 batch 100: avg loss -1.840554 avg loss no lamb -1.840554 time 2019-02-07 03:47:54.774813
Model ind 579 epoch 863 head B head_i_epoch 0 batch 200: avg loss -1.887388 avg loss no lamb -1.887388 time 2019-02-07 03:50:52.999246
Model ind 579 epoch 863 head A head_i_epoch 0 batch 0: avg loss -3.528479 avg loss no lamb -3.528479 time 2019-02-07 03:53:52.244122
Model ind 579 epoch 863 head A head_i_epoch 0 batch 100: avg loss -3.626902 avg loss no lamb -3.626902 time 2019-02-07 03:56:53.425966
Model ind 579 epoch 863 head A head_i_epoch 0 batch 200: avg loss -3.539263 avg loss no lamb -3.539263 time 2019-02-07 03:59:54.064053
Pre: time 2019-02-07 04:03:20.579620: 
 	std: 0.004396206
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2534, 0.25353333, 0.24263333, 0.25388333, 0.25365]
	train_accs: [0.2534, 0.25353333, 0.24263333, 0.25388333, 0.25365]
	best_train_sub_head: 3
	worst: 0.24263333
	avg: 0.25142002
	best: 0.25388333

Starting e_i: 864
Model ind 579 epoch 864 head B head_i_epoch 0 batch 0: avg loss -1.930140 avg loss no lamb -1.930140 time 2019-02-07 04:03:25.200527
Model ind 579 epoch 864 head B head_i_epoch 0 batch 100: avg loss -1.884015 avg loss no lamb -1.884015 time 2019-02-07 04:06:24.593808
Model ind 579 epoch 864 head B head_i_epoch 0 batch 200: avg loss -1.906281 avg loss no lamb -1.906281 time 2019-02-07 04:09:23.190655
Model ind 579 epoch 864 head A head_i_epoch 0 batch 0: avg loss -3.481723 avg loss no lamb -3.481723 time 2019-02-07 04:12:22.689286
Model ind 579 epoch 864 head A head_i_epoch 0 batch 100: avg loss -3.557700 avg loss no lamb -3.557700 time 2019-02-07 04:15:24.352403
Model ind 579 epoch 864 head A head_i_epoch 0 batch 200: avg loss -3.496907 avg loss no lamb -3.496907 time 2019-02-07 04:18:26.363503
Pre: time 2019-02-07 04:21:52.666764: 
 	std: 0.0046091974
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25211668, 0.25295, 0.2409, 0.25221667, 0.25231665]
	train_accs: [0.25211668, 0.25295, 0.2409, 0.25221667, 0.25231665]
	best_train_sub_head: 1
	worst: 0.2409
	avg: 0.2501
	best: 0.25295

Starting e_i: 865
Model ind 579 epoch 865 head B head_i_epoch 0 batch 0: avg loss -1.952745 avg loss no lamb -1.952745 time 2019-02-07 04:21:56.881687
Model ind 579 epoch 865 head B head_i_epoch 0 batch 100: avg loss -1.847228 avg loss no lamb -1.847228 time 2019-02-07 04:24:56.578926
Model ind 579 epoch 865 head B head_i_epoch 0 batch 200: avg loss -1.926841 avg loss no lamb -1.926841 time 2019-02-07 04:27:55.949111
Model ind 579 epoch 865 head A head_i_epoch 0 batch 0: avg loss -3.462729 avg loss no lamb -3.462729 time 2019-02-07 04:30:54.985944
Model ind 579 epoch 865 head A head_i_epoch 0 batch 100: avg loss -3.511928 avg loss no lamb -3.511928 time 2019-02-07 04:33:57.035096
Model ind 579 epoch 865 head A head_i_epoch 0 batch 200: avg loss -3.533825 avg loss no lamb -3.533825 time 2019-02-07 04:37:00.290140
Pre: time 2019-02-07 04:40:25.701839: 
 	std: 0.0048301523
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.2526, 0.25328332, 0.24095, 0.25278333, 0.25335]
	train_accs: [0.2526, 0.25328332, 0.24095, 0.25278333, 0.25335]
	best_train_sub_head: 4
	worst: 0.24095
	avg: 0.25059333
	best: 0.25335

Starting e_i: 866
Model ind 579 epoch 866 head B head_i_epoch 0 batch 0: avg loss -1.928436 avg loss no lamb -1.928436 time 2019-02-07 04:40:30.066826
Model ind 579 epoch 866 head B head_i_epoch 0 batch 100: avg loss -1.866848 avg loss no lamb -1.866848 time 2019-02-07 04:43:31.082274
Model ind 579 epoch 866 head B head_i_epoch 0 batch 200: avg loss -1.933561 avg loss no lamb -1.933561 time 2019-02-07 04:46:30.329548
Model ind 579 epoch 866 head A head_i_epoch 0 batch 0: avg loss -3.537479 avg loss no lamb -3.537479 time 2019-02-07 04:49:29.485996
Model ind 579 epoch 866 head A head_i_epoch 0 batch 100: avg loss -3.588636 avg loss no lamb -3.588636 time 2019-02-07 04:52:30.088752
Model ind 579 epoch 866 head A head_i_epoch 0 batch 200: avg loss -3.533641 avg loss no lamb -3.533641 time 2019-02-07 04:55:31.103156
Pre: time 2019-02-07 04:58:57.542932: 
 	std: 0.0045270203
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25215, 0.25205, 0.24086666, 0.25243333, 0.25208333]
	train_accs: [0.25215, 0.25205, 0.24086666, 0.25243333, 0.25208333]
	best_train_sub_head: 3
	worst: 0.24086666
	avg: 0.24991664
	best: 0.25243333

Starting e_i: 867
Model ind 579 epoch 867 head B head_i_epoch 0 batch 0: avg loss -1.862855 avg loss no lamb -1.862855 time 2019-02-07 04:59:01.979805
Model ind 579 epoch 867 head B head_i_epoch 0 batch 100: avg loss -1.806480 avg loss no lamb -1.806480 time 2019-02-07 05:02:02.097921
Model ind 579 epoch 867 head B head_i_epoch 0 batch 200: avg loss -1.877669 avg loss no lamb -1.877669 time 2019-02-07 05:05:01.895600
Model ind 579 epoch 867 head A head_i_epoch 0 batch 0: avg loss -3.546597 avg loss no lamb -3.546597 time 2019-02-07 05:08:02.239067
Model ind 579 epoch 867 head A head_i_epoch 0 batch 100: avg loss -3.527211 avg loss no lamb -3.527211 time 2019-02-07 05:11:10.224918
Model ind 579 epoch 867 head A head_i_epoch 0 batch 200: avg loss -3.579850 avg loss no lamb -3.579850 time 2019-02-07 05:14:12.580579
Pre: time 2019-02-07 05:17:40.270246: 
 	std: 0.004845461
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25281668, 0.25251666, 0.24063334, 0.25295, 0.25268334]
	train_accs: [0.25281668, 0.25251666, 0.24063334, 0.25295, 0.25268334]
	best_train_sub_head: 3
	worst: 0.24063334
	avg: 0.25032002
	best: 0.25295

Starting e_i: 868
Model ind 579 epoch 868 head B head_i_epoch 0 batch 0: avg loss -1.918718 avg loss no lamb -1.918718 time 2019-02-07 05:17:44.461971
Model ind 579 epoch 868 head B head_i_epoch 0 batch 100: avg loss -1.907702 avg loss no lamb -1.907702 time 2019-02-07 05:20:42.245751
Model ind 579 epoch 868 head B head_i_epoch 0 batch 200: avg loss -1.793187 avg loss no lamb -1.793187 time 2019-02-07 05:23:43.629949
Model ind 579 epoch 868 head A head_i_epoch 0 batch 0: avg loss -3.531657 avg loss no lamb -3.531657 time 2019-02-07 05:26:43.542019
Model ind 579 epoch 868 head A head_i_epoch 0 batch 100: avg loss -3.613486 avg loss no lamb -3.613486 time 2019-02-07 05:29:45.740171
Model ind 579 epoch 868 head A head_i_epoch 0 batch 200: avg loss -3.603029 avg loss no lamb -3.603029 time 2019-02-07 05:32:45.938783
Pre: time 2019-02-07 05:36:10.266833: 
 	std: 0.004594911
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2514, 0.25153333, 0.24011667, 0.25191668, 0.25153333]
	train_accs: [0.2514, 0.25153333, 0.24011667, 0.25191668, 0.25153333]
	best_train_sub_head: 3
	worst: 0.24011667
	avg: 0.2493
	best: 0.25191668

Starting e_i: 869
Model ind 579 epoch 869 head B head_i_epoch 0 batch 0: avg loss -2.009264 avg loss no lamb -2.009264 time 2019-02-07 05:36:14.405649
Model ind 579 epoch 869 head B head_i_epoch 0 batch 100: avg loss -1.896989 avg loss no lamb -1.896989 time 2019-02-07 05:39:12.892515
Model ind 579 epoch 869 head B head_i_epoch 0 batch 200: avg loss -1.889616 avg loss no lamb -1.889616 time 2019-02-07 05:42:11.423139
Model ind 579 epoch 869 head A head_i_epoch 0 batch 0: avg loss -3.585615 avg loss no lamb -3.585615 time 2019-02-07 05:45:09.366080
Model ind 579 epoch 869 head A head_i_epoch 0 batch 100: avg loss -3.590408 avg loss no lamb -3.590408 time 2019-02-07 05:48:09.144121
Model ind 579 epoch 869 head A head_i_epoch 0 batch 200: avg loss -3.633187 avg loss no lamb -3.633187 time 2019-02-07 05:51:09.664552
Pre: time 2019-02-07 05:54:34.522401: 
 	std: 0.004810185
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25556666, 0.2553, 0.24351667, 0.25585, 0.25541666]
	train_accs: [0.25556666, 0.2553, 0.24351667, 0.25585, 0.25541666]
	best_train_sub_head: 3
	worst: 0.24351667
	avg: 0.25313
	best: 0.25585

Starting e_i: 870
Model ind 579 epoch 870 head B head_i_epoch 0 batch 0: avg loss -1.902907 avg loss no lamb -1.902907 time 2019-02-07 05:54:45.899819
Model ind 579 epoch 870 head B head_i_epoch 0 batch 100: avg loss -1.957039 avg loss no lamb -1.957039 time 2019-02-07 05:57:44.716914
Model ind 579 epoch 870 head B head_i_epoch 0 batch 200: avg loss -1.920339 avg loss no lamb -1.920339 time 2019-02-07 06:00:43.841870
Model ind 579 epoch 870 head A head_i_epoch 0 batch 0: avg loss -3.515474 avg loss no lamb -3.515474 time 2019-02-07 06:03:41.466652
Model ind 579 epoch 870 head A head_i_epoch 0 batch 100: avg loss -3.540833 avg loss no lamb -3.540833 time 2019-02-07 06:06:40.822666
Model ind 579 epoch 870 head A head_i_epoch 0 batch 200: avg loss -3.555540 avg loss no lamb -3.555540 time 2019-02-07 06:09:42.262625
Pre: time 2019-02-07 06:13:06.223677: 
 	std: 0.00450971
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.2535, 0.25403333, 0.2427, 0.25441667, 0.25385]
	train_accs: [0.2535, 0.25403333, 0.2427, 0.25441667, 0.25385]
	best_train_sub_head: 3
	worst: 0.2427
	avg: 0.25169998
	best: 0.25441667

Starting e_i: 871
Model ind 579 epoch 871 head B head_i_epoch 0 batch 0: avg loss -1.969063 avg loss no lamb -1.969063 time 2019-02-07 06:13:17.134069
Model ind 579 epoch 871 head B head_i_epoch 0 batch 100: avg loss -1.871088 avg loss no lamb -1.871088 time 2019-02-07 06:16:12.667315
Model ind 579 epoch 871 head B head_i_epoch 0 batch 200: avg loss -2.021125 avg loss no lamb -2.021125 time 2019-02-07 06:19:08.753921
Model ind 579 epoch 871 head A head_i_epoch 0 batch 0: avg loss -3.531166 avg loss no lamb -3.531166 time 2019-02-07 06:22:04.672164
Model ind 579 epoch 871 head A head_i_epoch 0 batch 100: avg loss -3.607805 avg loss no lamb -3.607805 time 2019-02-07 06:25:03.014372
Model ind 579 epoch 871 head A head_i_epoch 0 batch 200: avg loss -3.613649 avg loss no lamb -3.613649 time 2019-02-07 06:28:03.530678
Pre: time 2019-02-07 06:31:28.616904: 
 	std: 0.0048613832
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25388333, 0.25406668, 0.242, 0.25453332, 0.25408334]
	train_accs: [0.25388333, 0.25406668, 0.242, 0.25453332, 0.25408334]
	best_train_sub_head: 3
	worst: 0.242
	avg: 0.25171334
	best: 0.25453332

Starting e_i: 872
Model ind 579 epoch 872 head B head_i_epoch 0 batch 0: avg loss -1.911113 avg loss no lamb -1.911113 time 2019-02-07 06:31:32.761369
Model ind 579 epoch 872 head B head_i_epoch 0 batch 100: avg loss -1.917650 avg loss no lamb -1.917650 time 2019-02-07 06:34:32.106509
Model ind 579 epoch 872 head B head_i_epoch 0 batch 200: avg loss -1.829842 avg loss no lamb -1.829842 time 2019-02-07 06:37:30.774443
Model ind 579 epoch 872 head A head_i_epoch 0 batch 0: avg loss -3.573247 avg loss no lamb -3.573247 time 2019-02-07 06:40:31.607139
Model ind 579 epoch 872 head A head_i_epoch 0 batch 100: avg loss -3.661484 avg loss no lamb -3.661484 time 2019-02-07 06:43:32.766628
Model ind 579 epoch 872 head A head_i_epoch 0 batch 200: avg loss -3.549417 avg loss no lamb -3.549417 time 2019-02-07 06:46:33.645691
Pre: time 2019-02-07 06:49:59.855307: 
 	std: 0.0045221024
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25138333, 0.2513, 0.2401, 0.25148332, 0.25145]
	train_accs: [0.25138333, 0.2513, 0.2401, 0.25148332, 0.25145]
	best_train_sub_head: 3
	worst: 0.2401
	avg: 0.24914332
	best: 0.25148332

Starting e_i: 873
Model ind 579 epoch 873 head B head_i_epoch 0 batch 0: avg loss -1.905000 avg loss no lamb -1.905000 time 2019-02-07 06:50:04.091954
Model ind 579 epoch 873 head B head_i_epoch 0 batch 100: avg loss -1.996507 avg loss no lamb -1.996507 time 2019-02-07 06:53:04.102854
Model ind 579 epoch 873 head B head_i_epoch 0 batch 200: avg loss -1.885357 avg loss no lamb -1.885357 time 2019-02-07 06:56:02.479713
Model ind 579 epoch 873 head A head_i_epoch 0 batch 0: avg loss -3.545254 avg loss no lamb -3.545254 time 2019-02-07 06:59:00.744850
Model ind 579 epoch 873 head A head_i_epoch 0 batch 100: avg loss -3.594188 avg loss no lamb -3.594188 time 2019-02-07 07:01:59.909130
Model ind 579 epoch 873 head A head_i_epoch 0 batch 200: avg loss -3.597061 avg loss no lamb -3.597061 time 2019-02-07 07:05:00.028422
Pre: time 2019-02-07 07:08:26.497078: 
 	std: 0.0043657813
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25461668, 0.25473332, 0.24376667, 0.25456667, 0.2548]
	train_accs: [0.25461668, 0.25473332, 0.24376667, 0.25456667, 0.2548]
	best_train_sub_head: 4
	worst: 0.24376667
	avg: 0.25249666
	best: 0.2548

Starting e_i: 874
Model ind 579 epoch 874 head B head_i_epoch 0 batch 0: avg loss -1.896786 avg loss no lamb -1.896786 time 2019-02-07 07:08:30.926185
Model ind 579 epoch 874 head B head_i_epoch 0 batch 100: avg loss -1.961394 avg loss no lamb -1.961394 time 2019-02-07 07:11:29.034868
Model ind 579 epoch 874 head B head_i_epoch 0 batch 200: avg loss -1.824507 avg loss no lamb -1.824507 time 2019-02-07 07:14:28.580074
Model ind 579 epoch 874 head A head_i_epoch 0 batch 0: avg loss -3.549706 avg loss no lamb -3.549706 time 2019-02-07 07:17:27.321457
Model ind 579 epoch 874 head A head_i_epoch 0 batch 100: avg loss -3.598583 avg loss no lamb -3.598583 time 2019-02-07 07:20:28.235470
Model ind 579 epoch 874 head A head_i_epoch 0 batch 200: avg loss -3.523920 avg loss no lamb -3.523920 time 2019-02-07 07:23:26.789534
Pre: time 2019-02-07 07:26:51.090632: 
 	std: 0.004395864
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25243333, 0.25245, 0.2413, 0.25246668, 0.25171667]
	train_accs: [0.25243333, 0.25245, 0.2413, 0.25246668, 0.25171667]
	best_train_sub_head: 3
	worst: 0.2413
	avg: 0.25007334
	best: 0.25246668

Starting e_i: 875
Model ind 579 epoch 875 head B head_i_epoch 0 batch 0: avg loss -2.005196 avg loss no lamb -2.005196 time 2019-02-07 07:26:55.285488
Model ind 579 epoch 875 head B head_i_epoch 0 batch 100: avg loss -1.841227 avg loss no lamb -1.841227 time 2019-02-07 07:29:53.875479
Model ind 579 epoch 875 head B head_i_epoch 0 batch 200: avg loss -1.894938 avg loss no lamb -1.894938 time 2019-02-07 07:32:51.492404
Model ind 579 epoch 875 head A head_i_epoch 0 batch 0: avg loss -3.536711 avg loss no lamb -3.536711 time 2019-02-07 07:35:49.768249
Model ind 579 epoch 875 head A head_i_epoch 0 batch 100: avg loss -3.539153 avg loss no lamb -3.539153 time 2019-02-07 07:38:50.183069
Model ind 579 epoch 875 head A head_i_epoch 0 batch 200: avg loss -3.624203 avg loss no lamb -3.624203 time 2019-02-07 07:41:51.146063
Pre: time 2019-02-07 07:45:15.201571: 
 	std: 0.0042078686
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25365, 0.25321665, 0.24295, 0.2536, 0.25338334]
	train_accs: [0.25365, 0.25321665, 0.24295, 0.2536, 0.25338334]
	best_train_sub_head: 0
	worst: 0.24295
	avg: 0.25136003
	best: 0.25365

Starting e_i: 876
Model ind 579 epoch 876 head B head_i_epoch 0 batch 0: avg loss -1.945933 avg loss no lamb -1.945933 time 2019-02-07 07:45:19.425496
Model ind 579 epoch 876 head B head_i_epoch 0 batch 100: avg loss -1.819000 avg loss no lamb -1.819000 time 2019-02-07 07:48:18.300280
Model ind 579 epoch 876 head B head_i_epoch 0 batch 200: avg loss -1.895143 avg loss no lamb -1.895143 time 2019-02-07 07:51:17.456579
Model ind 579 epoch 876 head A head_i_epoch 0 batch 0: avg loss -3.565807 avg loss no lamb -3.565807 time 2019-02-07 07:54:16.908123
Model ind 579 epoch 876 head A head_i_epoch 0 batch 100: avg loss -3.630561 avg loss no lamb -3.630561 time 2019-02-07 07:57:16.803899
Model ind 579 epoch 876 head A head_i_epoch 0 batch 200: avg loss -3.557087 avg loss no lamb -3.557087 time 2019-02-07 08:00:17.127310
Pre: time 2019-02-07 08:03:42.643713: 
 	std: 0.0047537484
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25285, 0.25338334, 0.24125, 0.25326666, 0.253]
	train_accs: [0.25285, 0.25338334, 0.24125, 0.25326666, 0.253]
	best_train_sub_head: 1
	worst: 0.24125
	avg: 0.25075
	best: 0.25338334

Starting e_i: 877
Model ind 579 epoch 877 head B head_i_epoch 0 batch 0: avg loss -1.896511 avg loss no lamb -1.896511 time 2019-02-07 08:03:46.808084
Model ind 579 epoch 877 head B head_i_epoch 0 batch 100: avg loss -1.868528 avg loss no lamb -1.868528 time 2019-02-07 08:06:45.049961
Model ind 579 epoch 877 head B head_i_epoch 0 batch 200: avg loss -1.879729 avg loss no lamb -1.879729 time 2019-02-07 08:09:44.237403
Model ind 579 epoch 877 head A head_i_epoch 0 batch 0: avg loss -3.528655 avg loss no lamb -3.528655 time 2019-02-07 08:12:40.585641
Model ind 579 epoch 877 head A head_i_epoch 0 batch 100: avg loss -3.539365 avg loss no lamb -3.539365 time 2019-02-07 08:15:39.364221
Model ind 579 epoch 877 head A head_i_epoch 0 batch 200: avg loss -3.531540 avg loss no lamb -3.531540 time 2019-02-07 08:18:38.153815
Pre: time 2019-02-07 08:22:01.872554: 
 	std: 0.0048104892
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25405, 0.25378335, 0.2418, 0.2536, 0.25385]
	train_accs: [0.25405, 0.25378335, 0.2418, 0.2536, 0.25385]
	best_train_sub_head: 0
	worst: 0.2418
	avg: 0.25141668
	best: 0.25405

Starting e_i: 878
Model ind 579 epoch 878 head B head_i_epoch 0 batch 0: avg loss -1.936038 avg loss no lamb -1.936038 time 2019-02-07 08:22:05.967584
Model ind 579 epoch 878 head B head_i_epoch 0 batch 100: avg loss -1.814027 avg loss no lamb -1.814027 time 2019-02-07 08:25:02.537054
Model ind 579 epoch 878 head B head_i_epoch 0 batch 200: avg loss -1.890380 avg loss no lamb -1.890380 time 2019-02-07 08:27:59.565528
Model ind 579 epoch 878 head A head_i_epoch 0 batch 0: avg loss -3.520644 avg loss no lamb -3.520644 time 2019-02-07 08:30:57.682811
Model ind 579 epoch 878 head A head_i_epoch 0 batch 100: avg loss -3.551213 avg loss no lamb -3.551213 time 2019-02-07 08:33:58.525227
Model ind 579 epoch 878 head A head_i_epoch 0 batch 200: avg loss -3.573055 avg loss no lamb -3.573055 time 2019-02-07 08:36:57.798803
Pre: time 2019-02-07 08:40:22.131905: 
 	std: 0.004545162
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25518334, 0.25548333, 0.24395, 0.25515, 0.25541666]
	train_accs: [0.25518334, 0.25548333, 0.24395, 0.25515, 0.25541666]
	best_train_sub_head: 1
	worst: 0.24395
	avg: 0.25303668
	best: 0.25548333

Starting e_i: 879
Model ind 579 epoch 879 head B head_i_epoch 0 batch 0: avg loss -1.907643 avg loss no lamb -1.907643 time 2019-02-07 08:40:27.552167
Model ind 579 epoch 879 head B head_i_epoch 0 batch 100: avg loss -1.921868 avg loss no lamb -1.921868 time 2019-02-07 08:43:26.934978
Model ind 579 epoch 879 head B head_i_epoch 0 batch 200: avg loss -1.961933 avg loss no lamb -1.961933 time 2019-02-07 08:46:24.705799
Model ind 579 epoch 879 head A head_i_epoch 0 batch 0: avg loss -3.518616 avg loss no lamb -3.518616 time 2019-02-07 08:49:25.830216
Model ind 579 epoch 879 head A head_i_epoch 0 batch 100: avg loss -3.518791 avg loss no lamb -3.518791 time 2019-02-07 08:52:27.041558
Model ind 579 epoch 879 head A head_i_epoch 0 batch 200: avg loss -3.524528 avg loss no lamb -3.524528 time 2019-02-07 08:55:28.278459
Pre: time 2019-02-07 08:58:53.894587: 
 	std: 0.0046180766
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25286666, 0.25293332, 0.24123333, 0.25266665, 0.25263333]
	train_accs: [0.25286666, 0.25293332, 0.24123333, 0.25266665, 0.25263333]
	best_train_sub_head: 1
	worst: 0.24123333
	avg: 0.25046667
	best: 0.25293332

Starting e_i: 880
Model ind 579 epoch 880 head B head_i_epoch 0 batch 0: avg loss -1.931700 avg loss no lamb -1.931700 time 2019-02-07 08:58:58.032096
Model ind 579 epoch 880 head B head_i_epoch 0 batch 100: avg loss -1.906094 avg loss no lamb -1.906094 time 2019-02-07 09:01:58.157952
Model ind 579 epoch 880 head B head_i_epoch 0 batch 200: avg loss -1.930550 avg loss no lamb -1.930550 time 2019-02-07 09:04:57.033934
Model ind 579 epoch 880 head A head_i_epoch 0 batch 0: avg loss -3.482825 avg loss no lamb -3.482825 time 2019-02-07 09:07:55.911896
Model ind 579 epoch 880 head A head_i_epoch 0 batch 100: avg loss -3.543612 avg loss no lamb -3.543612 time 2019-02-07 09:10:56.894407
Model ind 579 epoch 880 head A head_i_epoch 0 batch 200: avg loss -3.551500 avg loss no lamb -3.551500 time 2019-02-07 09:13:57.302308
Pre: time 2019-02-07 09:17:21.181831: 
 	std: 0.0047125504
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.253, 0.253, 0.24106666, 0.25258332, 0.25278333]
	train_accs: [0.253, 0.253, 0.24106666, 0.25258332, 0.25278333]
	best_train_sub_head: 0
	worst: 0.24106666
	avg: 0.25048667
	best: 0.253

Starting e_i: 881
Model ind 579 epoch 881 head B head_i_epoch 0 batch 0: avg loss -1.969128 avg loss no lamb -1.969128 time 2019-02-07 09:17:32.307946
Model ind 579 epoch 881 head B head_i_epoch 0 batch 100: avg loss -1.927419 avg loss no lamb -1.927419 time 2019-02-07 09:20:29.688067
Model ind 579 epoch 881 head B head_i_epoch 0 batch 200: avg loss -1.912331 avg loss no lamb -1.912331 time 2019-02-07 09:23:28.189495
Model ind 579 epoch 881 head A head_i_epoch 0 batch 0: avg loss -3.579897 avg loss no lamb -3.579897 time 2019-02-07 09:26:27.552486
Model ind 579 epoch 881 head A head_i_epoch 0 batch 100: avg loss -3.591351 avg loss no lamb -3.591351 time 2019-02-07 09:29:27.212688
Model ind 579 epoch 881 head A head_i_epoch 0 batch 200: avg loss -3.554257 avg loss no lamb -3.554257 time 2019-02-07 09:32:28.948918
Pre: time 2019-02-07 09:35:57.905615: 
 	std: 0.004327688
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 13), (11, 7), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25216666, 0.25201666, 0.2412, 0.25173333, 0.25213334]
	train_accs: [0.25216666, 0.25201666, 0.2412, 0.25173333, 0.25213334]
	best_train_sub_head: 0
	worst: 0.2412
	avg: 0.24984999
	best: 0.25216666

Starting e_i: 882
Model ind 579 epoch 882 head B head_i_epoch 0 batch 0: avg loss -1.919683 avg loss no lamb -1.919683 time 2019-02-07 09:36:03.372569
Model ind 579 epoch 882 head B head_i_epoch 0 batch 100: avg loss -1.922544 avg loss no lamb -1.922544 time 2019-02-07 09:39:41.713833
Model ind 579 epoch 882 head B head_i_epoch 0 batch 200: avg loss -1.904877 avg loss no lamb -1.904877 time 2019-02-07 09:43:44.839021
Model ind 579 epoch 882 head A head_i_epoch 0 batch 0: avg loss -3.529196 avg loss no lamb -3.529196 time 2019-02-07 09:48:05.279401
Model ind 579 epoch 882 head A head_i_epoch 0 batch 100: avg loss -3.559533 avg loss no lamb -3.559533 time 2019-02-07 09:52:28.009774
Model ind 579 epoch 882 head A head_i_epoch 0 batch 200: avg loss -3.574462 avg loss no lamb -3.574462 time 2019-02-07 09:56:51.654454
Pre: time 2019-02-07 10:00:18.941128: 
 	std: 0.004056668
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 7), (7, 10), (8, 14), (9, 0), (10, 11), (11, 18), (12, 13), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 5), (19, 12)]
	test_accs: [0.25275, 0.25276667, 0.24256666, 0.25248334, 0.25281668]
	train_accs: [0.25275, 0.25276667, 0.24256666, 0.25248334, 0.25281668]
	best_train_sub_head: 4
	worst: 0.24256666
	avg: 0.25067666
	best: 0.25281668

Starting e_i: 883
Model ind 579 epoch 883 head B head_i_epoch 0 batch 0: avg loss -1.969049 avg loss no lamb -1.969049 time 2019-02-07 10:00:23.194507
Model ind 579 epoch 883 head B head_i_epoch 0 batch 100: avg loss -1.915426 avg loss no lamb -1.915426 time 2019-02-07 10:03:23.265834
Model ind 579 epoch 883 head B head_i_epoch 0 batch 200: avg loss -1.980991 avg loss no lamb -1.980991 time 2019-02-07 10:06:25.406089
Model ind 579 epoch 883 head A head_i_epoch 0 batch 0: avg loss -3.490423 avg loss no lamb -3.490423 time 2019-02-07 10:09:31.164105
Model ind 579 epoch 883 head A head_i_epoch 0 batch 100: avg loss -3.557451 avg loss no lamb -3.557451 time 2019-02-07 10:12:37.259715
Model ind 579 epoch 883 head A head_i_epoch 0 batch 200: avg loss -3.536734 avg loss no lamb -3.536734 time 2019-02-07 10:15:51.118897
Pre: time 2019-02-07 10:20:46.424997: 
 	std: 0.0042938087
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25355, 0.25403333, 0.24316667, 0.25405, 0.25393334]
	train_accs: [0.25355, 0.25403333, 0.24316667, 0.25405, 0.25393334]
	best_train_sub_head: 3
	worst: 0.24316667
	avg: 0.25174665
	best: 0.25405

Starting e_i: 884
Model ind 579 epoch 884 head B head_i_epoch 0 batch 0: avg loss -1.878203 avg loss no lamb -1.878203 time 2019-02-07 10:20:52.183135
Model ind 579 epoch 884 head B head_i_epoch 0 batch 100: avg loss -1.848912 avg loss no lamb -1.848912 time 2019-02-07 10:25:12.414695
Model ind 579 epoch 884 head B head_i_epoch 0 batch 200: avg loss -1.922040 avg loss no lamb -1.922040 time 2019-02-07 10:29:28.882166
Model ind 579 epoch 884 head A head_i_epoch 0 batch 0: avg loss -3.535396 avg loss no lamb -3.535396 time 2019-02-07 10:33:50.641305
Model ind 579 epoch 884 head A head_i_epoch 0 batch 100: avg loss -3.516772 avg loss no lamb -3.516772 time 2019-02-07 10:37:06.914732
Model ind 579 epoch 884 head A head_i_epoch 0 batch 200: avg loss -3.546968 avg loss no lamb -3.546968 time 2019-02-07 10:41:26.223317
Pre: time 2019-02-07 10:45:48.090230: 
 	std: 0.00477251
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25485, 0.25483334, 0.24298333, 0.25508332, 0.25488332]
	train_accs: [0.25485, 0.25483334, 0.24298333, 0.25508332, 0.25488332]
	best_train_sub_head: 3
	worst: 0.24298333
	avg: 0.25252667
	best: 0.25508332

Starting e_i: 885
Model ind 579 epoch 885 head B head_i_epoch 0 batch 0: avg loss -1.948233 avg loss no lamb -1.948233 time 2019-02-07 10:45:52.721334
Model ind 579 epoch 885 head B head_i_epoch 0 batch 100: avg loss -1.972779 avg loss no lamb -1.972779 time 2019-02-07 10:49:10.951678
Model ind 579 epoch 885 head B head_i_epoch 0 batch 200: avg loss -1.915089 avg loss no lamb -1.915089 time 2019-02-07 10:53:38.391285
Model ind 579 epoch 885 head A head_i_epoch 0 batch 0: avg loss -3.520720 avg loss no lamb -3.520720 time 2019-02-07 10:58:09.820594
Model ind 579 epoch 885 head A head_i_epoch 0 batch 100: avg loss -3.545679 avg loss no lamb -3.545679 time 2019-02-07 11:02:46.271080
Model ind 579 epoch 885 head A head_i_epoch 0 batch 200: avg loss -3.597521 avg loss no lamb -3.597521 time 2019-02-07 11:07:23.378307
Pre: time 2019-02-07 11:12:35.322879: 
 	std: 0.004577025
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25431666, 0.25465, 0.24321666, 0.25478333, 0.25485]
	train_accs: [0.25431666, 0.25465, 0.24321666, 0.25478333, 0.25485]
	best_train_sub_head: 4
	worst: 0.24321666
	avg: 0.25236332
	best: 0.25485

Starting e_i: 886
Model ind 579 epoch 886 head B head_i_epoch 0 batch 0: avg loss -1.975950 avg loss no lamb -1.975950 time 2019-02-07 11:12:40.200312
Model ind 579 epoch 886 head B head_i_epoch 0 batch 100: avg loss -1.906811 avg loss no lamb -1.906811 time 2019-02-07 11:17:12.095640
Model ind 579 epoch 886 head B head_i_epoch 0 batch 200: avg loss -1.886185 avg loss no lamb -1.886185 time 2019-02-07 11:21:47.215284
Model ind 579 epoch 886 head A head_i_epoch 0 batch 0: avg loss -3.571702 avg loss no lamb -3.571702 time 2019-02-07 11:26:13.727156
Model ind 579 epoch 886 head A head_i_epoch 0 batch 100: avg loss -3.534387 avg loss no lamb -3.534387 time 2019-02-07 11:30:46.895325
Model ind 579 epoch 886 head A head_i_epoch 0 batch 200: avg loss -3.573457 avg loss no lamb -3.573457 time 2019-02-07 11:35:20.827687
Pre: time 2019-02-07 11:40:40.134468: 
 	std: 0.0044512753
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25201666, 0.25226668, 0.24095, 0.25226668, 0.25171667]
	train_accs: [0.25201666, 0.25226668, 0.24095, 0.25226668, 0.25171667]
	best_train_sub_head: 1
	worst: 0.24095
	avg: 0.24984331
	best: 0.25226668

Starting e_i: 887
Model ind 579 epoch 887 head B head_i_epoch 0 batch 0: avg loss -1.907418 avg loss no lamb -1.907418 time 2019-02-07 11:40:45.394297
Model ind 579 epoch 887 head B head_i_epoch 0 batch 100: avg loss -1.935103 avg loss no lamb -1.935103 time 2019-02-07 11:45:22.648433
Model ind 579 epoch 887 head B head_i_epoch 0 batch 200: avg loss -1.902287 avg loss no lamb -1.902287 time 2019-02-07 11:49:58.811445
Model ind 579 epoch 887 head A head_i_epoch 0 batch 0: avg loss -3.541153 avg loss no lamb -3.541153 time 2019-02-07 11:54:32.604227
Model ind 579 epoch 887 head A head_i_epoch 0 batch 100: avg loss -3.591429 avg loss no lamb -3.591429 time 2019-02-07 11:59:08.443248
Model ind 579 epoch 887 head A head_i_epoch 0 batch 200: avg loss -3.611809 avg loss no lamb -3.611809 time 2019-02-07 12:03:40.663918
Pre: time 2019-02-07 12:08:57.151630: 
 	std: 0.004314478
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25388333, 0.25403333, 0.24313334, 0.254, 0.25375]
	train_accs: [0.25388333, 0.25403333, 0.24313334, 0.254, 0.25375]
	best_train_sub_head: 1
	worst: 0.24313334
	avg: 0.25175998
	best: 0.25403333

Starting e_i: 888
Model ind 579 epoch 888 head B head_i_epoch 0 batch 0: avg loss -1.963400 avg loss no lamb -1.963400 time 2019-02-07 12:09:02.354560
Model ind 579 epoch 888 head B head_i_epoch 0 batch 100: avg loss -1.883897 avg loss no lamb -1.883897 time 2019-02-07 12:13:41.188051
Model ind 579 epoch 888 head B head_i_epoch 0 batch 200: avg loss -1.923751 avg loss no lamb -1.923751 time 2019-02-07 12:18:11.718637
Model ind 579 epoch 888 head A head_i_epoch 0 batch 0: avg loss -3.520423 avg loss no lamb -3.520423 time 2019-02-07 12:22:49.222793
Model ind 579 epoch 888 head A head_i_epoch 0 batch 100: avg loss -3.522214 avg loss no lamb -3.522214 time 2019-02-07 12:27:27.065316
Model ind 579 epoch 888 head A head_i_epoch 0 batch 200: avg loss -3.598646 avg loss no lamb -3.598646 time 2019-02-07 12:32:07.873876
Pre: time 2019-02-07 12:37:25.217750: 
 	std: 0.004368492
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25288334, 0.25291666, 0.24178334, 0.25271666, 0.25223333]
	train_accs: [0.25288334, 0.25291666, 0.24178334, 0.25271666, 0.25223333]
	best_train_sub_head: 1
	worst: 0.24178334
	avg: 0.25050664
	best: 0.25291666

Starting e_i: 889
Model ind 579 epoch 889 head B head_i_epoch 0 batch 0: avg loss -1.990306 avg loss no lamb -1.990306 time 2019-02-07 12:37:30.047061
Model ind 579 epoch 889 head B head_i_epoch 0 batch 100: avg loss -1.854032 avg loss no lamb -1.854032 time 2019-02-07 12:42:02.382378
Model ind 579 epoch 889 head B head_i_epoch 0 batch 200: avg loss -1.782001 avg loss no lamb -1.782001 time 2019-02-07 12:46:39.852826
Model ind 579 epoch 889 head A head_i_epoch 0 batch 0: avg loss -3.611062 avg loss no lamb -3.611062 time 2019-02-07 12:51:18.144076
Model ind 579 epoch 889 head A head_i_epoch 0 batch 100: avg loss -3.546602 avg loss no lamb -3.546602 time 2019-02-07 12:56:01.997389
Model ind 579 epoch 889 head A head_i_epoch 0 batch 200: avg loss -3.516687 avg loss no lamb -3.516687 time 2019-02-07 13:00:42.035045
Pre: time 2019-02-07 13:06:01.479316: 
 	std: 0.004894912
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25185, 0.25245, 0.23988333, 0.25231665, 0.2518]
	train_accs: [0.25185, 0.25245, 0.23988333, 0.25231665, 0.2518]
	best_train_sub_head: 1
	worst: 0.23988333
	avg: 0.24965999
	best: 0.25245

Starting e_i: 890
Model ind 579 epoch 890 head B head_i_epoch 0 batch 0: avg loss -1.841207 avg loss no lamb -1.841207 time 2019-02-07 13:06:06.251994
Model ind 579 epoch 890 head B head_i_epoch 0 batch 100: avg loss -1.948376 avg loss no lamb -1.948376 time 2019-02-07 13:10:43.231113
Model ind 579 epoch 890 head B head_i_epoch 0 batch 200: avg loss -1.899608 avg loss no lamb -1.899608 time 2019-02-07 13:15:13.117547
Model ind 579 epoch 890 head A head_i_epoch 0 batch 0: avg loss -3.543761 avg loss no lamb -3.543761 time 2019-02-07 13:19:53.542697
Model ind 579 epoch 890 head A head_i_epoch 0 batch 100: avg loss -3.473619 avg loss no lamb -3.473619 time 2019-02-07 13:24:34.151432
Model ind 579 epoch 890 head A head_i_epoch 0 batch 200: avg loss -3.525005 avg loss no lamb -3.525005 time 2019-02-07 13:29:16.352089
Pre: time 2019-02-07 13:34:34.702968: 
 	std: 0.004374886
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25365, 0.25431666, 0.24286667, 0.2538, 0.25333333]
	train_accs: [0.25365, 0.25431666, 0.24286667, 0.2538, 0.25333333]
	best_train_sub_head: 1
	worst: 0.24286667
	avg: 0.25159332
	best: 0.25431666

Starting e_i: 891
Model ind 579 epoch 891 head B head_i_epoch 0 batch 0: avg loss -2.022512 avg loss no lamb -2.022512 time 2019-02-07 13:34:51.473663
Model ind 579 epoch 891 head B head_i_epoch 0 batch 100: avg loss -1.994080 avg loss no lamb -1.994080 time 2019-02-07 13:39:31.071336
Model ind 579 epoch 891 head B head_i_epoch 0 batch 200: avg loss -1.951463 avg loss no lamb -1.951463 time 2019-02-07 13:44:01.127354
Model ind 579 epoch 891 head A head_i_epoch 0 batch 0: avg loss -3.596705 avg loss no lamb -3.596705 time 2019-02-07 13:48:39.077334
Model ind 579 epoch 891 head A head_i_epoch 0 batch 100: avg loss -3.572636 avg loss no lamb -3.572636 time 2019-02-07 13:53:20.071274
Model ind 579 epoch 891 head A head_i_epoch 0 batch 200: avg loss -3.612063 avg loss no lamb -3.612063 time 2019-02-07 13:58:01.217111
Pre: time 2019-02-07 14:03:18.677571: 
 	std: 0.004585553
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25291666, 0.25365, 0.24178334, 0.25333333, 0.25301668]
	train_accs: [0.25291666, 0.25365, 0.24178334, 0.25333333, 0.25301668]
	best_train_sub_head: 1
	worst: 0.24178334
	avg: 0.25094
	best: 0.25365

Starting e_i: 892
Model ind 579 epoch 892 head B head_i_epoch 0 batch 0: avg loss -1.882993 avg loss no lamb -1.882993 time 2019-02-07 14:03:23.995897
Model ind 579 epoch 892 head B head_i_epoch 0 batch 100: avg loss -1.838522 avg loss no lamb -1.838522 time 2019-02-07 14:08:02.950392
Model ind 579 epoch 892 head B head_i_epoch 0 batch 200: avg loss -1.922011 avg loss no lamb -1.922011 time 2019-02-07 14:12:40.915933
Model ind 579 epoch 892 head A head_i_epoch 0 batch 0: avg loss -3.590712 avg loss no lamb -3.590712 time 2019-02-07 14:17:18.145083
Model ind 579 epoch 892 head A head_i_epoch 0 batch 100: avg loss -3.566990 avg loss no lamb -3.566990 time 2019-02-07 14:21:59.565300
Model ind 579 epoch 892 head A head_i_epoch 0 batch 200: avg loss -3.549262 avg loss no lamb -3.549262 time 2019-02-07 14:26:40.773216
Pre: time 2019-02-07 14:31:55.063178: 
 	std: 0.00471204
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25338334, 0.25425, 0.24223334, 0.25395, 0.25435]
	train_accs: [0.25338334, 0.25425, 0.24223334, 0.25395, 0.25435]
	best_train_sub_head: 4
	worst: 0.24223334
	avg: 0.25163332
	best: 0.25435

Starting e_i: 893
Model ind 579 epoch 893 head B head_i_epoch 0 batch 0: avg loss -1.875968 avg loss no lamb -1.875968 time 2019-02-07 14:32:00.248925
Model ind 579 epoch 893 head B head_i_epoch 0 batch 100: avg loss -1.937280 avg loss no lamb -1.937280 time 2019-02-07 14:36:39.469525
Model ind 579 epoch 893 head B head_i_epoch 0 batch 200: avg loss -1.938669 avg loss no lamb -1.938669 time 2019-02-07 14:41:16.070179
Model ind 579 epoch 893 head A head_i_epoch 0 batch 0: avg loss -3.569517 avg loss no lamb -3.569517 time 2019-02-07 14:45:54.233641
Model ind 579 epoch 893 head A head_i_epoch 0 batch 100: avg loss -3.587044 avg loss no lamb -3.587044 time 2019-02-07 14:50:35.017725
Model ind 579 epoch 893 head A head_i_epoch 0 batch 200: avg loss -3.579613 avg loss no lamb -3.579613 time 2019-02-07 14:55:16.917804
Pre: time 2019-02-07 15:00:38.056481: 
 	std: 0.004588713
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25395, 0.25458333, 0.24296667, 0.25433335, 0.2548]
	train_accs: [0.25395, 0.25458333, 0.24296667, 0.25433335, 0.2548]
	best_train_sub_head: 4
	worst: 0.24296667
	avg: 0.25212666
	best: 0.2548

Starting e_i: 894
Model ind 579 epoch 894 head B head_i_epoch 0 batch 0: avg loss -1.979259 avg loss no lamb -1.979259 time 2019-02-07 15:00:42.573443
Model ind 579 epoch 894 head B head_i_epoch 0 batch 100: avg loss -1.841621 avg loss no lamb -1.841621 time 2019-02-07 15:05:13.706870
Model ind 579 epoch 894 head B head_i_epoch 0 batch 200: avg loss -1.997933 avg loss no lamb -1.997933 time 2019-02-07 15:09:51.694451
Model ind 579 epoch 894 head A head_i_epoch 0 batch 0: avg loss -3.597481 avg loss no lamb -3.597481 time 2019-02-07 15:14:28.989130
Model ind 579 epoch 894 head A head_i_epoch 0 batch 100: avg loss -3.634455 avg loss no lamb -3.634455 time 2019-02-07 15:19:10.115325
Model ind 579 epoch 894 head A head_i_epoch 0 batch 200: avg loss -3.600306 avg loss no lamb -3.600306 time 2019-02-07 15:23:52.232629
Pre: time 2019-02-07 15:29:10.616573: 
 	std: 0.0046290103
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25291666, 0.25316668, 0.24146667, 0.25303334, 0.25303334]
	train_accs: [0.25291666, 0.25316668, 0.24146667, 0.25303334, 0.25303334]
	best_train_sub_head: 1
	worst: 0.24146667
	avg: 0.25072336
	best: 0.25316668

Starting e_i: 895
Model ind 579 epoch 895 head B head_i_epoch 0 batch 0: avg loss -1.960700 avg loss no lamb -1.960700 time 2019-02-07 15:29:15.147642
Model ind 579 epoch 895 head B head_i_epoch 0 batch 100: avg loss -1.847928 avg loss no lamb -1.847928 time 2019-02-07 15:33:52.810193
Model ind 579 epoch 895 head B head_i_epoch 0 batch 200: avg loss -1.844530 avg loss no lamb -1.844530 time 2019-02-07 15:38:29.715561
Model ind 579 epoch 895 head A head_i_epoch 0 batch 0: avg loss -3.628309 avg loss no lamb -3.628309 time 2019-02-07 15:43:07.609546
Model ind 579 epoch 895 head A head_i_epoch 0 batch 100: avg loss -3.550032 avg loss no lamb -3.550032 time 2019-02-07 15:47:50.346302
Model ind 579 epoch 895 head A head_i_epoch 0 batch 200: avg loss -3.625931 avg loss no lamb -3.625931 time 2019-02-07 15:52:29.707762
Pre: time 2019-02-07 15:57:46.075507: 
 	std: 0.0043218555
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25166667, 0.2517, 0.24086666, 0.25171667, 0.2516]
	train_accs: [0.25166667, 0.2517, 0.24086666, 0.25171667, 0.2516]
	best_train_sub_head: 3
	worst: 0.24086666
	avg: 0.24951
	best: 0.25171667

Starting e_i: 896
Model ind 579 epoch 896 head B head_i_epoch 0 batch 0: avg loss -1.917843 avg loss no lamb -1.917843 time 2019-02-07 15:57:51.456383
Model ind 579 epoch 896 head B head_i_epoch 0 batch 100: avg loss -1.926028 avg loss no lamb -1.926028 time 2019-02-07 16:02:22.290716
Model ind 579 epoch 896 head B head_i_epoch 0 batch 200: avg loss -2.061747 avg loss no lamb -2.061747 time 2019-02-07 16:07:01.973395
Model ind 579 epoch 896 head A head_i_epoch 0 batch 0: avg loss -3.527828 avg loss no lamb -3.527828 time 2019-02-07 16:11:41.365683
Model ind 579 epoch 896 head A head_i_epoch 0 batch 100: avg loss -3.567317 avg loss no lamb -3.567317 time 2019-02-07 16:16:21.864866
Model ind 579 epoch 896 head A head_i_epoch 0 batch 200: avg loss -3.551504 avg loss no lamb -3.551504 time 2019-02-07 16:21:02.499681
Pre: time 2019-02-07 16:26:20.160996: 
 	std: 0.004003792
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25175, 0.252, 0.24196666, 0.25226668, 0.25185]
	train_accs: [0.25175, 0.252, 0.24196666, 0.25226668, 0.25185]
	best_train_sub_head: 3
	worst: 0.24196666
	avg: 0.24996667
	best: 0.25226668

Starting e_i: 897
Model ind 579 epoch 897 head B head_i_epoch 0 batch 0: avg loss -1.867700 avg loss no lamb -1.867700 time 2019-02-07 16:26:25.764556
Model ind 579 epoch 897 head B head_i_epoch 0 batch 100: avg loss -1.907808 avg loss no lamb -1.907808 time 2019-02-07 16:30:55.758297
Model ind 579 epoch 897 head B head_i_epoch 0 batch 200: avg loss -1.912493 avg loss no lamb -1.912493 time 2019-02-07 16:35:32.160751
Model ind 579 epoch 897 head A head_i_epoch 0 batch 0: avg loss -3.547164 avg loss no lamb -3.547164 time 2019-02-07 16:40:09.739327
Model ind 579 epoch 897 head A head_i_epoch 0 batch 100: avg loss -3.556464 avg loss no lamb -3.556464 time 2019-02-07 16:44:49.788335
Model ind 579 epoch 897 head A head_i_epoch 0 batch 200: avg loss -3.609726 avg loss no lamb -3.609726 time 2019-02-07 16:49:29.454275
Pre: time 2019-02-07 16:54:46.836393: 
 	std: 0.0042647608
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25233334, 0.25261667, 0.242, 0.25296667, 0.25268334]
	train_accs: [0.25233334, 0.25261667, 0.242, 0.25296667, 0.25268334]
	best_train_sub_head: 3
	worst: 0.242
	avg: 0.25052
	best: 0.25296667

Starting e_i: 898
Model ind 579 epoch 898 head B head_i_epoch 0 batch 0: avg loss -1.997799 avg loss no lamb -1.997799 time 2019-02-07 16:54:51.572714
Model ind 579 epoch 898 head B head_i_epoch 0 batch 100: avg loss -1.854386 avg loss no lamb -1.854386 time 2019-02-07 16:59:26.596810
Model ind 579 epoch 898 head B head_i_epoch 0 batch 200: avg loss -2.035098 avg loss no lamb -2.035098 time 2019-02-07 17:04:03.724492
Model ind 579 epoch 898 head A head_i_epoch 0 batch 0: avg loss -3.528409 avg loss no lamb -3.528409 time 2019-02-07 17:08:36.933742
Model ind 579 epoch 898 head A head_i_epoch 0 batch 100: avg loss -3.567441 avg loss no lamb -3.567441 time 2019-02-07 17:13:14.993261
Model ind 579 epoch 898 head A head_i_epoch 0 batch 200: avg loss -3.609473 avg loss no lamb -3.609473 time 2019-02-07 17:17:53.408424
Pre: time 2019-02-07 17:23:07.847740: 
 	std: 0.004634236
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25511667, 0.25533333, 0.24378334, 0.2556, 0.2554]
	train_accs: [0.25511667, 0.25533333, 0.24378334, 0.2556, 0.2554]
	best_train_sub_head: 3
	worst: 0.24378334
	avg: 0.25304666
	best: 0.2556

Starting e_i: 899
Model ind 579 epoch 899 head B head_i_epoch 0 batch 0: avg loss -1.964241 avg loss no lamb -1.964241 time 2019-02-07 17:23:13.719354
Model ind 579 epoch 899 head B head_i_epoch 0 batch 100: avg loss -1.861581 avg loss no lamb -1.861581 time 2019-02-07 17:27:51.154792
Model ind 579 epoch 899 head B head_i_epoch 0 batch 200: avg loss -1.956066 avg loss no lamb -1.956066 time 2019-02-07 17:32:31.270050
Model ind 579 epoch 899 head A head_i_epoch 0 batch 0: avg loss -3.551767 avg loss no lamb -3.551767 time 2019-02-07 17:37:08.226060
Model ind 579 epoch 899 head A head_i_epoch 0 batch 100: avg loss -3.595957 avg loss no lamb -3.595957 time 2019-02-07 17:41:48.706675
Model ind 579 epoch 899 head A head_i_epoch 0 batch 200: avg loss -3.595476 avg loss no lamb -3.595476 time 2019-02-07 17:46:30.006322
Pre: time 2019-02-07 17:51:47.975930: 
 	std: 0.0046224846
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25331667, 0.25366667, 0.24198334, 0.25331667, 0.25381666]
	train_accs: [0.25331667, 0.25366667, 0.24198334, 0.25331667, 0.25381666]
	best_train_sub_head: 4
	worst: 0.24198334
	avg: 0.25122
	best: 0.25381666

Starting e_i: 900
Model ind 579 epoch 900 head B head_i_epoch 0 batch 0: avg loss -1.925211 avg loss no lamb -1.925211 time 2019-02-07 17:51:53.323747
Model ind 579 epoch 900 head B head_i_epoch 0 batch 100: avg loss -1.937965 avg loss no lamb -1.937965 time 2019-02-07 17:56:33.199276
Model ind 579 epoch 900 head B head_i_epoch 0 batch 200: avg loss -1.896076 avg loss no lamb -1.896076 time 2019-02-07 18:01:08.828793
Model ind 579 epoch 900 head A head_i_epoch 0 batch 0: avg loss -3.612613 avg loss no lamb -3.612613 time 2019-02-07 18:05:46.624033
Model ind 579 epoch 900 head A head_i_epoch 0 batch 100: avg loss -3.610051 avg loss no lamb -3.610051 time 2019-02-07 18:10:26.347511
Model ind 579 epoch 900 head A head_i_epoch 0 batch 200: avg loss -3.593351 avg loss no lamb -3.593351 time 2019-02-07 18:15:06.136714
Pre: time 2019-02-07 18:20:24.137681: 
 	std: 0.004129604
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25235, 0.25255, 0.24206667, 0.25223333, 0.25241667]
	train_accs: [0.25235, 0.25255, 0.24206667, 0.25223333, 0.25241667]
	best_train_sub_head: 1
	worst: 0.24206667
	avg: 0.25032336
	best: 0.25255

Starting e_i: 901
Model ind 579 epoch 901 head B head_i_epoch 0 batch 0: avg loss -2.030968 avg loss no lamb -2.030968 time 2019-02-07 18:20:36.907207
Model ind 579 epoch 901 head B head_i_epoch 0 batch 100: avg loss -2.015468 avg loss no lamb -2.015468 time 2019-02-07 18:25:14.206559
Model ind 579 epoch 901 head B head_i_epoch 0 batch 200: avg loss -1.951330 avg loss no lamb -1.951330 time 2019-02-07 18:29:51.445704
Model ind 579 epoch 901 head A head_i_epoch 0 batch 0: avg loss -3.561665 avg loss no lamb -3.561665 time 2019-02-07 18:34:28.279875
Model ind 579 epoch 901 head A head_i_epoch 0 batch 100: avg loss -3.566163 avg loss no lamb -3.566163 time 2019-02-07 18:39:08.832749
Model ind 579 epoch 901 head A head_i_epoch 0 batch 200: avg loss -3.631124 avg loss no lamb -3.631124 time 2019-02-07 18:43:49.028717
Pre: time 2019-02-07 18:47:43.843575: 
 	std: 0.004696424
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25266665, 0.25301668, 0.24125, 0.25316668, 0.25308332]
	train_accs: [0.25266665, 0.25301668, 0.24125, 0.25316668, 0.25308332]
	best_train_sub_head: 3
	worst: 0.24125
	avg: 0.25063664
	best: 0.25316668

Starting e_i: 902
Model ind 579 epoch 902 head B head_i_epoch 0 batch 0: avg loss -1.948054 avg loss no lamb -1.948054 time 2019-02-07 18:47:48.295838
Model ind 579 epoch 902 head B head_i_epoch 0 batch 100: avg loss -1.949880 avg loss no lamb -1.949880 time 2019-02-07 18:50:48.656291
Model ind 579 epoch 902 head B head_i_epoch 0 batch 200: avg loss -1.868719 avg loss no lamb -1.868719 time 2019-02-07 18:53:50.563105
Model ind 579 epoch 902 head A head_i_epoch 0 batch 0: avg loss -3.498360 avg loss no lamb -3.498360 time 2019-02-07 18:56:50.149375
Model ind 579 epoch 902 head A head_i_epoch 0 batch 100: avg loss -3.634924 avg loss no lamb -3.634924 time 2019-02-07 18:59:50.898741
Model ind 579 epoch 902 head A head_i_epoch 0 batch 200: avg loss -3.550877 avg loss no lamb -3.550877 time 2019-02-07 19:02:50.765734
Pre: time 2019-02-07 19:06:15.093355: 
 	std: 0.0045936015
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25533333, 0.25548333, 0.24381667, 0.25506666, 0.2553]
	train_accs: [0.25533333, 0.25548333, 0.24381667, 0.25506666, 0.2553]
	best_train_sub_head: 1
	worst: 0.24381667
	avg: 0.25300002
	best: 0.25548333

Starting e_i: 903
Model ind 579 epoch 903 head B head_i_epoch 0 batch 0: avg loss -1.921966 avg loss no lamb -1.921966 time 2019-02-07 19:06:19.180997
Model ind 579 epoch 903 head B head_i_epoch 0 batch 100: avg loss -1.941917 avg loss no lamb -1.941917 time 2019-02-07 19:09:18.042804
Model ind 579 epoch 903 head B head_i_epoch 0 batch 200: avg loss -2.062245 avg loss no lamb -2.062245 time 2019-02-07 19:12:16.317434
Model ind 579 epoch 903 head A head_i_epoch 0 batch 0: avg loss -3.545691 avg loss no lamb -3.545691 time 2019-02-07 19:15:13.437239
Model ind 579 epoch 903 head A head_i_epoch 0 batch 100: avg loss -3.637167 avg loss no lamb -3.637167 time 2019-02-07 19:18:13.744187
Model ind 579 epoch 903 head A head_i_epoch 0 batch 200: avg loss -3.607699 avg loss no lamb -3.607699 time 2019-02-07 19:21:12.822385
Pre: time 2019-02-07 19:24:37.433909: 
 	std: 0.0047068694
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2537, 0.25388333, 0.24196666, 0.2535, 0.25383332]
	train_accs: [0.2537, 0.25388333, 0.24196666, 0.2535, 0.25383332]
	best_train_sub_head: 1
	worst: 0.24196666
	avg: 0.25137666
	best: 0.25388333

Starting e_i: 904
Model ind 579 epoch 904 head B head_i_epoch 0 batch 0: avg loss -1.964933 avg loss no lamb -1.964933 time 2019-02-07 19:24:41.703164
Model ind 579 epoch 904 head B head_i_epoch 0 batch 100: avg loss -1.944847 avg loss no lamb -1.944847 time 2019-02-07 19:27:40.936072
Model ind 579 epoch 904 head B head_i_epoch 0 batch 200: avg loss -1.892492 avg loss no lamb -1.892492 time 2019-02-07 19:30:41.247316
Model ind 579 epoch 904 head A head_i_epoch 0 batch 0: avg loss -3.520594 avg loss no lamb -3.520594 time 2019-02-07 19:33:39.211183
Model ind 579 epoch 904 head A head_i_epoch 0 batch 100: avg loss -3.635909 avg loss no lamb -3.635909 time 2019-02-07 19:36:38.621502
Model ind 579 epoch 904 head A head_i_epoch 0 batch 200: avg loss -3.623505 avg loss no lamb -3.623505 time 2019-02-07 19:39:39.714319
Pre: time 2019-02-07 19:43:04.591059: 
 	std: 0.004463489
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.253, 0.25281668, 0.24186666, 0.25321665, 0.25305]
	train_accs: [0.253, 0.25281668, 0.24186666, 0.25321665, 0.25305]
	best_train_sub_head: 3
	worst: 0.24186666
	avg: 0.25079
	best: 0.25321665

Starting e_i: 905
Model ind 579 epoch 905 head B head_i_epoch 0 batch 0: avg loss -1.958052 avg loss no lamb -1.958052 time 2019-02-07 19:43:08.959881
Model ind 579 epoch 905 head B head_i_epoch 0 batch 100: avg loss -1.955757 avg loss no lamb -1.955757 time 2019-02-07 19:46:07.750462
Model ind 579 epoch 905 head B head_i_epoch 0 batch 200: avg loss -1.998299 avg loss no lamb -1.998299 time 2019-02-07 19:49:07.116140
Model ind 579 epoch 905 head A head_i_epoch 0 batch 0: avg loss -3.548068 avg loss no lamb -3.548068 time 2019-02-07 19:52:06.648277
Model ind 579 epoch 905 head A head_i_epoch 0 batch 100: avg loss -3.584045 avg loss no lamb -3.584045 time 2019-02-07 19:55:07.987236
Model ind 579 epoch 905 head A head_i_epoch 0 batch 200: avg loss -3.671898 avg loss no lamb -3.671898 time 2019-02-07 19:58:08.480248
Pre: time 2019-02-07 20:01:33.724867: 
 	std: 0.004766073
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2554, 0.2546, 0.24318333, 0.25526667, 0.25505]
	train_accs: [0.2554, 0.2546, 0.24318333, 0.25526667, 0.25505]
	best_train_sub_head: 0
	worst: 0.24318333
	avg: 0.2527
	best: 0.2554

Starting e_i: 906
Model ind 579 epoch 906 head B head_i_epoch 0 batch 0: avg loss -1.950088 avg loss no lamb -1.950088 time 2019-02-07 20:01:38.008849
Model ind 579 epoch 906 head B head_i_epoch 0 batch 100: avg loss -1.972721 avg loss no lamb -1.972721 time 2019-02-07 20:04:36.953427
Model ind 579 epoch 906 head B head_i_epoch 0 batch 200: avg loss -1.936420 avg loss no lamb -1.936420 time 2019-02-07 20:07:36.396977
Model ind 579 epoch 906 head A head_i_epoch 0 batch 0: avg loss -3.558841 avg loss no lamb -3.558841 time 2019-02-07 20:10:36.379110
Model ind 579 epoch 906 head A head_i_epoch 0 batch 100: avg loss -3.570085 avg loss no lamb -3.570085 time 2019-02-07 20:13:37.930509
Model ind 579 epoch 906 head A head_i_epoch 0 batch 200: avg loss -3.600878 avg loss no lamb -3.600878 time 2019-02-07 20:16:39.507550
Pre: time 2019-02-07 20:20:06.311150: 
 	std: 0.0043673334
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25286666, 0.25241667, 0.24171667, 0.25261667, 0.25261667]
	train_accs: [0.25286666, 0.25241667, 0.24171667, 0.25261667, 0.25261667]
	best_train_sub_head: 0
	worst: 0.24171667
	avg: 0.25044668
	best: 0.25286666

Starting e_i: 907
Model ind 579 epoch 907 head B head_i_epoch 0 batch 0: avg loss -2.033124 avg loss no lamb -2.033124 time 2019-02-07 20:20:10.609794
Model ind 579 epoch 907 head B head_i_epoch 0 batch 100: avg loss -1.912888 avg loss no lamb -1.912888 time 2019-02-07 20:23:10.607068
Model ind 579 epoch 907 head B head_i_epoch 0 batch 200: avg loss -1.824475 avg loss no lamb -1.824475 time 2019-02-07 20:26:09.901608
Model ind 579 epoch 907 head A head_i_epoch 0 batch 0: avg loss -3.553306 avg loss no lamb -3.553306 time 2019-02-07 20:29:09.733198
Model ind 579 epoch 907 head A head_i_epoch 0 batch 100: avg loss -3.592832 avg loss no lamb -3.592832 time 2019-02-07 20:32:10.613221
Model ind 579 epoch 907 head A head_i_epoch 0 batch 200: avg loss -3.627074 avg loss no lamb -3.627074 time 2019-02-07 20:35:11.742629
Pre: time 2019-02-07 20:38:37.418819: 
 	std: 0.0044461135
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25296667, 0.25291666, 0.242, 0.2532, 0.25335]
	train_accs: [0.25296667, 0.25291666, 0.242, 0.2532, 0.25335]
	best_train_sub_head: 4
	worst: 0.242
	avg: 0.25088668
	best: 0.25335

Starting e_i: 908
Model ind 579 epoch 908 head B head_i_epoch 0 batch 0: avg loss -1.903610 avg loss no lamb -1.903610 time 2019-02-07 20:38:42.489808
Model ind 579 epoch 908 head B head_i_epoch 0 batch 100: avg loss -1.961554 avg loss no lamb -1.961554 time 2019-02-07 20:41:41.606057
Model ind 579 epoch 908 head B head_i_epoch 0 batch 200: avg loss -1.885278 avg loss no lamb -1.885278 time 2019-02-07 20:44:39.211734
Model ind 579 epoch 908 head A head_i_epoch 0 batch 0: avg loss -3.591795 avg loss no lamb -3.591795 time 2019-02-07 20:47:39.142121
Model ind 579 epoch 908 head A head_i_epoch 0 batch 100: avg loss -3.600441 avg loss no lamb -3.600441 time 2019-02-07 20:50:38.923407
Model ind 579 epoch 908 head A head_i_epoch 0 batch 200: avg loss -3.570689 avg loss no lamb -3.570689 time 2019-02-07 20:53:39.430003
Pre: time 2019-02-07 20:57:04.164743: 
 	std: 0.004575682
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25391668, 0.25365, 0.24263333, 0.25438333, 0.25426668]
	train_accs: [0.25391668, 0.25365, 0.24263333, 0.25438333, 0.25426668]
	best_train_sub_head: 3
	worst: 0.24263333
	avg: 0.25177002
	best: 0.25438333

Starting e_i: 909
Model ind 579 epoch 909 head B head_i_epoch 0 batch 0: avg loss -2.032183 avg loss no lamb -2.032183 time 2019-02-07 20:57:08.237388
Model ind 579 epoch 909 head B head_i_epoch 0 batch 100: avg loss -1.862342 avg loss no lamb -1.862342 time 2019-02-07 21:00:07.722544
Model ind 579 epoch 909 head B head_i_epoch 0 batch 200: avg loss -1.854504 avg loss no lamb -1.854504 time 2019-02-07 21:03:04.710473
Model ind 579 epoch 909 head A head_i_epoch 0 batch 0: avg loss -3.577499 avg loss no lamb -3.577499 time 2019-02-07 21:06:03.191108
Model ind 579 epoch 909 head A head_i_epoch 0 batch 100: avg loss -3.548159 avg loss no lamb -3.548159 time 2019-02-07 21:09:03.469384
Model ind 579 epoch 909 head A head_i_epoch 0 batch 200: avg loss -3.580056 avg loss no lamb -3.580056 time 2019-02-07 21:12:03.182304
Pre: time 2019-02-07 21:15:28.727393: 
 	std: 0.0043123937
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25123334, 0.25106665, 0.24051666, 0.2515, 0.25136667]
	train_accs: [0.25123334, 0.25106665, 0.24051666, 0.2515, 0.25136667]
	best_train_sub_head: 3
	worst: 0.24051666
	avg: 0.24913669
	best: 0.2515

Starting e_i: 910
Model ind 579 epoch 910 head B head_i_epoch 0 batch 0: avg loss -1.968566 avg loss no lamb -1.968566 time 2019-02-07 21:15:32.867309
Model ind 579 epoch 910 head B head_i_epoch 0 batch 100: avg loss -1.865704 avg loss no lamb -1.865704 time 2019-02-07 21:18:32.482670
Model ind 579 epoch 910 head B head_i_epoch 0 batch 200: avg loss -1.925770 avg loss no lamb -1.925770 time 2019-02-07 21:21:31.349918
Model ind 579 epoch 910 head A head_i_epoch 0 batch 0: avg loss -3.580927 avg loss no lamb -3.580927 time 2019-02-07 21:24:29.773481
Model ind 579 epoch 910 head A head_i_epoch 0 batch 100: avg loss -3.576286 avg loss no lamb -3.576286 time 2019-02-07 21:27:29.407521
Model ind 579 epoch 910 head A head_i_epoch 0 batch 200: avg loss -3.581877 avg loss no lamb -3.581877 time 2019-02-07 21:30:28.990563
Pre: time 2019-02-07 21:33:52.867919: 
 	std: 0.004505944
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25611666, 0.25628334, 0.24488333, 0.25618333, 0.256]
	train_accs: [0.25611666, 0.25628334, 0.24488333, 0.25618333, 0.256]
	best_train_sub_head: 1
	worst: 0.24488333
	avg: 0.25389332
	best: 0.25628334

Starting e_i: 911
Model ind 579 epoch 911 head B head_i_epoch 0 batch 0: avg loss -2.028058 avg loss no lamb -2.028058 time 2019-02-07 21:34:06.535910
Model ind 579 epoch 911 head B head_i_epoch 0 batch 100: avg loss -1.913955 avg loss no lamb -1.913955 time 2019-02-07 21:37:02.582706
Model ind 579 epoch 911 head B head_i_epoch 0 batch 200: avg loss -1.967617 avg loss no lamb -1.967617 time 2019-02-07 21:39:58.870431
Model ind 579 epoch 911 head A head_i_epoch 0 batch 0: avg loss -3.524216 avg loss no lamb -3.524216 time 2019-02-07 21:42:56.780746
Model ind 579 epoch 911 head A head_i_epoch 0 batch 100: avg loss -3.585445 avg loss no lamb -3.585445 time 2019-02-07 21:45:57.679001
Model ind 579 epoch 911 head A head_i_epoch 0 batch 200: avg loss -3.589514 avg loss no lamb -3.589514 time 2019-02-07 21:48:58.836298
Pre: time 2019-02-07 21:52:24.066555: 
 	std: 0.004701287
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25336668, 0.25345, 0.24175, 0.2537, 0.25348333]
	train_accs: [0.25336668, 0.25345, 0.24175, 0.2537, 0.25348333]
	best_train_sub_head: 3
	worst: 0.24175
	avg: 0.25114998
	best: 0.2537

Starting e_i: 912
Model ind 579 epoch 912 head B head_i_epoch 0 batch 0: avg loss -1.951462 avg loss no lamb -1.951462 time 2019-02-07 21:52:28.160937
Model ind 579 epoch 912 head B head_i_epoch 0 batch 100: avg loss -1.922038 avg loss no lamb -1.922038 time 2019-02-07 21:55:27.915896
Model ind 579 epoch 912 head B head_i_epoch 0 batch 200: avg loss -1.975705 avg loss no lamb -1.975705 time 2019-02-07 21:58:26.366855
Model ind 579 epoch 912 head A head_i_epoch 0 batch 0: avg loss -3.563559 avg loss no lamb -3.563559 time 2019-02-07 22:01:25.249981
Model ind 579 epoch 912 head A head_i_epoch 0 batch 100: avg loss -3.599208 avg loss no lamb -3.599208 time 2019-02-07 22:04:25.241119
Model ind 579 epoch 912 head A head_i_epoch 0 batch 200: avg loss -3.552506 avg loss no lamb -3.552506 time 2019-02-07 22:07:25.007261
Pre: time 2019-02-07 22:10:51.707959: 
 	std: 0.0045447545
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25408334, 0.25453332, 0.24298333, 0.25423333, 0.2545]
	train_accs: [0.25408334, 0.25453332, 0.24298333, 0.25423333, 0.2545]
	best_train_sub_head: 1
	worst: 0.24298333
	avg: 0.25206667
	best: 0.25453332

Starting e_i: 913
Model ind 579 epoch 913 head B head_i_epoch 0 batch 0: avg loss -1.936755 avg loss no lamb -1.936755 time 2019-02-07 22:10:56.828055
Model ind 579 epoch 913 head B head_i_epoch 0 batch 100: avg loss -1.873290 avg loss no lamb -1.873290 time 2019-02-07 22:13:56.521710
Model ind 579 epoch 913 head B head_i_epoch 0 batch 200: avg loss -1.929256 avg loss no lamb -1.929256 time 2019-02-07 22:16:56.205188
Model ind 579 epoch 913 head A head_i_epoch 0 batch 0: avg loss -3.617839 avg loss no lamb -3.617839 time 2019-02-07 22:19:57.773323
Model ind 579 epoch 913 head A head_i_epoch 0 batch 100: avg loss -3.574201 avg loss no lamb -3.574201 time 2019-02-07 22:22:58.185672
Model ind 579 epoch 913 head A head_i_epoch 0 batch 200: avg loss -3.581139 avg loss no lamb -3.581139 time 2019-02-07 22:26:00.255804
Pre: time 2019-02-07 22:29:29.746214: 
 	std: 0.004213144
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25188333, 0.25185, 0.2413, 0.25203332, 0.25153333]
	train_accs: [0.25188333, 0.25185, 0.2413, 0.25203332, 0.25153333]
	best_train_sub_head: 3
	worst: 0.2413
	avg: 0.24972
	best: 0.25203332

Starting e_i: 914
Model ind 579 epoch 914 head B head_i_epoch 0 batch 0: avg loss -1.914268 avg loss no lamb -1.914268 time 2019-02-07 22:29:34.085548
Model ind 579 epoch 914 head B head_i_epoch 0 batch 100: avg loss -1.921012 avg loss no lamb -1.921012 time 2019-02-07 22:32:37.574573
Model ind 579 epoch 914 head B head_i_epoch 0 batch 200: avg loss -1.890757 avg loss no lamb -1.890757 time 2019-02-07 22:35:42.245018
Model ind 579 epoch 914 head A head_i_epoch 0 batch 0: avg loss -3.570184 avg loss no lamb -3.570184 time 2019-02-07 22:38:42.987910
Model ind 579 epoch 914 head A head_i_epoch 0 batch 100: avg loss -3.628155 avg loss no lamb -3.628155 time 2019-02-07 22:41:46.511257
Model ind 579 epoch 914 head A head_i_epoch 0 batch 200: avg loss -3.594262 avg loss no lamb -3.594262 time 2019-02-07 22:44:48.209331
Pre: time 2019-02-07 22:48:15.845111: 
 	std: 0.0039814506
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25341666, 0.25361666, 0.2435, 0.25328332, 0.25348333]
	train_accs: [0.25341666, 0.25361666, 0.2435, 0.25328332, 0.25348333]
	best_train_sub_head: 1
	worst: 0.2435
	avg: 0.25146
	best: 0.25361666

Starting e_i: 915
Model ind 579 epoch 915 head B head_i_epoch 0 batch 0: avg loss -1.952964 avg loss no lamb -1.952964 time 2019-02-07 22:48:20.006679
Model ind 579 epoch 915 head B head_i_epoch 0 batch 100: avg loss -1.931903 avg loss no lamb -1.931903 time 2019-02-07 22:51:21.127468
Model ind 579 epoch 915 head B head_i_epoch 0 batch 200: avg loss -1.893857 avg loss no lamb -1.893857 time 2019-02-07 22:54:21.882496
Model ind 579 epoch 915 head A head_i_epoch 0 batch 0: avg loss -3.581396 avg loss no lamb -3.581396 time 2019-02-07 22:57:22.306682
Model ind 579 epoch 915 head A head_i_epoch 0 batch 100: avg loss -3.584008 avg loss no lamb -3.584008 time 2019-02-07 23:00:23.314174
Model ind 579 epoch 915 head A head_i_epoch 0 batch 200: avg loss -3.547726 avg loss no lamb -3.547726 time 2019-02-07 23:03:24.037907
Pre: time 2019-02-07 23:06:50.047984: 
 	std: 0.0046273116
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.2535, 0.2539, 0.24216667, 0.25365, 0.25386667]
	train_accs: [0.2535, 0.2539, 0.24216667, 0.25365, 0.25386667]
	best_train_sub_head: 1
	worst: 0.24216667
	avg: 0.25141668
	best: 0.2539

Starting e_i: 916
Model ind 579 epoch 916 head B head_i_epoch 0 batch 0: avg loss -1.945987 avg loss no lamb -1.945987 time 2019-02-07 23:06:54.364057
Model ind 579 epoch 916 head B head_i_epoch 0 batch 100: avg loss -1.954872 avg loss no lamb -1.954872 time 2019-02-07 23:09:51.134546
Model ind 579 epoch 916 head B head_i_epoch 0 batch 200: avg loss -1.867448 avg loss no lamb -1.867448 time 2019-02-07 23:12:48.006319
Model ind 579 epoch 916 head A head_i_epoch 0 batch 0: avg loss -3.516713 avg loss no lamb -3.516713 time 2019-02-07 23:15:45.755235
Model ind 579 epoch 916 head A head_i_epoch 0 batch 100: avg loss -3.649004 avg loss no lamb -3.649004 time 2019-02-07 23:18:42.645379
Model ind 579 epoch 916 head A head_i_epoch 0 batch 200: avg loss -3.659294 avg loss no lamb -3.659294 time 2019-02-07 23:21:40.522285
Pre: time 2019-02-07 23:25:01.856983: 
 	std: 0.0045478465
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25358334, 0.25368333, 0.24251667, 0.25395, 0.25426668]
	train_accs: [0.25358334, 0.25368333, 0.24251667, 0.25395, 0.25426668]
	best_train_sub_head: 4
	worst: 0.24251667
	avg: 0.25159997
	best: 0.25426668

Starting e_i: 917
Model ind 579 epoch 917 head B head_i_epoch 0 batch 0: avg loss -1.925155 avg loss no lamb -1.925155 time 2019-02-07 23:25:05.901702
Model ind 579 epoch 917 head B head_i_epoch 0 batch 100: avg loss -1.920393 avg loss no lamb -1.920393 time 2019-02-07 23:28:03.402204
Model ind 579 epoch 917 head B head_i_epoch 0 batch 200: avg loss -1.865927 avg loss no lamb -1.865927 time 2019-02-07 23:31:01.587485
Model ind 579 epoch 917 head A head_i_epoch 0 batch 0: avg loss -3.585233 avg loss no lamb -3.585233 time 2019-02-07 23:34:00.140589
Model ind 579 epoch 917 head A head_i_epoch 0 batch 100: avg loss -3.552610 avg loss no lamb -3.552610 time 2019-02-07 23:36:59.118916
Model ind 579 epoch 917 head A head_i_epoch 0 batch 200: avg loss -3.593309 avg loss no lamb -3.593309 time 2019-02-07 23:39:58.702822
Pre: time 2019-02-07 23:43:22.658534: 
 	std: 0.0047620866
	best_train_sub_head_match: [(0, 4), (1, 2), (2, 8), (3, 9), (4, 16), (5, 17), (6, 13), (7, 10), (8, 14), (9, 5), (10, 11), (11, 18), (12, 0), (13, 19), (14, 1), (15, 15), (16, 6), (17, 3), (18, 7), (19, 12)]
	test_accs: [0.25565, 0.25591666, 0.24403334, 0.2558, 0.25633332]
	train_accs: [0.25565, 0.25591666, 0.24403334, 0.2558, 0.25633332]
	best_train_sub_head: 4
	worst: 0.24403334
	avg: 0.25354666
	best: 0.25633332

Starting e_i: 918
Model ind 579 epoch 918 head B head_i_epoch 0 batch 0: avg loss -2.008442 avg loss no lamb -2.008442 time 2019-02-07 23:43:31.144337
Model ind 579 epoch 918 head B head_i_epoch 0 batch 100: avg loss -1.881680 avg loss no lamb -1.881680 time 2019-02-07 23:46:27.909104
Model ind 579 epoch 918 head B head_i_epoch 0 batch 200: avg loss -1.859154 avg loss no lamb -1.859154 time 2019-02-07 23:49:25.882867
Model ind 579 epoch 918 head A head_i_epoch 0 batch 0: avg loss -3.554827 avg loss no lamb -3.554827 time 2019-02-07 23:52:24.283743
Model ind 579 epoch 918 head A head_i_epoch 0 batch 100: avg loss -3.601215 avg loss no lamb -3.601215 time 2019-02-07 23:55:25.824034
Model ind 579 epoch 918 head A head_i_epoch 0 batch 200: avg loss -3.609162 avg loss no lamb -3.609162 time 2019-02-07 23:58:26.283966
Pre: time 2019-02-08 00:01:52.221393: 
 	std: 0.004775187
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25395, 0.25388333, 0.24201667, 0.25401667, 0.25396666]
	train_accs: [0.25395, 0.25388333, 0.24201667, 0.25401667, 0.25396666]
	best_train_sub_head: 3
	worst: 0.24201667
	avg: 0.25156668
	best: 0.25401667

Starting e_i: 919
Model ind 579 epoch 919 head B head_i_epoch 0 batch 0: avg loss -1.866445 avg loss no lamb -1.866445 time 2019-02-08 00:01:56.740861
Model ind 579 epoch 919 head B head_i_epoch 0 batch 100: avg loss -1.925066 avg loss no lamb -1.925066 time 2019-02-08 00:04:55.561380
Model ind 579 epoch 919 head B head_i_epoch 0 batch 200: avg loss -1.906198 avg loss no lamb -1.906198 time 2019-02-08 00:07:53.437857
Model ind 579 epoch 919 head A head_i_epoch 0 batch 0: avg loss -3.531044 avg loss no lamb -3.531044 time 2019-02-08 00:10:53.208544
Model ind 579 epoch 919 head A head_i_epoch 0 batch 100: avg loss -3.562009 avg loss no lamb -3.562009 time 2019-02-08 00:13:54.424325
Model ind 579 epoch 919 head A head_i_epoch 0 batch 200: avg loss -3.586932 avg loss no lamb -3.586932 time 2019-02-08 00:16:53.753081
Pre: time 2019-02-08 00:20:20.073236: 
 	std: 0.0045601823
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.2537, 0.25358334, 0.24225, 0.25363332, 0.25368333]
	train_accs: [0.2537, 0.25358334, 0.24225, 0.25363332, 0.25368333]
	best_train_sub_head: 0
	worst: 0.24225
	avg: 0.25137
	best: 0.2537

Starting e_i: 920
Model ind 579 epoch 920 head B head_i_epoch 0 batch 0: avg loss -2.001832 avg loss no lamb -2.001832 time 2019-02-08 00:20:24.138093
Model ind 579 epoch 920 head B head_i_epoch 0 batch 100: avg loss -1.971046 avg loss no lamb -1.971046 time 2019-02-08 00:23:23.693071
Model ind 579 epoch 920 head B head_i_epoch 0 batch 200: avg loss -1.881913 avg loss no lamb -1.881913 time 2019-02-08 00:26:22.677729
Model ind 579 epoch 920 head A head_i_epoch 0 batch 0: avg loss -3.538684 avg loss no lamb -3.538684 time 2019-02-08 00:29:22.011188
Model ind 579 epoch 920 head A head_i_epoch 0 batch 100: avg loss -3.635558 avg loss no lamb -3.635558 time 2019-02-08 00:32:23.365820
Model ind 579 epoch 920 head A head_i_epoch 0 batch 200: avg loss -3.537671 avg loss no lamb -3.537671 time 2019-02-08 00:35:25.144008
Pre: time 2019-02-08 00:38:51.783923: 
 	std: 0.0047652647
	best_train_sub_head_match: [(0, 9), (1, 2), (2, 5), (3, 15), (4, 4), (5, 7), (6, 13), (7, 11), (8, 3), (9, 16), (10, 8), (11, 17), (12, 18), (13, 1), (14, 0), (15, 12), (16, 10), (17, 14), (18, 6), (19, 19)]
	test_accs: [0.25378335, 0.25391668, 0.24193333, 0.25388333, 0.2538]
	train_accs: [0.25378335, 0.25391668, 0.24193333, 0.25388333, 0.2538]
	best_train_sub_head: 1
	worst: 0.24193333
	avg: 0.25146335
	best: 0.25391668

Starting e_i: 921
Model ind 579 epoch 921 head B head_i_epoch 0 batch 0: avg loss -2.004707 avg loss no lamb -2.004707 time 2019-02-08 00:39:01.083062
Model ind 579 epoch 921 head B head_i_epoch 0 batch 100: avg loss -1.945276 avg loss no lamb -1.945276 time 2019-02-08 00:42:01.307595
Model ind 579 epoch 921 head B head_i_epoch 0 batch 200: avg loss -1.966888 avg loss no lamb -1.966888 time 2019-02-08 00:44:59.685903
Model ind 579 epoch 921 head A head_i_epoch 0 batch 0: avg loss -3.593402 avg loss no lamb -3.593402 time 2019-02-08 00:47:57.861536
Model ind 579 epoch 921 head A head_i_epoch 0 batch 100: avg loss -3.580962 avg loss no lamb -3.580962 time 2019-02-08 00:50:58.145922
Model ind 579 epoch 921 head A head_i_epoch 0 batch 200: avg loss -3.536255 avg loss no lamb -3.536255 time 2019-02-08 00:53:56.455268
Pre: time 2019-02-08 00:57:20.730947: 
 	std: 0.0041687945
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25228333, 0.25208333, 0.24155, 0.25178334, 0.25168332]
	train_accs: [0.25228333, 0.25208333, 0.24155, 0.25178334, 0.25168332]
	best_train_sub_head: 0
	worst: 0.24155
	avg: 0.24987666
	best: 0.25228333

Starting e_i: 922
Model ind 579 epoch 922 head B head_i_epoch 0 batch 0: avg loss -1.930998 avg loss no lamb -1.930998 time 2019-02-08 00:57:24.966257
Model ind 579 epoch 922 head B head_i_epoch 0 batch 100: avg loss -1.795898 avg loss no lamb -1.795898 time 2019-02-08 01:00:23.295822
Model ind 579 epoch 922 head B head_i_epoch 0 batch 200: avg loss -1.957197 avg loss no lamb -1.957197 time 2019-02-08 01:03:22.442787
Model ind 579 epoch 922 head A head_i_epoch 0 batch 0: avg loss -3.516689 avg loss no lamb -3.516689 time 2019-02-08 01:06:22.102266
Model ind 579 epoch 922 head A head_i_epoch 0 batch 100: avg loss -3.550896 avg loss no lamb -3.550896 time 2019-02-08 01:09:22.382059
Model ind 579 epoch 922 head A head_i_epoch 0 batch 200: avg loss -3.641578 avg loss no lamb -3.641578 time 2019-02-08 01:12:20.332552
Pre: time 2019-02-08 01:15:43.417210: 
 	std: 0.0043707397
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25296667, 0.25293332, 0.24213333, 0.25333333, 0.25298333]
	train_accs: [0.25296667, 0.25293332, 0.24213333, 0.25333333, 0.25298333]
	best_train_sub_head: 3
	worst: 0.24213333
	avg: 0.25087
	best: 0.25333333

Starting e_i: 923
Model ind 579 epoch 923 head B head_i_epoch 0 batch 0: avg loss -1.895708 avg loss no lamb -1.895708 time 2019-02-08 01:15:47.496062
Model ind 579 epoch 923 head B head_i_epoch 0 batch 100: avg loss -1.981173 avg loss no lamb -1.981173 time 2019-02-08 01:18:44.210338
Model ind 579 epoch 923 head B head_i_epoch 0 batch 200: avg loss -1.930023 avg loss no lamb -1.930023 time 2019-02-08 01:21:42.034973
Model ind 579 epoch 923 head A head_i_epoch 0 batch 0: avg loss -3.564284 avg loss no lamb -3.564284 time 2019-02-08 01:24:38.528102
Model ind 579 epoch 923 head A head_i_epoch 0 batch 100: avg loss -3.511621 avg loss no lamb -3.511621 time 2019-02-08 01:27:38.299816
Model ind 579 epoch 923 head A head_i_epoch 0 batch 200: avg loss -3.606566 avg loss no lamb -3.606566 time 2019-02-08 01:30:37.625006
Pre: time 2019-02-08 01:34:00.247124: 
 	std: 0.004622897
	best_train_sub_head_match: [(0, 18), (1, 0), (2, 14), (3, 5), (4, 16), (5, 4), (6, 12), (7, 6), (8, 8), (9, 10), (10, 7), (11, 13), (12, 19), (13, 9), (14, 15), (15, 2), (16, 3), (17, 17), (18, 1), (19, 11)]
	test_accs: [0.25518334, 0.25493333, 0.24346666, 0.25488332, 0.25508332]
	train_accs: [0.25518334, 0.25493333, 0.24346666, 0.25488332, 0.25508332]
	best_train_sub_head: 0
	worst: 0.24346666
	avg: 0.25271
	best: 0.25518334

Starting e_i: 924
Model ind 579 epoch 924 head B head_i_epoch 0 batch 0: avg loss -1.899175 avg loss no lamb -1.899175 time 2019-02-08 01:34:04.471839
Model ind 579 epoch 924 head B head_i_epoch 0 batch 100: avg loss -1.936255 avg loss no lamb -1.936255 time 2019-02-08 01:37:01.770757
Model ind 579 epoch 924 head B head_i_epoch 0 batch 200: avg loss -1.873766 avg loss no lamb -1.873766 time 2019-02-08 01:40:00.619934
Model ind 579 epoch 924 head A head_i_epoch 0 batch 0: avg loss -3.524166 avg loss no lamb -3.524166 time 2019-02-08 01:42:59.537015
Model ind 579 epoch 924 head A head_i_epoch 0 batch 100: avg loss -3.579800 avg loss no lamb -3.579800 time 2019-02-08 01:45:58.779546
Model ind 579 epoch 924 head A head_i_epoch 0 batch 200: avg loss -3.635545 avg loss no lamb -3.635545 time 2019-02-08 01:49:00.481585
Pre: time 2019-02-08 01:52:24.090278: 
 	std: 0.0042857486
	best_train_sub_head_match: [(0, 15), (1, 5), (2, 2), (3, 7), (4, 4), (5, 3), (6, 18), (7, 13), (8, 6), (9, 14), (10, 9), (11, 8), (12, 16), (13, 11), (14, 10), (15, 1), (16, 12), (17, 17), (18, 0), (19, 19)]
	test_accs: [0.25515, 0.25473332, 0.24446666, 0.25551668, 0.25525]
	train_accs: [0.25515, 0.25473332, 0.24446666, 0.25551668, 0.25525]
	best_train_sub_head: 3
	worst: 0.24446666
	avg: 0.25302333
	best: 0.25551668

Starting e_i: 925
Model ind 579 epoch 925 head B head_i_epoch 0 batch 0: avg loss -1.936067 avg loss no lamb -1.936067 time 2019-02-08 01:52:28.394184
Model ind 579 epoch 925 head B head_i_epoch 0 batch 100: avg loss -1.945986 avg loss no lamb -1.945986 time 2019-02-08 01:55:26.976448
Model ind 579 epoch 925 head B head_i_epoch 0 batch 200: avg loss -1.941894 avg loss no lamb -1.941894 time 2019-02-08 01:58:25.818558
Model ind 579 epoch 925 head A head_i_epoch 0 batch 0: avg loss -3.513630 avg loss no lamb -3.513630 time 2019-02-08 02:01:23.942046
Model ind 579 epoch 925 head A head_i_epoch 0 batch 100: avg loss -3.545265 avg loss no lamb -3.545265 time 2019-02-08 02:04:22.645945
Model ind 579 epoch 925 head A head_i_epoch 0 batch 200: avg loss -3.606923 avg loss no lamb -3.606923 time 2019-02-08 02:07:21.414197
